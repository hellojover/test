# EdgeDB Documentation

## Release 0.5.

## magicstack

#### May 19, 2023



## CONTENTS


















- 1 Get Started
   - 1.1 Quickstart
      - 1.1.1 1. Installation
      - 1.1.2 2. Initialize a project
      - 1.1.3 3. Set up your schema
      - 1.1.4 4. Run a migration
      - 1.1.5 5. Write some queries
      - 1.1.6 Onwards and upwards
   - 1.2 The CLI
      - 1.2.1 Installation
      - 1.2.2 Seehelpcommands
      - 1.2.3 Upgrade the CLI
   - 1.3 Instances
      - 1.3.1 Creating databases
      - 1.3.2 Managing instances
      - 1.3.3 Listing instances
      - 1.3.4 Further reference
   - 1.4 Projects
      - 1.4.1 Initializing
      - 1.4.2 Connection
      - 1.4.3 Using remote instances
      - 1.4.4 Unlinking
      - 1.4.5 Upgrading
      - 1.4.6 See info
   - 1.5 Schema
      - 1.5.1 Scalar types
      - 1.5.2 Object types
      - 1.5.3 Properties
         - 1.5.3.1 Required vs optional
         - 1.5.3.2 Constraints
         - 1.5.3.3 Computed properties
      - 1.5.4 Links
         - 1.5.4.1 Computed links
         - 1.5.4.2 Backlinks
      - 1.5.5 Constraints
      - 1.5.6 Indexes
      - 1.5.7 Schema mixins
      - 1.5.8 Polymorphism
   - 1.6 Migrations
      - 1.6.1 1. Write an initial schema
      - 1.6.2 2. Edit your schema files
      - 1.6.3 3. Generate a migration
      - 1.6.4 4. Apply the migration
      - 1.6.5 Data migrations
         - 1.6.5.1 Further reading
   - 1.7 EdgeQL
      - 1.7.1 Scalar literals
      - 1.7.2 Functions and operators
      - 1.7.3 Insert an object
      - 1.7.4 Nested inserts
      - 1.7.5 Select objects
      - 1.7.6 Filtering, ordering, and pagination
      - 1.7.7 Query composition
      - 1.7.8 Computed properties
      - 1.7.9 Update objects
      - 1.7.10 Delete objects
      - 1.7.11 Query parameters
      - 1.7.12 Subqueries
      - 1.7.13 Polymorphic queries
      - 1.7.14 Grouping objects
   - 1.8 Client Libraries
      - 1.8.1 Available libraries
      - 1.8.2 Usage
      - 1.8.3 Connection
         - 1.8.3.1 Using projects
         - 1.8.3.2 UsingEDGEDB_DSN
         - 1.8.3.3 Using multiple environment variables
         - 1.8.3.4 Other mechanisms
         - 1.8.3.5 Reference
   - 1.9 How to read the docs
   - 1.10 Tooling
- 2 Schema
   - 2.1 Primitives
      - 2.1.1 Scalar types
      - 2.1.2 Enums
      - 2.1.3 Arrays
      - 2.1.4 Tuples
      - 2.1.5 Ranges
      - 2.1.6 Sequences
   - 2.2 Object Types
      - 2.2.1 IDs
      - 2.2.2 Abstract types
      - 2.2.3 Inheritance
         - 2.2.3.1 Multiple Inheritance
   - 2.3 Properties
      - 2.3.1 Required properties
      - 2.3.2 Property cardinality
      - 2.3.3 Default values
      - 2.3.4 Readonly properties
      - 2.3.5 Constraints
      - 2.3.6 Annotations
      - 2.3.7 Abstract properties
      - 2.3.8 Link properties
- 2.4 Links
   - 2.4.1 Defining links
   - 2.4.2 Link cardinality
   - 2.4.3 Required links
   - 2.4.4 Exclusive constraints
   - 2.4.5 Modeling relations
      - 2.4.5.1 Many-to-one
      - 2.4.5.2 One-to-many
      - 2.4.5.3 One-to-one
      - 2.4.5.4 Many-to-many
   - 2.4.6 Default values
   - 2.4.7 Link properties
   - 2.4.8 Deletion policies
      - 2.4.8.1 Target deletion
      - 2.4.8.2 Source deletion
   - 2.4.9 Polymorphic links
   - 2.4.10 Abstract links
- 2.5 Computeds
   - 2.5.1 Leading dot notation
   - 2.5.2 Type and cardinality inference
   - 2.5.3 Common use cases
      - 2.5.3.1 Filtering
      - 2.5.3.2 Backlinks
      - 2.5.3.3 Created Timestamp
- 2.6 Indexes
   - 2.6.1 Index on a property
   - 2.6.2 Index on an expression
   - 2.6.3 Index on multiple properties
   - 2.6.4 Index on a link property
   - 2.6.5 Specify a Postgres index type
   - 2.6.6 Annotate an index
- 2.7 Constraints
   - 2.7.1 Constraints on properties
      - 2.7.1.1 Custom constraints
   - 2.7.2 Constraints on object types
      - 2.7.2.1 Computed constraints
      - 2.7.2.2 Composite constraints
      - 2.7.2.3 Partial constraints
   - 2.7.3 Constraints on links
   - 2.7.4 Constraints on custom scalars
- 2.8 Aliases
- 2.9 Annotations
   - 2.9.1 Standard annotations
   - 2.9.2 User-defined annotations
- 2.10 Globals
   - 2.10.1 Setting global variables
      - 2.10.1.1 Cardinality
      - 2.10.1.2 Computed globals
      - 2.10.1.3 Usage in schema
- 2.11 Access Policies
   - 2.11.1 Defining a global
   - 2.11.2 Defining a policy
   - 2.11.3 Policy types
   - 2.11.4 Resolution order
      - 2.11.5 Custom error messages
      - 2.11.6 Disabling policies
      - 2.11.7 Examples
         - 2.11.7.1 Super constraints
   - 2.12 Functions
      - 2.12.1 User-defined Functions
   - 2.13 Triggers
   - 2.14 Mutation rewrites
      - 2.14.1 Available variables
      - 2.14.2 Mutation rewrite as cached computed
   - 2.15 Inheritance
      - 2.15.1 Object types
         - 2.15.1.1 Multiple Inheritance
         - 2.15.1.2 Overloading
      - 2.15.2 Properties
      - 2.15.3 Links
      - 2.15.4 Constraints
      - 2.15.5 Annotations
   - 2.16 Extensions
   - 2.17 Future Behavior
   - 2.18 vs SQL and ORMs
      - 2.18.1 Comparison to SQL
      - 2.18.2 Comparison to ORMs
   - 2.19 Introspection
      - 2.19.1 Object types
      - 2.19.2 Scalar types
      - 2.19.3 Collection types
         - 2.19.3.1 Array
         - 2.19.3.2 Tuple
      - 2.19.4 Functions
      - 2.19.5 Triggers
      - 2.19.6 Mutation rewrites
      - 2.19.7 Indexes
      - 2.19.8 Constraints
      - 2.19.9 Operators
      - 2.19.10 Casts
   - 2.20 SDL
   - 2.21 Migrations
   - 2.22 Terminology
- 3 EdgeQL
   - 3.1 Literals
      - 3.1.1 Strings
      - 3.1.2 Booleans
      - 3.1.3 Numbers
      - 3.1.4 UUID
      - 3.1.5 Enums
      - 3.1.6 Dates and times
      - 3.1.7 Durations
         - 3.1.7.1 Exact durations
         - 3.1.7.2 Relative durations
         - 3.1.7.3 Date durations
      - 3.1.8 Ranges
      - 3.1.9 Bytes
   - 3.1.10 Arrays
   - 3.1.11 Tuples
      - 3.1.11.1 Indexing tuples
   - 3.1.12 JSON
- 3.2 Sets
   - 3.2.1 Everything is a set
   - 3.2.2 Constructing sets
   - 3.2.3 Literals are singletons
   - 3.2.4 Empty sets
   - 3.2.5 Set references
   - 3.2.6 Multisets
   - 3.2.7 Checking membership
   - 3.2.8 Merging sets
   - 3.2.9 Finding common members
   - 3.2.10 Removing common members
   - 3.2.11 Coalescing
   - 3.2.12 Inheritance
   - 3.2.13 Aggregate vs element-wise operations
   - 3.2.14 Conversion to/from arrays
   - 3.2.15 Reference
- 3.3 Paths
   - 3.3.1 Backlinks
   - 3.3.2 Link properties
   - 3.3.3 Path roots
- 3.4 Types
   - 3.4.1 Type expressions
   - 3.4.2 Type casting
   - 3.4.3 Type intersections
   - 3.4.4 Type checking
   - 3.4.5 Thetypeofoperator
   - 3.4.6 Introspection
- 3.5 Parameters
   - 3.5.1 Usage with clients
      - 3.5.1.1 REPL
      - 3.5.1.2 Python
      - 3.5.1.3 JavaScript
      - 3.5.1.4 Go
   - 3.5.2 Parameter types and JSON
   - 3.5.3 Optional parameters
   - 3.5.4 What can be parameterized?
- 3.6 Select
   - 3.6.1 Selecting objects
   - 3.6.2 Shapes
      - 3.6.2.1 Nested shapes
      - 3.6.2.2 Splats
   - 3.6.3 Filtering
      - 3.6.3.1 Filtering by ID
      - 3.6.3.2 Nested filters
   - 3.6.4 Ordering
   - 3.6.5 Pagination
   - 3.6.6 Computed fields
   - 3.6.7 Backlinks
   - 3.6.8 Subqueries
   - 3.6.9 Polymorphic queries
         - 3.6.9.1 Polymorphic sets
         - 3.6.9.2 Polymorphic fields
         - 3.6.9.3 Filtering polymorphic links
      - 3.6.10 Free objects
      - 3.6.11 With block
   - 3.7 Insert
      - 3.7.1 Basic usage
      - 3.7.2 Inserting links
      - 3.7.3 Nested inserts
      - 3.7.4 With block
      - 3.7.5 Conflicts
         - 3.7.5.1 Upserts
         - 3.7.5.2 Suppressing failures
      - 3.7.6 Bulk inserts
   - 3.8 Update
      - 3.8.1 Syntax
         - 3.8.1.1 Updating links
         - 3.8.1.2 With blocks
         - 3.8.1.3 See also
   - 3.9 Delete
      - 3.9.1 Clauses
      - 3.9.2 Link deletion
         - 3.9.2.1 Cascading deletes
      - 3.9.3 Return value
   - 3.10 For
      - 3.10.1 Bulk inserts
   - 3.11 Group
   - 3.12 With
      - 3.12.1 Subqueries
      - 3.12.2 Query parameters
      - 3.12.3 Module selection
   - 3.13 Path resolution
      - 3.13.1 Scopes
         - 3.13.1.1 Clauses & Nesting
   - 3.14 Transactions
      - 3.14.1 Client libraries
         - 3.14.1.1 TypeScript/JS
         - 3.14.1.2 Python
         - 3.14.1.3 Golang
   - 3.15 Design goals
   - 3.16 Follow along
- 4 Guides
   - 4.1 Tutorials
      - 4.1.1 Next.js
         - 4.1.1.1 Updating the homepage
         - 4.1.1.2 Initializing EdgeDB
         - 4.1.1.3 Loading posts with an API route
         - 4.1.1.4 Generating the query builder
         - 4.1.1.5 Rendering blog posts
         - 4.1.1.6 Deploying to Vercel
         - 4.1.1.7 Wrapping up
      - 4.1.2 FastAPI
         - 4.1.2.1 Prerequisites
         - 4.1.2.1.1 Create a project directory
         - 4.1.2.1.2 Install the dependencies
         - 4.1.2.1.3 Initialize the database
         - 4.1.2.1.4 Connect to the database
      - 4.1.2.2 Schema design
      - 4.1.2.3 Run a migration
      - 4.1.2.4 Build the API endpoints
         - 4.1.2.4.1 Users API
         - 4.1.2.4.2 Events API
         - 4.1.2.4.3 Browse the endpoints using the native OpenAPI doc
      - 4.1.2.5 Wrapping up
   - 4.1.3 Flask
      - 4.1.3.1 Prerequisites
         - 4.1.3.1.1 Install the dependencies
         - 4.1.3.1.2 Initialize the database
         - 4.1.3.1.3 Connect to the database
      - 4.1.3.2 Schema design
      - 4.1.3.3 Build the API endpoints
         - 4.1.3.3.1 Fetch actors
         - 4.1.3.3.2 Create actor
         - 4.1.3.3.3 Update actor
         - 4.1.3.3.4 Delete actor
         - 4.1.3.3.5 Create movie
         - 4.1.3.3.6 Additional movie endpoints
      - 4.1.3.4 Conclusion
   - 4.1.4 Phoenix
      - 4.1.4.1 Prerequisites
      - 4.1.4.2 Schema design
      - 4.1.4.3 Ecto schemas
      - 4.1.4.4 User authentication via GitHub
      - 4.1.4.5 Running web server
   - 4.1.5 Strawberry
      - 4.1.5.1 Prerequisites
         - 4.1.5.1.1 Install the dependencies
         - 4.1.5.1.2 Initialize the database
         - 4.1.5.1.3 Connect to the database
      - 4.1.5.2 Schema design
      - 4.1.5.3 Build the GraphQL API
         - 4.1.5.3.1 Write the GraphQL schema
         - 4.1.5.3.2 Query actors
         - 4.1.5.3.3 Mutate actors
         - 4.1.5.3.4 Query movies
         - 4.1.5.3.5 Mutate movies
      - 4.1.5.4 Conclusion
- 4.2 Deployment
   - 4.2.1 AWS
      - 4.2.1.1 Prerequisites
      - 4.2.1.2 Quick Install with CloudFormation
         - 4.2.1.2.1 CloudFormation Web Portal
         - 4.2.1.2.2 CloudFormation CLI
      - 4.2.1.3 Manual Install with CLI
         - 4.2.1.3.1 Create a VPC
         - 4.2.1.3.2 Create a Gateway
         - 4.2.1.3.3 Create a Public Network ACL
      - 4.2.1.3.4 Create a Private Network ACL
      - 4.2.1.3.5 Create a Public Subnet in Availability Zone “A”
      - 4.2.1.3.6 Create a Private Subnet in Availability Zone “A”
      - 4.2.1.3.7 Create a Public Subnet in Availability Zone “B”
      - 4.2.1.3.8 Create a Private Subnet in Availability Zone “B”
      - 4.2.1.3.9 Create an EC2 security group
      - 4.2.1.3.10 Create an RDS Security Group
      - 4.2.1.3.11 Create an RDS Cluster
      - 4.2.1.3.12 Create a Load Balancer
      - 4.2.1.3.13 Create an ECS Cluster
      - 4.2.1.3.14 Create a local link to the new EdgeDB instance
   - 4.2.1.4 Health Checks
- 4.2.2 Azure
   - 4.2.2.1 Prerequisites
   - 4.2.2.2 Provision an EdgeDB instance
   - 4.2.2.3 Health Checks
- 4.2.3 DigitalOcean
   - 4.2.3.1 One-click Deploy
      - 4.2.3.1.1 Prerequisites
   - 4.2.3.2 Deploy with Managed PostgreSQL
      - 4.2.3.2.1 Prerequisites
      - 4.2.3.2.2 Create a managed PostgreSQL instance
      - 4.2.3.2.3 Provision a droplet
      - 4.2.3.2.4 Health Checks
- 4.2.4 Fly.io
   - 4.2.4.1 Prerequisites
   - 4.2.4.2 Provision a Fly.io app for EdgeDB
   - 4.2.4.3 Create a PostgreSQL cluster
   - 4.2.4.4 Start EdgeDB
   - 4.2.4.5 Persist the generated TLS certificate
   - 4.2.4.6 Connecting to the instance
      - 4.2.4.6.1 From a Fly.io app
      - 4.2.4.6.2 From external application
      - 4.2.4.6.3 From your local machine
   - 4.2.4.7 Health Checks
- 4.2.5 Google Cloud
   - 4.2.5.1 Prerequisites
   - 4.2.5.2 Create a project
   - 4.2.5.3 Provision a Postgres instance
   - 4.2.5.4 Create a Kubernetes cluster
   - 4.2.5.5 Configure service account
   - 4.2.5.6 Deploy EdgeDB
   - 4.2.5.7 Persist TLS Certificate
   - 4.2.5.8 Expose EdgeDB
   - 4.2.5.9 Get your instance’s DSN
      - 4.2.5.9.1 In development
      - 4.2.5.9.2 In production
   - 4.2.5.10 Health Checks
- 4.2.6 Heroku
   - 4.2.6.1 Prerequisites
   - 4.2.6.2 Setup
   - 4.2.6.3 Create a PostgreSQL Add-on
   - 4.2.6.4 Add the EdgeDB Buildpack
   - 4.2.6.5 Usestart-edgedbin the Procfile
      - 4.2.6.6 Deploy the App
      - 4.2.6.7 Health Checks
   - 4.2.7 Docker
      - 4.2.7.1 When to use the edgedb/edgedb Docker image
      - 4.2.7.2 How to use this image
      - 4.2.7.3 Data Persistence
      - 4.2.7.4 Schema Migrations
      - 4.2.7.5 Docker Compose
      - 4.2.7.6 Configuration
         - 4.2.7.6.1 Initial configuration
         - 4.2.7.6.2 Runtime configuration
      - 4.2.7.7 Health Checks
   - 4.2.8 Bare Metal
      - 4.2.8.1 Install the EdgeDB Package
         - 4.2.8.1.1 Debian/Ubuntu LTS
         - 4.2.8.1.2 CentOS/RHEL 7/8
      - 4.2.8.2 Enable a systemd unit
      - 4.2.8.3 Set environment variables
      - 4.2.8.4 Set a password
      - 4.2.8.5 Link the instance with the CLI
      - 4.2.8.6 Upgrading EdgeDB
         - 4.2.8.6.1 Debian/Ubuntu LTS
         - 4.2.8.6.2 CentOS/RHEL 7/8
      - 4.2.8.7 Health Checks
   - 4.2.9 Health Checks
      - 4.2.9.1 Check Instance Aliveness
      - 4.2.9.2 Check Instance Readiness
- 4.3 Migration Patterns
   - 4.3.1 Making a property required
   - 4.3.2 Adding backlinks
   - 4.3.3 Changing the type of a property
   - 4.3.4 Changing a property to a link
   - 4.3.5 Adding a required link
- 4.4 Cheatsheets
   - 4.4.1 Selecting data
   - 4.4.2 Inserting data
   - 4.4.3 Updating data
   - 4.4.4 Deleting data
   - 4.4.5 Using link properties
      - 4.4.5.1 Declaration
      - 4.4.5.2 Constraints
      - 4.4.5.3 Indexes
      - 4.4.5.4 Inserting
      - 4.4.5.5 Updating
      - 4.4.5.6 Querying
   - 4.4.6 Working with booleans
   - 4.4.7 Object types
   - 4.4.8 Declaring functions
   - 4.4.9 Declaring aliases
   - 4.4.10 Declaring annotations
   - 4.4.11 Using the CLI
   - 4.4.12 Using the REPL
      - 4.4.12.1 Commands
      - 4.4.12.2 Sample usage
      - 4.4.13 Administering an instance
   - 4.5 Contributing
      - 4.5.1 Code
         - 4.5.1.1 Building Locally
         - 4.5.1.2 Running Tests
         - 4.5.1.3 Dev Server
         - 4.5.1.4 Test Databases
      - 4.5.2 Documentation
         - 4.5.2.1 Guidelines
         - 4.5.2.2 Style
         - 4.5.2.3 Where to Find It
         - 4.5.2.4 How to Build It
            - 4.5.2.4.1 edgedb/edgedb
            - 4.5.2.4.2 Full Documentation Build
         - 4.5.2.5 Sphinx and reStructuredText
            - 4.5.2.5.1 reStructuredText Basics
            - 4.5.2.5.2 Sphinx Basics
         - 4.5.2.6 Rendering Code
            - 4.5.2.6.1 Inline Code
            - 4.5.2.6.2 Code Blocks
            - 4.5.2.6.3 Code Tabs
         - 4.5.2.7 Documenting EdgeQL
            - 4.5.2.7.1 Functions
            - 4.5.2.7.2 Operators
            - 4.5.2.7.3 Statements
            - 4.5.2.7.4 Types
            - 4.5.2.7.5 Keywords
         - 4.5.2.8 Documenting the EdgeQL CLI
         - 4.5.2.9 Documentation Versioning
            - 4.5.2.9.1 New in Version
            - 4.5.2.9.2 Changed in Version
         - 4.5.2.10 Other Useful Tricks
            - 4.5.2.10.1 Temporarily Disabling Linting
            - 4.5.2.10.2 Embedding a YouTube Video
            - 4.5.2.10.3 Displaying Illustrations
      - 4.5.3 General Guidelines
      - 4.5.4 Thank You!
- 5 Standard Library
   - 5.1 Generic
   - 5.2 Sets
   - 5.3 Types
   - 5.4 Math
   - 5.5 Strings
      - 5.5.1 Regular Expressions
         - 5.5.1.1 Option Flags
      - 5.5.2 Formatting
         - 5.5.2.1 Date and time formatting options
         - 5.5.2.2 Number formatting options
   - 5.6 Booleans
   - 5.7 Numbers
      - 5.7.1 Mathematical functions
      - 5.7.2 Bitwise functions
      - 5.7.3 String parsing
   - 5.8 JSON
      - 5.8.1 Constructing JSON Values
   - 5.9 UUIDs
   - 5.10 Enums
   - 5.11 Dates and Times
   - 5.12 Arrays
      - 5.12.1 Constructing arrays
      - 5.12.2 Empty arrays
      - 5.12.3 Reference
   - 5.13 Tuples
      - 5.13.1 Constructing tuples
      - 5.13.2 Accessing elements
      - 5.13.3 Nesting tuples
      - 5.13.4 Type syntax
   - 5.14 Ranges
      - 5.14.1 Constructing ranges
      - 5.14.2 JSON representation
      - 5.14.3 Functions and operators
      - 5.14.4 Reference
   - 5.15 Bytes
   - 5.16 Sequences
   - 5.17 Base Objects
   - 5.18 Abstract Types
      - 5.18.1 Abstract Numeric Types
      - 5.18.2 Abstract Range Types
   - 5.19 Constraints
   - 5.20 System
   - 5.21 Config
      - 5.21.1 Configuration Parameters
         - 5.21.1.1 Connection settings
         - 5.21.1.2 Resource usage
         - 5.21.1.3 Query planning
         - 5.21.1.4 Query behavior
         - 5.21.1.5 Client connections
   - 5.22 Deprecated
   - 5.23 Scalar Types
   - 5.24 Collection Types
   - 5.25 Range Types
   - 5.26 Object Types
   - 5.27 Types and Sets
   - 5.28 Utilities
- 6 Client Libraries
   - 6.1 Connection
   - 6.2 JavaScript
   - 6.3 Python
   - 6.4 Go
   - 6.5 Rust
   - 6.6 Dart
   - 6.7 .NET
   - 6.8 EdgeQL over HTTP
      - 6.8.1 Protocol
         - 6.8.1.1 GET request
         - 6.8.1.2 POST request
         - 6.8.1.3 Response
      - 6.8.2 Health Checks
         - 6.8.2.1 Aliveness
         - 6.8.2.2 Readiness
   - 6.9 GraphQL
      - 6.9.1 Basics
         - 6.9.1.1 Queries
            - 6.9.1.1.1 Filtering
            - 6.9.1.1.2 Ordering
            - 6.9.1.1.3 Paginating
            - 6.9.1.1.4 Variables
      - 6.9.2 Mutations
         - 6.9.2.1 Delete
         - 6.9.2.2 Insert
         - 6.9.2.3 Update
      - 6.9.3 Introspection
      - 6.9.4 Cheatsheet
      - 6.9.5 Setting up the extension
      - 6.9.6 Connection
      - 6.9.7 The protocol
         - 6.9.7.1 POST request (recommended)
         - 6.9.7.2 GET request
         - 6.9.7.3 Response format
      - 6.9.8 Known limitations
- 7 CLI
   - 7.1 Connection flags
      - 7.1.1 Connection flags
   - 7.2 Network usage
      - 7.2.1 Version Check
      - 7.2.2 Disabling Version Check
      - 7.2.3 edgedb serverandedgedb self upgrade
   - 7.3 edgedb
      - 7.3.1 Description
      - 7.3.2 Options
      - 7.3.3 Backslash Commands
   - 7.4 edgedb dump
      - 7.4.1 Description
      - 7.4.2 Options
   - 7.5 edgedb restore
      - 7.5.1 Description
      - 7.5.2 Options
   - 7.6 edgedb configure
      - 7.6.1 Description
      - 7.6.2 Actions
      - 7.6.3 Options
   - 7.7 edgedb watch
   - 7.8 edgedb migration
      - 7.8.1 edgedb migration create
         - 7.8.1.1 Options
      - 7.8.2 edgedb migration apply
         - 7.8.2.1 Options
      - 7.8.3 edgedb migration log
         - 7.8.3.1 Options
   - 7.8.4 edgedb migration status
      - 7.8.4.1 Options
   - 7.8.5 edgedb migration edit
      - 7.8.5.1 Options
   - 7.8.6 edgedb migration upgrade-check
      - 7.8.6.1 Options
   - 7.8.7 Setup
- 7.9 edgedb migrate
- 7.10 edgedb database create
   - 7.10.1 Description
   - 7.10.2 Options
- 7.11 edgedb describe
   - 7.11.1 edgedb describe object
      - 7.11.1.1 Description
      - 7.11.1.2 Options
   - 7.11.2 edgedb describe schema
      - 7.11.2.1 Description
      - 7.11.2.2 Options
- 7.12 edgedb list
   - 7.12.1 Description
   - 7.12.2 Types
   - 7.12.3 Options
- 7.13 edgedb query
   - 7.13.1 Description
   - 7.13.2 Options
- 7.14 edgedb analyze
   - 7.14.1 Options
- 7.15 edgedb ui
   - 7.15.1 Description
   - 7.15.2 Options
- 7.16 edgedb info
   - 7.16.1 Paths
      - 7.16.1.1 Options
- 7.17 edgedb project
   - 7.17.1 edgedb project init
      - 7.17.1.1 Description
         - 7.17.1.1.1 EdgeDB Cloud
      - 7.17.1.2 Options
   - 7.17.2 edgedb project unlink
      - 7.17.2.1 Description
      - 7.17.2.2 Options
   - 7.17.3 edgedb project info
      - 7.17.3.1 Description
      - 7.17.3.2 Options
   - 7.17.4 edgedb project upgrade
      - 7.17.4.1 Description
      - 7.17.4.2 Options
- 7.18 edgedb instance
   - 7.18.1 edgedb instance create
      - 7.18.1.1 Description
         - 7.18.1.1.1 EdgeDB Cloud
      - 7.18.1.2 Options
   - 7.18.2 edgedb instance link
      - 7.18.2.1 Description
      - 7.18.2.2 Options
   - 7.18.3 edgedb instance unlink
      - 7.18.3.1 Description
      - 7.18.3.2 Options
   - 7.18.4 edgedb instance list
      - 7.18.4.1 Description
      - 7.18.4.2 Options
   - 7.18.5 edgedb instance logs
      - 7.18.5.1 Description
      - 7.18.5.2 Options
   - 7.18.6 edgedb instance status
      - 7.18.6.1 Description
      - 7.18.6.2 Options
   - 7.18.7 edgedb instance start
      - 7.18.7.1 Description
      - 7.18.7.2 Options
   - 7.18.8 edgedb instance stop
      - 7.18.8.1 Description
      - 7.18.8.2 Options
   - 7.18.9 edgedb instance restart
      - 7.18.9.1 Description
      - 7.18.9.2 Options
   - 7.18.10 edgedb instance destroy
      - 7.18.10.1 Description
      - 7.18.10.2 Options
   - 7.18.11 edgedb instance revert
      - 7.18.11.1 Description
      - 7.18.11.2 Options
   - 7.18.12 edgedb instance reset-password
      - 7.18.12.1 Description
      - 7.18.12.2 Options
   - 7.18.13 edgedb instance upgrade
      - 7.18.13.1 Description
      - 7.18.13.2 Options
- 7.19 edgedb server
   - 7.19.1 edgedb server info
      - 7.19.1.1 Description
      - 7.19.1.2 Options
   - 7.19.2 edgedb server install
      - 7.19.2.1 Description
      - 7.19.2.2 Options
   - 7.19.3 edgedb server list-versions
      - 7.19.3.1 Description
      - 7.19.3.2 Options
   - 7.19.4 edgedb server uninstall
      - 7.19.4.1 Description
      - 7.19.4.2 Options
- 7.20 edgedb cloud
   - 7.20.1 edgedb cloud login
   - 7.20.2 edgedb cloud logout
      - 7.20.2.1 Options
   - 7.20.3 edgedb cloud secretkey
      - 7.20.3.1 edgedb cloud secretkey create
         - 7.20.3.1.1 Options
         - 7.20.3.2 edgedb cloud secretkey list
            - 7.20.3.2.1 Options
         - 7.20.3.3 edgedb cloud secretkey revoke
            - 7.20.3.3.1 Options
      - 7.20.4 Usage
   - 7.21 edgedb cli upgrade
      - 7.21.1 Description
      - 7.21.2 Options
- 8 Reference
   - 8.1 EdgeQL
      - 8.1.1 Lexical structure
         - 8.1.1.1 Identifiers
         - 8.1.1.2 Names and keywords
         - 8.1.1.3 Constants
            - 8.1.1.3.1 Strings
            - 8.1.1.3.2 Bytes
            - 8.1.1.3.3 Integers
            - 8.1.1.3.4 Real Numbers
         - 8.1.1.4 Punctuation
         - 8.1.1.5 Comments
         - 8.1.1.6 Operators
      - 8.1.2 Evaluation algorithm
      - 8.1.3 Shapes
         - 8.1.3.1 Shaping Query Results
         - 8.1.3.2 General Shaping Rules
         - 8.1.3.3 Losing Shapes
      - 8.1.4 Paths
      - 8.1.5 Casts
         - 8.1.5.1 Explicit Casts
         - 8.1.5.2 Assignment Casts
         - 8.1.5.3 Implicit Casts
         - 8.1.5.4 Casting Table
      - 8.1.6 Function calls
      - 8.1.7 Cardinality
         - 8.1.7.1 Terminology
         - 8.1.7.2 Functions and operators
            - 8.1.7.2.1 Aggregate operations
            - 8.1.7.2.2 Element-wise operations
            - 8.1.7.2.3 Cartesian products
            - 8.1.7.2.4 Per-input cardinality
            - 8.1.7.2.5 Type qualifiers
            - 8.1.7.2.6 Cardinality computation
      - 8.1.8 Select
         - 8.1.8.1 Description
         - 8.1.8.2 Filter
         - 8.1.8.3 Clause signatures
      - 8.1.9 Insert
         - 8.1.9.1 Description
         - 8.1.9.2 Outputs
         - 8.1.9.3 Examples
      - 8.1.10 Update
         - 8.1.10.1 Output
         - 8.1.10.2 Examples
   - 8.1.11 Delete
      - 8.1.11.1 Output
      - 8.1.11.2 Examples
   - 8.1.12 For
      - 8.1.12.1 Usage offorstatement
   - 8.1.13 Group
      - 8.1.13.1 Output
      - 8.1.13.2 Examples
   - 8.1.14 With block
      - 8.1.14.1 Specifying a module
      - 8.1.14.2 Local Expression Aliases
      - 8.1.14.3 Detached
   - 8.1.15 Start transaction
      - 8.1.15.1 Description
      - 8.1.15.2 Parameters
      - 8.1.15.3 Examples
   - 8.1.16 Commit
      - 8.1.16.1 Example
      - 8.1.16.2 Description
   - 8.1.17 Rollback
      - 8.1.17.1 Example
      - 8.1.17.2 Description
   - 8.1.18 Declare savepoint
      - 8.1.18.1 Description
      - 8.1.18.2 Example
   - 8.1.19 Release savepoint
      - 8.1.19.1 Description
      - 8.1.19.2 Example
   - 8.1.20 Rollback to savepoint
      - 8.1.20.1 Description
      - 8.1.20.2 Example
   - 8.1.21 Set
      - 8.1.21.1 Description
      - 8.1.21.2 Variations
      - 8.1.21.3 Examples
   - 8.1.22 Reset
      - 8.1.22.1 Description
      - 8.1.22.2 Variations
      - 8.1.22.3 Examples
   - 8.1.23 Describe
      - 8.1.23.1 Description
      - 8.1.23.2 Examples
- 8.2 SDL
   - 8.2.1 Modules
      - 8.2.1.1 Example
      - 8.2.1.2 Syntax
      - 8.2.1.3 Description
   - 8.2.2 Object Types
      - 8.2.2.1 Example
      - 8.2.2.2 Syntax
      - 8.2.2.3 Description
   - 8.2.3 Scalar Types
      - 8.2.3.1 Example
      - 8.2.3.2 Syntax
   - 8.2.3.3 Description
- 8.2.4 Links
   - 8.2.4.1 Examples
      - 8.2.4.1.1 Overloading
   - 8.2.4.2 Syntax
   - 8.2.4.3 Description
- 8.2.5 Properties
   - 8.2.5.1 Examples
   - 8.2.5.2 Syntax
   - 8.2.5.3 Description
- 8.2.6 Expression Aliases
   - 8.2.6.1 Example
   - 8.2.6.2 Syntax
   - 8.2.6.3 Description
- 8.2.7 Indexes
   - 8.2.7.1 Example
   - 8.2.7.2 Syntax
   - 8.2.7.3 Description
- 8.2.8 Constraints
   - 8.2.8.1 Examples
   - 8.2.8.2 Syntax
   - 8.2.8.3 Description
- 8.2.9 Annotations
   - 8.2.9.1 Examples
   - 8.2.9.2 Syntax
   - 8.2.9.3 Description
- 8.2.10 Globals
   - 8.2.10.1 Examples
   - 8.2.10.2 Syntax
   - 8.2.10.3 Description
- 8.2.11 Access Policies
   - 8.2.11.1 Examples
   - 8.2.11.2 Syntax
   - 8.2.11.3 Description
- 8.2.12 Functions
   - 8.2.12.1 Example
   - 8.2.12.2 Syntax
   - 8.2.12.3 Description
- 8.2.13 Triggers
   - 8.2.13.1 Example
   - 8.2.13.2 Syntax
   - 8.2.13.3 Description
- 8.2.14 Mutation rewrites
   - 8.2.14.1 Example
   - 8.2.14.2 Syntax
   - 8.2.14.3 Description
- 8.2.15 Extensions
   - 8.2.15.1 Syntax
   - 8.2.15.2 Description
   - 8.2.15.3 Examples
- 8.2.16 Future Behavior
   - 8.2.16.1 Syntax
   - 8.2.16.2 Description
   - 8.2.16.3 Examples
- 8.3 DDL
   - 8.3.1 Modules
      - 8.3.1.1 Create module
         - 8.3.1.1.1 Description
         - 8.3.1.1.2 Parameters
         - 8.3.1.1.3 Examples
      - 8.3.1.2 Drop module
         - 8.3.1.2.1 Description
         - 8.3.1.2.2 Examples
   - 8.3.2 Object Types
      - 8.3.2.1 Create type
         - 8.3.2.1.1 Description
         - 8.3.2.1.2 Parameters
         - 8.3.2.1.3 Examples
      - 8.3.2.2 Alter type
         - 8.3.2.2.1 Description
         - 8.3.2.2.2 Parameters
         - 8.3.2.2.3 Examples
      - 8.3.2.3 Drop type
         - 8.3.2.3.1 Description
         - 8.3.2.3.2 Examples
   - 8.3.3 Scalar Types
      - 8.3.3.1 Create scalar type
         - 8.3.3.1.1 Description
         - 8.3.3.1.2 Examples
      - 8.3.3.2 Alter scalar type
         - 8.3.3.2.1 Description
         - 8.3.3.2.2 Examples
      - 8.3.3.3 Drop scalar type
         - 8.3.3.3.1 Description
         - 8.3.3.3.2 Parameters
         - 8.3.3.3.3 Example
   - 8.3.4 Links
      - 8.3.4.1 Create link
         - 8.3.4.1.1 Description
         - 8.3.4.1.2 Parameters
         - 8.3.4.1.3 Examples
      - 8.3.4.2 Alter link
         - 8.3.4.2.1 Description
         - 8.3.4.2.2 Parameters
         - 8.3.4.2.3 Examples
      - 8.3.4.3 Drop link
         - 8.3.4.3.1 Description
         - 8.3.4.3.2 Examples
   - 8.3.5 Properties
      - 8.3.5.1 Create property
         - 8.3.5.1.1 Description
         - 8.3.5.1.2 Parameters
         - 8.3.5.1.3 Examples
      - 8.3.5.2 Alter property
         - 8.3.5.2.1 Description
         - 8.3.5.2.2 Parameters
         - 8.3.5.2.3 Examples
      - 8.3.5.3 Drop property


8.3.5.3.1 Description................................. 657
8.3.5.3.2 Example................................... 657
8.3.6 Aliases............................................. 657
8.3.6.1 Create alias...................................... 657
8.3.6.1.1 Description................................. 658
8.3.6.1.2 Parameters.................................. 658
8.3.6.1.3 Example................................... 658
8.3.6.2 Drop alias....................................... 658
8.3.6.2.1 Description................................. 658
8.3.6.2.2 Parameters.................................. 659
8.3.6.2.3 Example................................... 659
8.3.7 Indexes............................................. 659
8.3.7.1 Create index...................................... 659
8.3.7.1.1 Description................................. 659
8.3.7.1.2 Parameters.................................. 659
8.3.7.1.3 Example................................... 660
8.3.7.2 Alter index....................................... 660
8.3.7.2.1 Description................................. 660
8.3.7.2.2 Parameters.................................. 660
8.3.7.2.3 Example................................... 661
8.3.7.3 Drop index....................................... 661
8.3.7.3.1 Description................................. 661
8.3.7.3.2 Example................................... 661
8.3.8 Constraints........................................... 661
8.3.8.1 Create abstract constraint............................... 662
8.3.8.1.1 Description................................. 662
8.3.8.1.2 Parameters.................................. 662
8.3.8.1.3 Example................................... 663
8.3.8.2 Alter abstract constraint................................ 663
8.3.8.2.1 Description................................. 663
8.3.8.2.2 Parameters.................................. 663
8.3.8.2.3 Example................................... 664
8.3.8.3 Drop abstract constraint................................ 664
8.3.8.3.1 Description................................. 664
8.3.8.3.2 Parameters.................................. 664
8.3.8.3.3 Example................................... 664
8.3.8.4 Create constraint.................................... 665
8.3.8.4.1 Description................................. 665
8.3.8.4.2 Parameters.................................. 665
8.3.8.4.3 Example................................... 666
8.3.8.5 Alter constraint.................................... 666
8.3.8.5.1 Description................................. 667
8.3.8.5.2 Parameters.................................. 667
8.3.8.5.3 Example................................... 667
8.3.8.6 Drop constraint.................................... 667
8.3.8.6.1 Description................................. 668
8.3.8.6.2 Parameters.................................. 668
8.3.8.6.3 Example................................... 668
8.3.9 Annotations........................................... 668
8.3.9.1 Create abstract annotation............................... 668
8.3.9.1.1 Description................................. 669
8.3.9.1.2 Example................................... 669
8.3.9.2 Alter abstract annotation................................ 669
8.3.9.2.1 Description................................. 670

```
xix
```

```
8.3.9.2.2 Parameters.................................. 670
8.3.9.2.3 Examples.................................. 670
8.3.9.3 Drop abstract annotation................................ 670
8.3.9.3.1 Description................................. 670
8.3.9.3.2 Example................................... 670
8.3.9.4 Create annotation................................... 671
8.3.9.4.1 Description................................. 671
8.3.9.4.2 Example................................... 671
8.3.9.5 Alter annotation.................................... 671
8.3.9.5.1 Description................................. 671
8.3.9.5.2 Example................................... 671
8.3.9.6 Drop annotation.................................... 672
8.3.9.6.1 Description................................. 672
8.3.9.6.2 Example................................... 672
8.3.10 Globals............................................. 672
8.3.10.1 Create global...................................... 672
8.3.10.1.1 Description................................. 673
8.3.10.1.2 Parameters.................................. 673
8.3.10.1.3 Examples.................................. 673
8.3.10.2 Alter global...................................... 673
8.3.10.2.1 Description................................. 674
8.3.10.2.2 Parameters.................................. 674
8.3.10.2.3 Examples.................................. 675
8.3.10.3 Drop global...................................... 675
8.3.10.3.1 Description................................. 675
8.3.10.3.2 Example................................... 675
8.3.11 Access Policies......................................... 676
8.3.11.1 Create access policy.................................. 676
8.3.11.1.1 Description................................. 677
8.3.11.1.2 Parameters.................................. 677
8.3.11.2 Alter access policy................................... 678
8.3.11.2.1 Description................................. 679
8.3.11.2.2 Parameters.................................. 679
8.3.11.3 Drop access policy................................... 679
8.3.11.3.1 Description................................. 679
8.3.12 Functions............................................ 680
8.3.12.1 Create function.................................... 680
8.3.12.1.1 Description................................. 681
8.3.12.1.2 Parameters.................................. 681
8.3.12.1.3 Examples.................................. 681
8.3.12.2 Alter function..................................... 682
8.3.12.2.1 Description................................. 682
8.3.12.2.2 Subcommands................................ 682
8.3.12.2.3 Example................................... 683
8.3.12.3 Drop function..................................... 683
8.3.12.3.1 Description................................. 683
8.3.12.3.2 Parameters.................................. 683
8.3.12.3.3 Example................................... 684
8.3.13 Triggers............................................. 684
8.3.13.1 Create trigger..................................... 684
8.3.13.1.1 Description................................. 684
8.3.13.1.2 Parameters.................................. 684
8.3.13.1.3 Example................................... 685
8.3.13.2 Drop trigger...................................... 685
```
**xx**


8.3.13.2.1 Description................................. 685
8.3.13.2.2 Parameters.................................. 685
8.3.13.2.3 Example................................... 685
8.3.14 Mutation Rewrites....................................... 686
8.3.14.1 Create rewrite..................................... 686
8.3.14.1.1 Description................................. 686
8.3.14.1.2 Parameters.................................. 686
8.3.14.1.3 Examples.................................. 686
8.3.14.2 Drop rewrite...................................... 687
8.3.14.2.1 Description................................. 687
8.3.14.2.2 Parameters.................................. 687
8.3.14.2.3 Example................................... 687
8.3.15 Extensions............................................ 688
8.3.15.1 Create extension.................................... 688
8.3.15.1.1 Description................................. 688
8.3.15.1.2 Examples.................................. 688
8.3.15.2 drop extension..................................... 688
8.3.15.2.1 Description................................. 688
8.3.15.2.2 Examples.................................. 688
8.3.16 Future Behavior......................................... 689
8.3.16.1 Create future...................................... 689
8.3.16.1.1 Description................................. 689
8.3.16.1.2 Examples.................................. 689
8.3.16.2 drop future....................................... 689
8.3.16.2.1 Description................................. 689
8.3.16.2.2 Examples.................................. 689
8.3.17 Migrations............................................ 690
8.3.17.1 Start migration..................................... 690
8.3.17.1.1 Parameters.................................. 690
8.3.17.1.2 Description................................. 690
8.3.17.1.3 Examples.................................. 691
8.3.17.2 create migration.................................... 691
8.3.17.2.1 Parameters.................................. 691
8.3.17.2.2 Description................................. 691
8.3.17.2.3 Examples.................................. 691
8.3.17.3 Abort migration.................................... 692
8.3.17.3.1 Description................................. 692
8.3.17.3.2 Examples.................................. 692
8.3.17.4 Populate migration................................... 692
8.3.17.4.1 Description................................. 692
8.3.17.4.2 Examples.................................. 693
8.3.17.5 Describe current migration.............................. 693
8.3.17.5.1 Description................................. 693
8.3.17.6 Commit migration................................... 694
8.3.17.6.1 Description................................. 694
8.3.17.6.2 Example................................... 695
8.3.17.7 Reset schema to initial................................. 695
8.3.17.8 Migration Rewrites.................................. 695
8.3.17.8.1 Start migration rewrite........................... 695
8.3.17.8.2 Declare savepoint.............................. 695
8.3.17.8.3 Release savepoint.............................. 696
8.3.17.8.4 Rollback to savepoint............................ 696
8.3.17.8.5 Rollback................................... 696
8.3.17.8.6 Commit migration rewrite......................... 696

```
xxi
```

```
8.3.18 Comparison to SDL....................................... 697
8.4 Connection parameters.......................................... 697
8.4.1 Specifying an instance..................................... 697
8.4.2 Priority levels.......................................... 699
8.4.3 Granular parameters...................................... 700
8.4.3.1 Override behavior................................... 701
8.4.3.2 Overriding across priority levels........................... 701
8.5 Environment Variables.......................................... 701
8.5.1 Variants............................................. 702
8.5.2 Supported variables....................................... 702
8.5.2.1 EDGEDB_SERVER_BOOTSTRAP_COMMAND................. 702
8.5.2.2 EDGEDB_SERVER_DEFAULT_AUTH_METHOD................ 702
8.5.2.3 EDGEDB_SERVER_TLS_CERT_MODE...................... 702
8.5.2.4 EDGEDB_SERVER_TLS_CERT_FILE/EDGEDB_SERVER_TLS_KEY_FILE.. 703
8.5.2.5 EDGEDB_SERVER_SECURITY.......................... 703
8.5.2.6 EDGEDB_SERVER_PORT.............................. 703
8.5.2.7 EDGEDB_SERVER_BIND_ADDRESS....................... 703
8.5.2.8 EDGEDB_SERVER_DATADIR........................... 703
8.5.2.9 EDGEDB_SERVER_BACKEND_DSN....................... 703
8.5.2.10 EDGEDB_SERVER_RUNSTATE_DIR....................... 703
8.5.2.11 EDGEDB_SERVER_ADMIN_UI.......................... 704
8.6 Create a project.............................................. 704
8.6.1 FAQ............................................... 704
8.6.1.1 How does this help me?................................ 704
8.6.1.2 What do you mean link?................................ 705
8.6.1.3 How does this work in production?.......................... 705
8.6.1.4 What’s theedgedb.tomlfile?............................ 705
8.6.1.5 How do I useedgedb projectfor existing codebases?............... 705
8.6.1.6 How does this make projects more portable?..................... 706
8.6.1.7 How do I unlink a project?.............................. 706
8.6.1.8 How do I useedgedb projectwith a non-local instance?............. 706
8.7 DSN specification............................................ 707
8.7.1 Query parameters........................................ 707
8.8 Dump file format............................................. 708
8.8.1 General Structure........................................ 708
8.8.2 General Dump Block...................................... 708
8.8.3 Header Block.......................................... 709
8.8.4 Data Block........................................... 710
8.9 Backend high-availability........................................ 710
8.9.1 API-based HA......................................... 711
8.9.2 Adaptive HA.......................................... 711
8.10 Server configuration........................................... 712
8.10.1 Configuring the server..................................... 712
8.10.1.1 EdgeQL........................................ 712
8.10.1.2 CLI........................................... 712
8.10.2 Available settings........................................ 713
8.10.2.1 Connection settings.................................. 713
8.10.2.2 Resource usage.................................... 713
8.10.2.3 Query planning.................................... 713
8.10.2.4 Query behavior.................................... 713
8.10.2.5 Client connections................................... 714
8.11 HTTP API................................................ 714
8.11.1 Health Checks.......................................... 714
8.11.1.1 Aliveness....................................... 714
```
**xxii**


8.11.1.2 Readiness....................................... 715
8.11.2 Observability.......................................... 715
8.11.2.1 Processes........................................ 715
8.11.2.2 Backend connections and performance........................ 715
8.11.2.3 Client connections................................... 715
8.11.2.4 Query compilation................................... 716
8.11.2.5 Errors......................................... 716
8.11.3 Querying............................................ 716
8.11.3.1 Making a query request................................ 716
8.11.3.2 Response........................................ 717
8.12 SQL support............................................... 717
8.12.1 Connecting........................................... 717
8.12.2 Querying............................................ 718
8.12.3 Tested SQL tools........................................ 720
8.13 Binary protocol.............................................. 720
8.13.1 Messages............................................ 721
8.13.1.1 ErrorResponse..................................... 721
8.13.1.2 LogMessage...................................... 723
8.13.1.3 ReadyForCommand.................................. 723
8.13.1.4 RestoreReady..................................... 724
8.13.1.5 CommandComplete.................................. 724
8.13.1.6 Dump......................................... 725
8.13.1.7 CommandDataDescription.............................. 725
8.13.1.8 StateDataDescription................................. 726
8.13.1.9 Sync.......................................... 727
8.13.1.10 Restore......................................... 727
8.13.1.11 RestoreBlock...................................... 728
8.13.1.12 RestoreEof....................................... 728
8.13.1.13 Execute........................................ 728
8.13.1.14 Parse.......................................... 730
8.13.1.15 Data.......................................... 732
8.13.1.16 Dump Header..................................... 732
8.13.1.17 Dump Block...................................... 733
8.13.1.18 ServerKeyData..................................... 734
8.13.1.19 ParameterStatus.................................... 734
8.13.1.20 ClientHandshake.................................... 735
8.13.1.21 ServerHandshake................................... 736
8.13.1.22 AuthenticationOK................................... 737
8.13.1.23 AuthenticationSASL.................................. 737
8.13.1.24 AuthenticationSASLContinue............................. 738
8.13.1.25 AuthenticationSASLFinal............................... 739
8.13.1.26 AuthenticationSASLInitialResponse......................... 739
8.13.1.27 AuthenticationSASLResponse............................. 740
8.13.1.28 Terminate....................................... 740
8.13.2 Errors.............................................. 740
8.13.2.1 Errors inheritance................................... 740
8.13.2.2 Error codes...................................... 741
8.13.3 Type descriptors......................................... 741
8.13.3.1 Set Descriptor..................................... 741
8.13.3.2 Object Shape Descriptor................................ 741
8.13.3.3 Base Scalar Type Descriptor.............................. 742
8.13.3.4 Scalar Type Descriptor................................ 743
8.13.3.5 Tuple Type Descriptor................................. 743
8.13.3.6 Named Tuple Type Descriptor............................. 744

```
xxiii
```

```
8.13.3.7 Array Type Descriptor................................. 744
8.13.3.8 Enumeration Type Descriptor............................. 745
8.13.3.9 Input Shape Descriptor................................ 745
8.13.3.10 Range Type Descriptor................................ 745
8.13.3.11 Scalar Type Name Annotation............................. 746
8.13.3.12 Type Annotation Descriptor.............................. 746
8.13.4 Data wire formats........................................ 746
8.13.4.1 Sets and array<>.................................... 747
8.13.4.2 tuple<>, namedtuple<>, and object<>........................ 748
8.13.4.3 Sparse Objects..................................... 749
8.13.4.4 Ranges......................................... 749
8.13.4.5 std::uuid........................................ 750
8.13.4.6 std::str......................................... 750
8.13.4.7 std::bytes........................................ 750
8.13.4.8 std::int16........................................ 750
8.13.4.9 std::int32........................................ 750
8.13.4.10 std::int64........................................ 751
8.13.4.11 std::float32....................................... 751
8.13.4.12 std::float64....................................... 751
8.13.4.13 std::decimal...................................... 751
8.13.4.14 std::bool........................................ 752
8.13.4.15 std::datetime...................................... 752
8.13.4.16 cal::local_datetime................................... 753
8.13.4.17 cal::local_date..................................... 753
8.13.4.18 cal::local_time..................................... 753
8.13.4.19 std::duration...................................... 753
8.13.4.20 cal::relative_duration................................. 754
8.13.4.21 cal::date_duration................................... 754
8.13.4.22 std::json........................................ 755
8.13.4.23 std::bigint....................................... 755
8.13.4.24 cfg::memory...................................... 756
8.13.5 Conventions and data Types.................................. 756
8.13.6 Message Format......................................... 757
8.13.7 Errors.............................................. 758
8.13.8 Logs............................................... 758
8.13.9 Message Flow.......................................... 758
8.13.9.1 Connection Phase................................... 758
8.13.9.2 Authentication..................................... 758
8.13.9.3 Command Phase.................................... 759
8.13.9.4 Dump Database Flow................................. 760
8.13.9.5 Restore Database Flow................................ 760
8.13.10 Termination........................................... 760
8.14 Client Libraries.............................................. 761
8.14.1 Date/Time Handling...................................... 761
8.14.1.1 Precision........................................ 762
8.15 Administration.............................................. 762
8.15.1 Configure............................................ 763
8.15.1.1 Description...................................... 763
8.15.1.2 Parameters....................................... 763
8.15.1.3 Examples....................................... 763
8.15.2 Database............................................ 764
8.15.2.1 Create database.................................... 764
8.15.2.1.1 Description................................. 764
8.15.2.1.2 Examples.................................. 764
```
**xxiv**


```
8.15.2.2 Drop database..................................... 764
8.15.2.2.1 Description................................. 765
8.15.2.2.2 Examples.................................. 765
8.15.3 Role............................................... 765
8.15.3.1 Create role....................................... 765
8.15.3.1.1 Description................................. 765
8.15.3.1.2 Examples.................................. 766
8.15.3.2 Alter role........................................ 766
8.15.3.2.1 Description................................. 766
8.15.3.2.2 Examples.................................. 767
8.15.3.3 Drop role........................................ 767
8.15.3.3.1 Description................................. 767
8.15.3.3.2 Examples.................................. 767
```
**9 Changelog 769**
9.1 v1.0.................................................... 769
9.1.1 1.4................................................ 769
9.1.2 1.3................................................ 770
9.1.3 1.2................................................ 770
9.1.4 1.1................................................ 771
9.1.5 Pre-releases........................................... 772
9.2 v2.0.................................................... 772
9.2.1 Upgrading............................................ 772
9.2.1.1 Client libraries..................................... 773
9.2.2 New features.......................................... 773
9.2.2.1 Integrated admin UI.................................. 773
9.2.2.2 Analytical queries withGROUP............................ 774
9.2.2.3 Global variables.................................... 775
9.2.2.4 Object-level security.................................. 776
9.2.2.5 Range types...................................... 776
9.2.2.6 Thecal::date_durationtype........................... 777
9.2.2.7 Source deletion policies................................ 777
9.2.3 Additional changes....................................... 777
9.2.3.1 EdgeQL........................................ 777
9.2.3.2 Server......................................... 778
9.2.3.3 Bug fixes........................................ 778
9.2.3.4 Protocol overhaul................................... 779
9.2.4 2.1................................................ 779
9.2.5 2.2................................................ 779
9.2.6 2.3................................................ 780
9.2.7 2.4................................................ 781
9.2.8 2.5................................................ 781
9.2.9 2.6................................................ 782
9.2.9.1 Nonrecursive access policies and future behaviors.................. 782
9.2.9.2 Other changes..................................... 782
9.2.10 2.7................................................ 782
9.2.11 2.8................................................ 783
9.2.12 2.9................................................ 783
9.2.13 2.10............................................... 784
9.2.14 2.11............................................... 785
9.2.15 2.12............................................... 785
9.2.16 2.13............................................... 785
9.2.17 2.14............................................... 785
9.2.17.1 Schema repair on upgades............................... 785

```
xxv
```

```
9.2.17.2 Other changes..................................... 786
9.2.18 2.15............................................... 786
9.3 v3.0 (dev)................................................. 786
9.3.1 Upgrading............................................ 787
9.3.1.1 Client libraries..................................... 788
9.3.2 New features.......................................... 788
9.3.2.1 Simplified SDL syntax................................ 788
9.3.2.2 Query performance analysis.............................. 789
9.3.2.3 UI improvements................................... 790
9.3.2.3.1 New UI for setting globals and configuration................ 790
9.3.2.3.2 New UI REPL................................ 790
9.3.2.3.3 Query editor and visual builder....................... 791
9.3.2.4 edgedb watchand a new development workflow.................. 792
9.3.2.4.1 1. Start thewatchcommand........................ 792
9.3.2.4.2 2. Write an initial schema.......................... 792
9.3.2.4.3 3. Edit your schema files.......................... 792
9.3.2.4.4 4. Generate a migration........................... 792
9.3.2.5 Triggers........................................ 793
9.3.2.6 Mutation rewrites................................... 793
9.3.2.7 Splats......................................... 793
9.3.2.8 SQL support...................................... 794
9.3.2.9 Nested modules.................................... 795
9.3.2.10 intersectandexceptoperators.......................... 795
9.3.2.11 assertfunction.................................... 796
9.3.3 Additional changes....................................... 796
9.3.3.1 EdgeQL........................................ 796
9.3.3.2 CLI........................................... 798
9.3.3.3 Bug fixes........................................ 798
9.3.3.4 Deprecations...................................... 799
9.3.4 New release schedule...................................... 799
9.3.5 3.0 RC 1............................................. 799
9.3.5.1 Changes to new 3.0 features.............................. 799
9.3.5.2 Other changes and fixes................................ 800
9.4 Deprecation Policy............................................ 800
```
**xxvi**


Welcome to the EdgeDB 0.5.0 documentation.

**CONTENTS 1**


**2 CONTENTS**


```
CHAPTER
```
### ONE

### GET STARTED

### 1.1 Quickstart

Welcome to EdgeDB!

This quickstart will walk you through the entire process of creating a simple EdgeDB-powered application: installation,
defining your schema, adding some data, and writing your first query. Let’s jump in!

#### 1.1.1 1. Installation

First let’s install the EdgeDB CLI. Open a terminal and run the appropriate command below.

**macOS/Linux**

$ curl https://sh.edgedb.com --proto '=https' -sSf1 | sh

**Windows (Powershell)**

**Note:** EdgeDB on Windows requires WSL 2 because the EdgeDB server runs on Linux.

PS> iwr https://ps1.edgedb.com -useb | iex

This command downloads and executes a bash script that installs theedgedbCLI on your machine. You may be asked
for your password. Once the installation completes, you may need to **restart your terminal** before you can use the
edgedbcommand.

**Note:** Check out our additional installation methods for various Linux distros, via Homebrew on macOS, and for the
Windows Command Prompt.

Now let’s set up your EdgeDB project.

```
3
```

#### 1.1.2 2. Initialize a project

In a terminal, create a new directory andcdinto it.

$ mkdir quickstart
$ cd quickstart

Then initialize your EdgeDB project:

$ edgedb project init

This starts an interactive tool that walks you through the process of setting up your first EdgeDB instance. You should
see something like this:

$ edgedb project init
No `edgedb.toml` found in`/path/to/quickstart`or above
Do you want to initialize a new project? [Y/n]
> Y
Specify the name of EdgeDB instance to use with this project [quickstart]:
> quickstart
Checking EdgeDB versions...
Specify the version of EdgeDB to use with this project [default: 2.x]:
> 2.x

```
Project directory ~/path/to/quickstart
Project config ~/path/to/quickstart/edgedb.toml
Schema dir (empty) ~/path/to/quickstart/dbschema
Installation method portable package
Version 2.x+c21decd
Instance name quickstart
```
Downloading package...
00:00:01 [====================] 32.98MiB/32.98MiB 32.89MiB/s | ETA: 0s
Successfully installed 2.x+c21decd
Initializing EdgeDB instance...
Applying migrations...
Everything is up to date. Revision initial
Project initialized.
To connect to quickstart, run`edgedb`

This did a couple things.

1. First, it scaffolded your project by creating anedgedb.tomlconfig file and a schema filedbschema/default.
    esdl. In the next section, you’ll define a schema indefault.esdl.
2. Second, it spun up an EdgeDB instance calledquickstartand “linked” it to the current directory. As long as
    you’re inside the project directory, all CLI commands will be executed against this instance. For more details on
    how EdgeDB projects work, check out the _Managing instances_ guide.

**Note:** Quick note! You can have several **instances** of EdgeDB running on your computer simultaneously. Each
instance contains several **databases**. Each database may contain several **modules** (though commonly your schema will
be entirely defined inside thedefaultmodule).

Let’s connect to our new instance! Runedgedbin your terminal to open an interactive REPL to your instance. You’re
now connected to a live EdgeDB instance running on your computer! Try executing a simple query:

**4 Chapter 1. Get Started**


db>select 1 + 1;
{2}

Run\qto exit the REPL. More interesting queries are coming soon, promise! But first we need to set up a schema.

#### 1.1.3 3. Set up your schema

Open thequickstartdirectory in your IDE or editor of choice. You should see the following file structure.

/path/to/quickstart
edgedb.toml
dbschema
default.esdl
migrations

EdgeDB schemas are defined with a dedicated schema description language called (predictably) EdgeDB SDL (or just
**SDL** for short). It’s an elegant, declarative way to define your data model.

SDL lives inside.esdlfiles. Commonly, your entire schema will be declared in a file calleddefault.esdlbut you
can split your schema across several.esdlfiles if you prefer.

**Note:** Syntax-highlighter packages/extensions for.esdlfiles are available for Visual Studio Code, Sublime Text,
Atom, and Vim.

Let’s build a simple movie database. We’ll need to define two **object types** (equivalent to a _table_ in SQL): Movie and
Person. Opendbschema/default.esdlin your editor of choice and paste the following:

module default{
type Person {
required propertyname -> str;
}

type Movie {
propertytitle -> str;
multi linkactors -> Person;
}
};

module default{
type Person {
requiredname: str;
}

type Movie {
title: str;
multiactors: Person;
}
};

A few things to note here.

- Our types don’t contain anidproperty; EdgeDB automatically creates this property and assigns a unique UUID
    to every object inserted into the database.

**1.1. Quickstart 5**


- TheMovietype includes a **link** namedactors. In EdgeDB, links are used to represent relationships between
    object types. They eliminate the need for foreign keys; later, you’ll see just how easy it is to write “deep” queries
    without JOINs.
- The object types are inside amodulecalleddefault. You can split up your schema into logical subunits called
    modules, though it’s common to define the entire schema in a single module calleddefault.

Now we’re ready to run a migration to apply this schema to the database.

#### 1.1.4 4. Run a migration

Generate a migration file withedgedb migration create. This command gathers up our*.esdlfiles and sends
them to the database. The _database itself_ parses these files, compares them against its current schema, and generates
a migration plan! Then the database sends this plan back to the CLI, which creates a migration file.

$ edgedb migration create
Created ./dbschema/migrations/00001.edgeql (id: <hash>)

**Note:** If you’re interested, open this migration file to see what’s inside! It’s a simple EdgeQL script consisting of _DDL_
commands likecreate type,alter type, andcreate property.

The migration file has been _created_ but we haven’t _applied it_ against the database. Let’s do that.

$ edgedb migrate
Applied m1k54jubcs62wlzfebn3pxwwngajvlbf6c6qfslsuagkylg2fzv2lq (00001.edgeql)

Looking good! Let’s make sure that worked by runningedgedb list typeson the command line. This will print a
table containing all currently-defined object types.

$ edgedb list types

```
Name Extending
```
```
default::Movie std::BaseObject, std::Object
default::Person std::BaseObject, std::Object
```
Before we proceed, let’s try making a small change to our schema: making thetitleproperty ofMovierequired.
First, update the schema file:

```
type Movie {
```
- property title -> str;
+ required property title -> str;
    multi link actors -> Person;
}

```
type Movie {
```
- title: str;
+ required title: str;
    multi actors: Person;
}

Then create another migration. Because this isn’t the initial migration, we see something a little different than before.

**6 Chapter 1. Get Started**


$ edgedb migration create
did you make property'title' of object type'default::Movie'
required? [y,n,l,c,b,s,q,?]
>

As before, EdgeDB parses the schema files and compared them against its current internal schema. It correctly detects
the change we made, and prompts us to confirm it. This interactive process lets you sanity check every change and
provide guidance when a migration is ambiguous (e.g. when a property is renamed).

Enteryto confirm the change.

$ edgedb migration create
did you make property'title' of object type'default::Movie'
required? [y,n,l,c,b,s,q,?]
> y
Please specify an expression to populate existing objects in
order to make property'title'of object type 'default::Movie' required:
fill_expr>

Hm, now we’re seeing another prompt. Becausetitleis changing from _optional_ to _required_ , EdgeDB is asking us
what to do for all theMovieobjects that don’t currently have a value fortitledefined. We’ll just specify a placeholder
value:"Untitled".

fill_expr> "Untitled"
Created dbschema/migrations/00002.edgeql (id: <hash>)

If we look at the generated migration file, we see it contains the following lines:

ALTER TYPE default::Movie {
ALTER PROPERTY title {
SET REQUIRED USING("Untitled");
};
};

Let’s wrap up by applying the new migration.

$ edgedb migrate
Applied m1rd2ikgwdtlj5ws7ll6rwzvyiui2xbrkzig4adsvwy2sje7kxeh3a (00002.edgeql)

#### 1.1.5 5. Write some queries

Let’s write some simple queries via _EdgeDB UI_ , the admin dashboard baked into every EdgeDB instance (v2.0+ only).
To open the dashboard:

$ edgedb ui
Opening URL in browser:
[http://localhost:107xx/ui?authToken=<jwt](http://localhost:107xx/ui?authToken=<jwt) token>

You should see a simple landing page, as below. You’ll see a card for each database running on your in-
stance—remember: each instance can contain multiple databases!

**1.1. Quickstart 7**


Currently, there’s only one database, which is simply callededgedbby default. Click theedgedbcard.

Then clickOpen REPLso we can start writing some queries. We’ll start simple:select "Hello world!". Click
RUNto execute the query.

**8 Chapter 1. Get Started**


The query should appear in the “query notebook” on the right, along with the result of the query.

Now let’s actuallyinsertan object into our database. Copy the following query into the query textarea and hitRun.

insert Movie {
title := "Dune"
};

Nice! You’ve officially inserted the first object into your database! Let’s add a couple cast members with anupdate
query.

update Movie
filter .title = "Dune"
set{
actors := {
(insert Person { name := "Timothee Chalamet" }),
(insert Person { name := "Zendaya" })
}
};

Finally, we can run aselectquery to fetch all the data we just inserted.

select Movie {
title,
actors: {
name
}
};

ClickCOPY AS JSONto copy the result of this query to your clipboard. It will look something like this:

**1.1. Quickstart 9**


[
{
"title": "Dune",
"actors": [
{ "name": "Timothee Chalamet" },
{ "name": "Zendaya" }
]
}
]

EdgeDB UI is a useful development tool, but in practice your application will likely be using one of EdgeDB’s _client
libraries_ to execute queries. EdgeDB provides official libraries for JavaScript/TypeScript, Go, Python, Rust, and C#
and F#. Check out the _Clients_ guide to get started with the language of your choice.

#### 1.1.6 Onwards and upwards

You now know the basics of EdgeDB! You’ve installed the CLI and database, set up a local project, run a couple
migrations, inserted and queried some data, and used a client library.

- For a more in-depth exploration of each topic covered here, continue reading the other pages in the Getting
    Started section, which will cover important topics like migrations, the schema language, and EdgeQL in greater
    detail.
- For guided tours of major concepts, check out the showcase pages for Data Modeling, EdgeQL, and Migrations.
- For a deep dive into the EdgeQL query language, check out the Interactive Tutorial.
- For an immersive, comprehensive walkthrough of EdgeDB concepts, check out our illustrated e-book Easy
    EdgeDB; it’s designed to walk a total beginner through EdgeDB, from the basics all the way through advanced
    concepts.
- To start building an application using the language of your choice, check out our client libraries for
    JavaScript/TypeScript, Python, and Go.
- Or just jump into the _docs_!

### 1.2 The CLI

Theedgedbcommand line tool is an integral part of the developer workflow of building with EdgeDB. Below are
instructions for installing it.

#### 1.2.1 Installation

To get started with EdgeDB, the first step is install theedgedbCLI.

**Linux or macOS**

$ curl --proto'=https' --tlsv1.2 -sSf https://sh.edgedb.com | sh

**Windows Powershell**

**Note:** EdgeDB on Windows requires WSL 2 because the EdgeDB server runs on Linux.

**10 Chapter 1. Get Started**


PS> iwr https://ps1.edgedb.com -useb | iex

Follow the prompts on screen to complete the installation. The script will download theedgedbcommand built for
your OS and add a path to it to your shell environment. Then test the installation:

$ edgedb --version
EdgeDB CLI 2.x+abcdefg

**Note:** If you encounter acommand not founderror, you may need to open a fresh shell window.

**Note:** To install the CLI with a package manager, refer to the “Additional methods” section of the Install page for
instructions.

#### 1.2.2 Seehelpcommands

The entire CLI is self-documenting. Once it’s installed, runedgedb --helpto see a breakdown of all the commands
and options.

$ edgedb --help
EdgeDB CLI
Use the edgedb command-line tool to spin up local instances, manage EdgeDB
projects, create and apply migrations, and more.

Running edgedb without a subcommand opens an interactive shell.

USAGE:
edgedb [OPTIONS] [SUBCOMMAND]

OPTIONS:
<list of options>

CONNECTION OPTIONS (edgedb --help-connect to see the full list):
<list of connection options>

SUBCOMMANDS:
<list of all major commands>

The majority of CLI commands perform some action against a _particular_ EdgeDB instance. As such, there are a
standard set of flags that are used to specify _which instance_ should be the target of the command, plus additional
information like TLS certificates. The following command documents these flags.

$ edgedb --help-connect
-I, --instance <instance>
Local instance name created with edgedb instance create to connect to
(overrides host and port)
--dsn <dsn>
DSN for EdgeDB to connect to (overrides all other options except
password)
--credentials-file <credentials_file>
(continues on next page)

**1.2. The CLI 11**


(continued from previous page)
Path to JSON file to read credentials from
-H, --host <host>
Host of the EdgeDB instance
-P, --port <port>
Port to connect to EdgeDB
--unix-path <unix_path>
Unix socket dir for the
-u, --user <user>
User name of the EdgeDB user
-d, --database <database>
Database name to connect to
--password
Ask for password on the terminal (TTY)
--no-password
Don't ask for password

If you ever want to see documentation for a particular command (edgedb migration create) or group of commands
(edgedb instance), just append the--helpflag.

$ edgedb instance --help
Manage local EdgeDB instances

USAGE:
edgedb instance <SUBCOMMAND>

OPTIONS:
-h, --help Print help information

SUBCOMMANDS:
create Initialize a new EdgeDB instance
credentials Echo credentials to connect to the instance
destroy Destroy an instance and remove the data
link Link a remote instance
list Show all instances

#### 1.2.3 Upgrade the CLI

To upgrade to the latest version:

$ edgedb cli upgrade

**12 Chapter 1. Get Started**


### 1.3 Instances

Let’s get to the good stuff. You can spin up an EdgeDB instance with a single command.

$ edgedb instance create my_instance

This creates a new instance namedmy_instancethat runs the latest stable version of EdgeDB. (EdgeDB itself will be
automatically installed if it isn’t already.) Alternatively you can specify a specific version with--version.

$ edgedb instance create my_instance --version 2.1
$ edgedb instance create my_instance --version nightly

We can execute a query against our new instance withedgedb query. Specify which instance to connect to by passing
an instance name into the-Iflag.

$ edgedb query "select 3.14" -I my_instance
3.14

#### 1.3.1 Creating databases

A single EdgeDB _instance_ can contain multiple _databases_. Upon creation, an instance contains a single database called
edgedb. All queries and CLI commands are executed against this database unless otherwise specified.

To create a new database:

$ edgedb database create newdb -I my_instance

We can now execute queries against this new database by specifying it with the--database/-dflag.

$ edgedb query "select 3.14" -I my_instance -d newdb
3.14

#### 1.3.2 Managing instances

Instances can be stopped, started, restarted, and destroyed.

$ edgedb instance stop -I my_instance
$ edgedb instance start -I my_instance
$ edgedb instance restart -I my_instance
$ edgedb instance destroy -I my_instance

#### 1.3.3 Listing instances

To list all instances on your machine:

$ edgedb instance list

```
Kind Name Port Version Status
```
```
local my_instance 10700 2.x+8421216 active
(continues on next page)
```
**1.3. Instances 13**


```
(continued from previous page)
local my_instance_2 10701 2.x+8421216 active
local my_instance_3 10702 2.x+8421216 active
```
#### 1.3.4 Further reference

For complete documentation on managing instances with the CLI (upgrading, viewing logs, etc.), refer to the _edgedb
instance_ reference or view the help text in your shell:

$ edgedb instance --help

### 1.4 Projects

It can be inconvenient to pass the-Iflag every time you wish to run a CLI command.

$ edgedb migration create -I my_instance

That’s one of the reasons we introduced the concept of an _EdgeDB project_. A project is a directory on your file system
that is associated (“linked”) with an EdgeDB instance.

**Note:** Projects are intended to make _local development_ easier! They only exist on your local machine and are managed
with the CLI. When deploying EdgeDB for production, you will typically pass connection information to the client
library using environment variables.

When you’re inside a project, all CLI commands will be applied against the _linked instance_ by default (no CLI flags
required).

$ edgedb migration create

The same is true for all EdgeDB client libraries (discussed in more depth in the _Clients_ section). If the following file
lives inside an EdgeDB project directory,createClientwill discover the project and connect to its linked instance
with no additional configuration.

// clientTest.js
import {createClient}from'edgedb';

constclient = createClient();
awaitclient.query("select 5");

**14 Chapter 1. Get Started**


#### 1.4.1 Initializing

To initialize a project, create a new directory and runedgedb project initinside it. You’ll see something like this:

$ edgedb project init
No `edgedb.toml` found in this repo or above.
Do you want to initialize a new project? [Y/n]
> Y
Specify the version of EdgeDB to use with this project [2.x]:
> # (left blank for default)
Specify the name of EdgeDB instance to use with this project:
> my_instance
Initializing EdgeDB instance...
Bootstrap complete. Server is up and running now.
Project initialialized.

This command does a couple important things.

1. It spins up a new EdgeDB instance calledmy_instance.
2. If noedgedb.tomlfile exists, it will create one. This is a configuration file that indicates that a given directory
    is an EdgeDB project. Currently it only supports a single setting:server-version.

```
[edgedb]
server-version = "2.1"
```
3. If nodbschemadirectory exists, it will be created, along with an emptydefault.esdlfile which will contain
    your schema. If adbschemadirectory exists and contains a subdirectory calledmigrations, those migrations
    will be applied against the new instance.

Every project maps one-to-one to a particular EdgeDB instance. From inside a project directory, you can runedgedb
project infoto see information about the current project.

$ edgedb project info

```
Instance name my_instance
Project root /path/to/project
```
#### 1.4.2 Connection

As long as you are inside the project directory, all CLI commands will be executed against the project-linked instance.
For instance, you can simply runedgedbto open a REPL.

$ edgedb
EdgeDB 2.x+88c1706 (repl 2.x+a7fc49b)
Type \help for help, \quit to quit.
edgedb> select "Hello world!";

By contrast, if you leave the project directory, the CLI will no longer know which instance to connect to. You can solve
this by specifing an instance name with the-Iflag.

$ cd ~
$ edgedb
(continues on next page)

**1.4. Projects 15**


```
(continued from previous page)
```
ClientNoCredentialsError: no `edgedb.toml` found and no
connection options are specified
Hint: Run`edgedb project init`or use any of `-H`,`-P`,`-I` arguments
to specify connection parameters. See`--help` for details
$ edgedb -I my_instance
EdgeDB 2.x+88c1706 (repl 2.x+a7fc49b)
Type \help for help, \quit to quit.
edgedb>

Similarly, client libraries will auto-connect to the project’s linked instance without additional configuration.

#### 1.4.3 Using remote instances

You may want to initialize a project that points to a remote EdgeDB instance. This is totally a valid case and EdgeDB
fully supports it! Before runningedgedb project init, you just need to create an alias for the remote instance using
edgedb instance link, like so:

$ edgedb instance link
Specify the host of the server [default: localhost]:
> 192.168.4.2
Specify the port of the server [default: 5656]:
> 10818
Specify the database user [default: edgedb]:
> edgedb
Specify the database name [default: edgedb]:
> edgedb
Unknown server certificate: SHA1:c38a7a90429b033dfaf7a81e08112a9d58d97286.
Trust? [y/N]
> y
Password for'edgedb':
Specify a new instance name for the remote server [default: abcd]:
> staging_db
Successfully linked to remote instance. To connect run:
edgedb -I staging_db

After receving the necessary connection information, this command links the remote instance to a local alias
"staging_db". You can use this as instance name in CLI commands.

$ edgedb -I staging_db
edgedb>

To initialize a project that uses the remote instance, provide this alias when prompted for an instance name during the
edgedb project initworkflow.

**16 Chapter 1. Get Started**


#### 1.4.4 Unlinking

An instance can be unlinked from a project. This leaves the instance running but effectively “uninitializes” the project.
Theedgedb.tomlanddbschemaare left untouched.

$ edgedb project unlink

If you wish to delete the instance as well, use the-Dflag.

$ edgedb project unlink -D

#### 1.4.5 Upgrading

A standalone instance (not linked to a project) can be upgraded with theedgedb instance upgradecommand.

$ edgedb project upgrade --to-latest
$ edgedb project upgrade --to-nightly
$ edgedb project upgrade --to-version 2.x

#### 1.4.6 See info

You can see the location of a project and the name of its linked instance.

$ edgedb project info

```
Instance name my_app
Project root /path/to/my_app
```
### 1.5 Schema

This page is indended as a rapid-fire overview of EdgeDB’s schema definition language (SDL) so you can hit the ground
running with EdgeDB. Refer to the linked pages for more in-depth documentation!

#### 1.5.1 Scalar types

EdgeDB implements a rigorous type system containing the following primitive types.

```
Strings str
Booleans bool
Numbers int32 int64 float32 float64 bigint decimal
UUID uuid
JSON json
Dates and times datetime cal::local_datetime cal::local_date cal::local_time
Durations duration cal::relative_duration cal::date_duration
Binary data bytes
Auto-incrementing counters sequence
Enums enum<x, y, z>
```
**1.5. Schema 17**


These primitives can be combined into arrays, tuples, and ranges.

```
Arrays array<str>
Tuples (unnamed) tuple<str, int64, bool>
Tuples (named) tuple<name: str, age: int64, is_awesome: bool>
Ranges range<float64>
```
Collectively, _primitive_ and _collection_ types comprise EdgeDB’s _scalar type system_.

#### 1.5.2 Object types

Object types are analogous to tables in SQL. The can contain **properties** —which can correspond to any scalar type—
and **links** —which correspond to other object types.

#### 1.5.3 Properties

Thepropertykeyword is used to declare a property.

typeMovie {
property title -> str;
}

typeMovie {
title: str;
}

See _Schema > Object types_.

##### 1.5.3.1 Required vs optional

Properties are optional by default. Use therequiredkeyword to make them required.

typeMovie {
required property title -> str; # required
property release_year -> int64; # optional
}

typeMovie {
required title: str; # required
release_year: int64; # optional
}

See _Schema > Properties_.

**18 Chapter 1. Get Started**


##### 1.5.3.2 Constraints

Add a pair of curly braces after the property to define additional information, including constraints.

typeMovie {
required property title -> str {
constraintexclusive;
constraintmin_len_value(8);
constraintregexp(r'^[A-Za-z0-9 ]+$');
}
}

typeMovie {
required title: str {
constraintexclusive;
constraintmin_len_value(8);
constraintregexp(r'^[A-Za-z0-9 ]+$');
}
}

See _Schema > Constraints_.

##### 1.5.3.3 Computed properties

Object types can contain _computed properties_ that correspond to EdgeQL expressions. This expression is dynamically
computed whenever the property is queried.

typeMovie {
required property title -> str;
property uppercase_title := str_upper(.title);
}

typeMovie {
required title: str;
property uppercase_title := str_upper(.title);
}

See _Schema > Computeds_.

#### 1.5.4 Links

Object types can have links to other object types.

typeMovie {
required property title -> str;
link director -> Person;
}

typePerson {
required property name -> str;
}

**1.5. Schema 19**


typeMovie {
required title: str;
director: Person;
}

typePerson {
required name: str;
}

Use therequiredandmultikeywords to specify the cardinality of the relation.

typeMovie {
required property title -> str;

link cinematographer -> Person; # zero or one
required link director -> Person; # exactly one
multi link writers -> Person; # zero or more
required multi link actors -> Person; # one or more
}

typePerson {
required property name -> str;
}

typeMovie {
required title: str;

cinematographer: Person; # zero or one
required director: Person; # exactly one
multi writers: Person; # zero or more
required multi actors: Person; # one or more
}

typePerson {
required name: str;
}

To define a one-to-one relation, use anexclusiveconstraint.

typeMovie {
required property title -> str;
required link stats -> MovieStats {
constraintexclusive;
};
}

typeMovieStats {
required property budget -> int64;
required property box_office -> int64;
}

typeMovie {
required title: str;
(continues on next page)

**20 Chapter 1. Get Started**


(continued from previous page)
required stats: MovieStats {
constraintexclusive;
};
}

typeMovieStats {
required budget: int64;
required box_office: int64;
}

See _Schema > Links_.

##### 1.5.4.1 Computed links

Objects can contain “computed links”: stored expressions that return a set of objects. Computed links are dynamically
computed when they are referenced in queries. The example below defines a backlink.

typeMovie {
required property title -> str;
multi link actors -> Person;

# returns all movies with same title
multi link same_title := (
witht := .title
select detached Moviefilter .title = t
)
}

typeMovie {
required title: str;
multi actors: Person;

# returns all movies with same title
multi link same_title := (
witht := .title
select detached Moviefilter .title = t
)
}

##### 1.5.4.2 Backlinks

A common use case for computed links is _backlinks_.

typeMovie {
required property title -> str;
multi link actors -> Person;
}

typePerson {
required property name -> str;
(continues on next page)

**1.5. Schema 21**


(continued from previous page)
multi link acted_in := .<actors[is Movie];
}

typeMovie {
required title: str;
multi actors: Person;
}

typePerson {
required name: str;
multi link acted_in := .<actors[is Movie];
}

The computed linkacted_inreturns allMovieobjects with a link calledactorsthat points to the currentPerson.
The easiest way to understand backlink syntax is to split it into two parts:

.<actorsThis uses a special syntax.<to return all objects in the database with a link calledactorsthat points to
the current object. This set could conceivably contain other objects besidesMovie; for instance, we could define
aTVShowtype that also includedlink actors -> Person.

[is Movie]This is a _type filter_ that filters out all objects that aren’tMovieobjects. A backlink still works without
this filter, but could contain any other number of objects besides``Movie``objects.

See _Schema > Computeds > Backlinks_.

#### 1.5.5 Constraints

Constraints can also be defined at the _object level_.

typeBlogPost {
property title -> str;
link author -> User;

constraint exclusiveon ((.title, .author));
}

typeBlogPost {
title: str;
author: User;

constraint exclusiveon ((.title, .author));
}

Constraints can contain exceptions; these are called _partial constraints_.

typeBlogPost {
property title -> str;
property published -> bool;

constraint exclusiveon (.title)except (not.published);
}

**22 Chapter 1. Get Started**


typeBlogPost {
title: str;
published: bool;

constraint exclusiveon (.title)except (not.published);
}

#### 1.5.6 Indexes

Useindex onto define indexes on an object type.

typeMovie {
required property title -> str;
required property release_year -> int64;

index on (.title); # simple index
index on ((.title, .release_year)); # composite index
index on (str_trim(str_lower(.title))); # computed index
}

typeMovie {
required title: str;
required release_year: int64;

index on (.title); # simple index
index on ((.title, .release_year)); # composite index
index on (str_trim(str_lower(.title))); # computed index
}

Theidproperty, all links, and all properties withexclusiveconstraints are automatically indexed.

See _Schema > Indexes_.

#### 1.5.7 Schema mixins

Object types can be declared asabstract. Non-abstract types can _extend_ abstract types.

abstract typeContent {
required property title -> str;
}

typeMovie extendingContent {
required property release_year -> int64;
}

typeTVShow extendingContent {
required property num_seasons -> int64;
}

abstract typeContent {
required title: str;
(continues on next page)

**1.5. Schema 23**


```
(continued from previous page)
```
}

typeMovie extendingContent {
required release_year: int64;
}

typeTVShow extendingContent {
required num_seasons: int64;
}

Multiple inheritance is supported.

abstract typeHasTitle {
required property title -> str;
}

abstract typeHasReleaseYear {
required property release_year -> int64;
}

typeMovie extendingHasTitle, HasReleaseYear {
link sequel_to -> Movie;
}

abstract typeHasTitle {
required title: str;
}

abstract typeHasReleaseYear {
required release_year: int64;
}

typeMovie extendingHasTitle, HasReleaseYear {
sequel_to: Movie;
}

See _Schema > Object types > Inheritance_.

#### 1.5.8 Polymorphism

Links can correspond to abstract types. These are known as _polymorphic links_.

abstract typeContent {
required property title -> str;
}

typeMovie extendingContent {
required property release_year -> int64;
}

typeTVShow extendingContent {
(continues on next page)

**24 Chapter 1. Get Started**


(continued from previous page)
required property num_seasons -> int64;
}

typeFranchise {
required property name -> str;
multi link entries -> Content;
}

abstract typeContent {
required title: str;
}

typeMovie extendingContent {
required release_year: int64;
}

typeTVShow extendingContent {
required num_seasons: int64;
}

typeFranchise {
required name: str;
multi entries: Content;
}

See _Schema > Links > Polymorphism_ and _EdgeQL > Select > Polymorphic queries_.

### 1.6 Migrations

```
index migrations fill_expr cast_expr
```
EdgeDB’s baked-in migration system lets you painlessly evolve your schema throughout the development process. If
you want to work along with this guide, start a new project withedgedb project init. This will create a new
instance and create some empty schema files to get you started.

The recommended workflow has been improved in version 3.0, so if you’re running our beta, try the new workflow
instead.

#### 1.6.1 1. Write an initial schema

By convention, your EdgeDB schema is defined inside one or more.esdlfiles that live in a directory calleddbschema
in the root directory of your codebase.

.
dbschema
default.esdl # schema file (written by you)
migrations # migration files (typically generated by CLI)
00001.edgeql
...
edgedb.toml

**1.6. Migrations 25**


The schema itself is written using EdgeDB’s schema definition language.

typeUser {
required property name -> str;
}

typePost {
required property title -> str;
required link author -> User;
}

typeUser {
required name: str;
}

typePost {
required title: str;
required author: User;
}

It’s common to keep your entire schema in a single file, typically calleddefault.esdl. However it’s also possible to
split it across a number of.esdlfiles.

To spin up a new instance and populate it with an initial schema, execute the following commands in a fresh directory.

$ edgedb project init
Do you want to initialize a new project? [Y/n]
> Y
<additional prompts>
$ edgedb migration create
Created dbschema/migrations/00001.edgeql (id: <hash>)
$ edgedb migrate
Applied dbschema/migrations/00001.edgeql (id: <hash>)

#### 1.6.2 2. Edit your schema files

As your application evolves, directly edit your schema files to reflect your desired data model.

```
type User {
required property name -> str;
}
```
```
type BlogPost {
property title -> str;
required link author -> User;
}
```
+ type Comment {
+ required property content -> str;
+ }

**26 Chapter 1. Get Started**


```
type User {
required name: str;
}
```
```
type BlogPost {
title: str;
required author: User;
}
```
+ type Comment {
+ required content: str;
+ }

#### 1.6.3 3. Generate a migration

To generate a migration that reflects these changes, runedgedb migration create.

$ edgedb migration create

The CLI reads your schema file and sends it to the active EdgeDB instance. The instance compares the file’s contents
to its current schema state and determines a migration plan. **The migration plan is generated by the database itself.**

This plan is then presented to you interactively; each detected schema change will be individually presented to you for
approval. For each prompt, you have a variety of commands at your disposal. Typeyto approve,nto reject,qto cancel
the migration, or?for a breakdown of some more advanced options.

$ edgedb migration create
Did you create object type'default::Comment'? [y,n,l,c,b,s,q,?]
> y
Created dbschema/migrations/00002.edgeql (id: <hash>)

#### 1.6.4 4. Apply the migration

We’ve generated a migration file, but we haven’t yet applied it against our database! The following command will apply
all unapplied migration files:

$ edgedb migrate
Applied m1virjowa... (00002.edgeql)

That’s it! You’ve created and applied your first EdgeDB migration. Your instance is now using the latest schema.

#### 1.6.5 Data migrations

Depending on how the schema was changed, you may be prompted to provide an EdgeQL expression to map the
contents of your database to the new schema. To see this happen, let’s make thetitlepropertyrequired.

```
type User {
required property name -> str;
}
```
```
(continues on next page)
```
**1.6. Migrations 27**


```
(continued from previous page)
type BlogPost {
```
- property title -> str;
+ required property title -> str;
    required link author -> User;
}

```
type User {
required name: str;
}
```
```
type BlogPost {
```
- title: str;
+ required title: str;
    required author: User;
}

Then we’ll create another migration.

$ edgedb migration create
Did you make property'title' of object type
'default::BlogPost' required? [y,n,l,c,b,s,q,?]
> y
Please specify an expression to populate existing objects in order to make
property'title' of object type'default::Post'required:
fill_expr>

Becausetitleis currently optional, the database may contain blog posts without atitleproperty. The expression
you provide will be used to _assign a title_ to any post that doesn’t have one. We’ll just provide a simple default title:
'Untitled'.

fill_expr> 'Untitled'
Created dbschema/migrations/00002.edgeql, id:
m1yt3gbstvyfzy2rhqt5335ld6br2amw7ywqu2bvjiqsacbcdxzyya

Nice! It accepted our answer and created a new migration file00002.edgeql. Let’s see what the newly created
00002.edgeqlfile contains.

CREATE MIGRATIONm1yt3gbstvyfzy2rhqt5335ld6br2amw7ywqu2bvjiqsacbcdxzyya
ONTO m1cvx47vntfoy24evwrdli7o5unarx2c5t3i2rfspd2qosi6d6iahq
{
ALTER TYPE default::Post {
ALTER PROPERTY title {
SET REQUIRED USING ('Untitled');
};
};
};

We have aCREATE MIGRATIONblock containing anALTER TYPEstatement to makePost.title required. We can
see that our fill expression ('Untitled') is included directly in the migration file.

Note that we could have provide an _arbitrary EdgeQL expression_! The following EdgeQL features are often useful:

**28 Chapter 1. Get Started**


```
assert_exists This is an “escape hatch” function that tells EdgeDB to
assume the input has at least one element.
fill_expr> assert_exists(.title)
If you provide afill_exprlike the one above, you must
separately ensure that all movies have a title before exe-
cuting the migration; otherwise it will fail.
assert_single This tells EdgeDB to assume the input has at most one
element. This will throw an error if the argument is a set
containing more than one element. This is useful is you
are changing a property frommultitosingle.
fill_expr> assert_single(.sheep)
```
```
type casts Useful when converting a property to a different type.
cast_expr> <bigint>.xp
```
##### 1.6.5.1 Further reading

For guides on advanced migration workflows, refer to the following guides.

- _Making a property required_
- _Adding backlinks_
- _Changing the type of a property_
- _Changing a property to a link_
- _Adding a required link_

For more information on how migrations work in EdgeDB, check out the _CLI reference_ or the Beta 1 blog post, which
describes the design of the migration system.

### 1.7 EdgeQL

EdgeQL is the query language of EdgeDB. It’s intended as a spiritual successor to SQL that solves some of its biggest
design limitations. This page is intended as a rapid-fire overview so you can hit the ground running with EdgeDB.
Refer to the linked pages for more in-depth documentation.

Want to follow along with the queries below? Open the Interactive Tutorial in a separate tab. Copy and paste the queries
below and execute them directly from the browser.

**Note:** The examples below also demonstrate how to express the query with the _TypeScript client’s_ query builder, which
lets you express arbitrary EdgeQL queries in a code-first, typesafe way.

**1.7. EdgeQL 29**


#### 1.7.1 Scalar literals

EdgeDB has a rich primitive type system consisting of the following data types.

```
Strings str
Booleans bool
Numbers int32 int64 float32 float64 bigint decimal
UUID uuid
JSON json
Dates and times datetime cal::local_datetime cal::local_date cal::local_time
Durations duration cal::relative_duration cal::date_duration
Binary data bytes
Auto-incrementing counters sequence
Enums enum<x, y, z>
```
Basic literals can be declared using familiar syntax.

```
Listing 1: edgeql-repl
```
db>select "i edgedb";# str
{'i edgedb'}
db>select false;# bool
{false}
db>select 42;# int64
{42}
db>select 3.14;# float64
{3.14}
db>select 12345678n;# bigint
{12345678n}
db>select 15.0e+100n; # decimal
{15.0e+100n}
db>select b'bina\\x01ry';# bytes
{b'bina\\x01ry'}

```
Listing 2: typescript
```
e.str("i edgedb")
// string
e.bool(false)
// boolean
e.int64(42)
// number
e.float64(3.14)
// number
e.bigint(BigInt(12345678))
// bigint
e.decimal("1234.4567")
// n/a (not supported by JS clients)
e.bytes(Buffer.from("bina\\x01ry"))
// Buffer

Other type literals are declared by _casting_ an appropriately structured string.

**30 Chapter 1. Get Started**


```
Listing 3: edgeql-repl
```
db>select <uuid>'a5ea6360-75bd-4c20-b69c-8f317b0d2857';
{a5ea6360-75bd-4c20-b69c-8f317b0d2857}
db>select <datetime>'1999-03-31T15:17:00Z';
{<datetime>'1999-03-31T15:17:00Z'}
db>select <duration>'5 hours 4 minutes 3 seconds';
{<duration>'5:04:03'}
db>select <cal::relative_duration>'2 years 18 days';
{<cal::relative_duration>'P2Y18D'}

```
Listing 4: typescript
```
e.uuid("a5ea6360-75bd-4c20-b69c-8f317b0d2857")
// string
e.datetime("1999-03-31T15:17:00Z")
// Date
e.duration("5 hours 4 minutes 3 seconds")
// edgedb.Duration (custom class)
e.cal.relative_duration("2 years 18 days")
// edgedb.RelativeDuration (custom class)

Primitive data can be composed into arrays and tuples, which can themselves be nested.

```
Listing 5: edgeql-repl
```
db>select ['hello', 'world'];
{['hello', 'world']}
db>select ('Apple', 7, true);
{('Apple', 7,true)} # unnamed tuple
db>select (fruit :='Apple', quantity := 3.14, fresh := true);
{(fruit := 'Apple', quantity := 3.14, fresh := true)}# unnamed tuple
db>select <json>["this", "is", "an", "array"];
{"[\"this\", \"is\", \"an\", \"array\"]"}

```
Listing 6: typescript
```
e.array(["hello", "world"]);
// string[]
e.tuple(["Apple", 7,true]);
// [string, number, boolean]
e.tuple({fruit: "Apple", quantity:3.14, fresh:true});
// {fruit: string; quantity: number; fresh: boolean}
e.json(["this", "is", "an", "array"]);
// unknown

EdgeDB also supports a specialjsontype for representing unstructured data. Primitive data structures can be converted
to JSON using a type cast (<json>). Alternatively, a properly JSON-encoded string can be converted tojsonwith the
built-into_jsonfunction. Indexing ajsonvalue returns anotherjsonvalue.

**1.7. EdgeQL 31**


```
Listing 7: edgeql-repl
```
edgedb>select<json>5;
{"5"}
edgedb>select<json>[1,2,3];
{"[1, 2, 3]"}
edgedb>selectto_json('[{ "name": "Peter Parker" }]');
{"[{\"name\": \"Peter Parker\"}]"}
edgedb>selectto_json('[{ "name": "Peter Parker" }]')[0]['name'];
{"\"Peter Parker\""}

```
Listing 8: typescript
```
/*
The result of an query returning `json` is represented
with `unknown`in TypeScript.
*/
e.json(5); // => unknown
e.json([1, 2, 3]); // => unknown
e.to_json('[{ "name": "Peter Parker" }]'); // => unknown
e.to_json('[{ "name": "Peter Parker" }]')[0]["name"]; // => unknown

Refer to _Docs > EdgeQL > Literals_ for complete docs.

#### 1.7.2 Functions and operators

EdgeDB provides a rich standard library of functions to operate and manipulate various data types.

```
Listing 9: edgeql-repl
```
db>select str_upper('oh hi mark');
{'OH HI MARK'}
db>select len('oh hi mark');
{10}
db>select uuid_generate_v1mc();
{c68e3836-0d59-11ed-9379-fb98e50038bb}
db>select contains(['a','b','c'], 'd');
{false}

```
Listing 10: typescript
```
e.str_upper("oh hi mark");
// string
e.len("oh hi mark");
// number
e.uuid_generate_v1mc();
// string
e.contains(["a", "b", "c"], "d");
// boolean

Similarly, it provides a comprehensive set of built-in operators.

**32 Chapter 1. Get Started**


```
Listing 11: edgeql-repl
```
db>select not true;
{false}
db>select exists'hi';
{true}
db>select 2 + 2;
{4}
db>select 'Hello'++ ' world!';
{'Hello world!'}
db>select ''if true else '';
{''}
db>select <duration>'5 minutes' + <duration>'2 hours';
{<duration>'2:05:00'}

```
Listing 12: typescript
```
e.op("not", e.bool(true));
// booolean
e.op("exists", e.set("hi"));
// boolean
e.op("exists", e.cast(e.str, e.set()));
// boolean
e.op(e.int64(2), "+", e.int64(2));
// number
e.op(e.str("Hello "), "++", e.str("World!"));
// string
e.op(e.str(""), "if", e.bool(true), "else", e.str(""));
// string
e.op(e.duration("5 minutes"), "+", e.duration("2 hours"))

See _Docs > Standard Library_ for reference documentation on all built-in types, including the functions and operators
that apply to them.

#### 1.7.3 Insert an object

Objects are created usinginsert. Theinsertstatement relies on developer-friendly syntax like curly braces and the
:=operator.

```
Listing 13: edgeql
```
insert Movie {
title := 'Doctor Strange 2',
release_year := 2022
};

```
Listing 14: typescript
```
constquery = e.insert(e.Movie, {
title: 'Doctor Strange 2',
release_year: 2022
});
(continues on next page)

**1.7. EdgeQL 33**


```
(continued from previous page)
```
constresult =await query.run(client);
// {id: string}
// by default INSERT only returns
// the id of the new object

See _Docs > EdgeQL > Insert_.

#### 1.7.4 Nested inserts

One of EdgeQL’s greatest features is that it’s easy to compose. Nested inserts are easily achieved with subqueries.

```
Listing 15: edgeql
```
insert Movie {
title := 'Doctor Strange 2',
release_year := 2022,
director := (insert Person {
name :='Sam Raimi'
})
};

```
Listing 16: typescript
```
constquery = e.insert(e.Movie, {
title: 'Doctor Strange 2',
release_year: 2022 ,
director: e.insert(e.Person, {
name:'Sam Raimi'
})
});

constresult =await query.run(client);
// {id: string}
// by default INSERT only returns
// the id of the new object

#### 1.7.5 Select objects

Use a _shape_ to define which properties toselectfrom the given object type.

```
Listing 17: edgeql
```
select Movie {
id,
title
};

**34 Chapter 1. Get Started**


```
Listing 18: typescript
```
constquery = e.select(e.Movie, () => ({
id:true,
title: true
}));
constresult =await query.run(client);
// {id: string; title: string; }[]

// To select all properties of an object, use the
// spread operator with the special "*"" property:
constquery = e.select(e.Movie, () => ({
...e.Movie['*']
}));

Fetch linked objects with a nested shape.

```
Listing 19: edgeql
```
select Movie {
id,
title,
actors: {
name
}
};

```
Listing 20: typescript
```
constquery = e.select(e.Movie, () => ({
id:true,
title: true,
actors: {
name:true,
}
}));

constresult =await query.run(client);
// {id: string; title: string, actors: {name: string}[]}[]

See _Docs > EdgeQL > Select > Shapes_.

#### 1.7.6 Filtering, ordering, and pagination

Theselectstatement can be augmented withfilter,order by,offset, andlimitclauses (in that order).

```
Listing 21: edgeql
```
select Movie {
id,
title
}
(continues on next page)

**1.7. EdgeQL 35**


```
(continued from previous page)
```
filter .release_year > 2017
order by.title
offset 10
limit10;

```
Listing 22: typescript
```
constquery = e.select(e.Movie, (movie) => ({
id:true,
title: true,
filter:e.op(movie.release_year, ">", 1999),
order_by: movie.title,
offset: 10 ,
limit: 10 ,
}));

constresult =await query.run(client);
// {id: string; title: number}[]

Note that you reference properties of the object to include in yourselectby prepending the property name with a
period:.release_year. This is known as _leading dot notation_.

Every new set of curly braces introduces a new scope. You can addfilter,limit, andoffsetclauses to nested
shapes.

```
Listing 23: edgeql
```
select Movie {
title,
actors: {
name
} filter .nameilike'chris%'
}
filter .titleilike '%avengers%';

**36 Chapter 1. Get Started**


```
Listing 24: typescript
```
e.select(e.Movie, movie => ({
title: true,
characters:c => ({
name:true,
filter:e.op(c.name, "ilike", "chris%"),
}),
filter:e.op(movie.title, "ilike", "%avengers%"),
}));
// => { characters: { name: string; }[]; title: string; }[]

constresult =await query.run(client);
// {id: string; title: number}[]

See _Filtering_ , _Ordering_ , and _Pagination_.

#### 1.7.7 Query composition

We’ve seen how toinsertandselect. How do we do both in one query? Answer: query composition. EdgeQL’s
syntax is designed to be _composable_ , like any good programming language.

```
Listing 25: edgeql
```
select (
insert Movie { title :='The Marvels'}
) {
id,
title
};

```
Listing 26: typescript
```
constnewMovie = e.insert(e.Movie, {
title: "The Marvels"
});
constquery = e.select(newMovie, () => ({
id:true,
title: true
}));

constresult =await query.run(client);
// {id: string; title: string}

We can clean up this query by pulling out theinsertstatement into awithblock. Awithblock is useful for composing
complex multi-step queries, like a script.

```
Listing 27: edgeql
```
withnew_movie := (insert Movie { title :='The Marvels'})
select new_movie {
id,
(continues on next page)

**1.7. EdgeQL 37**


(continued from previous page)
title
};

```
Listing 28: typescript
```
/*
Same as above.

In the query builder, explicit ``with``blocks aren't necessary!
Just assign your EdgeQL subqueries to variables and compose them as you
like. The query builder automatically convert your top-level query to an
EdgeQL expression with proper``with``blocks.
*/

#### 1.7.8 Computed properties

Selection shapes can contain computed properties.

```
Listing 29: edgeql
```
select Movie {
title,
title_upper := str_upper(.title),
cast_size := count(.actors)
};

```
Listing 30: typescript
```
e.select(e.Movie, movie => ({
title: true,
title_upper:e.str_upper(movie.title),
cast_size: e.count(movie.actors)
}))
// {title: string; title_upper: string; cast_size: number}[]

A common use for computed properties is to query a link in reverse; this is known as a _backlink_ and it has special
syntax.

```
Listing 31: edgeql
```
select Person {
name,
acted_in := .<actors[is Content] {
title
}
};

```
Listing 32: typescript
```
e.select(e.Person, person => ({
name: true,
(continues on next page)

**38 Chapter 1. Get Started**


(continued from previous page)
acted_in: e.select(person["<actors[is Content]"], () => ({
title: true,
})),
}));
// {name: string; acted_in: {title: string}[];}[]

See _Docs > EdgeQL > Select > Computed_ and _Docs > EdgeQL > Select > Backlinks_.

#### 1.7.9 Update objects

Theupdatestatement accepts afilterclause up-front, followed by asetshape indicating how the matching objects
should be updated.

```
Listing 33: edgeql
```
update Movie
filter .title = "Doctor Strange 2"
set{
title := "Doctor Strange in the Multiverse of Madness"
};

```
Listing 34: typescript
```
constquery = e.update(e.Movie, (movie) => ({
filter:e.op(movie.title,'=', 'Doctor Strange 2'),
set: {
title: 'Doctor Strange in the Multiverse of Madness',
},
}));

constresult =await query.run(client);
// {id: string}

When updating links, the set of linked objects can be added to with+=, subtracted from with-=, or overwritten with
:=.

```
Listing 35: edgeql
```
update Movie
filter .title = "Doctor Strange 2"
set{
actors += (select Personfilter .name = "Rachel McAdams")
};

```
Listing 36: typescript
```
e.update(e.Movie, (movie) => ({
filter:e.op(movie.title,'=', 'Doctor Strange 2'),
set: {
actors: {
"+=": e.select(e.Person, person => ({
filter:e.op(person.name, "=", "Rachel McAdams")
(continues on next page)

**1.7. EdgeQL 39**


(continued from previous page)
}))
}
},
}));

See _Docs > EdgeQL > Update_.

#### 1.7.10 Delete objects

Thedeletestatement can containfilter,order by,offset, andlimitclauses.

```
Listing 37: edgeql
```
delete Movie
filter .ilike "the avengers%"
limit3;

```
Listing 38: typescript
```
constquery = e.delete(e.Movie, (movie) => ({
filter:e.op(movie.title,'ilike', "the avengers%"),
}));

constresult =await query.run(client);
// {id: string}[]

See _Docs > EdgeQL > Delete_.

#### 1.7.11 Query parameters

You can reference query parameters in your queries with$<name>notation. Since EdgeQL is a strongly typed language,
all query parameters must be prepending with a _type cast_ to indicate the expected type.

**Note:** Scalars likestr,int64, andjsonare supported. Tuples, arrays, and object types are not.

```
Listing 39: edgeql
```
insert Movie {
title := <str>$title,
release_year := <int64>$release_year
};

```
Listing 40: typescript
```
constquery = e.params({ title:e.str, release_year:e.int64}, ($) => {
return e.insert(e.Movie, {
title: $.title,
release_year:$.release_year,
}))
(continues on next page)

**40 Chapter 1. Get Started**


```
(continued from previous page)
```
};

constresult =await query.run(client, {
title: 'Thor: Love and Thunder',
release_year: 2022 ,
});
// {id: string}

All client libraries provide a dedicated API for specifying parameters when executing a query.

```
Listing 41: javascript
```
import {createClient}from"edgedb";

constclient = createClient();
constresult =await client.query(`select <str>$param`, {
param: "Play it, Sam."
});
// => "Play it, Sam."

```
Listing 42: python
```
import edgedb

client = edgedb.create_async_client()

async def main():

```
result =awaitclient.query("select <str>$param", param="Play it, Sam")
# => "Play it, Sam"
```
```
Listing 43: go
```
packagemain

import (
"context"
"log"

"github.com/edgedb/edgedb-go"
)

funcmain() {
ctx := context.Background()
client, err := edgedb.CreateClient(ctx, edgedb.Options{})
if err != nil{
log.Fatal(err)
}
deferclient.Close()

```
var(
param string = "Play it, Sam."
(continues on next page)
```
**1.7. EdgeQL 41**


```
(continued from previous page)
result string
)
```
query := "select <str>$0"
err = client.Query(ctx, query, &result, param)
// ...
}

See _Docs > EdgeQL > Parameters_.

#### 1.7.12 Subqueries

Unlike SQL, EdgeQL is _composable_ ; queries can be naturally nested. This is useful, for instance, when performing
nested mutations.

```
Listing 44: edgeql
```
with
dr_strange := (select Moviefilter .title = "Doctor Strange"),
benedicts := (selectPerson filter .namein {
'Benedict Cumberbatch',
'Benedict Wong'
})
update dr_strange
set{
actors += benedicts
};

```
Listing 45: typescript
```
// select Doctor Strange
constdrStrange = e.select(e.Movie, movie => ({
filter:e.op(movie.title,'=', "Doctor Strange")
}));

// select actors
constactors = e.select(e.Person, person => ({
filter:e.op(person.name,'in', e.set(
'Benedict Cumberbatch',
'Benedict Wong'
))
}));

// add actors to cast of drStrange
constquery = e.update(drStrange, ()=>({
actors: { "+=": actors }
}));

We can also use subqueries to fetch properties of an object we just inserted.

**42 Chapter 1. Get Started**


Listing 46: edgeql
withnew_movie := (insertMovie {
title := "Avengers: The Kang Dynasty",
release_year := 2025
})
select new_movie {
title, release_year
};

```
Listing 47: typescript
```
// "with" blocks are added automatically
// in the generated query!

constnewMovie = e.insert(e.Movie, {
title: "Avengers: The Kang Dynasty",
release_year: 2025
});

constquery = e.select(newMovie, ()=>({
title: true,
release_year: true,
}));

constresult =await query.run(client);
// {title: string; release_year: number;}

See _Docs > EdgeQL > Select > Subqueries_.

#### 1.7.13 Polymorphic queries

Consider the following schema.

abstract typeContent {
required property title -> str;
}

typeMovie extendingContent {
property release_year -> int64;
}

typeTVShow extendingContent {
property num_seasons -> int64;
}

abstract typeContent {
required title: str;
}

typeMovie extendingContent {
release_year: int64;
(continues on next page)

**1.7. EdgeQL 43**


```
(continued from previous page)
```
}

typeTVShow extendingContent {
num_seasons: int64;
}

We canselectthe abstract typeContentto simultaneously fetch all objects that extend it, and use the[is <type>]
syntax to select properties from known subtypes.

```
Listing 48: edgeql
```
select Content {
title,
[isTVShow].num_seasons,
[isMovie].release_year
};

```
Listing 49: typescript
```
constquery = e.select(e.Content, (content) => ({
title: true,
...e.is(e.Movie, {release_year: true}),
...e.is(e.TVShow, {num_seasons: true}),
}));
/* {
title: string;
release_year: number | null;
num_seasons: number | null;
}[] */

See _Docs > EdgeQL > Select > Polymorphic queries_.

#### 1.7.14 Grouping objects

Unlike SQL, EdgeQL provides a top-levelgroupstatement to compute groupings of objects.

```
Listing 50: edgeql
```
groupMovie { title, actors: { name }}
by .release_year;

```
Listing 51: typescript
```
e.group(e.Movie, (movie) => {
const release_year = movie.release_year;
return {
title: true,
by: {release_year},
};
});
/* {
grouping: string[];
(continues on next page)

**44 Chapter 1. Get Started**


(continued from previous page)
key: { release_year: number | null };
elements: { title: string; }[];
}[] */

See _Docs > EdgeQL > Group_.

### 1.8 Client Libraries

EdgeDB implements libraries for popular languages that make it easier to work with EdgeDB. These libraries provide
a common set of functionality.

- _Instantiating clients._ Most libraries implement aClientclass that internally manages a pool of physical con-
    nections to your EdgeDB instance.
- _Resolving connections._ All client libraries implement a standard protocol for determining how to connect to your
    database. In most cases, this will involve checking for special environment variables likeEDGEDB_DSN. (More
    on this in the Connection section below.)
- _Executing queries._ AClientwill provide some methods for executing queries against your database. Under the
    hood, this query is executed using EdgeDB’s efficient binary protocol.

**Note:** For some use cases, you may not need a client library. EdgeDB allows you to execute _queries over HTTP_. This
is slower than the binary protocol and lacks support for transactions and rich data types, but may be suitable if a client
library isn’t available for your language of choice.

#### 1.8.1 Available libraries

To execute queries from your application code, use one of EdgeDB’s _client libraries_ for the following languages.

- JavaScript/TypeScript
- Go
- Python
- Rust
- .NET

Unofficial (community-maintained) libraries are available for the following languages.

- Elixir

#### 1.8.2 Usage

To follow along with the guide below, first create a new directory and initialize a project.

$ mydir myproject
$ cd myproject
$ edgedb project init

Configure the environment as needed for your preferred language.

**1.8. Client Libraries 45**


```
Listing 52: Node.js
```
$ npm init -y
$ tsc --init # (TypeScript only)
$ touch index.ts

```
Listing 53: Deno
```
$ touch index.ts

```
Listing 54: Python
```
$ python -m venv venv
$ source venv/bin/activate
$ touch main.py

```
Listing 55: Rust
```
$ cargo init

```
Listing 56: Go
```
$ go mod init example/quickstart
$ touch hello.go

```
Listing 57: .NET
```
$ dotnet new console -o. -f net6.0

Install the EdgeDB client library.

```
Listing 58: Node.js
```
$ npm install edgedb # npm
$ yarn add edgedb # yarn

```
Listing 59: Deno
```
n/a

```
Listing 60: Python
```
$ pip install edgedb

```
Listing 61: Rust
```
# Cargo.toml

[dependencies]
edgedb-tokio = "0.3.0"
# additional dependencies
tokio = { version = "1", features = ["full"] }
(continues on next page)

**46 Chapter 1. Get Started**


```
(continued from previous page)
```
anyhow = "1.0.63"

```
Listing 62: Go
```
$ go get github.com/edgedb/edgedb-go

```
Listing 63: .NET
```
$ dotnet add package EdgeDB.Net.Driver

Copy and paste the following simple script. This script initializes aClientinstance. Clients manage an internal pool
of connections to your database and provide a set of methods for executing queries.

**Note:** Note that we aren’t passing connection information (say, a connection URL) when creating a client. The client
libraries can detect that they are inside a project directory and connect to the project-linked instance automatically. For
details on configuring connections, refer to the _Connection_ section below.

```
Listing 64: Node.js
```
import {createClient}from'edgedb';

constclient = createClient();

client.querySingle(`select random()`).then((result) => {
console.log(result);
});

```
Listing 65: Deno
```
import {createClient}from'https://deno.land/x/edgedb';

constclient = createClient();

constresult =await client.querySingle(`select random()`);
console.log(result);

```
Listing 66: python
```
from edgedb import create_client

client = create_client()

result = client.query_single("select random()")
print(result)

```
Listing 67: rust
```
// src/main.rs
#[tokio::main]
async fnmain() ->anyhow::Result<()> {
(continues on next page)

**1.8. Client Libraries 47**


(continued from previous page)
letconn = edgedb_tokio::create_client().await?;
letval = conn
.query_required_single::<f64, _>("select random()", &())
.await?;
println!("Result: {}", val);
Ok(())
}

```
Listing 68: go
```
// hello.go
packagemain

import (
"context"
"fmt"
"log"

"github.com/edgedb/edgedb-go"
)

funcmain() {
ctx := context.Background()
client, err := edgedb.CreateClient(ctx, edgedb.Options{})
if err != nil{
log.Fatal(err)
}
defer client.Close()

```
varresult float64
err = client.
QuerySingle(ctx, "select random();", &result)
if err != nil{
log.Fatal(err)
}
```
fmt.Println(result)
}

```
Listing 69: .NET
```
using EdgeDB;

varclient =newEdgeDBClient();
varresult =awaitclient.QuerySingleAsync<double>("select random();");
Console.WriteLine(result);

Finally, execute the file.

**48 Chapter 1. Get Started**


```
Listing 70: Node.js
```
$ npx tsx index.ts

```
Listing 71: Deno
```
$ deno run --allow-all --unstable index.deno.ts

```
Listing 72: Python
```
$ python index.py

```
Listing 73: Rust
```
$ cargo run

```
Listing 74: Go
```
$ go run.

```
Listing 75: .NET
```
$ dotnet run

You should see a random number get printed to the console. This number was generated inside your EdgeDB instance
using EdgeQL’s built-inrandom()function.

#### 1.8.3 Connection

All client libraries implement a standard protocol for determining how to connect to your database.

##### 1.8.3.1 Using projects

In development, we recommend _initializing a project_ in the root of your codebase.

$ edgedb project init

Once the project is initialized, any code that uses an official client library will automatically connect to the project-
linked instance—no need for environment variables or hard-coded credentials. Follow the _Using projects_ guide to get
started.

##### 1.8.3.2 UsingEDGEDB_DSN

In production, connection information can be securely passed to the client library via environment variables. Most
commonly, you set a value forEDGEDB_DSN.

**Note:** If environment variables likeEDGEDB_DSNare defined inside a project directory, the environment variables will
take precedence.

A DSN is also known as a “connection string” and takes the following form.

**1.8. Client Libraries 49**


edgedb://<username>:<password>@<hostname>:<port>

Each element of the DSN is optional; in factedgedb://is a technically a valid DSN. Any unspecified element will
default to the following values.

```
<host> localhost
<port> 5656
<user> edgedb
<password> null
```
A typical DSN may look like this:

edgedb://username:pas$$word@db.domain.com:8080

DSNs can also contain the following query parameters.

```
database The database to connect to within the given instance.
Defaults toedgedb.
tls_security The TLS security mode. Accepts the following values.
```
- "strict"( **default** ) — verify certificates and
    hostnames
- "no_host_verification" — verify certifi-
    cates only
- "insecure"— trust self-signed certificates

```
tls_ca_file A filesystem path pointing to a CA root certificate. This
is usually only necessary when attempting to connect via
TLS to a remote instance with a self-signed certificate.
```
These parameters can be added to any DSN using Web-standard query string notation.

edgedb://user:pass@example.com:8080?database=my_db&tls_security=insecure

For a more comprehensive guide to DSNs, see the _DSN Specification_.

##### 1.8.3.3 Using multiple environment variables

If needed for your deployment pipeline, each element of the DSN can be specified independently.

- EDGEDB_HOST
- EDGEDB_PORT
- EDGEDB_USER
- EDGEDB_PASSWORD
- EDGEDB_DATABASE
- EDGEDB_TLS_CA_FILE
- EDGEDB_CLIENT_TLS_SECURITY

**Note:** If a value forEDGEDB_DSNis defined, it will override these variables!

**50 Chapter 1. Get Started**


##### 1.8.3.4 Other mechanisms

EDGEDB_CREDENTIALS_FILEA path to a.jsonfile containing connection information. In some scenarios (including
local Docker development) its useful to represent connection information with files.

```
{
"host": "localhost",
"port": 10700,
"user": "testuser",
"password": "testpassword",
"database": "edgedb",
"tls_cert_data": "-----BEGIN CERTIFICATE-----\nabcdef..."
}
```
EDGEDB_INSTANCE **(local only)** The name of a local instance. Only useful in development.

##### 1.8.3.5 Reference

These are the most common ways to connect to an instance, however EdgeDB supports several other options for ad-
vanced use cases. For a complete reference on connection configuration, see _Reference > Connection Parameters_.

EdgeDB is a next-generation graph-relational database designed as a spiritual successor to the relational database.

It inherits the strengths of SQL databases: type safety, performance, reliability, and transactionality. But instead of
modeling data in a relational (tabular) way, EdgeDB represents data with _object types_ containing _properties_ and _links_
to other objects. It leverages this object-oriented model to provide a superpowered query language that solves some of
SQL’s biggest usability problems.

### 1.9 How to read the docs

EdgeDB is a complex system, but we’ve structured the documentation so you can learn it in “phases”. You only need
to learn as much as you need to start building your application.

- **Get Started** — Start with the _quickstart_. It walks through EdgeDB’s core workflows: how to install EdgeDB,
    create an instance, write a simple schema, execute a migration, write some simple queries, and use the client
    libraries. The rest of the section goes deeper on each of these subjects.
- **Schema** — A set of pages that break down the concepts of syntax of EdgeDB’s schema definition language
    (SDL). This starts with a rundown of EdgeDB’s primitive type system ( _Primitives_ ), followed by a description of
    ( _Object Types_ ) and the things they can contain: links, properties, indexes, access policies, and more.
- **EdgeQL** — A set of pages that break down EdgeDB’s query language, EdgeQL. It starts with a rundown of how
    to declare _literal values_ , then introduces some key EdgeQL concepts like sets, paths, and type casts. With the
    basics established, it proceeds to break down all of EdgeQL’s top-level statements:select,insert, and so on.
- **Guides** — Contains collections of guides on topics that are peripheral to EdgeDB itself: how to deploy to
    various cloud providers, how to integrate with various frameworks, and how to introspect the schema to build
    code-generation tools on top of EdgeDB.
- **Standard Library** — This section contains an encyclopedic breakdown of EdgeDB’s built-in types and the
    functions/operators that can be used with them. We didn’t want to clutter the **EdgeQL** section with all the nitty-
    gritty on each of these. If you’re looking for a particular function (say, areplace), go to the Standard Library
    page for the relevant type (in this case, _String_ ), and peruse the table for what you’re looking for (str_replace()).

**1.9. How to read the docs 51**


- **Client Libraries** The documentation for EdgeDB’s set of official client libraries for JavaScript/TypeScript,
    Python, Go, and Rust. All client libraries implement EdgeDB’s binary protocol and provide a standard inter-
    face for executing queries. If you’re using another language, you can execute queries _over HTTP_. This section
    also includes documentation for EdgeDB’s _GraphQL_ endpoint.
- **CLI** Complete reference for theedgedbcommand-line tool. The CLI is self-documenting—add the--helpflag
    after any command to print the relevant documentation—so you shouldn’t need to reference this section often.
- **Reference** The _Reference_ section contains a complete breakdown of EdgeDB’s _syntax_ (for both EdgeQL and
    SDL), _internals_ (like the binary protocol and dump file format), and _configuration settings_. Usually you’ll only
    need to reference these once you’re an advanced user.
- **Changelog** Detailed changelogs for each successive version of EdgeDB, including any breaking changes, new
    features, bigfixes, and links to

### 1.10 Tooling

To actually build apps with EdgeDB, you’ll need to know more than SDL and EdgeQL.

- **CLI** — The most commonly used CLI functionality is covered in the _Quickstart_. For additional details, we have
    dedicated guides for _Migrations_ and _Projects_. A full CLI reference is available under _CLI_.
- **Client Libraries** — To actually execute queries, you’ll use one of our client libraries for JavaScript, Go, or
    Python; find your preferred library under _Client Libraries_. If you’re using another language, you can still use
    EdgeDB! You can execute _queries via HTTP_.
- **Deployment** — To publish an EdgeDB-backed application, you’ll need to deploy EdgeDB. Refer to _Guides >_
    _Deployment_ for step-by-step deployment guides for all major cloud hosting platforms, as well as instructions for
    self-hosting with Docker.

EdgeDB features:

- strict, strongly typed schema;
- powerful and clean query language;
- ability to easily work with complex hierarchical data;
- built-in support for schema migrations.

EdgeDB is not a graph database: the data is stored and queried using relational database techniques. Unlike most graph
databases, EdgeDB maintains a strict schema.

EdgeDB is not a document database, but inserting and querying hierarchical document-like data is trivial.

EdgeDB is not a traditional object database, despite the classification, it is not an implementation of OOP persistence.

**52 Chapter 1. Get Started**


```
CHAPTER
```
### TWO

### SCHEMA

### 2.1 Primitives

EdgeDB has a robust type system consisting of primitive and object types. Below is a review of EdgeDB’s primitive
types; later, these will be used to declare _properties_ on object types.

#### 2.1.1 Scalar types

```
str A variable-length string
bool Logical boolean (true/false)
int16 16-bit integer
int32 32-bit integer
int64 64-bit integer
float32 32-bit floating point number
float64 64-bit floating point number
bigint Arbitrary precision integer
decimal Arbitrary precision number
json Arbitrary JSON data
uuid UUID type
bytes Raw binary data
datetime Timezone-aware point in time
duration Absolute time span
cal::local_datetime Date and time without timezone
cal::local_date Date type
cal::local_time Time type
cal::relative_duration Relative time span (in months, days, and seconds)
cal::date_duration Relative time span (in months and days only)
sequence Auto-incrementing sequence ofint64
```
Custom scalar types can also be declared. For full documentation, see _SDL > Scalar types_.

```
53
```

#### 2.1.2 Enums

To represent an enum, declare a custom scalar that extends the abstract _enum_ type.

scalar typeColorextendingenum<Red, Green, Blue>;

typeShirt {
property color -> Color;
}

scalar typeColorextendingenum<Red, Green, Blue>;

typeShirt {
color: Color;
}

**Important:** To reference enum values inside EdgeQL queries, use dot notation, e.g.Color.Green.

For a full reference on enum types, see the _Enum docs_.

#### 2.1.3 Arrays

Arrays store zero or more primitive values of the same type in an ordered list. Arrays cannot contain object types or
other arrays.

typePerson {
property str_array -> array<str>;
property json_array -> array<json>;

```
# INVALID: arrays of object types not allowed
# property friends -> array<Person>
```
# INVALID: arrays cannot be nested
# property nested_array -> array<array<str>>
}

typePerson {
str_array: array<str>;
json_array: array<json>;

```
# INVALID: arrays of object types not allowed
# property friends -> array<Person>
```
# INVALID: arrays cannot be nested
# property nested_array -> array<array<str>>
}

For a full reference on array types, see the _Array docs_.

**54 Chapter 2. Schema**


#### 2.1.4 Tuples

Like arrays, tuples are ordered sequences of primitive data. Unlike arrays, each element of a tuple can have a distinct
type. Tuple elements can be _any type_ , including primitives, objects, arrays, and other tuples.

typePerson {

```
property unnamed_tuple -> tuple<str, bool, int64>;
property nested_tuple -> tuple<tuple<str, tuple<bool, int64>>>;
property tuple_of_arrays -> tuple<array<str>, array<int64>>;
```
}

typePerson {

```
unnamed_tuple: tuple<str, bool, int64>;
nested_tuple: tuple<tuple<str, tuple<bool, int64>>>;
tuple_of_arrays: tuple<array<str>, array<int64>>;
```
}

Optionally, you can assign a _key_ to each element of the tuple. Tuples containing explicit keys are known as _named
tuples_. You must assign keys to all elements (or none of them).

typeBlogPost {
property metadata -> tuple<title: str, published: bool, upvotes: int64>;
}

typeBlogPost {
metadata: tuple<title: str, published: bool, upvotes: int64>;
}

Named and unnamed tuples are the same data structure under the hood. You can add, remove, and change keys in a
tuple type after it’s been declared. For details, see _EdgeQL > Literals > Tuples_.

**Important:** When you query an _unnamed_ tuple using one of EdgeQL’s _client libraries_ , its value is converted to a
list/array. When you fetch a named tuple, it is converted into an object/dictionary/hashmap depending on the language.

#### 2.1.5 Ranges

Ranges represent some interval of values. The intervals can be bound or unbound on either end. They can also be
empty, containing no values. Only some scalar types have corresponding range types:

- range<int32>
- range<int64>
- range<float32>
- range<float64>
- range<decimal>
- range<datetime>

**2.1. Primitives 55**


- range<cal::local_datetime>
- range<cal::local_date>

typeDieRoll {
property values -> range<int64>;
}

typeDieRoll {
values: range<int64>;
}

For a full reference on ranges, functions and operators see the _Range docs_.

#### 2.1.6 Sequences

To represent an auto-incrementing integer property, declare a custom scalar that extends the abstractsequencetype.
Creating a sequence type initializes a globalint64counter that auto-increments whenever a new object is created. All
properties that point to the same sequence type will share the counter.

scalar typeticket_numberextendingsequence;
typeTicket {
property number -> ticket_number;
}

scalar typeticket_numberextendingsequence;
typeTicket {
number: ticket_number;
}

For a full reference on sequences, see the _Sequence docs_.

### 2.2 Object Types

_Object types_ are the primary components of an EdgeDB schema. They are analogous to SQL _tables_ or ORM _models_ ,
and consist of _properties_ and _links_.

Properties are used to attach primitive data to an object type. They are declared with thepropertykeyword. For the
full documentation on properties, see _Properties_.

typePerson {
property email -> str;
}

typePerson {
email: str;
}

Links are used to define relationships between object types. Prior to EdgeDB 3.0, they must be declared with the
linkkeyword, but the keyword is not required in 3.0+ unless the link is computed (e.g., backlinks). For the full
documentation on links, see _Links_.

**56 Chapter 2. Schema**


typePerson {
link best_friend -> Person;
}

typePerson {
best_friend: Person;
}

#### 2.2.1 IDs

There’s no need to manually declare a primary key on your object types. All object types automatically contain a
propertyidof typeUUIDthat’s _required_ , _globally unique_ , and _readonly_. Thisidis assigned upon creation and never
changes.

#### 2.2.2 Abstract types

Object types can either be _abstract_ or _non-abstract_. By default all object types are non-abstract. You can’t create or
store instances of abstract types, but they’re a useful way to share functionality and structure among other object types.

abstract typeHasName {
property first_name -> str;
property last_name -> str;
}

abstract typeHasName {
first_name: str;
last_name: str;
}

Abstract types are commonly used in tandem with inheritance.

#### 2.2.3 Inheritance

Object types can _extend_ other object types. The extending type (AKA the _subtype_ ) inherits all links, properties, indexes,
constraints, etc. from its _supertypes_.

abstract typeAnimal {
property species -> str;
}

typeDogextendingAnimal {
property breed -> str;
}

abstract typeAnimal {
species: str;
}

typeDogextendingAnimal {
(continues on next page)

**2.2. Object Types 57**


(continued from previous page)
breed: str;
}

##### 2.2.3.1 Multiple Inheritance

Object types can _extend more than one type_ — that’s called _multiple inheritance_. This mechanism allows building
complex object types out of combinations of more basic types.

abstract typeHasName {
property first_name -> str;
property last_name -> str;
}

abstract typeHasEmail {
property email -> str;
}

typePerson extendingHasName, HasEmail {
property profession -> str;
}

abstract typeHasName {
first_name: str;
last_name: str;
}

abstract typeHasEmail {
email: str;
}

typePerson extendingHasName, HasEmail {
profession: str;
}

If multiple supertypes share links or properties, those properties must be of the same type and cardinality.

**Note:** Refer to the dedicated pages on _Indexes_ , _Constraints_ , _Object-Level Security_ , and _Annotations_ for documentation
on these concepts.

```
See also
SDL > Object types
DDL > Object types
Introspection > Object types
Cheatsheets > Object types
```
**58 Chapter 2. Schema**


### 2.3 Properties

```
index property
```
Properties are used to associate primitive data with an _object type_ or _link_.

typePlayer {
property email -> str;
property points -> int64;
property is_online -> bool;
}

typePlayer {
email: str;
points: int64;
is_online: bool;
}

Properties are associated with a _key_ (e.g.first_name) and a primitive type (e.g.str). The term _primitive type_ is an
umbrella term that encompasses _scalar types_ likestrandbool, _enums_ , _arrays_ , and _tuples_.

#### 2.3.1 Required properties

Properties can be eitheroptional(the default) orrequired.

typeUser {
required property email -> str;
}

typeUser {
required email: str;
}

#### 2.3.2 Property cardinality

Properties have a **cardinality** , eithersingle(the default) ormulti. Amultiproperty of typestrpoints to an
_unordered set_ of strings.

typeUser {

```
# single isn't necessary here
# properties are single by default
single property name -> str;
```
```
# an unordered set of strings
multi property nicknames -> str;
```
# an unordered set of string arrays
multi property set_of_arrays -> array<str>;
}

**2.3. Properties 59**


typeUser {

```
# single isn't necessary here
# properties are single by default
single name: str;
```
```
# an unordered set of strings
multi nicknames: str;
```
# an unordered set of string arrays
multi set_of_arrays: array<str>;
}

**Comparison to arrays**

The values associated with amultiproperty are stored in no particular order. If order is important, use an _array_.
Otherwise,multiproperties are recommended. For a more involved discussion, see _EdgeQL > Sets_.

#### 2.3.3 Default values

Properties can have a default value. This default can be a static value or an arbitrary EdgeQL expression, which will
be evaluated upon insertion.

typePlayer {
required property points -> int64 {
default:= 0;
}

required property latitude -> float64 {
default:= (360 * random() - 180);
}
}

typePlayer {
required points: int64 {
default:= 0;
}

required latitude: float64 {
default:= (360 * random() - 180);
}
}

**60 Chapter 2. Schema**


#### 2.3.4 Readonly properties

Properties can be marked asreadonly. In the example below, theUser.external_idproperty can be set at the time
of creation but not modified thereafter.

typeUser {
required property external_id -> uuid {
readonly :=true;
}
}

typeUser {
required external_id: uuid {
readonly :=true;
}
}

#### 2.3.5 Constraints

Properties can be augmented wth constraints. The example below showcases a subset of EdgeDB’s built-in constraints.

typeBlogPost {
property title -> str {
constraintexclusive; # all post titles must be unique
constraintmin_len_value(8);
constraintmax_len_value(30);
constraintregexp(r'^[A-Za-z0-9 ]+$');
}

```
property status -> str {
constraintone_of('Draft','InReview', 'Published');
}
```
property upvotes -> int64 {
constraintmin_value(0);
constraintmax_value(9999);
}
}

typeBlogPost {
title: str {
constraintexclusive; # all post titles must be unique
constraintmin_len_value(8);
constraintmax_len_value(30);
constraintregexp(r'^[A-Za-z0-9 ]+$');
}

```
status: str {
constraintone_of('Draft','InReview', 'Published');
}
```
```
upvotes: int64 {
(continues on next page)
```
**2.3. Properties 61**


(continued from previous page)
constraintmin_value(0);
constraintmax_value(9999);
}
}

You can constrain properties with arbitrary _EdgeQL_ expressions returningbool. To reference the value of the property,
use the special scope keyword__subject__.

typeBlogPost {
property title -> str {
constraint expression on(
__subject__ = str_trim(__subject__)
);
}
}

typeBlogPost {
title: str {
constraint expression on(
__subject__ = str_trim(__subject__)
);
}
}

The constraint above guarantees thatBlogPost.titledoesn’t contain any leading or trailing whitespace by checking
that the raw string is equal to the trimmed version. It uses the built-instr_trim()function.

For a full reference of built-in constraints, see the _Constraints reference_.

#### 2.3.6 Annotations

Properties can contain annotations, small human-readable notes. The built-in annotations aretitle,description,
anddeprecated. You may also declare _custom annotation types_.

typeUser {
property email -> str {
annotationtitle := 'Email address';
annotationdescription := "The user's email address.";
annotationdeprecated := 'Use NewUser instead.';
}
}

typeUser {
email: str {
annotationtitle := 'Email address';
annotationdescription := "The user's email address.";
annotationdeprecated := 'Use NewUser instead.';
}
}

**62 Chapter 2. Schema**


#### 2.3.7 Abstract properties

Properties can be _concrete_ (the default) or _abstract_. Abstract properties are declared independent of a source or target,
can contain _annotations_ , and can be marked asreadonly.

abstract propertyemail_prop {
annotation title :='An email address';
readonly :=true;
}

typeStudent {
# inherits annotations and "readonly := true"
property emailextendingemail_prop -> str;
}

abstract propertyemail_prop {
annotation title :='An email address';
readonly :=true;
}

typeStudent {
# inherits annotations and "readonly := true"
email: str {
extendingemail_prop;
};
}

#### 2.3.8 Link properties

Properties can also be defined on **links**. For a full guide, refer to _Guides > Using link properties_.

```
See also
SDL > Properties
DDL > Properties
Introspection > Object types
```
**2.3. Properties 63**


## 2.4 Links

```
index link one-to-one one-to-many many-to-one many-to-many
```
Links define a specific relationship between two _object types_.

### 2.4.1 Defining links

typePerson {
link best_friend -> Person;
}

typePerson {
best_friend: Person;
}

Links are _directional_ ; they have a source (the object type on which they are declared) and a _target_ (the type they point
to).

### 2.4.2 Link cardinality

All links have a cardinality: eithersingleormulti. The default issingle(a “to-one” link). Use themultikeyword
to declare a “to-many” link.

typePerson {
multi link friends -> Person;
}

typePerson {
multi friends: Person;
}

On the other hand, backlinks work in reverse to find objects that link to the object, and thus assumemultias a default.
Use thesinglekeyword to declare a “to-one” backlink.

typeAuthor {
link posts := .<authors[is Article];
}

typeCompanyEmployee {
single linkcompany := .<employees[isCompany];
}

**64 Chapter 2. Schema**


### 2.4.3 Required links

All links are eitheroptionalorrequired; the default isoptional. Use therequiredkeyword to declare a re-
quired link. A required link must point to _at least one_ target instance. In this scenario, everyPersonmust have a
best_friend:

typePerson {
required link best_friend -> Person;
}

typePerson {
required best_friend: Person;
}

Links with cardinalitymultican also berequired;required multilinks must point to _at least one_ target object.

typePerson {
property name -> str;
}

typeGroupChat {
required multi link members -> Person;
}

typePerson {
name: str;
}

typeGroupChat {
required multi members: Person;
}

In this scenario, eachGroupChatmust contain at least one person. Attempting to create aGroupChatwith no members
would fail.

### 2.4.4 Exclusive constraints

You can add anexclusiveconstraint to a link to guarantee that no other instances can link to the same target(s).

typePerson {
property name -> str;
}

typeGroupChat {
required multi link members -> Person {
constraintexclusive;
}
}

typePerson {
name: str;
}
(continues on next page)

**2.4. Links 65**


```
(continued from previous page)
```
typeGroupChat {
required multi members: Person {
constraintexclusive;
}
}

In theGroupChatexample, theGroupChat.memberslink is nowexclusive. TwoGroupChatobjects cannot link
to the samePerson; put differently, noPersoncan be amemberof multipleGroupChat.

### 2.4.5 Modeling relations

By combinining _link cardinality_ and _exclusivity constraints_ , we can model every kind of relationship: one-to-one,
one-to-many, many-to-one, and many-to-many.

```
Relation type Cardinality Exclusive
One-to-one single Yes
One-to-many multi Yes
Many-to-one single No
Many-to-many multi No
```
#### 2.4.5.1 Many-to-one

Many-to-one relationships typically represent concepts like ownership, membership, or hierarchies. For example,
PersonandShirt. One person may own many shirts, and a shirt is (usually) owned by just one person.

typePerson {
required property name -> str
}

typeShirt {
required property color -> str;
link owner -> Person;
}

typePerson {
required name: str
}

typeShirt {
required color: str;
owner: Person;
}

Since links aresingleby default, eachShirtonly corresponds to onePerson. In the absence of any exclusivity
constraints, multiple shirts can link to the samePerson. Thus, we have a one-to-many relationship betweenPerson
andShirt.

When fetching aPerson, it’s possible to deeply fetch their collection ofShirtsby traversing theShirt.ownerlink
_in reverse_. This is known as a **backlink** ; read the _select docs_ to learn more.

**66 Chapter 2. Schema**


#### 2.4.5.2 One-to-many

Conceptually, one-to-many and many-to-one relationships are identical; the “directionality” of a relation is just a matter
of perspective. Here, the same “shirt owner” relationship is represented with amultilink.

typePerson {
required property name -> str;
multi link shirts -> Shirt {
# ensures a one-to-many relationship
constraintexclusive;
}
}

typeShirt {
required property color -> str;
}

typePerson {
required name: str;
multi shirts: Shirt {
# ensures a one-to-many relationship
constraintexclusive;
}
}

typeShirt {
required color: str;
}

**Note:** Don’t forget the exclusive constraint! This is required to ensure that eachShirtcorresponds to a singlePerson.
Without it, the relationship will be many-to-many.

Under the hood, amultilink is stored in an intermediate association table, whereas asinglelink is stored as a column
in the object type where it is declared. As a result, single links are marginally more efficient. Generallysinglelinks
are recommended when modeling 1:N relations.

#### 2.4.5.3 One-to-one

Under a _one-to-one_ relationship, the source object links to a single instance of the target type, and vice versa. As an
example consider a schema to represent assigned parking spaces.

typeEmployee {
required property name -> str;
link assigned_space -> ParkingSpace {
constraintexclusive;
}
}

typeParkingSpace {
required property number -> int64;
}

**2.4. Links 67**


typeEmployee {
required name: str;
assigned_space: ParkingSpace {
constraintexclusive;
}
}

typeParkingSpace {
required number: int64;
}

All links aresingleunless otherwise specified, so noEmployeecan have more than oneassigned_space. Moreover,
theexclusiveconstraint guarantees that a givenParkingSpacecan’t be assigned to multiple employees at once.
Together thesingle linkand exclusivity constraint constitute a _one-to-one_ relationship.

#### 2.4.5.4 Many-to-many

A _many-to-many_ relation is the least constrained kind of relationship. There is no exclusivity or cardinality constraints
in either direction. As an example consider a simple app where aUsercan “like” their favoriteMovies.

typeUser {
required property name -> str;
multi link likes -> Movie;
}
typeMovie {
required property title -> str;
}

typeUser {
required name: str;
multi likes: Movie;
}
typeMovie {
required title: str;
}

A user can like multiple movies. And in the absence of anexclusiveconstraint, each movie can be liked by multiple
users. Thus this is a _many-to-many_ relationship.

### 2.4.6 Default values

Like properties, links can declare a default value in the form of an EdgeQL expression, which will be executed upon
insertion. In the example below, new people are automatically assigned three random friends.

typePerson {
required property name -> str;
multi link friends -> Person {
default:= (selectPerson order byrandom()limit3);
}
}

**68 Chapter 2. Schema**


typePerson {
required name: str;
multi friends: Person {
default:= (selectPerson order byrandom()limit3);
}
}

### 2.4.7 Link properties

Like object types, links in EdgeDB can contain **properties**. Link properties can be used to store metadata about links,
such as _when_ they were created or the _nature/strength_ of the relationship.

typePerson {
property name -> str;
multi link family_members -> Person {
propertyrelationship -> str;
}
}

typePerson {
name: str;
multi family_members: Person {
relationship: str;
}
}

Above, we model a family tree with a singlePersontype. ThePerson. family_memberslink is a many-to-many
relation; eachfamily_memberslink can contain a stringrelationshipdescribing the relationship of the two indi-
viduals.

Due to how they’re persisted under the hood, link properties must always besingleandoptional.

In practice, link properties are most useful with many-to-many relationships. In that situation there’s a significant differ-
ence between the _relationship_ described by the link and the _target object_. Thus it makes sense to separate properties of
the relationships and properties of the target objects. On the other hand, for one-to-one, one-to-many, and many-to-one
relationships there’s an exact correspondence between the link and one of the objects being linked. In these situations
any property of the relationship can be equally expressed as the property of the target object (for one-to-many and one-
to-one cases) or as the property of the source object (for many-to-one and one-to-one cases). It is generally advisable to
use object properties instead of link properties in these cases due to better ergonomics of selecting, updating, and even
casting intojsonwhen keeping all data in the same place rather than spreading it across link and object properties.

**Note:** For a full guide on modeling, inserting, updating, and querying link properties, see the _Using Link Properties_
guide.

**2.4. Links 69**


### 2.4.8 Deletion policies

Links can declare their own **deletion policy**. There are two kinds of events that might trigger these policies: _target
deletion_ and _source deletion_.

#### 2.4.8.1 Target deletion

Target deletion policies determine what action should be taken when the _target_ of a given link is deleted. They are
declared with theon target deleteclause.

typeMessageThread {
property title -> str;
}

typeMessage {
property content -> str;
link chat -> MessageThread {
on target delete delete source;
}
}

typeMessageThread {
title: str;
}

typeMessage {
content: str;
chat: MessageThread {
on target delete delete source;
}
}

TheMessage.chatlink in the example uses thedelete sourcepolicy. There are 4 available target deletion policies.

- restrict(default) - Any attempt to delete the target object immediately raises an exception.
- delete source- when the target of a link is deleted, the source is also deleted. This is useful for implementing
    cascading deletes.

```
Note: There is a limit to the depth of a deletion cascade due to an upstream stack size limitation.
```
- allow- the target object is deleted and is removed from the set of the link targets.
- deferred restrict- any attempt to delete the target object raises an exception at the end of the transaction,
    unless by that time this object is no longer in the set of link targets.

**70 Chapter 2. Schema**


#### 2.4.8.2 Source deletion

Source deletion policies determine what action should be taken when the _source_ of a given link is deleted. They are
declared with theon source deleteclause.

typeMessageThread {
property title -> str;
multi link messages -> Message {
on source delete delete target;
}
}

typeMessage {
property content -> str;
}

typeMessageThread {
title: str;
multi messages: Message {
on source delete delete target;
}
}

typeMessage {
content: str;
}

Under this policy, deleting aMessageThreadwill _unconditionally_ delete itsmessagesas well.

To avoid deleting aMessagethat is linked to by otherMessageThreadobjects via theirmessagelink, appendif
orphanto that link’s deletion policy.

```
type MessageThread {
property title -> str;
multi link messages -> Message {
```
- on source delete delete target;
+ on source delete delete target if orphan;
    }
}

```
type MessageThread {
title: str;
multi messages: Message {
```
- on source delete delete target;
+ on source delete delete target if orphan;
    }
}

**Note:** Deletion policies usingif orphanwill result in the target being deleted _unless it is linked by another object via
the same link the policy is on_. This qualifier does not apply globally across all links in the database or across different
links even if they’re on the same type. For example, aMessagemight be linked from both aMessageThreadand a
Channel. If theMessageThreadlinking to it is deleted, the deletion policy would still result in theMessagebeing
deleted as long as no otherMessageThreadobjects link to it on that same field. It is orphaned with respect to the

**2.4. Links 71**


MessageThreadtype’slinkfield, even though it is not orphaned globally.

Similarly, if theMessageThreadhad two links both linking to messages — maybe the existingmessageslink and
another calledrelatedto link other relatedMessageobjects that are not in the thread —if orphancould result
in linked messages being deleted even if they were also linked from anotherMessageThreadobject’srelatedlink
because they were orphaned with respect to themessageslink.

### 2.4.9 Polymorphic links

Links can haveabstracttargets, in which case the link is considered **polymorphic**. Consider the following schema:

abstract typePerson {
property name -> str;
}

typeHeroextending Person {
# additional fields
}

typeVillainextendingPerson {
# additional fields
}

abstract typePerson {
name: str;
}

typeHeroextending Person {
# additional fields
}

typeVillainextendingPerson {
# additional fields
}

TheabstracttypePersonhas two concrete subtypes:HeroandVillain. Despite being abstract,Personcan be
used as a link target in concrete object types.

typeMovie {
property title -> str;
multi link characters -> Person;
}

typeMovie {
title: str;
multi characters: Person;
}

In practice, theMovie.characterslink can point to aHero,Villain, or any other non-abstract subtype ofPerson.
For details on how to write queries on such a link, refer to the _Polymorphic Queries docs_

**72 Chapter 2. Schema**


### 2.4.10 Abstract links

It’s possible to defineabstractlinks that aren’t tied to a particular _source_ or _target_. If you’re declaring several links
with the same set of properties, annotations, constraints, or indexes, abstract links can be used to eliminate repetitive
SDL.

abstract linklink_with_strength {
property strength -> float64;
index on (__subject__@strength);
}

typePerson {
multi link friendsextendinglink_with_strength -> Person;
}

abstract linklink_with_strength {
strength: float64;
index on (__subject__@strength);
}

typePerson {
multi friends: Person {
extendinglink_with_strength;
};
}

```
See also
SDL > Links
DDL > Links
Introspection > Object types
```
## 2.5 Computeds

```
edb-alt-title Computed properties and links
```
**Important:** This section assumes a basic understanding of EdgeQL. If you aren’t familiar with it, feel free to skip this
page for now.

Object types can contain _computed_ links and properties. Computed properties and links are not persisted in the
database. Instead, they are evaluated _on the fly_ whenever that field is queried.

typePerson {
property name -> str;
property all_caps_name := str_upper(__subject__.name);
}

typePerson {
name: str;
property all_caps_name := str_upper(__subject__.name);
}

**2.5. Computeds 73**


Computed fields are associated with an EdgeQL expression. This expression can be an _arbitrary_ EdgeQL query. This
expression is evaluated whenever the field is referenced in a query.

**Note:** Computed fields don’t need to be pre-defined in your schema; you can drop them into individual queries as
well. They behave in exactly the same way. For more information, see the _EdgeQL > Select > Computeds_.

```
Warning: Volatile functions are not allowed in computed properties defined in schema. This means
that, for example, your schema-defined computed property cannot calldatetime_current(), but it can call
datetime_of_transaction()ordatetime_of_statement(). This does not apply to computed properties
outside of schema.
```
### 2.5.1 Leading dot notation

The example above used the special keyword__subject__to refer to the current object; it’s analogous tothisor
selfin many object-oriented languages.

However, explicitly using__subject__is optional here; inside the scope of an object type declaration, you can omit
it entirely and use the.<name>shorthand.

typePerson {
property first_name -> str;
property last_name -> str;
property full_name := .first_name ++' '++ .last_name;
}

typePerson {
first_name: str;
last_name: str;
property full_name := .first_name ++' '++ .last_name;
}

### 2.5.2 Type and cardinality inference

The type and cardinality of a computed field is _inferred_ from the expression. There’s no need for the modifier keywords
you use for non-computed fields (likemultiandrequired). However, it’s common to specify them anyway; it makes
the schema more readable and acts as a sanity check: if the provided EdgeQL expression disagrees with the modifiers,
an error will be thrown the next time you try to _create a migration_.

typePerson {
property first_name -> str;

# this is invalid, because first_name is not a required property
required property first_name_upper := str_upper(.first_name);
}

typePerson {
first_name: str;

```
(continues on next page)
```
**74 Chapter 2. Schema**


(continued from previous page)
# this is invalid, because first_name is not a required property
required property first_name_upper := str_upper(.first_name);
}

### 2.5.3 Common use cases

#### 2.5.3.1 Filtering

If you find yourself writing the samefilterexpression repeatedly in queries, consider defining a computed field that
encapsulates the filter.

typeClub {
multi link members -> Person;
multi link active_members := (
select .membersfilter.is_active =true
)
}

typePerson {
property name -> str;
property is_active -> bool;
}

typeClub {
multi members: Person;
multi link active_members := (
select .membersfilter.is_active =true
)
}

typePerson {
name: str;
is_active: bool;
}

#### 2.5.3.2 Backlinks

Backlinks are one of the most common use cases for computed links. In EdgeDB links are _directional_ ; they have a
source and a target. Often it’s convenient to traverse a link in the _reverse_ direction.

typeBlogPost {
property title -> str;
link author -> User;
}

typeUser {
property name -> str;
multi link blog_posts := .<author[is BlogPost]
}

**2.5. Computeds 75**


typeBlogPost {
title: str;
author: User;
}

typeUser {
name: str;
multi link blog_posts := .<author[is BlogPost]
}

TheUser.blog_posts expression above uses the _backlink operator_ .<in conjunction with a _type filter_ [is
BlogPost]to fetch all theBlogPostsassociated with a givenUser. For details on this syntax, see the EdgeQL
docs for _Backlinks_.

#### 2.5.3.3 Created Timestamp

Using a computed property, you can timestamp when an object was created in your database.

typeBlogPost {
property title -> str;
link author -> User;
required property created_at -> datetime {
readonly :=true;
default:= datetime_of_statement();
}
}

typeBlogPost {
title: str;
author: User;
required created_at: datetime {
readonly :=true;
default:= datetime_of_statement();
}
}

When aBlogPostis created,datetime_of_statement()will be called to supply it with a timestamp as the
created_atproperty. You might also considerdatetime_of_transaction()if that’s better suited to your use
case.

```
SDL > Links
DDL > Links
SDL > Properties
DDL > Properties
```
**76 Chapter 2. Schema**


## 2.6 Indexes

An index is a data structure used internally by a database to speed up filtering and sorting operations. Most commonly,
indexes are declared within object type declarations and reference a particular property; this will speed up any query
that references that property in afilterororder byclause.

**Note:** While improving query performance, indexes also increase disk and memory usage and slow down insertions
and updates. Creating too many indexes may be detrimental; only index properties you often filter or order by.

### 2.6.1 Index on a property

Below, we are referencing theUser.nameproperty with the _dot notation shorthand_ :.name.

typeUser {
required property name -> str;
index on (.name);
}

typeUser {
required name: str;
index on (.name);
}

By indexing onUser.name, queries that filter by thenameproperty will be faster, as the database can look up a name
in the index instead of scanning through all Users sequentially.

### 2.6.2 Index on an expression

Indexes may be defined using an arbitrary _singleton_ expression that references multiple properties of the enclosing
object type.

**Important:** A singleton expression is an expression that’s guaranteed to return _at most one_ element. As such, you
can’t index on amultiproperty.

typeUser {
required property first_name -> str;
required property last_name -> str;
index on (str_lower(.firstname +' '+ .lastname));
}

typeUser {
required first_name: str;
required last_name: str;
index on (str_lower(.firstname +' '+ .lastname));
}

**2.6. Indexes 77**


### 2.6.3 Index on multiple properties

A _composite index_ is an index that references multiple properties. This will speed up queries that filter or sort on _both
properties_. In EdgeDB, this is accomplished by indexing on atupleof properties.

typeUser {
required property name -> str;
required property email -> str;
index on ((.name, .email));
}

typeUser {
required name: str;
required email: str;
index on ((.name, .email));
}

### 2.6.4 Index on a link property

Link properties can also be indexed.

abstract linkfriendship {
property strength -> float64;
index on (__subject__@strength);
}

typeUser {
multi link friendsextendingfriendship -> User;
}

abstract linkfriendship {
strength: float64;
index on (__subject__@strength);
}

typeUser {
multi friends: User {
extendingfriendship;
};
}

### 2.6.5 Specify a Postgres index type

EdgeDB exposes Postgres indexes that you can use in your schemas. These are exposed through thepgmodule.

- pg::hash- Index based on a 32-bit hash derived from the indexed value
- pg::btree- B-tree index can be used to retrieve data in sorted order
- pg::gin- GIN is an “inverted index” appropriate for data values that contain multiple elements, such as arrays
    and JSON
- pg::gist- GIST index can be used to optimize searches involving ranges

**78 Chapter 2. Schema**


- pg::spgist- SP-GIST index can be used to optimize searches involving ranges and strings
- pg::brin- BRIN (Block Range INdex) index works with summaries about the values stored in consecutive
    physical block ranges in the database

You can use them like this:

typeUser {
required property name -> str;
index pg::spgiston (.name);
};

### 2.6.6 Annotate an index

Indexes can be augmented with annotations.

typeUser {
property name -> str;
index on (.name) {
annotationdescription := 'Indexing all users by name.';
};
}

typeUser {
name: str;
index on (.name) {
annotationdescription := 'Indexing all users by name.';
};
}

**Important: Foreign and primary keys**

In SQL databases, indexes are commonly used to index _primary keys_ and _foreign keys_. In EdgeDB, these fields are
automatically indexed; there’s no need to manually declare them. Moreover, any property with anexclusiveconstraint
is also automatically indexed.

```
See also
SDL > Indexes
DDL > Indexes
Introspection > Indexes
```
## 2.7 Constraints

**Important:** This section assumes a basic understanding of EdgeQL.

Constraints give users fine-grained control over which data is considered valid. They can be defined on _properties_ ,
_links_ , _object types_ , and _custom scalars_.

Below is a simple property constraint.

**2.7. Constraints 79**


typeUser {
required property username -> str {
constraintexclusive;
}
}

typeUser {
required username: str {
constraintexclusive;
}
}

This example uses a built-in constraint,exclusive. Refer to the table below for a complete list; click the name of a
given constraint for the full documentation.

```
exclusive Enforce uniqueness among all instances of the containing type
expression Custom constraint expression
one_of A list of allowable values
max_value Maximum value numerically/lexicographically
max_ex_value Maximum value numerically/lexicographically (exclusive range)
max_len_value Maximum length (strings only)
min_value Minimum value numerically/lexicographically
min_ex_value Minimum value numerically/lexicographically (exclusive range)
min_len_value Minimum length (strings only)
regexp Regex constraint (strings only)
```
### 2.7.1 Constraints on properties

Themax_len_valueconstraint below uses the built-inlen()function, which returns the length of a string.

typeUser {
required property username -> str {
# usernames must be unique
constraintexclusive;

# max length (built-in)
constraintmax_len_value(25);
};
}

typeUser {
required username: str {
# usernames must be unique
constraintexclusive;

# max length (built-in)
constraintmax_len_value(25);
};
}

**80 Chapter 2. Schema**


#### 2.7.1.1 Custom constraints

Theexpressionconstraint is used to define custom constraint logic. Inside custom constraints, the keyword
__subject__can used to reference the _value_ being constrained.

typeUser {
required property username -> str {
# max length (as custom constraint)
constraint expression on(len(__subject__) <= 25);
};
}

typeUser {
required username: str {
# max length (as custom constraint)
constraint expression on(len(__subject__) <= 25);
};
}

### 2.7.2 Constraints on object types

Constraints can be defined on object types. This is useful when the constraint logic must reference multiple links or
properties.

**Important:** Inside an object type declaration, you can omit__subject__and simply refer to properties with the
_leading dot notation_ (e.g..<name>).

typeConstrainedVector {
required property x -> float64;
required property y -> float64;

constraint expression on(
.x ^ 2 + .y ^ 2 <= 25
);
}

typeConstrainedVector {
required x: float64;
required y: float64;

constraint expression on(
.x ^ 2 + .y ^ 2 <= 25
);
}

Note that the constraint expression cannot contain arbitrary EdgeQL! Due to how constraints are implemented, you can
only referencesingle(non-multi) properties and links defined on the object type.

# Not valid!
typeUser {
(continues on next page)

**2.7. Constraints 81**


```
(continued from previous page)
required property username -> str;
multi link friends -> User;
```
# constraints cannot contain paths with more than one hop
constraint expression on('bob' in .friends.username);
}

# Not valid!
typeUser {
required username: str;
multi friends: User;

# constraints cannot contain paths with more than one hop
constraint expression on('bob' in .friends.username);
}

#### 2.7.2.1 Computed constraints

Constraints can be defined on computed properties.

typeUser {
required property username -> str;
required property clean_username := str_trim(str_lower(.username));

constraint exclusiveon (.clean_username);
}

typeUser {
required username: str;
required property clean_username := str_trim(str_lower(.username));

constraint exclusiveon (.clean_username);
}

#### 2.7.2.2 Composite constraints

To define a composite constraint, create anexclusiveconstraint on a tuple of properties or links.

typeUser {
property username -> str;
}

typeBlogPost {
property title -> str;
link author -> User;

constraint exclusiveon ((.title, .author));
}

**82 Chapter 2. Schema**


typeUser {
username: str;
}

typeBlogPost {
title: str;
author: User;

constraint exclusiveon ((.title, .author));
}

#### 2.7.2.3 Partial constraints

Constraints on object types can be made partial, so that they don’t apply when some condition holds.

typeUser {
required property username -> str;
property deleted -> bool;

# Usernames must be unique unless marked deleted
constraint exclusiveon (.username)except(.deleted);
}

typeUser {
required username: str;
deleted: bool;

# Usernames must be unique unless marked deleted
constraint exclusiveon (.username)except(.deleted);
}

### 2.7.3 Constraints on links

When defining a constraint on a link,__subject__refers to the _link itself_. This is commonly used add constraints to
_link properties_.

typeUser {
property name -> str;
multi link friends -> User {
single property strength -> float64;
constraint expression on(
__subject__@strength >= 0
);
}
}

typeUser {
name: str;
multi friends: User {
single strength: float64;
(continues on next page)

**2.7. Constraints 83**


(continued from previous page)
constraint expression on(
__subject__@strength >= 0
);
}
}

### 2.7.4 Constraints on custom scalars

Custom scalar types can be constrained.

scalar typeusernameextendingstr {
constraint regexp(r'^[A-Za-z0-9_]{4,20}$');
}

Note: you can’t useexclusiveconstraints on custom scalar types, as the concept of exclusivity is only defined in the
context of a given object type.

Useexpressionconstraints to declare custom constraints using arbitrary EdgeQL expressions. The example below
uses the built-instr_trim()function.

scalar typetitleextendingstr {
constraint expression on(
__subject__ = str_trim(__subject__)
);
}

```
See also
SDL > Constraints
DDL > Constraints
Introspection > Constraints
Standard Library > Constraints
Tutorial > Advanced EdgeQL > Constraints
```
## 2.8 Aliases

**Important:** This section assumes a basic understanding of EdgeQL. If you aren’t familiar with it, feel free to skip this
page for now.

An **alias** is a _pointer_ to a set of values. This set is defined with an arbitrary EdgeQL expression.

Like computed properties, this expression is evaluated on the fly whenever the alias is referenced in a query. Unlike
computed properties, aliases are defined independent of an object type; they are standalone expressions.

**Scalar alias**

aliasdigits := {0,1,2,3,4,5,6,7,8,9};

**Object type alias**

**84 Chapter 2. Schema**


The name of a given object type (e.g.User) is itself a pointer to the _set of all User objects_. After declaring the alias
below, you can useUserandUserAliasinterchangably.

aliasUserAlias := User;

**Object type alias with computeds**

Object type aliases can include a _shape_ that declare additional computed properties or links.

typePost {
required property title -> str;
}

aliasPostAlias := Post {
trimmed_title := str_trim(.title)
}

typePost {
required title: str;
}

aliasPostAlias := Post {
trimmed_title := str_trim(.title)
}

In effect, this creates a _virtual subtype_ of the base type, which can be referenced in queries just like any other type.

**Query alias**

Aliases can correspond to an arbitrary EdgeQL expression, including entire queries.

typeBlogPost {
required property title -> str;
required property is_published -> bool;
}

aliasPublishedPosts := (
select BlogPost
filter .is_published = true
);

typeBlogPost {
required title: str;
required is_published: bool;
}

aliasPublishedPosts := (
select BlogPost
filter .is_published = true
);

**Note:** All aliases are reflected in the database’s built-in _GraphQL schema_.

**2.8. Aliases 85**


```
See also
SDL > Aliases
DDL > Aliases
Cheatsheets > Aliases
```
## 2.9 Annotations

_Annotations_ are named values associated with schema items and are designed to hold arbitrary schema-level metadata
represented as astr.

### 2.9.1 Standard annotations

There are a number of annotations defined in the standard library. The following are the annotations which can be set
on any schema item:

- title
- description
- deprecated

For example, consider the following declaration:

typeStatus {
annotationtitle := 'Activity status';
annotationdescription := 'All possible user activities';

required propertyname -> str {
constraintexclusive
}
}

typeStatus {
annotationtitle := 'Activity status';
annotationdescription := 'All possible user activities';

requiredname: str {
constraintexclusive
}
}

Thedeprecatedannotation is used to mark deprecated items (e.g.str_rpad()) and to provide some information
such as what should be used instead.

**86 Chapter 2. Schema**


### 2.9.2 User-defined annotations

To declare a custom constraint type beyond the three built-ins, add an abstract annotation type to your schema. A custom
annotation could be used to attach arbitrary JSON-encoded data to your schema—potentially useful for introspection
and code generation.

abstract annotation admin_note;

typeStatus {
annotation admin_note :='system-critical';
}

```
See also
SDL > Annotations
DDL > Annotations
Cheatsheets > Annotations
Introspection > Object types
```
## 2.10 Globals

Schemas can contain scalar-typed _global variables_.

global current_user_id -> uuid;

global current_user_id: uuid;

These provide a useful mechanism for specifying session-level data that can be referenced in queries with theglobal
keyword.

select User {
id,
posts: { title, content }
}
filter .id =global current_user_id;

As in the example above, this is particularly useful for representing the notion of a session or “current user”.

### 2.10.1 Setting global variables

Global variables are set when initializing a client. The exact API depends on which client library you’re using.

```
Listing 1: typescript
```
import createClientfrom'edgedb';

constbaseClient = createClient()
constclientWithGlobals = baseClient.withGlobals({
current_user_id:'2141a5b4-5634-4ccc-b835-437863534c51',
});

awaitclientWithGlobals.query(`select global current_user_id;`);

**2.10. Globals 87**


```
Listing 2: python
```
from edgedb import create_client

client = create_client().with_globals({
'current_user_id':'580cc652-8ab8-4a20-8db9-4c79a4b1fd81'
})

result = client.query("""
select global current_user_id;
""")
print(result)

```
Listing 3: go
```
packagemain

import (
"context"
"fmt"
"log"

"github.com/edgedb/edgedb-go"
)

funcmain() {
ctx := context.Background()
client, err := edgedb.CreateClient(ctx, edgedb.Options{})
if err != nil{
log.Fatal(err)
}
defer client.Close()

```
id, err := edgedb.ParseUUID("2141a5b4-5634-4ccc-b835-437863534c51")
if err != nil{
log.Fatal(err)
}
```
```
varresult edgedb.UUID
err = client.
WithGlobals(map[string]interface{}{"current_user": id}).
QuerySingle(ctx, "SELECT global current_user;", &result)
if err != nil{
log.Fatal(err)
}
```
fmt.Println(result)
}

**88 Chapter 2. Schema**


```
Listing 4: edgeql
```
set global current_user_id := <uuid>'2141a5b4-5634-4ccc-b835-437863534c51';

The.withGlobals/.with_globalsmethod returns a newClientinstance that stores the provided globals and
sends them along with all future queries.

#### 2.10.1.1 Cardinality

Global variables can be markedrequired; in this case, you must specify a default value.

required global one_string -> str {
default:= "Hi Mom!"
};

required global one_string: str {
default:= "Hi Mom!"
};

#### 2.10.1.2 Computed globals

Global variables can also be computed. The value of computed globals are dynamically computed when they are
referenced in queries.

required global random_global := datetime_of_transaction();

The provided expression will be computed at the start of each query in which the global is referenced. There’s no need
to provide an explicit type; the type is inferred from the computed expression.

Computed globals are not subject to the same constraints as non-computed ones; specifically, they can be object-typed
and have amulticardinality.

global current_user_id -> uuid;

# object-typed global
global current_user := (
select Userfilter .id =global current_user_id
);

# multi global
global current_user_friends := (global current_user).friends;

global current_user_id: uuid;

# object-typed global
global current_user := (
select Userfilter .id =global current_user_id
);

# multi global
global current_user_friends := (global current_user).friends;

**2.10. Globals 89**


#### 2.10.1.3 Usage in schema

Unlike query parameters, globals can be referenced _inside your schema declarations_.

typeUser {
property name -> str;
property is_self := (.id =globalcurrent_user_id)
};

typeUser {
name: str;
property is_self := (.id =globalcurrent_user_id)
};

This is particularly useful when declaring _access policies_.

typePerson {
required property name -> str;
access policy my_policyallow all using (.id =global current_user_id);
}

typePerson {
required name: str;
access policy my_policyallow all using (.id =global current_user_id);
}

Refer to _Access Policies_ for complete documentation.

```
See also
SDL > Globals
DDL > Globals
```
## 2.11 Access Policies

Object types can contain security policies that restrict the set of objects that can be selected, inserted, updated, or
deleted by a particular query. This is known as _object-level security_.

Let’s start with a simple schema without any access policies.

typeUser {
required property email -> str {constraint exclusive; };
}

typeBlogPost {
required property title -> str;
required link author -> User;
}

typeUser {
required email: str {constraintexclusive; };
}
(continues on next page)

**90 Chapter 2. Schema**


```
(continued from previous page)
```
typeBlogPost {
required title: str;
required author: User;
}

When no access policies are defined, object-level security is not activated. Any properly authenticated client can select
or modify any object in the database.

```
Warning: Once a policy is added to a particular object type, all operations (select,insert,delete,update,
etc.) on any object of that type are now disallowed by default unless specifically allowed by an access policy!
```
### 2.11.1 Defining a global

To start, we’ll add a _global variable_ to our schema. We’ll use this global to represent the identity of the user executing
the query.

+ global current_user -> uuid;

```
type User {
required property email -> str { constraint exclusive; };
}
```
```
type BlogPost {
required property title -> str;
required link author -> User;
}
```
+ global current_user: uuid;

```
type User {
required email: str { constraint exclusive; };
}
```
```
type BlogPost {
required title: str;
required author: User;
}
```
Global variables are a generic mechanism for providing _context_ to a query. Most commonly, they are used in the context
of access policies.

The value of these variables is attached to the _client_ you use to execute queries. The exact API depends on which client
library you’re using:

```
Listing 5: typescript
```
import createClientfrom'edgedb';

constclient = createClient().withGlobals({
(continues on next page)

**2.11. Access Policies 91**


(continued from previous page)
current_user: '2141a5b4-5634-4ccc-b835-437863534c51',
});

awaitclient.query(`select global current_user;`);

```
Listing 6: python
```
from edgedb import create_client

client = create_client().with_globals({
'current_user': '580cc652-8ab8-4a20-8db9-4c79a4b1fd81'
})

result = client.query("""
select global current_user;
""")

```
Listing 7: go
```
packagemain

import (
"context"
"fmt"
"log"

"github.com/edgedb/edgedb-go"
)

funcmain() {
ctx := context.Background()
client, err := edgedb.CreateClient(ctx, edgedb.Options{})
if err != nil{
log.Fatal(err)
}
defer client.Close()

```
id, err := edgedb.ParseUUID("2141a5b4-5634-4ccc-b835-437863534c51")
if err != nil{
log.Fatal(err)
}
```
```
varresult edgedb.UUID
err = client.
WithGlobals(map[string]interface{}{"current_user": id}).
QuerySingle(ctx, "SELECT global current_user;", &result)
if err != nil{
log.Fatal(err)
}
```
fmt.Println(result)
}

**92 Chapter 2. Schema**


### 2.11.2 Defining a policy

Let’s add a policy to our sample schema.

```
global current_user -> uuid;
```
```
type User {
required property email -> str { constraint exclusive; };
}
```
```
type BlogPost {
required property title -> str;
required link author -> User;
```
+ access policy author_has_full_access
+ allow all
+ using (global current_user ?= .author.id);
}

```
global current_user: uuid;
```
```
type User {
required email: str { constraint exclusive; };
}
```
```
type BlogPost {
required title: str;
required author: User;
```
+ access policy author_has_full_access
+ allow all
+ using (global current_user ?= .author.id);
}

Let’s break down the access policy syntax piece-by-piece. This policy grants full read-write access (all) to theauthor
of eachBlogPost. No one else will be able to edit, delete, or view this post.

**Note:** We’re using the _coalescing equality_ operator?=which returnsfalseeven if one of its arguments is an empty
set.

- access policy: The keyword used to declare a policy inside an object type.
- author_has_full_access: The name of this policy; could be any string.
- allow: The kind of policy; could beallowordeny
- all: The set of operations being allowed/denied; a comma-separated list of the following:all,select,insert,
    delete,update,update read,update write.
- using (<expr>): A boolean expression. Think of this as afilterexpression that defines the set of objects
    to which the policy applies.

Let’s do some experiments.

**2.11. Access Policies 93**


db>insert User { email := "test@edgedb.com" };
{default::User {id: be44b326-03db-11ed-b346-7f1594474966}}
db>set globalcurrent_user := <uuid>"be44b326-03db-11ed-b346-7f1594474966";
OK:SET GLOBAL
db>insert BlogPost {
... title := "My post",
... author := (select Userfilter .id =global current_user)
... };
{default::BlogPost {id: e76afeae-03db-11ed-b346-fbb81f537ca6}}

We’ve created aUser, set the value ofcurrent_userto itsid, and created a newBlogPost. When we try to select
allBlogPostobjects, we’ll see the post we just created.

db>select BlogPost;
{default::BlogPost {id: e76afeae-03db-11ed-b346-fbb81f537ca6}}
db>select count(BlogPost);
{1}

Now let’s unsetcurrent_userand see what happens.

db>set globalcurrent_user := {};
OK:SET GLOBAL
db>select BlogPost;
{}
db>select count(BlogPost);
{0}

Nowselect BlogPostreturns zero results. We can onlyselectthe _posts_ written by the _user_ specified by
current_user. Whencurrent_userhas no value, we can’t read any posts.

The access policies use global variables to define a “subgraph” of data that is visible to a particular query.

### 2.11.3 Policy types

For the most part, the policy types correspond to EdgeQL’s _statement types_ :

- select: Applies to all queries; objects without aselectpermission cannot be modified either.
- insert: Applies to insert queries; executed _post-insert_. If an inserted object violates the policy, the query will
    fail.
- delete: Applies to delete queries.
- update: Applies to update queries.

Additionally, theupdateoperation can broken down into two sub-policies:update readandupdate write.

- update read: This policy restricts _which_ objects can be updated. It runs _pre-update_ ; that is, this policy is
    executed before the updates have been applied.
- update write: This policy restricts _how_ you update the objects; you can think of it as a _post-update_ validity
    check. This could be used to prevent aUserfrom transferring aBlogPostto anotherUser.

Finally, there’s an umbrella policy that can be used as a shorthand for all the others.

- all: A shorthand policy that can be used to allow or deny full read/ write permissions. Exactly equivalent to
    select, insert, update, delete.

**94 Chapter 2. Schema**


### 2.11.4 Resolution order

An object type can contain an arbitrary number of access policies, including several conflictingallowanddeny
policies. EdgeDB uses a particular algorithm for resolving these policies.

```
Fig. 1: The access policy resolution algorithm, explained with Venn diagrams.
```
1. When no policies are defined on a given object type, all objects of that type can be read or modified by any
    appropriately authenticated connection.
2. EdgeDB then applies allallowpolicies. Each policy grants a _permission_ that is scoped to a particular _set of_
    _objects_ as defined by theusingclause. Conceptually, these permissions are merged with theunion/oroperator
    to determine the set of allowable actions.
3. After theallowpolicies are resolved, thedenypolicies can be used to carve out exceptions to theallowrules.
    Deny rules _supersede_ allow rules! As before, the set of objects targeted by the policy is defined by theusing
    clause.
4. This results in the final access level: a set of objects targetable by each ofselect,insert,update read,
    update write, anddelete.

Currently, by default the access policies affect the values visible in expressions of _other_ access policies. This means
that they can affect each other in various ways. Because of this, great care needs to be taken when creating access
policies based on objects other than the ones they are defined on. For example:

global current_user_id -> uuid;
global current_user := (
select Userfilter .id =global current_user_id
);

typeUser {
required property email -> str {constraint exclusive; };
required property is_admin -> bool {default:= false};

access policy admin_only
allow all
using(globalcurrent_user.is_admin ??false);
}

typeBlogPost {
required property title -> str;
link author -> User;

```
access policy author_has_full_access
(continues on next page)
```
**2.11. Access Policies 95**


(continued from previous page)
allow all
using(globalcurrent_user ?= .author.id);
}

global current_user_id: uuid;
global current_user := (
select Userfilter .id =global current_user_id
);

typeUser {
required email: str {constraintexclusive; };
required is_admin: bool {default:= false};

access policy admin_only
allow all
using(globalcurrent_user.is_admin ??false);
}

typeBlogPost {
required title: str;
author: User;

access policy author_has_full_access
allow all
using(globalcurrent_user ?= .author.id);
}

In the above schema only the admin will see a non-emptyauthorlink, because only the admin can see any user objects
at all. This means that instead of makingBlogPostvisible to its author, all non-admin authors won’t be able to see
their own posts. The above issue can be remedied by making the current user able to see their ownUserrecord.

**Note:** Starting with EdgeDB 3.0, access policy restrictions will **not** apply to any access policy expression. This means
that when reasoning about access policies it is no longer necessary to take other policies into account. Instead, all data
is visible for the purpose of _defining_ an access policy.

This change is being made to simplify reasoning about access policies and to allow certain patterns to be express
efficiently. Since those who have access to modifying the schema can remove unwanted access policies, no additional
security is provided by applying access policies to each other’s expressions.

It is possible (and recommended) to enable this _future_ behavior in EdgeDB 2.6 and later by adding the following to the
schema:using future nonrecursive_access_policies;

**96 Chapter 2. Schema**


#### 2.11.5 Custom error messages

When you run a query that attempts a write and is restricted by an access policy, you will get a generic error message.

edgedb error: AccessPolicyError: access policy violation on insert of
<type>

**Note:** When attempting aselectqueries, you simply won’t get the data that is being restricted by the access policy.

If you have multiple access policies, it can be useful to know which policy is restricting your query and provide a
friendly error message. You can do this by adding a custom error message to your policy.

```
global current_user_id -> uuid;
global current_user := (
select User filter .id = global current_user_id
);
```
```
type User {
required property email -> str { constraint exclusive; };
required property is_admin -> bool { default := false };
```
access policy admin_only
allow all
+ using (global current_user.is_admin ?? false) {
+ errmessage :='Only admins may query Users'
+ };
}

```
type BlogPost {
required property title -> str;
link author -> User;
```
access policy author_has_full_access
allow all
+ using (global current_user ?= .author.id) {
+ errmessage :='BlogPosts may only be queried by their authors'
+ };
}

Now if you attempt, for example, aUserinsert as a non-admin user, you will receive this error:

edgedb error: AccessPolicyError: access policy violation on insert of
default::User (Only admins may query Users)

**2.11. Access Policies 97**


#### 2.11.6 Disabling policies

You may disable all access policies by setting theapply_access_policies _configuration parameter_ tofalse.

You may also toggle access policies using the “Disable Access Policies” checkbox in the “Config” dropdown in the
EdgeDB UI (accessible by running the CLI commandedgedb uifrom inside your project). This is the most convenient
way to temporarily disable access policies since it applies only to your UI session.

#### 2.11.7 Examples

Blog posts are publicly visible ifpublishedbut only writable by the author.

```
global current_user -> uuid;
```
```
type User {
required property email -> str { constraint exclusive; };
}
```
type BlogPost {
required property title -> str;
required link author -> User;
+ required property published -> bool { default := false }

access policy author_has_full_access
allow all
using (global current_user ?= .author.id);
+ access policy visible_if_published
+ allow select
+ using (.published);
}

```
global current_user: uuid;
```
```
type User {
required email: str { constraint exclusive; };
}
```
type BlogPost {
required title: str;
required author: User;
+ required published: bool { default := false }

access policy author_has_full_access
allow all
using (global current_user ?= .author.id);
+ access policy visible_if_published
+ allow select
+ using (.published);
}

Blog posts are visible to friends but only modifiable by the author.

**98 Chapter 2. Schema**


```
global current_user -> uuid;
```
type User {
required property email -> str { constraint exclusive; };
+ multi link friends -> User;
}

```
type BlogPost {
required property title -> str;
required link author -> User;
```
access policy author_has_full_access
allow all
using (global current_user ?= .author.id);
+ access policy friends_can_read
+ allow select
+ using ((global current_user in .author.friends.id) ?? false);
}

```
global current_user: uuid;
```
type User {
required email: str { constraint exclusive; };
+ multi friends: User;
}

```
type BlogPost {
required title: str;
required author: User;
```
access policy author_has_full_access
allow all
using (global current_user ?= .author.id);
+ access policy friends_can_read
+ allow select
+ using ((global current_user in .author.friends.id) ?? false);
}

Blog posts are publicly visible except to users that have beenblockedby the author.

type User {
required property email -> str { constraint exclusive; };
+ multi link blocked -> User;
}

```
type BlogPost {
required property title -> str;
required link author -> User;
```
access policy author_has_full_access
allow all
using (global current_user ?= .author.id);
+ access policy anyone_can_read
(continues on next page)

**2.11. Access Policies 99**


```
(continued from previous page)
```
+ allow select;
+ access policy exclude_blocked
+ deny select
+ using ((global current_user in .author.blocked.id) ?? false);
}

type User {
required email: str { constraint exclusive; };
+ multi blocked: User;
}

```
type BlogPost {
required title: str;
required author: User;
```
access policy author_has_full_access
allow all
using (global current_user ?= .author.id);
+ access policy anyone_can_read
+ allow select;
+ access policy exclude_blocked
+ deny select
+ using ((global current_user in .author.blocked.id) ?? false);
}

“Disappearing” posts that become invisible after 24 hours.

```
type User {
required property email -> str { constraint exclusive; };
}
```
type BlogPost {
required property title -> str;
required link author -> User;
+ required property created_at -> datetime {
+ default := datetime_of_statement() # non-volatile
+ }

access policy author_has_full_access
allow all
using (global current_user ?= .author.id);
+ access policy hide_after_24hrs
+ allow select
+ using (datetime_of_statement() - .created_at < <duration>'24 hours');
}

```
type User {
required email: str { constraint exclusive; };
}
```
```
type BlogPost {
required title: str;
(continues on next page)
```
**100 Chapter 2. Schema**


(continued from previous page)
required author: User;
+ required created_at: datetime {
+ default := datetime_of_statement() # non-volatile
+ }

access policy author_has_full_access
allow all
using (global current_user ?= .author.id);
+ access policy hide_after_24hrs
+ allow select
+ using (datetime_of_statement() - .created_at < <duration>'24 hours');
}

##### 2.11.7.1 Super constraints

Access policies support arbitrary EdgeQL and can be used to define “super constraints”. Policies oninsertand
update writecan be thought of as post-write “validity checks”; if the check fails, the write will be rolled back.

**Note:** Due to an underlying Postgres limitation, _constraints on object types_ can only reference properties, not links.

Here’s a policy that limits the number of blog posts aUsercan post.

type User {
required property email -> str { constraint exclusive; };
+ multi link posts := .<author[is BlogPost]
}

```
type BlogPost {
required property title -> str;
required link author -> User;
```
access policy author_has_full_access
allow all
using (global current_user ?= .author.id);
+ access policy max_posts_limit
+ deny insert
+ using (count(.author.posts) > 500);
}

type User {
required email: str { constraint exclusive; };
+ multi link posts := .<author[is BlogPost]
}

```
type BlogPost {
required title: str;
required author: User;
```
```
access policy author_has_full_access
allow all
(continues on next page)
```
**2.11. Access Policies 101**


(continued from previous page)
using (global current_user ?= .author.id);
+ access policy max_posts_limit
+ deny insert
+ using (count(.author.posts) > 500);
}

```
See also
SDL > Access policies
DDL > Access policies
```
### 2.12 Functions

**Note:** This page documents how to define custom functions, however EdgeDB provides a large library of built-in
functions and operators. These are documented in _Standard Library_.

Functions are ways to transform one set of data into another.

#### 2.12.1 User-defined Functions

It is also possible to define custom functions. For example, consider a function that adds an exclamation mark'!'at
the end of the string:

functionexclamation(word: str) -> str
using (word ++'!');

This function accepts astras an argument and produces astras output as well.

test>select exclamation({'Hello','World'});
{'Hello!', 'World!'}

```
See also
SDL > Functions
DDL > Functions
Reference > Function calls
Introspection > Functions
Cheatsheets > Functions
Tutorial > Advanced EdgeQL > User-Defined Functions
```
**102 Chapter 2. Schema**


### 2.13 Triggers

Triggers allow you to define an expression to be executed whenever a given query type is run on an object type. The
original query will _trigger_ your pre-defined expression to run in a transaction along with the original query. These can
be defined in your schema.

**Note:** Triggers cannot be used to modify the object that set off the trigger. This functionality will be addressed by the
upcoming mutation rewrites feature.

Here’s an example that creates a simple audit log type so that we can keep track of what’s happening to our users in a
database. First, we will create aLogtype:

typeLog {
action: str;
timestamp: datetime {
default:= datetime_current();
}
target_name: str;
change: str;
}

With theLogtype in place, we can write some triggers that will automatically createLogobjects for any insert, update,
or delete queries on thePersontype:

typePerson {
required name: str;

```
trigger log_insert after insert foreachdo (
insert Log {
action := 'insert',
target_name := __new__.name
}
);
```
```
trigger log_update after update foreachdo (
insert Log {
action := 'update',
target_name := __new__.name,
change := __old__.name ++'->' ++ __new__.name
}
);
```
trigger log_delete after delete foreachdo (
insert Log {
action := 'delete',
target_name := __old__.name
}
);
}

In a trigger’s expression, we have access to the__old__and/or__new__variables which capture the object before
and after the query. Triggers onupdatecan use both variables. Triggers ondeletecan use__old__. Triggers on
insertcan use__new__.

**2.13. Triggers 103**


**Note:** If you access an object in the trigger expression _without_ using__old__or__new__(for example, via a
selectquery for that object), you will get the object state _after_ the triggering query. This is the same data you will
get if the object is part of the query and you access it via__new__.

Now, whenever we run a query, we get a log entry as well:

db>insert Person {name :='Jonathan Harker'};
{default::Person {id: b4d4e7e6-bd19-11ed-8363-1737d8d4c3c3}}
db>select Log {action, timestamp, target_name, change};
{
default::Log {
action:'insert',
timestamp: <datetime>'2023-03-07T18:56:02.403817Z',
target_name:'Jonathan Harker',
change: {}
}
}
db>update Personfilter .name ='Jonathan Harker'
...set{name :='Mina Murray'};
{default::Person {id: b4d4e7e6-bd19-11ed-8363-1737d8d4c3c3}}
db>select Log {action, timestamp, target_name, change};
{
default::Log {
action:'insert',
timestamp: <datetime>'2023-03-07T18:56:02.403817Z',
target_name:'Jonathan Harker',
change: {}
},
default::Log {
action:'update',
timestamp: <datetime>'2023-03-07T18:56:39.520889Z',
target_name:'Mina Murray',
change:'Jonathan Harker->Mina Murray'
},
}
db>delete Personfilter .name ='Mina Murray';
{default::Person {id: b4d4e7e6-bd19-11ed-8363-1737d8d4c3c3}}
db>select Log {action, timestamp, target_name, change};
{
default::Log {
action:'insert',
timestamp: <datetime>'2023-03-07T18:56:02.403817Z',
target_name:'Jonathan Harker',
change: {}
},
default::Log {
action:'update',
timestamp: <datetime>'2023-03-07T18:56:39.520889Z',
target_name:'Mina Murray',
change:'Jonathan Harker->Mina Murray'
},
default::Log {
(continues on next page)

**104 Chapter 2. Schema**


(continued from previous page)
action:'delete',
timestamp: <datetime>'2023-03-07T19:00:52.636084Z',
target_name:'Mina Murray',
change: {}
},
}

**Note:** In some cases, a trigger can cause another trigger to fire. When this happens, EdgeDB completes all the triggers
fired by the initial query before kicking off a new “stage” of triggers. In the second stage, any triggers fired by the initial
stage of triggers will fire. EdgeDB will continue adding trigger stages until all triggers are complete.

The exception to this is when triggers would cause a loop or would cause the same trigger to be run in two different
stages. These triggers will generate an error.

You might find that one log entry per row is too granular or too noisy for your use case. In that case, afor alltrigger
may be a better fit. Here’s a schema that changes theLogtype so that each object can log multiple writes by making
target_nameandchange _multi properties_ and switches tofor alltriggers:

```
type Log {
action: str;
timestamp: datetime {
default := datetime_current();
}
```
- target_name: str;
- change: str;
+ multi target_name: str;
+ multi change: str;
    }

```
type Person {
required name: str;
```
- trigger log_insert after insert for each do (
+ trigger log_insert after insert for all do (
    insert Log {
       action :='insert',
       target_name := __new__.name
    }
);
- trigger log_update after update for each do (
+ trigger log_update after update for all do (
    insert Log {
       action :='update',
       target_name := __new__.name,
       change := __old__.name ++'->'++ __new__.name
    }
);
- trigger log_delete after delete for each do (
+ trigger log_delete after delete for all do (
    (continues on next page)

**2.13. Triggers 105**


```
(continued from previous page)
insert Log {
action :='delete',
target_name := __old__.name
}
);
}
```
Under this new schema, each query matching the trigger gets a singleLogobject instead of oneLogobject per row:

db>fornamein {'Jonathan Harker','Mina Murray', 'Dracula'}
...union(
... insert Person {name := name}
... );
{
default::Person {id: 3836f9c8-d393-11ed-9638-3793d3a39133},
default::Person {id: 38370a8a-d393-11ed-9638-d3e9b92ca408},
default::Person {id: 38370abc-d393-11ed-9638-5390f3cbd375},
}
db>select Log {action, timestamp, target_name, change};
{
default::Log {
action:'insert',
timestamp: <datetime>'2023-03-07T19:12:21.113521Z',
target_name: {'Jonathan Harker', 'Mina Murray','Dracula'},
change: {},
},
}
db>forchangein {
... (old_name :='Jonathan Harker', new_name := 'Jonathan'),
... (old_name :='Mina Murray', new_name := 'Mina')
... }
...union(
... update Person filter.name = change.old_name set{
... name := change.new_name
... }
... );
{
default::Person {id: 3836f9c8-d393-11ed-9638-3793d3a39133},
default::Person {id: 38370a8a-d393-11ed-9638-d3e9b92ca408},
}
db>select Log {action, timestamp, target_name, change};
{
default::Log {
action:'insert',
timestamp: <datetime>'2023-04-05T09:21:17.514089Z',
target_name: {'Jonathan Harker', 'Mina Murray','Dracula'},
change: {},
},
default::Log {
action:'update',
timestamp: <datetime>'2023-04-05T09:35:30.389571Z',
target_name: {'Jonathan', 'Mina'},
(continues on next page)

**106 Chapter 2. Schema**


(continued from previous page)
change: {'Jonathan Harker->Jonathan', 'Mina Murray->Mina'},
},
}

```
See also
SDL > Triggers
DDL > Triggers
Introspection > Triggers
```
### 2.14 Mutation rewrites

Mutation rewrites allow you to intercept database mutations (i.e., _inserts_ and/or _updates_ ) and set the value of a property
or link to the result of an expression you define. They can be defined in your schema.

Mutation rewrites are complementary to _triggers_. While triggers are unable to modify the triggering object, mutation
rewrites are built for that purpose.

Here’s an example of a mutation rewrite that updates a property of aPosttype to reflect the time of the most recent
modification:

typePost {
required title: str;
required body: str;
modified: datetime {
rewriteinsert, update using(datetime_of_statement())
}
}

Every time aPostis updated, the mutation rewrite will be triggered, updating themodifiedproperty:

db>insert Post {
... title :='One wierd trick to fix all your spelling errors'
... };
{default::Post {id: 19e024dc-d3b5-11ed-968c-37f5d0159e5f}}
db>select Post {title, modified};
{
default::Post {
title: 'One wierd trick to fix all your spelling errors',
modified: <datetime>'2023-04-05T13:23:49.488335Z',
},
}
db>update Post
...filter .id = <uuid>'19e024dc-d3b5-11ed-968c-37f5d0159e5f'
...set{title :='One weird trick to fix all your spelling errors'};
{default::Post {id: 19e024dc-d3b5-11ed-968c-37f5d0159e5f}}
db>select Post {title, modified};
{
default::Post {
title: 'One weird trick to fix all your spelling errors',
modified: <datetime>'2023-04-05T13:25:04.119641Z',
(continues on next page)

**2.14. Mutation rewrites 107**


(continued from previous page)
},
}

In some cases, you will want different rewrites depending on the type of query. Here, we will add aninsertrewrite
and anupdaterewrite:

typePost {
required title: str;
required body: str;
created: datetime {
rewriteinsert using(datetime_of_statement())
}
modified: datetime {
rewriteupdate using(datetime_of_statement())
}
}

With this schema, inserts will set thePostobject’screatedproperty while updates will set themodifiedproperty:

db>insert Post {
... title :='One wierd trick to fix all your spelling errors'
... };
{default::Post {id: 19e024dc-d3b5-11ed-968c-37f5d0159e5f}}
db>select Post {title, created, modified};
{
default::Post {
title: 'One wierd trick to fix all your spelling errors',
created: <datetime>'2023-04-05T13:23:49.488335Z',
modified: {},
},
}
db>update Post
...filter .id = <uuid>'19e024dc-d3b5-11ed-968c-37f5d0159e5f'
...set{title :='One weird trick to fix all your spelling errors'};
{default::Post {id: 19e024dc-d3b5-11ed-968c-37f5d0159e5f}}
db>select Post {title, created, modified};
{
default::Post {
title: 'One weird trick to fix all your spelling errors',
created: <datetime>'2023-04-05T13:23:49.488335Z',
modified: <datetime>'2023-04-05T13:25:04.119641Z',
},
}

**Note:** Each property may have a singleinsertand a singleupdatemutation rewrite rule, or they may have a single
rule that covers both.

**108 Chapter 2. Schema**


#### 2.14.1 Available variables

Inside the rewrite rule’s expression, you have access to a few special values:

- __subject__refers to the object type with the new property and link values
- __specified__is a named tuple with a key for each property or link in the type and a boolean value indicating
    whether this value was explicitly set in the mutation
- __old__refers to the object type with the previous property and link values (available for update-only mutation
    rewrites)

Here are some examples of the special values in use. Maybe your blog hosts articles about particularly controversial
topics. You could use__subject__to enforce a “cooling off” period before publishing a blog post:

typePost {
required title: str;
required body: str;
publish_time: datetime {
rewriteinsert, update using(
__subject__.publish_time ?? datetime_of_statement() +
cal::to_relative_duration(days := 10)
)
}
}

Here we take the post’spublish_timeif set or the time the statement is executed and add 10 days to it. That should
give our authors time to consider if they want to make any changes before a post goes live.

You can omit__subject__in many cases and achieve the same thing:

```
type Post {
required title: str;
required body: str;
publish_time: datetime {
rewrite insert, update using (
```
- __subject__.publish_time ?? datetime_of_statement() +
+ .publish_time ?? datetime_of_statement() +
    cal::to_relative_duration(days := 10)
)
}
}

but only if the path prefix has not changed. In the following schema, for example, the__subject__in the rewrite rule
is required, because in the context of the nestedselectquery, the leading dot resolves from theUserpath:

typePost {
required title: str;
required body: str;
author_email: str;
author_name: str {
rewriteinsert, update using(
(selectUser {name}filter .email = __subject__.author_email).name
)
}
}
(continues on next page)

**2.14. Mutation rewrites 109**


```
(continued from previous page)
```
typeUser {
name: str;
email: str;
}

**Note:** Learn more about how this works in our documentation on _path resolution_.

Using__specified__, we can determine which fields were specified in the mutation. This would allow us to track
when a single property was last modified as in thetitle_modifiedproperty in this schema:

typePost {
required title: str;
required body: str;
title_modified: datetime {
rewriteupdate using(
datetime_of_statement()
if __specified__.title
else __old__.title_modified
)
}
}

__specified__.titlewill betrueif that value was set as part of the update, and this rewrite mutation rule will
updatetitle_modifiedtodatetime_of_statement()in that case.

Another way you might use this is to set a default value but allow overriding:

typePost {
required title: str;
required body: str;
modified: datetime {
rewriteupdate using(
datetime_of_statement()
if not__specified__.modified
else .modified
)
}
}

Here, we rewritemodifiedon updates todatetime_of_statment()unlessmodifiedwas set in the update. In that
case, we allow the specified value to be set. This is different from a _default_ value because the rewrite happens on each
update whereas a default value is applied only on insert of a new object.

Lastly, if we want to add anauthorproperty that can be set for each write and keep a history of all the authors, we can
do this with the help of__old__:

typePost {
required title: str;
required body: str;
author: str;
all_authors: array<str> {
default:= <array<str>>[];
(continues on next page)

**110 Chapter 2. Schema**


(continued from previous page)
rewriteupdate using(
__old__.all_authors
++ [__subject__.author]
);
}
}

On insert, ourall_authorsproperty will get initialized to an empty array of strings. We will rewrite updates to
concatenate that array with an array containing the new author value.

#### 2.14.2 Mutation rewrite as cached computed

Mutation rewrites can be used to effectively create a cached computed value as demonstrated with thebylineproperty
in this schema:

typePost {
required title: str;
required body: str;
author: str;
created: datetime {
rewriteinsert using(datetime_of_statement())
}
byline: str {
rewriteinsert, update using(
'by' ++
__subject__.author ++
' on '++
to_str(__subject__.created, 'Mon DD, YYYY')
)
}
}

Thebylineproperty will be updated on each insert or update, but the value will not need to be calculated at read time
like a proper _computed propety_.

```
See also
SDL > Mutation rewrites
DDL > Mutation rewrites
Introspection > Mutation rewrites
```
### 2.15 Inheritance

Inheritance is a crucial aspect of schema modeling in EdgeDB. Schema items can _extend_ one or more parent types.
When extending, the child (subclass) inherits the definition of its parents (superclass).

You can declareabstractobject types, properties, links, constraints, and annotations.

- _Objects_
- _Properties_
- _Links_

**2.15. Inheritance 111**


- _Constraints_
- _Annotations_

#### 2.15.1 Object types

Object types can _extend_ other object types. The extending type (AKA the _subtype_ ) inherits all links, properties, indexes,
constraints, etc. from its _supertypes_.

abstract typeAnimal {
property species -> str;
}

typeDogextendingAnimal {
property breed -> str;
}

abstract typeAnimal {
species: str;
}

typeDogextendingAnimal {
breed: str;
}

For details on querying polymorphic data, see _EdgeQL > Select > Polymorphic queries_.

##### 2.15.1.1 Multiple Inheritance

Object types can _extend more than one type_ — that’s called _multiple inheritance_. This mechanism allows building
complex object types out of combinations of more basic types.

abstract typeHasName {
property first_name -> str;
property last_name -> str;
}

abstract typeHasEmail {
property email -> str;
}

typePerson extendingHasName, HasEmail {
property profession -> str;
}

abstract typeHasName {
first_name: str;
last_name: str;
}

abstract typeHasEmail {
email: str;
(continues on next page)

**112 Chapter 2. Schema**


```
(continued from previous page)
```
}

typePerson extendingHasName, HasEmail {
profession: str;
}

##### 2.15.1.2 Overloading

An object type can overload an inherited property or link. All overloaded declarations must be prefixed with the
overloadedprefix to avoid unintentional overloads.

abstract typePerson {
property name -> str;
multi link friends -> Person;
}

typeStudentextendingPerson {
overloaded property name -> str {
constraintexclusive;
}
overloaded multi link friends -> Student;
}

abstract typePerson {
name: str;
multi friends: Person;
}

typeStudentextendingPerson {
overloaded name: str {
constraintexclusive;
}
overloaded multifriends: Student;
}

Overloaded fields cannot _generalize_ the associated type; it can only make it _more specific_ by setting the type to a subtype
of the original or adding additional constraints.

#### 2.15.2 Properties

Properties can be _concrete_ (the default) or _abstract_. Abstract properties are declared independent of a source or target,
can contain _annotations_ , and can be marked asreadonly.

abstract propertytitle_prop {
annotation title :='A title.';
readonly :=false;
}

**2.15. Inheritance 113**


#### 2.15.3 Links

It’s possible to defineabstractlinks that aren’t tied to a particular _source_ or _target_. Abstract links can be marked as
readonly and contain annotations, property declarations, constraints, and indexes.

abstract linklink_with_strength {
property strength -> float64;
index on (__subject__@strength);
}

typePerson {
multi link friendsextendinglink_with_strength -> Person;
}

abstract linklink_with_strength {
strength: float64;
index on (__subject__@strength);
}

typePerson {
multi friends: Person {
extendinglink_with_strength;
};
}

#### 2.15.4 Constraints

Useabstractto declare reusable, user-defined constraint types.

abstract constraint in_range(min: anyreal, max: anyreal) {
errmessage :=
'Value must be in range [{min}, {max}].';
using (max > __subject__and__subject__ >= min);
}

typePlayer {
property points -> int64 {
constraintin_range(0, 100);
}
}

abstract constraint in_range(min: anyreal, max: anyreal) {
errmessage :=
'Value must be in range [{min}, {max}].';
using (max > __subject__and__subject__ >= min);
}

typePlayer {
points: int64 {
constraintin_range(0, 100);
}
}

**114 Chapter 2. Schema**


#### 2.15.5 Annotations

EdgeQL supports three annotation types by default: title,description, anddeprecated. Useabstract
annotationto declare custom user-defined annotation types.

abstract annotation admin_note;

typeStatus {
annotation admin_note :='system-critical';
# more properties
}

By default, annotations defined on abstract types, properties, and links will not be inherited by their subtypes. To
override this behavior, use theinheritablemodifier.

abstract inheritable annotationadmin_note;

### 2.16 Extensions

Extensions are the way EdgeDB adds more functionality. In principle, extensions could add new types, scalars, func-
tions, etc., but, more importantly, they can add new ways of interacting with the database.

At the moment there are only two extensions available:

- edgeql_http: enables _EdgeQL over HTTP_
- graphql: enables _GraphQL_

```
See also
SDL > Extensions
DDL > CREATE EXTENSION
DDL > DROP EXTENSION
```
### 2.17 Future Behavior

Any time that we add new functionality to EdgeDB we strive to do it in the least disruptive way possible. Deprecation
warnings, documentation and guides can help make these transiotions smoother, but sometimes the changes are just
too big, especially if they affect already existing functionality. It is often inconvenient dealing with these changes
at the same time as upgrading to a new major version of EdgeDB. To help with this transition we introduce _future_
specification.

The purpose of this specification is to provide a way to try out and ease into an upcoming feature before a major release.
Sometimes enabling future behavior is necessary to fix some current issues. Other times enabling future behavior can
simply provide a way to test out the feature before it gets released, to make sure that the current project codebase is
compatible and well-behaved. It provides a longer timeframe for adopting a new feature and for catching bugs that
arise from the change in behavior.

Thefuturespecification is intended to help with transitions between major releases. Once a feature is released this
specification is no longer necessary to enable that feature and it will be removed from the schema during the upgrade
process.

Once some behavior is available as afutureall new _projects_ enable this behavior by default when initializing an
empty database. It is possible to explicitly disable thefuturefeature by removing it from the schema, but it is not

**2.16. Extensions 115**


recommended unless the feature is causing some issues which cannot be fixed otherwise. Existing projects don’t change
their behavior by default, thefuturespecification needs to be added to the schema by the developer in order to gain
early access to it.

At the moment there is only onefutureavailable:

- nonrecursive_access_policies: makes access policies _non-recursive_ and simplifies policy interactions.

```
See also
SDL > Future Behavior
DDL > CREATE FUTURE
DDL > DROP FUTURE
```
### 2.18 vs SQL and ORMs

EdgeDB’s approach to schema modeling builds upon the foundation of SQL while taking cues from modern tools like
ORM libraries. Let’s see how it stacks up.

#### 2.18.1 Comparison to SQL

When using SQL databases, there’s no convenient representation of the schema. Instead, the schema only exists as
a series of{CREATE|ALTER|DELETE} {TABLE| COLUMN}commands, usually spread across several SQL migration
scripts. There’s no simple way to see the current state of your schema at a glance.

Moreover, SQL stores data in a _relational_ way. Connections between tables are represented with foreign key constraints
andJOINoperations are required to query across tables.

CREATE TABLE people (
id uuid PRIMARY KEY,
name text,
);
CREATE TABLE movies (
id uuid PRIMARY KEY,
title text,
director_id uuid REFERENCES people(id)
);

In EdgeDB, connections between tables are represented with _Links_.

typeMovie {
required property title -> str;
required link director -> Person;
}

typePerson {
required property name -> str;
}

typeMovie {
required title: str;
required director: Person;
}
(continues on next page)

**116 Chapter 2. Schema**


```
(continued from previous page)
```
typePerson {
required name: str;
}

This approach makes it simple to write queries that traverse this link, no JOINs required.

select Movie {
title,
director: {
name
}
}

#### 2.18.2 Comparison to ORMs

Object-relational mapping libraries are popular for a reason. They provide a way to model your schema and write
queries in a way that feels natural in the context of modern, object-oriented programming languages. But ORMs have
downsides too.

- **Lock-in**. Your schema is strongly coupled to the ORM library you are using. More generally, this also locks you
    into using a particular programming language.
- Most ORMs have more **limited querying capabilities** than the query languages they abstract.
- Many ORMs produce **suboptimal queries** that can have serious performance implications.
- **Migrations** can be difficult. Since most ORMs aim to be the single source of truth for your schema, they nec-
    essarily must provide some sort of migration tool. These migration tools are maintained by the contributors to
    the ORM library, not the maintainers of the database itself. Quality control and long-term maintenance is not
    always guaranteed.

From the beginning, EdgeDB was designed to incorporate the best aspects of ORMs — declarative modeling, object-
oriented APIs, and intuitive querying — without the drawbacks.

### 2.19 Introspection

All of the schema information in EdgeDB is stored in theschema _module_ and is accessible via _introspection queries_.

All the introspection types are themselves extendingBaseObject, so they are also subject to introspection _as object
types_. The following query will give a list of all the types used in introspection:

select name := schema::ObjectType.name
filter namelike'schema::%';

There’s also a couple of ways of getting the introspection type of a particular expression. AnyObjecthas a__type__
link to theschema::ObjectType. For scalars there’s theintrospectandtypeofoperators that can be used to get
the type of an expression.

Finally, the commanddescribecan be used to get information about EdgeDB types in a variety of human-readable
formats.

**2.19. Introspection 117**


#### 2.19.1 Object types

This section describes introspection of _object types_.

Introspection of theschema::ObjectType:

db>with module schema
...select ObjectType {
... name,
... links: {
... name,
... },
... properties: {
... name,
... }
... }
...filter .name ='schema::ObjectType';
{
Object {
name:'schema::ObjectType',
links: {
Object{ name:'__type__' },
Object{ name:'annotations'},
Object{ name:'bases'},
Object{ name:'constraints'},
Object{ name:'indexes' },
Object{ name:'links'},
Object{ name:'ancestors'},
Object{ name:'pointers' },
Object{ name:'properties'}
},
properties: {
Object{ name:'id'},
Object{ name:'abstract' },
Object{ name:'name' }
}
}
}

Consider the following schema:

typeAddressable {
propertyaddress -> str;
}

typeUserextending Addressable {
# define some properties and a link
required propertyname -> str;

```
multi linkfriends -> User;
```
# define an index for User based on name
index on(.name);
}

**118 Chapter 2. Schema**


Introspection ofUser:

db>with module schema
...select ObjectType {
... name,
... abstract,
... bases: { name },
... ancestors: { name },
... annotations: { name, @value },
... links: {
... name,
... cardinality,
... required,
... target: { name },
... },
... properties: {
... name,
... cardinality,
... required,
... target: { name },
... },
... constraints: { name },
... indexes: { expr },
... }
...filter .name ='default::User';
{
Object {
name:'default::User',
abstract:false,
bases: {Object{ name:'default::Addressable'}},
ancestors: {
Object{ name:'std::BaseObject'},
Object{ name:'std::Object'},
Object{ name:'default::Addressable' }
},
annotations: {},
links: {
Object{
name:'__type__',
cardinality:'One',
required: {},
target:Object{ name:'schema::Type'}
},
Object{
name:'friends',
cardinality:'Many',
required:false,
target:Object{ name:'default::User' }
}
},
properties: {
Object{
name:'address',
(continues on next page)

**2.19. Introspection 119**


(continued from previous page)
cardinality:'One',
required:false,
target:Object{ name:'std::str' }
},
Object{
name:'id',
cardinality:'One',
required:true,
target:Object{ name:'std::uuid' }
},
Object{
name:'name',
cardinality:'One',
required:true,
target:Object{ name:'std::str' }
}
},
constraints: {},
indexes: {
Object{
expr:'.name'
}
}
}
}

```
See also
Schema > Object types
SDL > Object types
DDL > Object types
Cheatsheets > Object types
```
#### 2.19.2 Scalar types

This section describes introspection of _scalar types_.

Introspection of theschema::ScalarType:

db>with module schema
...select ObjectType {
... name,
... links: {
... name,
... },
... properties: {
... name,
... }
... }
...filter .name ='schema::ScalarType';
{
Object {
(continues on next page)

**120 Chapter 2. Schema**


(continued from previous page)
name:'schema::ScalarType',
links: {
Object{ name:'__type__' },
Object{ name:'annotations'},
Object{ name:'bases'},
Object{ name:'constraints'},
Object{ name:'ancestors'}
},
properties: {
Object{ name:'default' },
Object{ name:'enum_values'},
Object{ name:'id'},
Object{ name:'abstract' },
Object{ name:'name' }
}
}
}

Introspection of the built-in scalarstr:

db>with module schema
...select ScalarType {
... name,
... default,
... enum_values,
... abstract,
... bases: { name },
... ancestors: { name },
... annotations: { name, @value },
... constraints: { name },
... }
...filter .name ='std::str';
{
Object {
name:'std::str',
default: {},
enum_values: {},
abstract: {},
bases: {Object{ name:'std::anyscalar'}},
ancestors: {Object{ name:'std::anyscalar'}},
annotations: {},
constraints: {}
}
}

For an _enumerated scalar type_ , consider the following:

scalar typeColorextendingenum<Red, Green, Blue>;

Introspection of the enum scalarColor:

db>with module schema
...select ScalarType {
(continues on next page)

**2.19. Introspection 121**


```
(continued from previous page)
```
... name,
... default,
... enum_values,
... abstract,
... bases: { name },
... ancestors: { name },
... annotations: { name, @value },
... constraints: { name },
... }
...filter .name ='default::Color';
{
Object {
name:'default::Color',
default: {},
enum_values: ['Red', 'Green', 'Blue'],
abstract: {},
bases: {Object{ name:'std::anyenum' }},
ancestors: {
Object{ name:'std::anyscalar'},
Object{ name:'std::anyenum' }
},
annotations: {},
constraints: {}
}
}

#### 2.19.3 Collection types

This section describes introspection of _collection types_.

##### 2.19.3.1 Array

Introspection of theschema::Array:

db>with module schema
...select ObjectType {
... name,
... links: {
... name,
... },
... properties: {
... name,
... }
... }
...filter .name ='schema::Array';
{
Object {
name:'schema::Array',
links: {
Object{ name:'__type__' },
(continues on next page)

**122 Chapter 2. Schema**


(continued from previous page)
Object{ name:'element_type' }
},
properties: {
Object{ name:'id'},
Object{ name:'name' }
}
}
}

For a type with anarrayproperty, consider the following:

typeUser {
required propertyname -> str;
propertyfavorites -> array<str>;
}

Introspection of theUserwith emphasis on properties:

db>with module schema
...select ObjectType {
... name,
... properties: {
... name,
... target: {
... name,
... [is Array].element_type: { name },
... },
... },
... }
...filter .name ='default::User';
{
Object {
name:'default::User',
properties: {
Object{
name:'favorites',
target:Object{
name:'array',
element_type:Object{ name:'std::str' }
}
},
...
}
}
}

**2.19. Introspection 123**


##### 2.19.3.2 Tuple

Introspection of theschema::Tuple:

db>with module schema
...select ObjectType {
... name,
... links: {
... name,
... },
... properties: {
... name,
... }
... }
...filter .name ='schema::Tuple';
{
Object {
name:'schema::Tuple',
links: {
Object{ name:'__type__' },
Object{ name:'element_types' }
},
properties: {
Object{ name:'id'},
Object{ name:'name' }
}
}
}

For example, below is an introspection of the return type of thesys::get_version()function:

db>with module schema
...select `Function`{
... return_type[isTuple]: {
... element_types: {
... name,
... type: { name }
... }order by.num
... }
... }
...filter .name ='sys::get_version';
{
Object {
return_type:Object{
element_types: {
Object{
name:'major',
type:Object {
name:'std::int64'
}
},
Object{
name:'minor',
type:Object {
(continues on next page)

**124 Chapter 2. Schema**


(continued from previous page)
name:'std::int64'
}
},
Object{
name:'stage',
type:Object {
name:'sys::VersionStage'
}
},
Object{
name:'stage_no',
type:Object {
name:'std::int64'
}
},
Object{
name:'local',
type:Object { name:'array'}
}
}
}
}
}

#### 2.19.4 Functions

This section describes introspection of _functions_.

Introspection of theschema::Function:

db>with module schema
...select ObjectType {
... name,
... links: {
... name,
... },
... properties: {
... name,
... }
... }
...filter .name ='schema::Function';
{
Object {
name:'schema::Function',
links: {
Object{ name:'__type__' },
Object{ name:'annotations'},
Object{ name:'params'},
Object{ name:'return_type'}
},
properties: {
(continues on next page)

**2.19. Introspection 125**


(continued from previous page)
Object{ name:'id'},
Object{ name:'name' },
Object{ name:'return_typemod'}
}
}
}

Sinceparamsare quite important to functions, here’s their structure:

db>with module schema
...select ObjectType {
... name,
... links: {
... name,
... },
... properties: {
... name,
... }
... }
...filter .name ='schema::Parameter';
{
Object {
name:'schema::Parameter',
links: {
Object{ name:'__type__' },
Object{ name:'type' }
},
properties: {
Object{ name:'default' },
Object{ name:'id'},
Object{ name:'kind' },
Object{ name:'name' },
Object{ name:'num' },
Object{ name:'typemod' }
}
}
}

Introspection of the built-incount():

db>with module schema
...select `Function`{
... name,
... annotations: { name, @value },
... params: {
... kind,
... name,
... num,
... typemod,
... type: { name },
... default,
... },
(continues on next page)

**126 Chapter 2. Schema**


```
(continued from previous page)
```
... return_typemod,
... return_type: { name },
... }
...filter .name ='std::count';
{
Object {
name:'std::count',
annotations: {},
params: {
Object{
kind:'PositionalParam',
name:'s',
num: 0,
typemod:'SetOfType',
type:Object { name:'anytype' },
default: {}
}
},
return_typemod: 'SingletonType',
return_type:Object{ name:'std::int64'}
}
}

```
See also
Schema > Functions
SDL > Functions
DDL > Functions
Reference > Function calls
Cheatsheets > Functions
```
#### 2.19.5 Triggers

This section describes introspection of _triggers_.

Introspection ofschema::Trigger:

db>with module schema
...select ObjectType {
... name,
... links: {
... name,
... },
... properties: {
... name,
... }
... }filter .name ='schema::Trigger';
{
schema::ObjectType {
name:'schema::Trigger',
links: {
schema::Link {name: 'subject'},
(continues on next page)

**2.19. Introspection 127**


(continued from previous page)
schema::Link {name: '__type__'},
schema::Link {name: 'ancestors'},
schema::Link {name: 'bases'},
schema::Link {name: 'annotations'}
},
properties: {
schema::Property {name: 'inherited_fields'},
schema::Property {name: 'computed_fields'},
schema::Property {name: 'builtin'},
schema::Property {name: 'internal'},
schema::Property {name: 'name'},
schema::Property {name: 'id'},
schema::Property {name: 'abstract'},
schema::Property {name: 'is_abstract'},
schema::Property {name: 'final'},
schema::Property {name: 'is_final'},
schema::Property {name: 'timing'},
schema::Property {name: 'kinds'},
schema::Property {name: 'scope'},
schema::Property {name: 'expr'},
},
},
}

Introspection of a trigger namedlog_inserton theUsertype:

db>with module schema
...select Trigger {
... name,
... kinds,
... timing,
... scope,
... expr,
... subject: {
... name
... }
... }filter .name ='log_insert';
{
schema::Trigger {
name:'log_insert',
kinds: {Insert},
timing:After,
scope: Each,
expr:'insert default::Log { action := \'insert\', target_name := __new__.name }',
subject: schema::ObjectType {name:'default::User'},
},
}

```
See also
Schema > Triggers
SDL > Triggers
DDL > Triggers
```
**128 Chapter 2. Schema**


#### 2.19.6 Mutation rewrites

This section describes introspection of _mutation rewrites_.

Introspection of theschema::Rewrite:

db>select schema::ObjectType {
... name,
... links: {
... name
... },
... properties: {
... name
... }
... }filter .name ='schema::Rewrite';
{
schema::ObjectType {
name:'schema::Rewrite',
links: {
schema::Link {name: 'subject'},
schema::Link {name: '__type__'},
schema::Link {name: 'ancestors'},
schema::Link {name: 'bases'},
schema::Link {name: 'annotations'}
},
properties: {
schema::Property {name: 'inherited_fields'},
schema::Property {name: 'computed_fields'},
schema::Property {name: 'builtin'},
schema::Property {name: 'internal'},
schema::Property {name: 'name'},
schema::Property {name: 'id'},
schema::Property {name: 'abstract'},
schema::Property {name: 'is_abstract'},
schema::Property {name: 'final'},
schema::Property {name: 'is_final'},
schema::Property {name: 'kind'},
schema::Property {name: 'expr'},
},
},
}

Introspection of all properties in thedefaultschema with a mutation rewrite:

db>select schema::ObjectType {
... name,
... properties := (
... select.properties {
... name,
... rewrites: {
... kind
... }
... }filter exists .rewrites
... )
(continues on next page)

**2.19. Introspection 129**


```
(continued from previous page)
```
... }filter .nameilike 'default::%'
...and exists.properties.rewrites;
{
schema::ObjectType {
name:'default::Post',
properties: {
schema::Property {
name:'created',
rewrites: {
schema::Rewrite {
kind:Insert
}
}
},
schema::Property {
name:'modified',
rewrites: {
schema::Rewrite {
kind: Insert
},
schema::Rewrite {
kind:Update
}
}
},
},
},
}

Introspection of all rewrites, including the type of query (kind), rewrite expression, and the object and property they
are on:

db>select schema::Rewrite {
... subject := (
... select.subject {
... name,
... source: {
... name
... }
... }
... ),
... kind,
... expr
... };
{
schema::Rewrite {
subject: schema::Property {
name: 'created',
source: schema::ObjectType {
name:'default::Post'
}
},
(continues on next page)

**130 Chapter 2. Schema**


(continued from previous page)
kind:Insert,
expr:'std::datetime_of_statement()'
},
schema::Rewrite {
subject: schema::Property {
name: 'modified',
source: schema::ObjectType {
name:'default::Post'
}
},
kind:Insert,
expr:'std::datetime_of_statement()'
},
schema::Rewrite {
subject: schema::Property {
name: 'modified',
source: schema::ObjectType {
name:'default::Post'
}
},
kind:Update,
expr:'std::datetime_of_statement()'
},
}

Introspection of all rewrites on adefault::Postproperty namedmodified:

db>select schema::Rewrite {kind, expr}
...filter .subject.source.name ='default::Post'
...and.subject.name = 'modified';
{
schema::Rewrite {
kind:Insert,
expr:'std::datetime_of_statement()'
},
schema::Rewrite {
kind:Update,
expr:'std::datetime_of_statement()'
}
}

```
See also
Schema > Mutation rewrites
SDL > Mutation rewrites
DDL > Mutation rewrites
```
**2.19. Introspection 131**


#### 2.19.7 Indexes

This section describes introspection of _indexes_.

Introspection of theschema::Index:

db>with module schema
...select ObjectType {
... name,
... links: {
... name,
... },
... properties: {
... name,
... }
... }
...filter .name ='schema::Index';
{
Object {
name:'schema::Index',
links: {Object{ name:'__type__' }},
properties: {
Object{ name:'expr' },
Object{ name:'id'},
Object{ name:'name' }
}
}
}

Consider the following schema:

typeAddressable {
propertyaddress -> str;
}

typeUserextending Addressable {
# define some properties and a link
required propertyname -> str;

```
multi linkfriends -> User;
```
# define an index for User based on name
index on(.name);
}

Introspection ofUser.nameindex:

db>with module schema
...select Index{
... expr,
... }
...filter .exprlike'%.name';
{
Object {
(continues on next page)

**132 Chapter 2. Schema**


(continued from previous page)
expr:'.name'
}
}

For introspection of the index within the context of its host type see _object type introspection_.

```
See also
Schema > Indexes
SDL > Indexes
DDL > Indexes
```
#### 2.19.8 Constraints

This section describes introspection of _constraints_.

Introspection of theschema::Constraint:

db>with module schema
...select ObjectType {
... name,
... links: {
... name,
... },
... properties: {
... name,
... }
... }
...filter .name ='schema::Constraint';
{
Object {
name:'schema::Constraint',
links: {
Object{ name:'__type__' },
Object{ name:'args' },
Object{ name:'annotations'},
Object{ name:'bases'},
Object{ name:'ancestors'},
Object{ name:'params'},
Object{ name:'return_type'},
Object{ name:'subject' }
},
properties: {
Object{ name:'errmessage'},
Object{ name:'expr' },
Object{ name:'finalexpr'},
Object{ name:'id'},
Object{ name:'abstract' },
Object{ name:'name' },
Object{ name:'return_typemod'},
Object{ name:'subjectexpr'}
}
(continues on next page)

**2.19. Introspection 133**


(continued from previous page)
}
}

Consider the following schema:

scalar typemaxex_100extendingint64 {
constraintmax_ex_value(100);
}

Introspection of the scalarmaxex_100with focus on the constraint:

db>with module schema
...select ScalarType {
... name,
... constraints: {
... name,
... expr,
... annotations: { name, @value },
... subject: { name },
... params: { name, @value, type: { name } },
... return_typemod,
... return_type: { name },
... errmessage,
... },
... }
...filter .name ='default::maxex_100';
{
Object {
name:'default::maxex_100',
constraints: {
Object{
name:'std::max_ex_value',
expr:'(__subject__ <= max)',
annotations: {},
subject:Object{ name:'default::maxex_100'},
params: {
Object{
name:'max',
type:Object { name:'anytype' },
@value:' 100 '
}
},
return_typemod:'SingletonType',
return_type:Object{ name:'std::bool' }
errmessage:'{__subject__} must be less ...',
}
}
}
}

**134 Chapter 2. Schema**


```
See also
Schema > Constraints
SDL > Constraints
DDL > Constraints
Standard Library > Constraints
```
#### 2.19.9 Operators

This section describes introspection of EdgeDB operators. Much like functions, operators have parameters and return
types as well as a few other features.

Introspection of theschema::Operator:

db>with module schema
...select ObjectType {
... name,
... links: {
... name,
... },
... properties: {
... name,
... }
... }
...filter .name ='schema::Operator';
{
Object {
name:'schema::Operator',
links: {
Object{ name:'__type__' },
Object{ name:'annotations'},
Object{ name:'params'},
Object{ name:'return_type'}
},
properties: {
Object{ name:'id'},
Object{ name:'name' },
Object{ name:'operator_kind' },
Object{ name:'return_typemod'}
}
}
}

Sinceparamsare quite important to operators, here’s their structure:

db>with module schema
...select ObjectType {
... name,
... links: {
... name,
... },
... properties: {
... name,
(continues on next page)

**2.19. Introspection 135**


```
(continued from previous page)
```
... }
... }
...filter .name ='schema::Parameter';
{
Object {
name:'schema::Parameter',
links: {
Object{ name:'__type__' },
Object{ name:'type' }
},
properties: {
Object{ name:'default' },
Object{ name:'id'},
Object{ name:'kind' },
Object{ name:'name' },
Object{ name:'num' },
Object{ name:'typemod' }
}
}
}

Introspection of theandoperator:

db>with module schema
...select Operator {
... name,
... operator_kind,
... annotations: { name, @value },
... params: {
... kind,
... name,
... num,
... typemod,
... type: { name },
... default,
... },
... return_typemod,
... return_type: { name },
... }
...filter .name ='std::AND';
{
Object {
name:'std::AND',
operator_kind:'Infix',
annotations: {},
params: {
Object{
kind:'PositionalParam',
name:'a',
num: 0,
typemod:'SingletonType',
type:Object { name:'std::bool'},
(continues on next page)

**136 Chapter 2. Schema**


(continued from previous page)
default: {}
},
Object{
kind:'PositionalParam',
name:'b',
num: 1,
typemod:'SingletonType',
type:Object { name:'std::bool'},
default: {}
}
},
return_typemod: 'SingletonType',
return_type:Object{ name:'std::bool'}
}
}

#### 2.19.10 Casts

This section describes introspection of EdgeDBtype casts. Features like whether the casts are implicit can be
discovered by introspectingschema::Cast.

Introspection of theschema::Cast:

db>with module schema
...select ObjectType {
... name,
... links: {
... name,
... },
... properties: {
... name,
... }
... }
...filter .name ='schema::Cast';
{
Object {
name:'schema::Cast',
links: {
Object{ name:'__type__' },
Object{ name:'from_type'},
Object{ name:'to_type' }
},
properties: {
Object{ name:'allow_assignment' },
Object{ name:'allow_implicit'},
Object{ name:'id'},
Object{ name:'name' }
}
}
}

Introspection of the possible casts fromstd::int64to other types:

**2.19. Introspection 137**


db>with module schema
...select Cast{
... allow_assignment,
... allow_implicit,
... to_type: { name },
... }
...filter .from_type.name ='std::int64'
...order by.to_type.name;
{
Object {
allow_assignment:false,
allow_implicit: true,
to_type:Object { name:'std::bigint' }
},
Object {
allow_assignment:false,
allow_implicit: true,
to_type:Object { name:'std::decimal' }
},
Object {
allow_assignment:true,
allow_implicit: false,
to_type:Object { name:'std::float32' }
},
Object {
allow_assignment:false,
allow_implicit: true,
to_type:Object { name:'std::float64' }
},
Object {
allow_assignment:true,
allow_implicit: false,
to_type:Object { name:'std::int16'}
},
Object {
allow_assignment:true,
allow_implicit: false,
to_type:Object { name:'std::int32'}
},
Object {
allow_assignment:false,
allow_implicit: false,
to_type:Object { name:'std::json'}
},
Object {
allow_assignment:false,
allow_implicit: false,
to_type:Object { name:'std::str' }
}
}

Theallow_implicitproperty tells whether this is an _implicit cast_ in all contexts (such as when determining the
type of a set of mixed literals or resolving the argument types of functions or operators if there’s no exact match). For

**138 Chapter 2. Schema**


example, a literal 1 is anint64and it is implicitly cast into abigintorfloat64if it is added to a set containing
either one of those types:

db>select {1, 2n};
{1n, 2n}
db>select {1, 2.0};
{1.0, 2.0}

What happens if there’s no implicit cast between a couple of scalars in this type of example? EdgeDB checks whether
there’s a scalar type such that all of the set elements can be implicitly cast into that:

db>select introspect(typeof {<int64>1, <float32>2}).name;
{'std::float64'}

The scalar typesint64andfloat32cannot be implicitly cast into each other, but they both can be implicitly cast into
float64.

Theallow_assignmentproperty tells whether this is an implicit cast during assignment if a more general _implicit
cast_ is not allowed. For example, consider the following type:

typeExample {
propertyp_int16 -> int16;
propertyp_float32 -> float32;
propertyp_json ->json;
}

db>insert Example {
... p_int16 := 1,
... p_float32 := 2
... };
{Object { id: <uuid>'...'}}
db>insert Example {
... p_json := 3 # assignment cast to json not allowed
... };
InvalidPropertyTargetError: invalidtarget for property
'p_json'of object type'default::Example':'std::int64'
(expecting 'std::json')

EdgeDB schemas are declared using **SDL** (EdgeDB’s Schema Definition Language).

### 2.20 SDL

Your schema is defined inside.esdlfiles. It’s common to define your entire schema in a single file calleddefault.
esdl, but you can split it across multiple files if you wish.

By convention, your schema files should live in a directory calleddbschemain the root of your project.

# dbschema/default.esdl

typeMovie {
required property title -> str;
required link director -> Person;
}
(continues on next page)

**2.20. SDL 139**


```
(continued from previous page)
```
typePerson {
required property name -> str;
}

# dbschema/default.esdl

typeMovie {
required title: str;
required director: Person;
}

typePerson {
required name: str;
}

**Important:** Syntax highlighter packages/extensions for.esdlfiles are available for Visual Studio Code, Sublime
Text, Atom, and Vim.

### 2.21 Migrations

EdgeDB’s baked-in migration system lets you painlessly evolve your schema over time. Just update the contents of
your.esdlfile(s) and use the EdgeDB CLI to _create_ and _apply_ migrations.

$ edgedb migration create
Created dbschema/migrations/00001.esdl
$ edgedb migrate
Applied dbschema/migrations/00001.esdl.

For a full guide on migrations, refer to the _Creating and applying migrations_ guide.

**Important:** A migration consists of a sequence of _imperative_ schema-modifying commands likecreate type,
alter property, etc. Collectively these commands are known as _DDL_ ( _data definition language_ ). We recommend
using SDL and the migration system when building applications, however you’re free to use DDL directly if you prefer.

### 2.22 Terminology

**Instance**

An EdgeDB **instance** is a collection of databases that store their data in a shared directory, listen for queries on a
particular port, and are managed by a running EdgeDB process. Instances can be created, started, stopped, and destroyed
locally with the _EdgeDB CLI_.

**140 Chapter 2. Schema**


**Database**

Each instance can contain several **databases** , each with a unique name. At the time of creation, all instances contain a
single default database callededgedb. All incoming queries are executed against it unless otherwise specified.

**Module**

Each database has a schema consisting of several **modules** , each with a unique name. Modules can be used to organize
large schemas into logical units. In practice, though, most users put their entire schema inside a single module called
default.

module default{
# declare types here
}

You may define nested modules using the following syntax:

module dracula {
typePerson {
required property name -> str;
multi link places_visited -> City;
propertystrength -> int16;
}

module combat {
functionfight(one: Person, two: Person) -> str
using (
(one.name ??'Fighter 1') ++' wins!'
IF(one.strength ?? 0) > (two.strength ?? 0)
ELSE(two.name ??'Fighter 2') ++ 'wins!'
);
}
}

Here we have adraculamodule containing aPersontype. Nested in thedraculamodule we have acombatmodule
which will be used for all the combat functionality for our game based on Bram Stoker’s Dracula we built in the Easy
EdgeDB textbook.

**Note:** Name resolution

When referencing schema objects from another module, you must use a _fully-qualified_ name in the form
module_name::object_name.

The following module names are reserved by EdgeDB and contain pre-defined types, utility functions, and operators.

- std: standard types, functions, and operators in the _standard library_
- math: algebraic and statistical _functions_
- cal: local (non-timezone-aware) and relative date/time _types and functions_
- schema: types describing the _introspection_ schema
- sys: system-wide entities, such as user roles and _databases_
- cfg: configuration and settings

**2.22. Terminology 141**


You can chain together module names in a fully-qualified name to traverse a tree of nested modules. For example, to call
thefightfunction in the nested module example above, you would usedracula::combat::fight(<arguments>).

**142 Chapter 2. Schema**


```
CHAPTER
```
### THREE

### EDGEQL

### 3.1 Literals

EdgeQL is _inextricably tied_ to EdgeDB’s rigorous type system. Below is an overview of how to declare a literal value
of each _primitive type_. Click a link in the left column to jump to the associated section.

```
String str
Boolean bool
Numbers int16 int32 int64 float32 float64 bigint decimal
UUID uuid
Enums enum<X, Y, Z>
Dates and
times
```
```
datetime duration cal::local_datetime cal::local_date cal::local_time
cal::relative_duration
Durations duration cal::relative_duration cal::date_duration
Bytes bytes
Arrays array<x>
Tuples tuple<x, y, ...>ortuple<foo: x, bar: y, ...>
JSON json
```
#### 3.1.1 Strings

Thestrtype is a variable-length string of Unicode characters. A string can be declared with either single or double
quotes.

db>select 'i edgedb';
{'i edgedb'}
db>select "hello there!";
{'hello there!'}
db>select 'hello\nthere!';
{'hello
there!'}
db>select 'hello
... there!';
{'hello
there!'}
db>select r'hello
... there!';# multiline
{'hello
there!'}

```
143
```

There is a special syntax for declaring “raw strings”. Raw strings treat the backslash\as a literal character instead of
an escape character.

db>select r'hello\nthere'; # raw string
{r'hello\\nthere'}
db> select $$one
... two
... three$$; # multiline raw string
{'one
two
three'}
db> select $label$You can add an interstitial label
... if you need to use "$$" in your string.$label$;
{
'You can add an interstital label
if you need touse "$$"in your string.',
}

EdgeQL contains a set of built-in functions and operators for searching, comparing, and manipulating strings.

db>select 'hellothere'[5:10];
{'there'}
db>select 'hello'++ 'there';
{'hellothere'}
db>select len('hellothere');
{10}
db>select str_trim(' hello there ');
{'hello there'}
db>select str_split('hello there',' ');
{['hello', 'there']}

For a complete reference on strings, see _Standard Library > String_ or click an item below.

```
Indexing and
slicing
```
```
str[i] str[from:to]
```
```
Concatenation str ++ str
Utilities len()
Transformation
functions
```
```
str_split() str_lower() str_upper() str_title() str_pad_start()
str_pad_end() str_trim() str_trim_start() str_trim_end() str_repeat()
Comparison op-
erators
```
```
= != ?= ?!= < > <= >=
```
```
Search contains() find()
Pattern match-
ing and regexes
```
```
str like pattern str ilike pattern re_match() re_match_all() re_replace()
re_test()
```
**144 Chapter 3. EdgeQL**


#### 3.1.2 Booleans

Thebooltype represents a true/false value.

db>select true;
{true}
db>select false;
{false}

EdgeDB provides a set of operators that operate on boolean values.

```
Comparison operators = != ?= ?!= < > <= >=
Logical operators or and not
Aggregation all() any()
```
#### 3.1.3 Numbers

There are several numerical types in EdgeDB’s type system.

```
int16 16-bit integer
int32 32-bit integer
int64 64-bit integer
float32 32-bit floating point number
float64 64-bit floating point number
bigint Arbitrary precision integer.
decimal Arbitrary precision number.
```
Number literals that _do not_ contain a decimal are interpreted asint64. Numbers containing decimals are interpreted
asfloat64. Thensuffix designates a number with _arbitrary precision_ : eitherbigintordecimal.

```
Syntax Inferred type
select 3; int64
select 3.14; float64
select 314e-2; float64
select 42n; bigint
select 42.0n; decimal
select 42e+100n; decimal
```
To declare anint16,int32, orfloat32, you must provide an explicit type cast. For details on type casting, see
_Casting_.

```
Syntax Type
select <int16>1234; int16
select <int32>123456; int32
select <float32>123.456; float32
```
EdgeQL includes a full set of arithmetic and comparison operators. Parentheses can be used to indicate the order-of-
operations or visually group subexpressions; this is true across all EdgeQL queries.

**3.1. Literals 145**


db>select 5 > 2;
{true}
db>select 2 + 2;
{4}
db>select 2 ^ 10;
{1024}
db>select (1 + 1) * 2 / (3 + 8);
{0.36363636363636365}

EdgeQL provides a comprehensive set of built-in functions and operators on numerical data.

```
Comparison oper-
ators
```
```
= != ?= ?!= < > <= >=
```
```
Arithmetic + - - * / // % ^
Statistics sum() min() max() math::mean() math::stddev() math::stddev_pop()
math::var() math::var_pop()
Math round() math::abs() math::ceil() math::floor() math::ln() math::lg()
math::log()
Random number random()
```
#### 3.1.4 UUID

Theuuidtype is commonly used to represent object identifiers. UUID literal must be explicitly cast from a string
value matching the UUID specification.

db>select <uuid>'a5ea6360-75bd-4c20-b69c-8f317b0d2857';
{a5ea6360-75bd-4c20-b69c-8f317b0d2857}

Generate a random UUID.

db>select uuid_generate_v1mc();
{b4d94e6c-3845-11ec-b0f4-93e867a589e7}

#### 3.1.5 Enums

Enum types must be _declared in your schema_.

scalar typeColorextendingenum<Red, Green, Blue>;

Once declared, an enum literal can be declared with dot notation, or by casting an appropriate string literal:

db>select Color.Red;
{Red}
db>select <Color>"Red";
{Red}

**146 Chapter 3. EdgeQL**


#### 3.1.6 Dates and times

EdgeDB’s typesystem contains several temporal types.

```
datetime Timezone-aware point in time
cal::local_datetime Date and time w/o timezone
cal::local_date Date type
cal::local_time Time type
```
All temporal literals are declared by casting an appropriately formatted string.

db>select <datetime>'1999-03-31T15:17:00Z';
{<datetime>'1999-03-31T15:17:00Z'}
db>select <datetime>'1999-03-31T17:17:00+02';
{<datetime>'1999-03-31T15:17:00Z'}
db>select <cal::local_datetime>'1999-03-31T15:17:00';
{<cal::local_datetime>'1999-03-31T15:17:00'}
db>select <cal::local_date>'1999-03-31';
{<cal::local_date>'1999-03-31'}
db>select <cal::local_time>'15:17:00';
{<cal::local_time>'15:17:00'}

EdgeQL supports a set of functions and operators on datetime types.

```
Comparison opera-
tors
```
```
= != ?= ?!= < > <= >=
```
```
Arithmetic dt + dt dt - dt
String parsing to_datetime() cal::to_local_datetime() cal::to_local_date()
cal::to_local_time()
Component extrac-
tion
```
```
datetime_get() cal::time_get() cal::date_get()
```
```
Truncation datetime_truncate()
System timestamps datetime_current() datetime_of_transaction() datetime_of_statement()
```
#### 3.1.7 Durations

EdgeDB’s type system contains three duration types.

```
duration Exact duration
cal::relative_duration Duration in relative units
cal::date_duration Duration in months and days only
```
**3.1. Literals 147**


##### 3.1.7.1 Exact durations

Thedurationtype represents _exact_ durations that can be represented by some fixed number of microseconds. It can
be negative and it supports units ofmicroseconds,milliseconds,seconds,minutes, andhours.

db>select <duration>'45.6 seconds';
{<duration>'0:00:45.6'}
db>select <duration>'-15 microseconds';
{<duration>'-0:00:00.000015'}
db>select <duration>'5 hours 4 minutes 3 seconds';
{<duration>'5:04:03'}
db>select <duration>'8760 hours';# about a year
{<duration>'8760:00:00'}

All temporal units beyondhourno longer correspond to a fixed duration of time; the length of a day/month/year/etc
changes based on daylight savings time, the month in question, leap years, etc.

##### 3.1.7.2 Relative durations

By contrast, thecal::relative_durationtype represents a “calendar” duration, like1 month. Because months
have different number of days,1 monthdoesn’t correspond to a fixed number of milliseconds, but it’s often a useful
quantity to represent recurring events, postponements, etc.

**Note:** Thecal::relative_durationtype supports the same units asduration, plusdays,weeks,months,
years,decades,centuries, andmillennia.

To declare relative duration literals:

db>select <cal::relative_duration>'15 milliseconds';
{<cal::relative_duration>'PT.015S'}
db>select <cal::relative_duration>'2 months 3 weeks 45 minutes';
{<cal::relative_duration>'P2M21DT45M'}
db>select <cal::relative_duration>'-7 millennia';
{<cal::relative_duration>'P-7000Y'}

##### 3.1.7.3 Date durations

Thecal::date_durationrepresents spans consisting of some number of _months_ and _days_. This type is primarily
intended to simplify logic involvingcal::local_datevalues.

db>select <cal::date_duration>'5 days';
{<cal::date_duration>'P5D'}
db>select <cal::local_date>'2022-06-25'+ <cal::date_duration>'5 days';
{<cal::local_date>'2022-06-30'}
db>select <cal::local_date>'2022-06-30'- <cal::local_date>'2022-06-25';
{<cal::date_duration>'P5D'}

EdgeQL supports a set of functions and operators on duration types.

**148 Chapter 3. EdgeQL**


```
Comparison opera-
tors
```
```
= != ?= ?!= < > <= >=
```
```
Arithmetic dt + dt dt - dt
Duration string
parsing
```
```
to_duration() cal::to_relative_duration() cal::to_date_duration()
```
```
Component extrac-
tion
```
```
duration_get()
```
```
Conversion duration_truncate() cal::duration_normalize_hours()
cal::duration_normalize_days()
```
#### 3.1.8 Ranges

Ranges represent a range of orderable scalar values. A range comprises a lower bound, upper bound, and two boolean
flags indicating whether each bound is inclusive.

Create a range literal with therangeconstructor function.

db>select range(1, 10);
{range(1, 10, inc_lower :=true, inc_upper := false)}
db>select range(2.2, 3.3);
{range(2.2, 3.3, inc_lower :=true, inc_upper :=false)}

Ranges can be _empty_ , when the upper and lower bounds are equal.

db>select range(1, 1);
{range({}, empty:= true)}

Ranges can be _unbounded_. An empty set is used to indicate the lack of a particular upper or lower bound.

db>select range(4, <int64>{});
{range(4, {})}
db>select range(<int64>{}, 4);
{range({}, 4)}
db>select range(<int64>{}, <int64>{});
{range({}, {})}

To compute the set of concrete values defined by a range literal, userange_unpack. An empty range will unpack to
the empty set. Unbounded ranges cannot be unpacked.

db>select range_unpack(range(0, 10));
{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}
db>select range_unpack(range(1, 1));
{}
db>select range_unpack(range(0, <int64>{}));
edgedb error: InvalidValueError: cannot unpack an unbounded range

**3.1. Literals 149**


#### 3.1.9 Bytes

Thebytestype represents raw binary data.

db>select b'bina\\x01ry';
{b'bina\\x01ry'}

There is a special syntax for declaring “raw byte strings”. Raw byte strings treat the backslash\as a literal character
instead of an escape character.

db>select rb'hello\nthere';
{b'hello\\nthere'}
db>select br'\';
{b'\\'}

### 3.1.10 Arrays

An array is an _ordered_ collection of values of the _same type_. For example:

db>select [1, 2, 3];
{[1, 2, 3]}
db>select ['hello', 'world'];
{['hello', 'world']}
db>select [(1, 2), (100, 200)];
{[(1, 2), (100, 200)]}

EdgeQL provides a set of functions and operators on arrays.

```
Indexing and slicing array[i] array[from:to] array_get()
Concatenation array ++ array
Comparison operators = != ?= ?!= < > <= >=
Utilities len() array_join()
Search contains() find()
Conversion to/from sets array_agg() array_unpack()
```
See _Standard Library > Array_ for a complete reference on array data types.

### 3.1.11 Tuples

A tuple is _fixed-length_ , _ordered_ collection of values, each of which may have a _different type_. The elements of a tuple
can be of any type, including scalars, arrays, other tuples, and object types.

db>select ('Apple', 7, true);
{('Apple', 7,true)}

Optionally, you can assign a key to each element of a tuple. These are known as _named tuples_. You must assign keys
to all or none of the elements; you can’t mix-and-match.

db>select (fruit :='Apple', quantity := 3.14, fresh := true);
{(fruit := 'Apple', quantity := 3.14, fresh := true)}

**150 Chapter 3. EdgeQL**


#### 3.1.11.1 Indexing tuples

Tuple elements can be accessed with dot notation. Under the hood, there’s no difference between named and unnamed
tuples. Named tuples support key-based and numerical indexing.

db>select (1, 3.14,'red').0;
{1}
db>select (1, 3.14,'red').2;
{'red'}
db>select (name :='george', age := 12).name;
{('george')}
db>select (name :='george', age := 12).0;
{('george')}

**Important:** When you query an _unnamed_ tuple using one of EdgeQL’s _client libraries_ , its value is converted to a
list/array. When you fetch a _named tuple_ , it is converted to an object/dictionary/hashmap.

For a full reference on tuples, see _Standard Library > Tuple_.

### 3.1.12 JSON

Thejsonscalar type is a stringified representation of structured data. JSON literals are declared by explicitly casting
other values or passing a properly formatted JSON string intoto_json(). Any type can be converted into JSON except
bytes.

db>select <json>5;
{' 5 '}
db>select <json>"a string";
{'"a string"'}
db>select <json>["this", "is", "an", "array"];
{'["this", "is", "an", "array"]'}
db>select <json>("unnamed tuple", 2);
{'["unnamed tuple", 2]'}
db>select <json>(name := "named tuple", count := 2);
{'{
"name": "named tuple",
"count": 2
}'}
db>select to_json('{"a": 2, "b": 5}');
{'{"a": 2, "b": 5}'}

JSON values support indexing operators. The resulting value is also of typejson.

db>select to_json('{"a": 2, "b": 5}')['a'];
{2}
db>select to_json('["a", "b", "c"]')[2];
{'"c"'}

EdgeQL supports a set of functions and operators onjsonvalues. Refer to the _Standard Library > JSON_ or click an
item below for detailed documentation.

**3.1. Literals 151**


```
Indexing json[i] json[from:to] json[name] json_get()
Merging json ++ json
Comparison operators = != ?= ?!= < > <= >=
Conversion to/from strings to_json() to_str()
Conversion to/from sets json_array_unpack() json_object_unpack()
Introspection json_typeof()
```
## 3.2 Sets

### 3.2.1 Everything is a set

All values in EdgeQL are actually **sets** : a collection of values of a given **type**. All elements of a set must have the same
type. The number of items in a set is known as its **cardinality**. A set with a cardinality of zero is referred to as an
**empty set**. A set with a cardinality of one is known as a **singleton**.

### 3.2.2 Constructing sets

Set literals are declared with _set constructor_ syntax: a comma-separated list of values inside a set of{curly braces}.

db>select {"set", "of", "strings"};
{"set", "of", "strings"}
db>select {1, 2, 3};
{1, 2, 3}

In actuality, curly braces are a syntactic sugar for theunionoperator. The previous examples are perfectly equivalent
to the following:

db>select "set"union"of"union "strings";
{"set", "of", "strings"}
db>select 1 union 2 union3;
{1, 2, 3}

A consequence of this is that nested sets are _flattened_.

db>select {1, {2, {3, 4}}};
{1, 2, 3, 4}
db>select 1 union(2 union (3union 4));
{1, 2, 3, 4}

All values in a set must have the same type. For convenience, EdgeDB will _implicitly cast_ values to other types, as
long as there is no loss of information (e.g. converting aint16to anint64). For a full reference, see the casting table
in _Standard Library > Casts_.

db>select {1, 1.5};
{1.0, 1.5}
db>select {1, 1234.5678n};
{1.0n, 1234.5678n}

Attempting to declare a set containing elements of _incompatible_ types is not permitted.

**152 Chapter 3. EdgeQL**


db>select {"apple", 3.14};
error: QueryError:setconstructor has argumentsof incompatible types
'std::str' and'std::float64'

**Note:** Types are considered _compatible_ if one can be implicitly cast into the other. For reference on implicit castability,
see _Standard Library > Casts_.

### 3.2.3 Literals are singletons

Literal syntax like 6 or"hello world"is just a shorthand for declaring a _singleton_ of a given type. This is why the
literals we created in the previous section were printed inside braces: to indicate that these values are _actually sets_.

db>select 6;
{6}
db>select "hello world";
{"hello world"}

Wrapping a literal in curly braces does not change the meaning of the expression. For instance,"hello world"is
_exactly equivalent_ to{"hello world"}.

db>select {"hello world"};
{"hello world"}
db>select "hello world" = {"hello world"};
{true}

You can retrieve the cardinality of a set with thecount()function.

db>select count('aaa');
{1}
db>select count({'aaa', 'bbb'});
{2}

### 3.2.4 Empty sets

The reason EdgeQL introduced the concept of _sets_ is to eliminate the concept ofnull. In SQL databasesnullis a
special value denoting the absence of data; in EdgeDB the absence of data is just an empty set.

**Note:** Why is the existence of NULL a problem? Put simply, it’s an edge case that permeates all of SQL and is often
handled inconsistently in different circumstances. A number of specific inconsistencies are documented in detail in the
We Can Do Better Than SQL post on the EdgeDB blog. For broader context, see Tony Hoare’s talk “The Billion Dollar
Mistake”.

Declaring empty sets isn’t as simple as{}; in EdgeQL, all expressions are _strongly typed_ , including empty sets. With
nonempty sets (like{1, 2, 3}) , the type is inferred from the set’s contents (int64). But with empty sets this isn’t
possible, so an _explicit cast_ is required.

db>select {};
error: QueryError:expression returns valueof indeterminatetype
(continues on next page)

**3.2. Sets 153**


```
(continued from previous page)
query:1:8
```
1 select {};
^^ Considerusing an explicittype cast.

db>select <int64>{};
{}
db>select <str>{};
{}
db>select count(<str>{});
{0}

You can check whether or not a set is _empty_ with theexistsoperator.

db>select exists<str>{};
{false}
db>select exists{'not','empty'};
{true}

### 3.2.5 Set references

A set reference is a _pointer_ to a set of values. Most commonly, this is the name of an _object type_ you’ve declared in
your schema.

db>select User;
{
default::User {id: 9d2ce01c-35e8-11ec-acc3-83b1377efea0},
default::User {id: b0e0dd0c-35e8-11ec-acc3-abf1752973be},
}
db>select count(User);
{2}

It may also be an _alias_ , which can be defined in a _with block_ or as an _alias declaration_ in your schema.

**Note:** In the example above, theUserobject type was declared inside thedefaultmodule. If it was in a non-default
module (say,my_module, we would need to use its _fully-qualified_ name.

db>select my_module::User;

### 3.2.6 Multisets

Technically sets in EdgeDB are actually _multisets_ , because they can contain duplicates of the same element. To eliminate
duplicates, use thedistinctset operator.

db>select {'aaa','aaa','aaa'};
{'aaa', 'aaa','aaa'}
db>select distinct {'aaa','aaa','aaa'};
{'aaa'}

**154 Chapter 3. EdgeQL**


### 3.2.7 Checking membership

Use theinoperator to check whether a set contains a particular element.

db>select 'aaa' in {'aaa','bbb','ccc'};
{true}
db>select 'ddd' in {'aaa','bbb','ccc'};
{false}

### 3.2.8 Merging sets

Use theunionoperator to merge two sets.

db>select 'aaa' union'bbb' union'ccc';
{'aaa', 'bbb','ccc'}
db>select {1, 2}union {3.1, 4.4};
{1.0, 2.0, 3.1, 4.4}

### 3.2.9 Finding common members

Use theintersectoperator to find common members between two sets.

db>select {1, 2, 3, 4, 5} intersect {3, 4, 5, 6, 7};
{3, 5, 4}
db>select {'a', 'b','c','d','e'} intersect {'c','d','e', 'f', 'g'};
{'e','d', 'c'}

If set members are repeated in both sets, they will be repeated in the set produced byintersectthe same number of
times they are repeated in both of the operand sets.

db>select {0, 1, 1, 1, 2, 3, 3} intersect {1, 3, 3, 3, 3, 3};
{1, 3, 3}

In this example, 1 appears three times in the first set but only once in the second, so it appears only once in the result.
3 appears twice in the first set and five times in the second. Both 3 appearances in the first set are overlapped by 3
appearances in the second, so they both end up in the resulting set.

### 3.2.10 Removing common members

Use theexceptoperator to leave only the members in the first set that do not appear in the second set.

db>select {1, 2, 3, 4, 5}except {3, 4, 5, 6, 7};
{1, 2}
db>select {'a', 'b','c','d','e'} except{'c', 'd', 'e', 'f','g'};
{'b','a'}

Whenexcepteliminates a common member that is repeated, it never eliminates more than the number of instances of
that member appearing in the second set.

db>select {0, 1, 1, 1, 2, 3, 3}except{1, 3, 3, 3, 3, 3};
{0, 1, 1, 2}

**3.2. Sets 155**


In this example, both sets share the member 1. The first set contains three of them while the second contains only one.
The result retains two 1 members from the first set since the sets shared only a single 1 in common. The second set has
five 3 members to the first set’s two, so both of the first set’s 3 members are eliminated from the resulting set.

### 3.2.11 Coalescing

Occasionally in queries, you need to handle the case where a set is empty. This can be achieved with a coalescing
operator??. This is commonly used to provide default values for optional _query parameters_.

db>select 'value'?? 'default';
{'value'}
db>select <str>{} ??'default';
{'default'}

**Note:** Coalescing is an example of a function/operator with _optional inputs_. By default, passing an empty set into a
function/operator will “short circuit” the operation and return an empty set. However it’s possible to mark inputs as
_optional_ , in which case the operation will be defined over empty sets. Another example iscount(), which returns{0}
when an empty set is passed as input.

### 3.2.12 Inheritance

EdgeDB schemas support _inheritance_ ; types (usually object types) can extend one or more other types. For instance
you may declare an abstract object typeMediathat is extended byMovieandTVShow.

abstract typeMedia {
required property title -> str;
}

typeMovie extendingMedia {
property release_year -> int64;
}

typeTVShow extendingMedia {
property num_seasons -> int64;
}

abstract typeMedia {
required title: str;
}

typeMovie extendingMedia {
release_year: int64;
}

typeTVShow extendingMedia {
num_seasons: int64;
}

A set of typeMediamay contain bothMovieandTVShowobjects.

**156 Chapter 3. EdgeQL**


db>select Media;
{
default::Movie {id: 9d2ce01c-35e8-11ec-acc3-83b1377efea0},
default::Movie {id: 3bfe4900-3743-11ec-90ee-cb73d2740820},
default::TVShow {id: b0e0dd0c-35e8-11ec-acc3-abf1752973be},
}

We can use the _type intersection_ operator[is <type>]to restrict the elements of a set by subtype.

db>select Media[is Movie];
{
default::Movie {id: 9d2ce01c-35e8-11ec-acc3-83b1377efea0},
default::Movie {id: 3bfe4900-3743-11ec-90ee-cb73d2740820},
}
db>select Media[is TVShow];
{
default::TVShow {id: b0e0dd0c-35e8-11ec-acc3-abf1752973be}
}

Type filters are commonly used in conjunction with _backlinks_.

### 3.2.13 Aggregate vs element-wise operations

EdgeQL provides a large library of built-in functions and operators for handling data structures. It’s useful to consider
functions/operators as either _aggregate_ or _element-wise_.

**Note:** This is an over-simplification, but it’s a useful mental model when just starting out with EdgeDB. For a more
complete guide, see _Reference > Cardinality_.

_Aggregate_ operations are applied to the set _as a whole_ ; they accept a set with arbitrary cardinality and return a _singleton_
(or perhaps an empty set if the input was also empty).

db>select count({'aaa', 'bbb'});
{2}
db>select sum({1, 2, 3});
{6}
db>select min({1, 2, 3});
{1}

Element-wise operations are applied on _each element_ of a set.

db>select str_upper({'aaa', 'bbb'});
{'AAA', 'BBB'}
db>select {1, 2, 3} ^ 2;
{1, 4, 9}
db>select str_split({"hello world", "hi again"}, " ");
{["hello", "world"], ["hi", "again"]}

When an _element-wise_ operation accepts two or more inputs, the operation is applied to all possible combinations of
inputs; in other words, the operation is applied to the _Cartesian product_ of the inputs.

**3.2. Sets 157**


db>select {'aaa','bbb'} ++ {'ccc', 'ddd'};
{'aaaccc', 'aaaddd', 'bbbccc','bbbddd'}

Accordingly, operations involving an empty set typically return an empty set. In constrast, aggregate operations like
count()are able to operate on empty sets.

db>select <str>{} ++'ccc';
{}
db>select count(<str>{});
{0}

For a more complete discussion of cardinality, see _Reference > Cardinality_.

### 3.2.14 Conversion to/from arrays

Both arrays and sets are collections of values that share a type. EdgeQL provides ways to convert one into the other.

**Note:** Remember that _all values_ in EdgeQL are sets; an array literal is just a singleton set of arrays. So here, “con-
verting” a set into an array means converting a set of typexinto another set with cardinality 1 (a singleton) and type
array<x>.

db>select array_unpack([1,2,3]);
{1, 2, 3}
db>select array_agg({1,2,3});
{[1, 2, 3]}

Arrays are an _ordered collection_ , whereas sets are generally unordered (unless explicitly sorted with anorder by
clause in a _select_ statement).

Element-wise scalar operations in the standard library cannot be applied to arrays, so sets of scalars are typically easier
to manipulate, search, and transform than arrays.

db>select str_trim({' hello','world '});
{'hello','world'}
db>select str_trim([' hello','world ']);
error: QueryError:function"str_trim(arg0: array<std::str>)" doesnotexist

Most _aggregate_ operations have analogs that operate on arrays. For instance, the set functioncount()is analogous to
the array functionlen().

### 3.2.15 Reference

```
Set operators distinct in union exists if..else ?? detached [is type]
Utility functions count() enumerate()
Cardinality assertion assert_distinct() assert_single() assert_exists()
```
```
See also
Tutorial > Building Blocks > Sets
```
**158 Chapter 3. EdgeQL**


## 3.3 Paths

A _path expression_ (or simply a _path_ ) represents a set of values that are reachable by traversing a given sequence of links
or properties from some source set of objects.

Consider the following schema:

typeUser {
required property email -> str;
multi link friends -> User;
}

typeBlogPost {
required property title -> str;
required link author -> User;
}

typeUser {
required email: str;
multi friends: User;
}

typeBlogPost {
required title: str;
required author: User;
}

The simplest path is simplyUser. This is a _set reference_ that refers to allUserobjects in the database.

select User;

Paths can traverse links. The path below refers to _all Users who are the friend of another User_.

select User.friends;

Paths can traverse to an arbitrary depth in a series of nested links.

select BlogPost.author.friends.friends;

Paths can terminate with a property reference.

select BlogPost.title;# all blog post titles
select BlogPost.author.email;# all author emails
select User.friends.email;# all friends'emails

**3.3. Paths 159**


### 3.3.1 Backlinks

All examples thus far have traversed links in the _forward direction_ , however it’s also possible to traverse links _backwards_
with.<notation. These are called **backlinks**.

Starting from each user, the path below traverses all _incoming_ links labeledauthorand returns the union of their
sources.

select User.<author;

As written, EdgeDB infers the _type_ of this expression to beBaseObject, notBlogPost. Why? Because in theory,
there may be several links namedauthorthat point toUser.

**Note:** BaseObjectis the root ancestor of all object types and it only contains a single property,id.

Consider the following addition to the schema:

```
type User {
# as before
}
```
```
type BlogPost {
required link author -> User;
}
```
+ type Comment {
+ required link author -> User;
+ }

```
type User {
# as before
}
```
```
type BlogPost {
required author: User;
}
```
+ type Comment {
+ required author: User;
+ }

With the above schema, the pathUser.<authorwould return a mixed set ofBlogPostandCommentobjects. This
may be desirable in some cases, but commonly you’ll want to narrow the results to a particular type. To do so, use the
type intersectionoperator:[is Foo]:

select User.<author[isBlogPost]; # returns all blog posts
select User.<author[isComment]; # returns all comments

**160 Chapter 3. EdgeQL**


### 3.3.2 Link properties

Paths can also reference _link properties_ with@notation. To demonstrate this, let’s add a property to theUser. friends
link:

```
type User {
required property email -> str;
```
- multi link friends -> User;
+ multi link friends -> User {
+ property since -> cal::local_date;
+ }
    }

```
type User {
required email: str;
```
- multi friends: User;
+ multi friends: User {
+ since: cal::local_date;
+ }
    }

The following represents a set of all dates on which friendships were formed.

select User.friends@since;

### 3.3.3 Path roots

For simplicity, all examples above use set references likeUseras the root of the path; however, the root can be _any
expression_ returning object types. Below, the root of the path is a _subquery_.

db>withedgedb_lovers := (
... select BlogPostfilter .titleilike "EdgeDB is awesome"
... )
...select edgedb_lovers.author;

This expression returns a set of allUserswho have written a blog post titled “EdgeDB is awesome”.

For a full syntax definition, see the _Reference > Paths_.

## 3.4 Types

The foundation of EdgeQL is EdgeDB’s rigorous type system. There is a set of EdgeQL operators and functions for
changing, introspecting, and filtering by types.

**3.4. Types 161**


### 3.4.1 Type expressions

Type expressions are exactly what they sound like: EdgeQL expressions that refer to a type. Most commonly, these are
simply the _names_ of established types:str,int64,BlogPost, etc. Arrays and tuples have a dedicated type syntax.

```
Type Syntax
Array array<x>
Tuple (unnamed) tuple<x, y, z>
Tuple (named) tuple<foo: x, bar: y>
```
For additional details on type syntax, see _Schema > Primitive Types_.

### 3.4.2 Type casting

Type casting is used to convert primitive values into another type. Casts are indicated with angle brackets containing a
type expression.

db>select <str>10;
{"10"}
db>select <bigint>10;
{10n}
db>select <array<str>>[1, 2, 3];
{[' 1 ', ' 2 ', ' 3 ']}
db>select <tuple<str, float64, bigint>>(1, 2, 3);
{(' 1 ', 2, 3n)}

Type casts are useful for declaring literals for types likedatetime,uuid, andint16that don’t have a dedicated syntax.

db>select <datetime>'1999-03-31T15:17:00Z';
{<datetime>'1999-03-31T15:17:00Z'}
db>select <int16>42;
{42}
db>select <uuid>'89381587-705d-458f-b837-860822e1b219';
{89381587-705d-458f-b837-860822e1b219}

There are limits to what values can be cast to a certain type. In some cases two types are entirely incompatible, like
boolandint64; in other cases, the source data must be in a particular format, like castingstrtodatetime. For a
comprehensive table of castability, see _Standard Library > Casts_.

Type casts can only be used on primitive expressions, not object type expressions. Every object stored in the database
is strongly and immutably typed; you can’t simply convert an object to an object of a different type.

db>select <BlogPost>10;
QueryError: cannotcast 'std::int64' to'default::BlogPost'
db>select <int64>'asdf';
InvalidValueError: invalid input syntaxfor typestd::int64: "asdf"
db>select <int16>100000000000000n;
NumericOutOfRangeError: std::int16 outof range

**162 Chapter 3. EdgeQL**


### 3.4.3 Type intersections

All elements of a given set have the same type; however, in the context of _sets of objects_ , this type might beabstract
and contain elements of multiple concrete subtypes. For instance, a set ofMediaobjects may contain bothMovieand
TVShowobjects.

db>select Media;
{
default::Movie {id: 9d2ce01c-35e8-11ec-acc3-83b1377efea0},
default::Movie {id: 3bfe4900-3743-11ec-90ee-cb73d2740820},
default::TVShow {id: b0e0dd0c-35e8-11ec-acc3-abf1752973be},
}

We can use the _type intersection_ operator to restrict the elements of a set by subtype.

db>select Media[is Movie];
{
default::Movie {id: 9d2ce01c-35e8-11ec-acc3-83b1377efea0},
default::Movie {id: 3bfe4900-3743-11ec-90ee-cb73d2740820},
}

Logically, this computes the intersection of theMediaandMoviesets; since onlyMovieobjects occur in both sets,
this can be conceptualized as a “filter” that removes all elements that aren’t of typeMovie.

### 3.4.4 Type checking

The[is foo]“type intersection” syntax should not be confused with the _type checking_ operatoris.

db>select 5 is int64;
{true}
db>select {3.14, 2.718}is notint64;
{true, true}
db>select Mediais Movie;
{true, true,false}

### 3.4.5 Thetypeofoperator

The type of any expression can be extracted with thetypeofoperator. This can be used in any expression that expects
a type.

db>select <typeof 5>' 100 ';
{100}
db>select "tuna"is typeof "trout";
{true}

**3.4. Types 163**


### 3.4.6 Introspection

The entire type system of EdgeDB is _stored inside EdgeDB_. All types are introspectable as instances of the
schema::Typetype. For a set of introspection examples, see _Guides > Introspection_. To try introspection for yourself,
see our interactive introspection tutorial.

## 3.5 Parameters

```
edb-alt-title Query Parameters
```
EdgeQL queries can reference parameters with$notation. The value of these parameters are supplied externally.

select <str>$var;
select <int64>$a + <int64>$b;
select BlogPostfilter.id = <uuid>$blog_id;

Note that we provided an explicit type cast before the parameter. This is required, as it enables EdgeDB to enforce the
provided types at runtime.

Parameters can be named or unnamed tuples.

select <tuple<str, bool>>$var;
select <optional tuple<str, bool>>$var;
select <tuple<name: str, flag: bool>>$var;
select <optional tuple<name: str, flag: bool>>$var;

### 3.5.1 Usage with clients

#### 3.5.1.1 REPL

When you include a parameter reference in an EdgeDB REPL, you’ll be prompted interactively to provide a value or
values.

db>select 'I ' ++ <str>$var ++ '!';
Parameter <str>$var: EdgeDB
{'I EdgeDB!'}

#### 3.5.1.2 Python

awaitclient.query(
"select'I '++ <str>$var ++ '!';",
var="lamp")

awaitclient.query(
"select <datetime>$date;",
date=datetime.today())

**164 Chapter 3. EdgeQL**


#### 3.5.1.3 JavaScript

awaitclient.query("select'I ' ++ <str>$name ++'!';", {
name: "rock and roll"
});

awaitclient.query("select <datetime>$date;", {
date: newDate()
});

#### 3.5.1.4 Go

varresult string
err = db.QuerySingle(ctx,
`select'I ' ++ <str>$var ++'!';"`,
&result, "Golang")

vardate time.Time
err = db.QuerySingle(ctx,
`select <datetime>$date;`,
&date, time.Now())

Refer to the Datatypes page of your preferred _client library_ to learn more about mapping between EdgeDB types and
language-native types.

### 3.5.2 Parameter types and JSON

Prior to EdgeDB 3.0, parameters can be only _scalars_ or arrays of scalars. In EdgeDB 3.0, parameters can also be
tuples. This may seem limiting at first, but in actuality this doesn’t impose any practical limitation on what can be
parameterized. To pass complex structures as parameters, use EdgeDB’s built-in _JSON_ functionality.

db>withdata := <json>$data
...insert Movie {
... title := <str>data['title'],
... release_year := <int64>data['release_year'],
... };
Parameter <json>$data: {"title": "The Marvels", "release_year": 2023}
{default::Movie {id: 8d286cfe-3c0a-11ec-aa68-3f3076ebd97f}}

Arrays can be “unpacked” into sets and assigned tomultilinks or properties.

withfriends := (
select Userfilter .idinarray_unpack(<array<uuid>>$friend_ids)
)
insert User {
name := <str>$name,
friends := friends,
};

**3.5. Parameters 165**


### 3.5.3 Optional parameters

By default, query parameters arerequired; the query will fail if the parameter value is an empty set. You can use an
optionalmodifier inside the type cast if the parameter is optional.

db>select <optional str>$name;
Parameter <str>$name (Ctrl+D for empty set`{}`):
{}

When using a client library, pass the idiomatic null pointer for your language:null,None,nil, etc.

**Note:** The<required foo>type cast is also valid (though redundant) syntax.

select <required str>$name;

### 3.5.4 What can be parameterized?

Any data manipulation language (DML) statement can be parameterized:select,insert,update, anddelete.

Schema definition language (SDL) and _configure_ statements **cannot** be parameterized. Data definition language (DDL)
has limited support for parameters, but it’s not a recommended pattern. Some of the limitations might be lifted in the
future versions.

## 3.6 Select

Theselectcommand retrieves or computes a set of values. We’ve already seen simple queries that select primitive
values.

db>select 'hello world';
{'hello world'}
db>select [1, 2, 3];
{[1, 2, 3]}
db>select {1, 2, 3};
{1, 2, 3}

With the help of awithblock, we can add filters, ordering, and pagination clauses.

db>withx := {1, 2, 3, 4, 5}
...select x
...filter x >= 3;
{3, 4, 5}
db>withx := {1, 2, 3, 4, 5}
...select x
...order byxdesc;
{5, 4, 3, 2, 1}
db>withx := {1, 2, 3, 4, 5}
...select x
...offset 1 limit3;
{2, 3, 4}

These queries can also be rewritten to use inline aliases, like so:

**166 Chapter 3. EdgeQL**


db>select x := {1, 2, 3, 4, 5}
...filter x >= 3;

### 3.6.1 Selecting objects

However most queries are selecting _objects_ that live in the database. For demonstration purposes, the queries below
assume the following schema.

module default{
abstract type Person {
required propertyname -> str {constraint exclusive };
}

```
type HeroextendingPerson {
propertysecret_identity -> str;
multi linkvillains := .<nemesis[isVillain];
}
```
```
type Villainextending Person {
linknemesis -> Hero;
}
```
type Movie {
required propertytitle -> str { constraintexclusive };
required propertyrelease_year -> int64;
multi linkcharacters -> Person;
}
}

module default{
abstract type Person {
requiredname: str {constraintexclusive };
}

```
type HeroextendingPerson {
secret_identity: str;
multi linkvillains := .<nemesis[isVillain];
}
```
```
type Villainextending Person {
nemesis: Hero;
}
```
type Movie {
requiredtitle: str {constraint exclusive };
requiredrelease_year: int64;
multicharacters: Person;
}
}

Let’s start by selecting allVillainobjects in the database. In this example, there are only three. Remember,Villain
is a _reference_ to the set of all Villain objects.

**3.6. Select 167**


db>select Villain;
{
default::Villain {id: ea7bad4c...},
default::Villain {id: 6ddbb04a...},
default::Villain {id: b233ca98...},
}

**Note:** For the sake of readability, theidvalues have been truncated.

By default, this only returns theidof each object. If serialized to JSON, this result would look like this:

[
{"id": "ea7bad4c-35d6-11ec-9519-0361f8abd380"},
{"id": "6ddbb04a-3c23-11ec-b81f-7b7516f2a868"},
{"id": "b233ca98-3c23-11ec-b81f-6ba8c4f0084e"},
]

Learn to select objects by trying it in our interactive object query tutorial.

### 3.6.2 Shapes

To specify which properties to select, we attach a **shape** toVillain. A shape can be attached to any object type
expression in EdgeQL.

db>select Villain { id, name };
{
default::Villain { id: ea7bad4c..., name: 'Whiplash' },
default::Villain { id: 6ddbb04a..., name: 'Green Goblin', },
default::Villain { id: b233ca98..., name: 'Doc Ock'},
}

To learn to use shapes by trying them yourself, see our interactive shapes tutorial.

#### 3.6.2.1 Nested shapes

Nested shapes can be used to fetch linked objects and their properties. Here we fetch allVillainobjects and their
nemeses.

db>select Villain {
... name,
... nemesis: { name }
... };
{
default::Villain {
name:'Green Goblin',
nemesis: default::Hero {name:'Spider-Man'},
},
...
}

**168 Chapter 3. EdgeQL**


In the context of EdgeQL, computed links likeHero.villainsare treated identically to concrete/non-computed links
likeVillain.nemesis.

db>select Hero {
... name,
... villains: { name }
... };
{
default::Hero {
name:'Spider-Man',
villains: {
default::Villain {name: 'Green Goblin'},
default::Villain {name: 'Doc Ock'},
},
},

}

#### 3.6.2.2 Splats

Splats allow you to select all properties of a type using the asterisk (*) or all properties of the type and a single level of
linked types with a double asterisk (**).

If you have this schema:

module default{
abstract type Person {
requiredname: str {constraintexclusive };
}

```
type HeroextendingPerson {
secret_identity: str;
multi linkvillains := .<nemesis[isVillain];
}
```
```
type Villainextending Person {
nemesis: Hero;
}
```
type Movie {
requiredtitle: str {constraint exclusive };
requiredrelease_year: int64;
multicharacters: Person;
}
}

splats will help you more easily select all properties when using the REPL. You can select all of an object’s properties
using the single splat:

db>select Movie {*};
{
default::Movie {
id: 6fe5c3ec-b776-11ed-8bef-3b2fba99fe8a,
(continues on next page)

**3.6. Select 169**


(continued from previous page)
release_year: 2021,
title: 'Spiderman: No Way Home',
},
default::Movie {
id: 76998656-b776-11ed-8bef-237907a987fa,
release_year: 2008,
title: 'Iron Man'
},
}

or you can select all of an object’s properties and the properties of a single level of nested objects with the double splat:

db>select Movie {**};
{
default::Movie {
id: 6fe5c3ec-b776-11ed-8bef-3b2fba99fe8a,
release_year: 2021,
title: 'Spiderman: No Way Home',
characters: {
default::Hero {
id: 01d9cc22-b776-11ed-8bef-73f84c7e91e7,
name:'Spiderman'
},
default::Villain {
id: efa2c4bc-b777-11ed-99eb-43f835d79384,
name:'Electro'
},
default::Villain {
id: f2c99a96-b775-11ed-8f7e-0b4a4a8e433e,
name:'Green Goblin'
},
default::Villain {
id: f8ca354a-b775-11ed-8bef-273145019e1d,
name:'Doc Ock'
},
},
},
default::Movie {
id: 76998656-b776-11ed-8bef-237907a987fa,
release_year: 2008,
title: 'Iron Man',
characters: {
default::Hero {
id: 48edcf8c-b776-11ed-8bef-c7d61b6780d2,
name:'Iron Man'
},
default::Villain {
id: 335f4104-b777-11ed-81eb-ab4de34e9c36,
name:'Obadiah Stane'
},
},
},
(continues on next page)

**170 Chapter 3. EdgeQL**


```
(continued from previous page)
```
}

**Note:** Splats are not yet supported in function bodies.

The splat expands all properties defined on the type as well as inherited properties. Given the same schema shown
above:

db>select Hero {*};
{
default::Hero {
id: 01d9cc22-b776-11ed-8bef-73f84c7e91e7,
name:'Spiderman',
secret_identity:'Peter Parker'
},
default::Hero {
id: 48edcf8c-b776-11ed-8bef-c7d61b6780d2,
name:'Iron Man',
secret_identity:'Tony Stark'
},
}

The splat here expands the heroes’ names even though thenameproperty is not defined on theHerotype but on the
Persontype it extends. If we want to select heroes but get only properties defined on thePersontype, we can do this
instead:

db>select Hero {Person.*};
{
default::Hero {
id: 01d9cc22-b776-11ed-8bef-73f84c7e91e7,
name:'Spiderman'
},
default::Hero {
id: 48edcf8c-b776-11ed-8bef-c7d61b6780d2,
name:'Iron Man'
},
}

If there are links on ourPersontype, we can usePerson.**in a similar fashion to get all properties and one level of
linked object properties, but only for links and properties that are defined on thePersontype.

You can use the splat to expand properties using a _type intersection_. Maybe we want to select allPersonobjects with
their names but also get any properties defined on theHerofor thosePersonobjects which are alsoHeroobjects:

db>select Person {
... name,
... [isHero].*
... };
{
default::Hero {
id: 01d9cc22-b776-11ed-8bef-73f84c7e91e7,
name:'Spiderman'
secret_identity:'Peter Parker'
(continues on next page)

**3.6. Select 171**


(continued from previous page)
},
default::Hero {
id: 48edcf8c-b776-11ed-8bef-c7d61b6780d2,
name:'Iron Man'
secret_identity:'Tony Stark'
},
default::Villain {
id: efa2c4bc-b777-11ed-99eb-43f835d79384,
name:'Electro'
},
default::Villain {
id: f2c99a96-b775-11ed-8f7e-0b4a4a8e433e,
name:'Green Goblin'
},
default::Villain {
id: f8ca354a-b775-11ed-8bef-273145019e1d,
name:'Doc Ock'
},
default::Villain {
id: 335f4104-b777-11ed-81eb-ab4de34e9c36,
name:'Obadiah Stane'
},
}

The double splat also works with type intersection expansion to expand both properties and links on the specified type.

db>select Person {
... name,
... [isHero].**
... };
{
default::Hero {
id: 01d9cc22-b776-11ed-8bef-73f84c7e91e7,
name:'Spiderman'
secret_identity:'Peter Parker',
villains: {
default::Villain {
id: efa2c4bc-b777-11ed-99eb-43f835d79384,
name:'Electro'
},
default::Villain {
id: f2c99a96-b775-11ed-8f7e-0b4a4a8e433e,
name:'Green Goblin'
},
default::Villain {
id: f8ca354a-b775-11ed-8bef-273145019e1d,
name:'Doc Ock'
}
}
},
default::Hero {
id: 48edcf8c-b776-11ed-8bef-c7d61b6780d2,
(continues on next page)

**172 Chapter 3. EdgeQL**


(continued from previous page)
name:'Iron Man'
secret_identity:'Tony Stark'
villains: {
default::Villain {
id: 335f4104-b777-11ed-81eb-ab4de34e9c36,
name:'Obadiah Stane'
}
}
},
default::Villain {
id: efa2c4bc-b777-11ed-99eb-43f835d79384,
name:'Electro'
},
default::Villain {
id: f2c99a96-b775-11ed-8f7e-0b4a4a8e433e,
name:'Green Goblin'
},
default::Villain {
id: f8ca354a-b775-11ed-8bef-273145019e1d,
name:'Doc Ock'
},
default::Villain {
id: 335f4104-b777-11ed-81eb-ab4de34e9c36,
name:'Obadiah Stane'
},
}

With this query, we getnamefor eachPersonand all the properties and one level of links on theHeroobjects. We
don’t getVillainobjects’ nemeses because that link is not covered by our double splat which only expansHerolinks.
If theVillaintype had properties defined on it, we wouldn’t get those with this query either.

### 3.6.3 Filtering

To filter the set of selected objects, use afilter <expr>clause. The<expr>that follows thefilterkeyword can
be _any boolean expression_.

To reference thenameproperty of theVillainobjects being selected, we useVillain.name.

db>select Villain {id, name}
...filter Villain.name = "Doc Ock";
{default::Villain {id: b233ca98..., name: 'Doc Ock'}}

**Note:** This query contains two occurrences ofVillain. The first (outer) is passed as the argument toselectand
refers to the set of allVillainobjects. However the _inner_ occurrence is inside the _scope_ of theselectstatement and
refers to the _object being selected_.

However, this looks a little clunky, so EdgeQL provides a shorthand: just dropVillainentirely and simply use.name.
Since we are selecting a set of Villains, it’s clear from context that.namemust refer to a link/property of theVillain
type. In other words, we are in the **scope** of theVillaintype.

**3.6. Select 173**


db>select Villain {name}
...filter .name = "Doc Ock";
{default::Villain {name:'Doc Ock'}}

Learn to filter your queries by trying it in our interactive filters tutorial.

#### 3.6.3.1 Filtering by ID

To filter byid, remember to cast the desired ID to _uuid_ :

db>select Villain {id, name}
...filter .id = <uuid>"b233ca98-3c23-11ec-b81f-6ba8c4f0084e";
{
default::Villain {
id:'b233ca98-3c23-11ec-b81f-6ba8c4f0084e',
name:'Doc Ock'
}
}

#### 3.6.3.2 Nested filters

Filters can be added at every level of shape nesting. The query below applies a filter to both the selectedHeroobjects
and their linkedvillains.

db>select Hero {
... name,
... villains: {
... name
... }filter.name ilike"%er"
... }filter .nameilike "%man";
{
default::Hero {
name:'Iron Man',
villains: {default::Villain {name:'Justin Hammer'}},
},
default::Hero {
name:'Spider-Man',
villains: {
default::Villain {name: 'Shocker'},
default::Villain {name: 'Tinkerer'},
default::Villain {name: 'Kraven the Hunter'},
},
},
}

Note that the _scope_ changes inside nested shapes. When we use.namein the outerfilter, it refers to the name of the
hero. But when we use.namein the nestedvillainsshape, the scope has changed toVillain.

**174 Chapter 3. EdgeQL**


### 3.6.4 Ordering

Order the result of a query with anorder byclause.

db>select Villain { name }
...order by.name;
{
default::Villain {name: 'Abomination'},
default::Villain {name: 'Doc Ock'},
default::Villain {name: 'Green Goblin'},
default::Villain {name: 'Justin Hammer'},
default::Villain {name: 'Kraven the Hunter'},
default::Villain {name: 'Loki'},
default::Villain {name: 'Shocker'},
default::Villain {name: 'The Vulture'},
default::Villain {name: 'Tinkerer'},
default::Villain {name: 'Zemo'},
}

The expression provided toorder bymay be _any_ singleton expression, primitive or otherwise.

**Note:** In EdgeDB all values are orderable. Objects are compared using theirid; tuples and arrays are compared
element-by-element from left to right. By extension, the generic comparison operators=,<,>, etc. can be used with
any two expressions of the same type.

You can also order by multiple expressions and specify the _direction_ with anasc(default) ordescmodifier.

**Note:** When ordering by multiple expressions, arrays, or tuples, the leftmost expression/element is compared. If these
elements are the same, the next element is used to “break the tie”, and so on. If all elements are the same, the order is
not well defined.

db>select Movie { title, release_year }
...order by
... .release_year desc then
... str_trim(.title)desc;
{
default::Movie {title: 'Spider-Man: No Way Home', release_year: 2021},
...
default::Movie {title: 'Iron Man', release_year: 2008},
}

When ordering by multiple expressions, each expression is separated with thethenkeyword. For a full reference on
ordering, including how empty values are handled, see _Reference > Commands > Select_.

**3.6. Select 175**


### 3.6.5 Pagination

EdgeDB supportslimitandoffsetclauses. These are typically used in conjunction withorder byto maintain a
consistent ordering across pagination queries.

db>select Villain { name }
...order by.name
...offset 3
...limit3;
{
default::Villain {name: 'Hela'},
default::Villain {name: 'Justin Hammer'},
default::Villain {name: 'Kraven the Hunter'},
}

The expressions passed tolimitandoffsetcan be any singletonint64expression. This query fetches all Villains
except the last (sorted by name).

db>select Villain {name}
...order by.name
...limitcount(Villain) - 1;
{
default::Villain {name: 'Abomination'},
default::Villain {name: 'Doc Ock'},
...
default::Villain {name: 'Winter Soldier'},# no Zemo
}

You may pass the empty set tolimitoroffset. Passing the empty set is effectively the same as excludinglimitor
offsetfrom your query (i.e., no limit or no offset). This is useful if you need to parameterizelimitand/oroffset
but may still need to execute your query without providing one or the other.

db>select Villain {name}
...order by.name
...offset <optional int64>$offset
...limit<optional int64>$limit;
Parameter <int64>$offset (Ctrl+D for empty set`{}`):
Parameter <int64>$limit (Ctrl+Dfor empty set `{}`):
{
default::Villain {name: 'Abomination'},
default::Villain {name: 'Doc Ock'},
...
}

**Note:** If you parameterizelimitandoffsetand want to reserve the option to pass the empty set, make sure those
parameters areoptionalas shown in the example above.

**176 Chapter 3. EdgeQL**


### 3.6.6 Computed fields

Shapes can contain _computed fields_. These are EdgeQL expressions that are computed on the fly during the execution
of the query. As with other clauses, we can use _leading dot notation_ (e.g..name) to refer to the properties and links of
the object type currently _in scope_.

db>select Villain {
... name,
... name_upper := str_upper(.name)
... };
{
default::Villain {
id: 4114dd56...,
name:'Abomination',
name_upper:'ABOMINATION',
},

}

As with nested filters, the _current scope_ changes inside nested shapes.

db>select Villain {
... id,
... name,
... name_upper := str_upper(.name),
... nemesis: {
... secret_identity,
... real_name_upper := str_upper(.secret_identity)
... }
... };
{
default::Villain {
id: 6ddbb04a...,
name:'Green Goblin',
name_upper:'GREEN GOBLIN',
nemesis: default::Hero {
secret_identity:'Peter Parker',
real_name_upper:'PETER PARKER',
},
},

}

### 3.6.7 Backlinks

Fetching backlinks is a common use case for computed fields. To demonstrate this, let’s fetch a list of all movies starring
a particular Hero.

db>select Hero {
... name,
... movies := .<characters[isMovie] { title }
... }filter .name = "Iron Man";
(continues on next page)

**3.6. Select 177**


```
(continued from previous page)
```
{
default::Hero {
name:'Iron Man',
movies: {
default::Movie {title: 'Iron Man'},
default::Movie {title: 'Iron Man 2'},
default::Movie {title: 'Iron Man 3'},
default::Movie {title: 'Captain America: Civil War'},
default::Movie {title: 'The Avengers'},
},
},
}

**Note:** The computed backlinkmoviesis a combination of the _backlink operator_ .<and a type intersection[is
Movie]. For a full reference on backlink syntax, see _EdgeQL > Paths_.

Instead of re-declaring backlinks inside every query where they’re needed, it’s common to add them directly into your
schema as computed links.

abstract type Person {
required property name -> str {
constraint exclusive;
};
+ multi link movies := .<characters[is Movie]
}

abstract type Person {
required name: str {
constraint exclusive;
};
+ multi link movies := .<characters[is Movie]
}

**Note:** In the example above, thePerson.moviesis amultilink. Including these keywords is optional, since EdgeDB
can infer this from the assigned expression.<characters[is Movie]. However, it’s a good practice to include the
explicit keywords to make the schema more readable and “sanity check” the cardinality.

This simplifies future queries;Person.moviescan now be traversed in shapes just like a non-computed link.

select Hero {
name,
movies: { title }
}filter .name = "Iron Man";

**178 Chapter 3. EdgeQL**


### 3.6.8 Subqueries

There’s no limit to the complexity of computed expressions. EdgeQL is designed to be fully composable; entire queries
can be embedded inside each other. Below, we use a subquery to select all movies containing a villain’s nemesis.

db>select Villain {
... name,
... nemesis_name := .nemesis.name,
... movies_with_nemesis := (
... selectMovie { title }
... filterVillain.nemesis in .characters
... )
... };
{
default::Villain {
name:'Loki',
nemesis_name:'Thor',
movies_with_nemesis: {
default::Movie {title: 'Thor'},
default::Movie {title: 'Thor: The Dark World'},
default::Movie {title: 'Thor: Ragnarok'},
default::Movie {title: 'The Avengers'},
},
},

}

### 3.6.9 Polymorphic queries

```
index poly polymorphism nested shapes
```
All queries thus far have referenced concrete object types:HeroandVillain. However, both of these types extend
the abstract typePerson, from which they inherit thenameproperty.

To learn how to leverage polymorphism in your queries, see our interactive polymorphism tutorial.

##### 3.6.9.1 Polymorphic sets

It’s possible to directly query allPersonobjects; the resulting set will be a mix ofHeroandVillainobjects (and
possibly other subtypes ofPerson, should they be declared).

db>select Person { name };
{
default::Villain {name: 'Abomination'},
default::Villain {name: 'Zemo'},
default::Hero {name:'The Hulk'},
default::Hero {name:'Iron Man'},
...
}

You may also encounter such “mixed sets” when querying a link that points to an abstract type (such asMovie.
characters) or aunion type.

**3.6. Select 179**


db>select Movie {
... title,
... characters: {
... name
... }
... }
...filter .title = "Iron Man 2";
{
default::Movie {
title: 'Iron Man 2',
characters: {
default::Villain {name: 'Whiplash'},
default::Villain {name: 'Justin Hammer'},
default::Hero {name:'Iron Man'},
default::Hero {name:'Black Widow'},
},
},
}

##### 3.6.9.2 Polymorphic fields

We can fetch different properties _conditional_ on the subtype of each object by prefixing property/link references with
[is <type>]. This is known as a **polymorphic query**.

db>select Person {
... name,
... secret_identity := [is Hero].secret_identity,
... number_of_villains := count([is Hero].villains),
... nemesis := [is Villain].nemesis {
... name
... }
... };
{
default::Villain {
name:'Green Goblin',
secret_identity: {},
number_of_villains: 0,
nemesis: default::Hero {name:'Spider-Man'},
},
default::Hero {
name:'Spider-Man',
secret_identity:'Peter Parker',
number_of_villains: 6,
nemesis: {},
},
...
}

This syntax might look familiar; it’s the _type intersection_ again. In effect, this operator conditionally returns the value
of the referenced field only if the object matches a particular type. If the match fails, an empty set is returned.

The linesecret_identity := [is Hero].secret_identityis a bit redundant, since the computed property has
the same name as the polymorphic field. In these cases, EdgeQL supports a shorthand.

**180 Chapter 3. EdgeQL**


db>select Person {
... name,
... [isHero].secret_identity,
... [isVillain].nemesis: {
... name
... }
... };
{
default::Villain {
name:'Green Goblin',
secret_identity: {},
nemesis: default::Hero {name:'Spider-Man'},
},
default::Hero {
name:'Spider-Man',
secret_identity:'Peter Parker',
nemesis: {},
},

}

##### 3.6.9.3 Filtering polymorphic links

Relatedly, it’s possible to filter polymorphic links by subtype. Below, we exclusively fetch theMovie.charactersof
typeHero.

db>select Movie {
... title,
... characters[is Hero]: {
... secret_identity
... },
... };
{
default::Movie {
title: 'Spider-Man: Homecoming',
characters: {default::Hero {secret_identity:'Peter Parker'}},
},
default::Movie {
title: 'Iron Man',
characters: {default::Hero {secret_identity:'Tony Stark'}},
},
...
}

**3.6. Select 181**


#### 3.6.10 Free objects

To select several values simultaneously, you can “bundle” them into a “free object”. Free objects are a set of key-value
pairs that can contain any expression. Here, the term “free” is used to indicate that the object in question is not an
instance of a particular _object type_ ; instead, it’s constructed ad hoc inside the query.

db>select {
... my_string := "This is a string",
... my_number := 42,
... several_numbers := {1, 2, 3},
... all_heroes := Hero { name }
... };
{
{
my_string:'This is a string',
my_number: 42,
several_numbers: {1, 2, 3},
all_heroes: {
default::Hero {name:'The Hulk'},
default::Hero {name:'Iron Man'},
default::Hero {name:'Spider-Man'},
default::Hero {name:'Thor'},
default::Hero {name:'Captain America'},
default::Hero {name:'Black Widow'},
},
},
}

Note that the result is a _singleton_ but each key corresponds to a set of values, which may have any cardinality.

#### 3.6.11 With block

All top-level EdgeQL statements (select,insert,update, anddelete) can be prefixed with awithblock. These
blocks let you declare standalone expressions that can be used in your query.

db>withhero_name := "Iron Man"
...select Hero { secret_identity }
...filter .name = hero_name;
{default::Hero {secret_identity: 'Tony Stark'}}

For full documentation onwith, see _EdgeQL > With_.

```
See also
Reference > Commands > Select
Cheatsheets > Selecting data
Tutorial > Basic Queries > Objects
Tutorial > Basic Queries > Filters
Tutorial > Basic Queries > Aggregates
Tutorial > Nested Structures > Shapes
Tutorial > Nested Structures > Polymorphism
```
**182 Chapter 3. EdgeQL**


### 3.7 Insert

Theinsertcommand is used to create instances of object types. The code samples on this page assume the following
schema:

module default{
abstract type Person {
required propertyname -> str {constraint exclusive };
}

```
type HeroextendingPerson {
propertysecret_identity -> str;
multi linkvillains := .<nemesis[isVillain];
}
```
```
type Villainextending Person {
linknemesis -> Hero;
}
```
type Movie {
required propertytitle -> str { constraintexclusive };
required propertyrelease_year -> int64;
multi linkcharacters -> Person;
}
}

module default{
abstract type Person {
requiredname: str {constraintexclusive };
}

```
type HeroextendingPerson {
secret_identity: str;
multi linkvillains := .<nemesis[isVillain];
}
```
```
type Villainextending Person {
nemesis: Hero;
}
```
type Movie {
requiredtitle: str {constraint exclusive };
requiredrelease_year: int64;
multicharacters: Person;
}
}

**3.7. Insert 183**


#### 3.7.1 Basic usage

You caninsertinstances of any _non-abstract_ object type.

db>insert Hero {
... name := "Spider-Man",
... secret_identity := "Peter Parker"
... };
{default::Hero {id: b0fbe9de-3e90-11ec-8c12-ffa2d5f0176a}}

Similar to _selecting fields_ inselect,insertstatements include a _shape_ specified withcurly braces; the values of
properties/links are assigned with the:=operator.

Optional links or properties can be omitted entirely, as well as those with adefaultvalue (likeid).

db>insert Hero {
... name := "Spider-Man"
... # secret_identity is omitted
... };
{default::Hero {id: b0fbe9de-3e90-11ec-8c12-ffa2d5f0176a}}

You can onlyinsertinstances of concrete (non-abstract) object types.

db>insert Person {
... name := "The Man With No Name"
... };
error: QueryError: cannotinsert into abstract object type 'default::Person'

#### 3.7.2 Inserting links

EdgeQL’s composable syntax makes link insertion painless. Below, we insert “Spider-Man: No Way Home” and
include all known heroes and villains ascharacters(which is basically true).

db>insert Movie {
... title := "Spider-Man: No Way Home",
... characters := (
... selectPerson
... filter.name in {
... 'Spider-Man',
... 'Doctor Strange',
... 'Doc Ock',
... 'Green Goblin'
... }
... )
... };
{default::Movie {id: 9b1cf9e6-3e95-11ec-95a2-138eeb32759c}}

To assign to theMovie.characterslink, we’re using a _subquery_. This subquery is executed and resolves to a singleton
set of typePerson, which is assignable tocharacters. Note that the innerselect Personstatement is wrapped in
parentheses; this is required for all subqueries in EdgeQL.

Now let’s assign to a _single link_.

**184 Chapter 3. EdgeQL**


db>insert Villain {
... name := "Doc Ock",
... nemesis := (select Herofilter .name = "Spider-Man")
... };

This query is valid because the inner subquery is guaranteed to return at most oneHeroobject, due to the uniqueness
constraint onHero.name. If you are filtering on a non-exclusive property, useassert_singleto guarantee that the
subquery will return zero or one results. If more than one result is returned, this query will fail at runtime.

db>insert Villain {
... name := "Doc Ock",
... nemesis := assert_single((
... selectHero
... filter.secret_identity = "Peter B. Parker"
... ))
... };

#### 3.7.3 Nested inserts

Just as we used subqueries to populate links with existing objects, we can also execute _nested inserts_.

db>insert Villain {
... name := "The Mandarin",
... nemesis := (insert Hero {
... name := "Shang-Chi",
... secret_identity := "Shaun"
... })
... };
{default::Villain {id: d47888a0-3e7b-11ec-af13-fb68c8777851}}

Now let’s write a nested insert for amultilink.

db>insert Movie {
... title := "Black Widow",
... characters := {
... (select Herofilter.name = "Black Widow"),
... (insert Hero { name := "Yelena Belova"}),
... (insert Villain {
... name := "Dreykov",
... nemesis := (select Herofilter.name = "Black Widow")
... })
... }
... };
{default::Movie {id: af706c7c-3e98-11ec-abb3-4bbf3f18a61a}}

We are using _set literal syntax_ to construct a set literal containing severalselectandinsertsubqueries. This set
contains a mix ofHeroandVillainobjects; since these are both subtypes ofPerson(the expected type ofMovie.
characters), this is valid.

You also can’t _assign_ to a computed property or link; these fields don’t actually exist in the database.

db>insert Hero {
... name := "Ant-Man",
(continues on next page)

**3.7. Insert 185**


```
(continued from previous page)
```
... villains := (select Villain)
... };
error: QueryError: modificationof computedlink 'villains'of object type
'default::Hero' isprohibited

#### 3.7.4 With block

In the previous query, we selected Black Widow twice: once in thecharactersset and again as thenemesisof
Dreykov. In circumstances like this, pulling a subquery into awithblock lets you avoid duplication.

db>withblack_widow := (selectHero filter.name = "Black Widow")
...insert Movie {
... title := "Black Widow",
... characters := {
... black_widow,
... (insert Hero { name := "Yelena Belova"}),
... (insert Villain {
... name := "Dreykov",
... nemesis := black_widow
... })
... }
... };
{default::Movie {id: af706c7c-3e98-11ec-abb3-4bbf3f18a61a}}

Thewithblock can contain an arbitrary number of clauses; later clauses can reference earlier ones.

db>with
... black_widow := (selectHero filter.name = "Black Widow"),
... yelena := (insertHero { name := "Yelena Belova"}),
... dreykov := (insert Villain {name := "Dreykov", nemesis := black_widow})
...insert Movie {
... title := "Black Widow",
... characters := { black_widow, yelena, dreykov }
... };
{default::Movie {id: af706c7c-3e98-11ec-abb3-4bbf3f18a61a}}

#### 3.7.5 Conflicts

EdgeDB provides a general-purpose mechanism for gracefully handling possible exclusivity constraint violations. Con-
sider a scenario where we are trying toinsertEternals (theMovie), but we can’t remember if it already exists in the
database.

db>insert Movie {
... title := "Eternals"
... }
...unless conflict on.title
...else(select Movie);
{default::Movie {id: af706c7c-3e98-11ec-abb3-4bbf3f18a61a}}

**186 Chapter 3. EdgeQL**


This query attempts toinsertEternals. If it already exists in the database, it will violate the uniqueness constraint
onMovie.title, causing a _conflict_ on thetitlefield. Theelseclause is then executed and returned instead. In
essence,unless conflictlets us “catch” exclusivity conflicts and provide a fallback expression.

**Note:** Note that theelseclause is simplyselect Movie. There’s no need to apply additional filters onMovie; in
the context of theelseclause,Movieis bound to the conflicting object.

**Note:** Usingunless conflicton _multi properties_ is only supported in 2.10 and later.

##### 3.7.5.1 Upserts

There are no limitations on what theelseclause can contain; it can be any EdgeQL expression, including an _update_
statement. This lets you express _upsert_ logic in a single EdgeQL query.

db>with
... title := "Eternals",
... release_year := 2021
...insert Movie {
... title := title,
... release_year := release_year
... }
...unless conflict on.title
...else(
... update Movieset{ release_year := release_year }
... );
{default::Movie {id: f1bf5ac0-3e9d-11ec-b78d-c7dfb363362c}}

When a conflict occurs during the initialinsert, the statement falls back to theupdatestatement in theelseclause.
This updates therelease_yearof the conflicting object.

To learn to use upserts by trying them yourself, see our interactive upserts tutorial.

##### 3.7.5.2 Suppressing failures

Theelseclause is optional; when omitted, theinsertstatement will return an _empty set_ if a conflict occurs. This is
a common way to preventinsertqueries from failing on constraint violations.

db>insert Hero { name := "The Wasp" }# initial insert
...unless conflict;
{default::Hero {id: 35b97a92-3e9b-11ec-8e39-6b9695d671ba}}
db>insert Hero { name := "The Wasp" }# The Wasp now exists
...unless conflict;
{}

**3.7. Insert 187**


#### 3.7.6 Bulk inserts

Bulk inserts are performed by passing in a JSON array as a _query parameter_ ,unpackingit, and using a _for loop_ to
insert the objects.

db>with
... raw_data := <json>$data,
...foritemin json_array_unpack(raw_data)union (
... insert Hero { name := <str>item['name'] }
... );
Parameter <json>$data: [{"name":"Sersi"},{"name":"Ikaris"},{"name":"Thena"}]
{
default::Hero {id: 35b97a92-3e9b-11ec-8e39-6b9695d671ba},
default::Hero {id: 35b97a92-3e9b-11ec-8e39-6b9695d671ba},
default::Hero {id: 35b97a92-3e9b-11ec-8e39-6b9695d671ba},

}

```
See also
Reference > Commands > Insert
Cheatsheets > Inserting data
Tutorial > Data Mutations > Insert
Tutorial > Data Mutations > Upsert
```
### 3.8 Update

Theupdatecommand is used to update existing objects.

db>update Hero
...filter .name = "Hawkeye"
...set{ name := "Ronin" };
{default::Hero {id: d476b12e-3e7b-11ec-af13-2717f3dc1d8a}}

If you omit thefilterclause, all objects will be updated. This is useful for updating values across all objects of a
given type. The example below cleans up allHero.namevalues by trimming whitespace and converting them to title
case.

db>update Hero
...set{ name := str_trim(str_title(.name)) };
{default::Hero {id: d476b12e-3e7b-11ec-af13-2717f3dc1d8a}}

**188 Chapter 3. EdgeQL**


#### 3.8.1 Syntax

The structure of theupdatestatement (update...filter...set) is an intentional inversion of SQL’sUPDATE...
SET...WHEREsyntax. Curiously, in SQL, thewhereclauses typically occur _last_ despite being applied before theset
statement. EdgeQL is structured to reflect this; first, a target set is specified, then filters are applied, then the data is
updated.

##### 3.8.1.1 Updating links

When updating links, the:=operator will _replace_ the set of linked values.

db>update movie
...filter .title = "Black Widow"
...set{
... characters := (
... select Person
... filter .namein { "Black Widow", "Yelena", "Dreykov" }
... )
... };
{default::Title {id: af706c7c-3e98-11ec-abb3-4bbf3f18a61a}}
db>select Movie { num_characters := count(.characters) }
...filter .title = "Black Widow";
{default::Movie {num_characters: 3}}

To add additional linked items, use the+=operator.

db>update Movie
...filter .title = "Black Widow"
...set{
... characters += (insertVillain {name := "Taskmaster"})
... };
{default::Title {id: af706c7c-3e98-11ec-abb3-4bbf3f18a61a}}
db>select Movie { num_characters := count(.characters) }
...filter .title = "Black Widow";
{default::Movie {num_characters: 4}}

To remove items, use-=.

db>update Movie
...filter .title = "Black Widow"
...set{
... characters -= Villain# remove all villains
... };
{default::Title {id: af706c7c-3e98-11ec-abb3-4bbf3f18a61a}}
db>select Movie { num_characters := count(.characters) }
...filter .title = "Black Widow";
{default::Movie {num_characters: 2}}

**3.8. Update 189**


##### 3.8.1.2 With blocks

All top-level EdgeQL statements (select,insert,update, anddelete) can be prefixed with awithblock. This is
useful for updating the results of a complex query.

db>withpeople := (
... selectPerson
... order by.name
... offset 3
... limit 3
... )
...update people
...set{ name := str_trim(.name) };
{
default::Hero {id: d4764c66-3e7b-11ec-af13-df1ba5b91187},
default::Hero {id: d7d7e0f6-40ae-11ec-87b1-3f06bed494b9},
default::Villain {id: d477a836-3e7b-11ec-af13-4fea611d1c31},
}

**Note:** You can pass any object-type expression intoupdate, including polymorphic ones (as above).

##### 3.8.1.3 See also

For documentation on performing _upsert_ operations, see _EdgeQL > Insert > Upserts_.

```
Reference > Commands > Update
Cheatsheets > Updating data
Tutorial > Data Mutations > Update
```
### 3.9 Delete

Thedeletecommand is used to delete objects from the database.

delete Hero
filter .name ='Iron Man';

#### 3.9.1 Clauses

Deletion statements supportfilter,order by, andoffset/limitclauses. See _EdgeQL > Select_ for full documen-
tation on these clauses.

delete Hero
filter .nameilike'the %'
order by.name
offset 10
limit5;

**190 Chapter 3. EdgeQL**


#### 3.9.2 Link deletion

Every link is associated with a _link deletion policy_. By default, it isn’t possible to delete an object linked to by another.

db>delete Herofilter.name = "Yelena Belova";
ConstraintViolationError: deletionof default::Hero
(af7076e0-3e98-11ec-abb3-b3435bbe7c7e)is prohibitedby link target policy
{}

This deletion failed because Yelena is still in thecharacterslist of the Black Widow movie. We must destroy this
link before Yelena can be deleted.

db>update Movie
...filter .title = "Black Widow"
...set{
... characters -= (selectHero filter.name = "Yelena Belova")
... };
{default::Movie {id: af706c7c-3e98-11ec-abb3-4bbf3f18a61a}}
db>delete Herofilter.name = "Yelena Belova";
{default::Hero {id: af7076e0-3e98-11ec-abb3-b3435bbe7c7e}}

To avoid this behavior, we could update theMovie.characterslink to use theallowdeletion policy.

```
type Movie {
required property title -> str { constraint exclusive };
required property release_year -> int64;
```
- multi link characters -> Person;
+ multi link characters -> Person {
+ on target delete allow;
+ };
    }

```
type Movie {
required title: str { constraint exclusive };
required release_year: int64;
```
- multi characters: Person;
+ multi characters: Person {
+ on target delete allow;
+ };
    }

##### 3.9.2.1 Cascading deletes

If a link uses thedelete sourcepolicy, then deleting a _target_ of the link will also delete the object that links to it
(the _source_ ). This behavior can be used to implement cascading deletes; be careful with this power!

The full list of deletion policies is documented at _Schema > Links_.

**3.9. Delete 191**


#### 3.9.3 Return value

Adeletestatement returns the set of deleted objects. You can pass this set intoselectto fetch properties and links
of the (now-deleted) objects. This is the last moment this data will be available before being permanently deleted.

db>withmovie := (delete Moviefilter .title = "Untitled")
...select movie {id, title};
{default::Movie {
id: b11303c6-40ac-11ec-a77d-d393cdedde83,
title: 'Untitled',
}}

```
See also
Reference > Commands > Delete
Cheatsheets > Deleting data
Tutorial > Data Mutations > Delete
```
### 3.10 For

EdgeQL supports a top-levelforstatement. These “for loops” iterate over each element of some input set, execute
some expression with it, and merge the results into a single output set.

db>fornumberin {0, 1, 2, 3}
...union(
... select { number, number + 0.5 }
... );
{0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5}

This statement iterates through each number in the set. Inside the loop, thenumbervariable is bound to a singleton
set. The inner expression is executed for every element of the input set, and the results of each execution are merged
into a single output set.

**Note:** Theunionkeyword is a required part of theforstatement syntax; it is intended to indicate explicitly that the
results of each loop execution are ultimately merged.

#### 3.10.1 Bulk inserts

Theforstatement is commonly used for bulk inserts.

db>forhero_namein {'Cersi','Ikaris','Thena'}
...union(
... insert Hero { name := hero_name }
... );
{
default::Hero {id: d7d7e0f6-40ae-11ec-87b1-3f06bed494b9},
default::Hero {id: d7d7f870-40ae-11ec-87b1-f712a4efc3a5},
default::Hero {id: d7d7f8c0-40ae-11ec-87b1-6b8685d56610}
}

**192 Chapter 3. EdgeQL**


This statement iterates through each name in the list of names. Inside the loop,hero_nameis bound to astrsingleton,
so it can be assigned toHero.name.

Instead of literal sets, it’s common to use a _json_ parameter for bulk inserts. This value is then “unpacked” into a set of
jsonelements and used inside theforloop:

db>with
... raw_data := <json>$data,
...foritemin json_array_unpack(raw_data)union (
... insert Hero { name := <str>item['name'] }
... );
Parameter <json>$data: [{"name":"Sersi"},{"name":"Ikaris"},{"name":"Thena"}]
{
default::Hero {id: d7d7e0f6-40ae-11ec-87b1-3f06bed494b9},
default::Hero {id: d7d7f870-40ae-11ec-87b1-f712a4efc3a5},
default::Hero {id: d7d7f8c0-40ae-11ec-87b1-6b8685d56610}
}

A similar approach can be used for bulk updates.

```
See also
Reference > Commands > For
```
### 3.11 Group

EdgeQL supports a top-levelgroupstatement. This is used to partition sets into subsets based on some parameters.
These subsets then can be additionally aggregated to provide some analytics.

The most basic format is just using the baregroupto group a set of objects by some property:

db>groupMovie by.release_year;
{
{
key: {release_year: 2016},
grouping: {'release_year'},
elements: {
default::Movie {title: 'Captain America: Civil War'},
default::Movie {title: 'Doctor Strange'},
},
},
{
key: {release_year: 2017},
grouping: {'release_year'},
elements: {
default::Movie {title: 'Spider-Man: Homecoming'},
default::Movie {title: 'Thor: Ragnarok'},
},
},
{
key: {release_year: 2018},
grouping: {'release_year'},
elements: {default::Movie {title:'Ant-Man and the Wasp'}},
(continues on next page)

**3.11. Group 193**


(continued from previous page)
},
{
key: {release_year: 2019},
grouping: {'release_year'},
elements: {default::Movie {title:'Spider-Man: No Way Home'}},
},
{
key: {release_year: 2021},
grouping: {'release_year'},
elements: {default::Movie {title:'Black Widow'}},
},
...
}

Notice that the result ofgroupis a set of _free objects_ with three fields:

- key: another free object containing the specific value of the grouping parameter for a given subset.
- grouping: set of names of grouping parameters, i.e. the specific names that also appear in thekeyfree object.
- elements: the actual subset of values that match thekey.

In thegroupstatement, referring to the property in thebyclause **must** be done by using the leading dot shothand
.release_year. The property name then shows up ingroupingandkeyto indicate the defining characteristics of
the particular result. Alternatively, we can give it an alias in an optionalusingclause and then that alias can be used
in thebyclause and will appear in the results:

db>groupMovie {title}
...usingyear := .release_yearby year;
{
{
key: {year: 2016},
grouping: {'year'},
elements: {
default::Movie {title: 'Captain America: Civil War'},
default::Movie {title: 'Doctor Strange'},
},
},
{
key: {year: 2017},
grouping: {'year'},
elements: {
default::Movie {title: 'Spider-Man: Homecoming'},
default::Movie {title: 'Thor: Ragnarok'},
},
},
{
key: {year: 2018},
grouping: {'year'},
elements: {default::Movie {title:'Ant-Man and the Wasp'}},
},
{
key: {year: 2019},
grouping: {'year'},
(continues on next page)

**194 Chapter 3. EdgeQL**


(continued from previous page)
elements: {default::Movie {title:'Spider-Man: No Way Home'}},
},
{
key: {year: 2021},
grouping: {'year'},
elements: {default::Movie {title:'Black Widow'}},
},
...
}

Theusingclause is perfect for defining a more complex expression to group things by. For example, instead of
grouping by therelease_yearwe can group by the release decade:

db>groupMovie {title}
...usingdecade := .release_year // 10
...by decade;
{
{
{
key: {decade: 200},
grouping: {'decade'},
elements: {
default::Movie {title: 'Spider-Man'},
default::Movie {title: 'Spider-Man 2'},
default::Movie {title: 'Spider-Man 3'},
default::Movie {title: 'Iron Man'},
default::Movie {title: 'The Incredible Hulk'},
},
},
{
key: {decade: 201},
grouping: {'decade'},
elements: {
default::Movie {title: 'Iron Man 2'},
default::Movie {title: 'Thor'},
default::Movie {title: 'Captain America: The First Avenger'},
default::Movie {title: 'The Avengers'},
default::Movie {title: 'Iron Man 3'},
default::Movie {title: 'Thor: The Dark World'},
default::Movie {title: 'Captain America: The Winter Soldier'},
default::Movie {title: 'Ant-Man'},
default::Movie {title: 'Captain America: Civil War'},
default::Movie {title: 'Doctor Strange'},
default::Movie {title: 'Spider-Man: Homecoming'},
default::Movie {title: 'Thor: Ragnarok'},
default::Movie {title: 'Ant-Man and the Wasp'},
default::Movie {title: 'Spider-Man: No Way Home'},
},
},
{
key: {decade: 202},
grouping: {'decade'},
(continues on next page)

**3.11. Group 195**


(continued from previous page)
elements: {default::Movie {title:'Black Widow'}},
},
}

It’s also possible to group by more than one parameter, so we can group by whether the movietitlecontains a colon
_and_ the decade it was released. Additionally, let’s only consider more recent movies, say, released after 2015, so that
we’re not overwhelmed by all the combination of results:

db>with
... # Apply the group query only to more recent movies
... M := (selectMovie filter.release_year > 2015)
...groupM {title}
...using
... decade := .release_year // 10,
... has_colon := .titlelike'%:%'
...by decade, has_colon;
{
{
key: {decade: 201, has_colon:false},
grouping: {'decade', 'has_colon'},
elements: {
default::Movie {title: 'Ant-Man and the Wasp'},
default::Movie {title: 'Doctor Strange'},
},
},
{
key: {decade: 201, has_colon:true},
grouping: {'decade', 'has_colon'},
elements: {
default::Movie {title: 'Captain America: Civil War'},
default::Movie {title: 'Spider-Man: No Way Home'},
default::Movie {title: 'Thor: Ragnarok'},
default::Movie {title: 'Spider-Man: Homecoming'},
},
},
{
key: {decade: 202, has_colon:false},
grouping: {'decade', 'has_colon'},
elements: {default::Movie {title:'Black Widow'}},
},
}

Once we break a set into partitions, we can also use _aggregate_ functions to provide some analytics about the data. For
example, for the above partitioning (by decade and presence of:in thetitle) we can calculate how many movies are
in each subset as well as the average number of words in the movie titles:

db>with
... # Apply the group query only to more recent movies
... M := (selectMovie filter.release_year > 2015),
... groups := (
... groupM {title}
... using
(continues on next page)

**196 Chapter 3. EdgeQL**


```
(continued from previous page)
```
... decade := .release_year // 10 - 200,
... has_colon := .title like'%:%'
... by decade, has_colon
... )
...select groups {
... key := .key {decade, has_colon},
... count := count(.elements),
... avg_words := math::mean(
... len(str_split(.elements.title,' ')))
... };
{
{key: {decade: 1, has_colon: false}, count: 2, avg_words: 3},
{key: {decade: 1, has_colon: true}, count: 4, avg_words: 3},
{key: {decade: 2, has_colon: false}, count: 1, avg_words: 2},
}

**Note:** It is possible to produce results that are grouped in multiple different ways using _grouping sets_. This may be
useful in more sophisticated analytics.

```
See also
Reference > Commands > Group
```
### 3.12 With

All top-level EdgeQL statements (select,insert,update, anddelete) can be prefixed by awithblock. These
blocks contain declarations of standalone expressions that can be used in your query.

db>withmy_str := "hello world"
...select str_title(my_str);
{'Hello World'}

Thewithclause can contain more than one variable. Earlier variables can be referenced by later ones. Taken together,
it becomes possible to write “script-like” queries that execute several statements in sequence.

db>witha := 5,
... b := 2,
... c := a ^ b
...select c;
{25}

**3.12. With 197**


#### 3.12.1 Subqueries

There’s no limit to the complexity of computed expressions. EdgeQL is fully composable; queries can simply be
embedded inside each other. The following query fetches a list of all movies featuring at least one of the original six
Avengers.

db>withavengers := (select Herofilter.name in {
... 'Iron Man',
... 'Black Widow',
... 'Captain America',
... 'Thor',
... 'Hawkeye',
... 'The Hulk'
... })
...select Movie {title}
...filter avengersin.characters;
{

```
default::Movie {title: 'Iron Man'},
default::Movie {title: 'The Incredible Hulk'},
default::Movie {title: 'Iron Man 2'},
default::Movie {title: 'Thor'},
default::Movie {title: 'Captain America: The First Avenger'},
```
}

#### 3.12.2 Query parameters

A common use case forwithclauses is the initialization of _query parameters_.

withuser_id := <uuid>$user_id
select User { name }
filter .id = user_id;

For a full reference on using query parameters, see _EdgeQL > Parameters_.

#### 3.12.3 Module selection

By default, the _active module_ isdefault, so all schema objects inside this module can be referenced by their
_short name_ , e.g.User,BlogPost, etc. To reference objects in other modules, we must use fully-qualified names
(default::Hero).

However,withclauses also provide a mechanism for changing the _active module_ on a per-query basis.

db>with module schema
...select ObjectType;

Thiswith moduleclause changes the default module to schema, so we can refer toschema::ObjectType(a built-in
EdgeDB type) as simplyObjectType.

```
See also
Reference > Commands > With
```
**198 Chapter 3. EdgeQL**


### 3.13 Path resolution

Element-wise operations with multiple arguments in EdgeDB are generally applied to the _cartesian product_ of all the
input sets.

db>select {'aaa','bbb'} ++ {'ccc', 'ddd'};
{'aaaccc', 'aaaddd', 'bbbccc','bbbddd'}

In some cases, this works out fine, but in others it doesn’t make sense. Take this example:

select User.first_name ++' '++ User.last_name;

Should the result of this query be everyfirst_namein yourUserobjects concatenated with everylast_name? That’s
probably not what you want.

This is why, in cases where multiple element-wise arguments share a common path (User.in this example), EdgeDB
factors out the common path rather than using cartesian multiplication.

db>select User.first_name ++' '++ User.last_name;
{'Mina Murray', 'Jonathan Harker','Lucy Westenra','John Seward'}

We assume this is what you want, but if your goal is to get the cartesian product, you can accomplish it one of three
ways. You could usedetached.

edgedb>selectUser.first_name ++ ' '++detached User.last_name;
{
'Mina Murray',
'Mina Harker',
'Mina Westenra',
'Mina Seward',
'Jonathan Murray',
'Jonathan Harker',
'Jonathan Westenra',
'Jonathan Seward',
'Lucy Murray',
'Lucy Harker',
'Lucy Westenra',
'Lucy Seward',
'John Murray',
'John Harker',
'John Westenra',
'John Seward',
}

You could use _with_ to attach a different symbol to your set ofUserobjects.

edgedb>withU := User
.......selectU.first_name ++ ' '++ User.last_name;
{
'Mina Murray',
'Mina Harker',
'Mina Westenra',
'Mina Seward',
'Jonathan Murray',
(continues on next page)

**3.13. Path resolution 199**


(continued from previous page)
'Jonathan Harker',
'Jonathan Westenra',
'Jonathan Seward',
'Lucy Murray',
'Lucy Harker',
'Lucy Westenra',
'Lucy Seward',
'John Murray',
'John Harker',
'John Westenra',
'John Seward',
}

Or you could leverage the effect scopes have on path resolution. More on that _in the Scopes section_.

The reasonwithworks here even though the aliasUrefers to the exact same set is that we only assume you want the path
factored in this way when you use the same _symbol_ to refer to a set. This means operations withUser.first_name
andUser.last_name _do_ get the common path factored whileU.first_nameandUser.last_name _do not_ and are
resolved with cartesian multiplication.

That may leave you still wondering whyUandUserdid not get a common path factored.Uis just an alias ofselect
UserandUseris the same symbol that we use in our name query. That’s true, but EdgeDB doesn’t factor in this case
because of the queries’ scopes.

#### 3.13.1 Scopes

Scopes change the way path resolution works. Two sibling select queries — that is, queries at the same level — do not
have their paths factored even when they use a common symbol.

edgedb>select((select User.first_name), (select User.last_name));
{
('Mina', 'Murray'),
('Mina', 'Harker'),
('Mina', 'Westenra'),
('Mina', 'Seward'),
('Jonathan','Murray'),
('Jonathan','Harker'),
('Jonathan','Westenra'),
('Jonathan','Seward'),
('Lucy', 'Murray'),
('Lucy', 'Harker'),
('Lucy', 'Westenra'),
('Lucy', 'Seward'),
('John', 'Murray'),
('John', 'Harker'),
('John', 'Westenra'),
('John', 'Seward'),
}

Common symbols in nested scopes _are_ factored when they use the same symbol. In this example, the nested queries
both use the sameUsersymbol as the top-level query. As a result, theUserin those queries refers to a single object
because it has been factored.

**200 Chapter 3. EdgeQL**


edgedb>selectUser {
....... name:= (selectUser.first_name) ++ ' '++ (selectUser.last_name)
....... };
{
default::User {name:'Mina Murray'},
default::User {name:'Jonathan Harker'},
default::User {name:'Lucy Westenra'},
default::User {name:'John Seward'},
}

If you have two common scopes and only _one_ of them is in a nested scope, the paths are still factored.

edgedb>select(Person.name, count(Person.friends));
{('Fran', 3), ('Bam', 2), ('Emma', 3), ('Geoff', 1), ('Tyra', 1)}

In this example,count, like all aggregate function, creates a nested scope, but this doesn’t prevent the paths from
being factored as you can see from the results. If the paths were _not_ factored, the friend count would be the same for
all the result tuples and it would reflect the total number ofPersonobjects that are in _all_ friendslinks rather than
the number ofPersonobjects that are in the namedPersonobject’sfriendslink.

If you have two aggregate functions creating _sibling_ nested scopes, the paths are _not_ factored.

edgedb>select(array_agg(distinctPerson.name), count(Person.friends));
{(['Fran', 'Bam','Emma','Geoff'], 3)}

This query selects a tuple containing two nested scopes. Here, EdgeDB assumes you want an array of all unique names
and a count of the total number of people who are anyone’s friend.

##### 3.13.1.1 Clauses & Nesting

Most clauses are nested and are subjected to the same rules described above: common symbols are factored and assumed
to refer to the same object as the outer query. This is because clauses like _filter_ and _order by_ need to be applied to each
value in the result.

The _limit_ clause is not nested in the scope because it needs to be applied globally to the entire result set of your query.

### 3.14 Transactions

EdgeQL supports atomic transactions. The transaction API consists of several commands:

start transaction Start a transaction, specifying the isolation level, access mode (read onlyvsread write),
and deferrability.

declare savepointEstablish a new savepoint within the current transaction. A savepoint is a intermediate point in
a transaction flow that provides the ability to partially rollback a transaction.

release savepointDestroys a savepoint previously defined in the current transaction.

rollback to savepointRollback to the named savepoint. All changes made after the savepoint are discarded. The
savepoint remains valid and can be rolled back to again later, if needed.

rollback Rollback the entire transaction. All updates made within the transaction are discarded.

commit Commit the transaction. All changes made by the transaction become visible to others and will persist if a
crash occurs.

**3.14. Transactions 201**


#### 3.14.1 Client libraries

There is rarely a reason to use these commands directly. All EdgeDB client libraries provide dedicated transaction
APIs that handle transaction creation under the hood.

##### 3.14.1.1 TypeScript/JS

Using an EdgeQL query string:

client.transaction(async tx => {
await tx.execute(`insert Fish { name :='Wanda' };`);
});

Using the querybuilder:

constquery = e.insert(e.Fish, {
name: 'Wanda'
});
client.transaction(async tx => {
await query.run(tx);
});

Full documentation at Client Libraries > TypeScript/JS;

##### 3.14.1.2 Python

async fortx in client.transaction():
async withtx:
awaittx.execute("insert Fish { name :='Wanda' };")

Full documentation at Client Libraries > Python;

##### 3.14.1.3 Golang

err := client.Tx(ctx,func(ctx context.Context, tx *Tx)error{
query := "insert Fish { name :='Wanda'};"
if e := tx.Execute(ctx, query); e !=nil{
returne
}
})

Full documentation at Client Libraries > Go.

EdgeQL is a next-generation query language designed to match SQL in power and surpass it in terms of clarity, brevity,
and intuitiveness. It’s used to query the database, insert/update/delete data, modify/introspect the schema, manage
transactions, and more.

**202 Chapter 3. EdgeQL**


### 3.15 Design goals

EdgeQL is a spiritual successor to SQL designed with a few core principles in mind.

**Compatible with modern languages**. A jaw-dropping amount of effort has been spent attempting to bridge the gap
between the _relational_ paradigm of SQL and the _object-oriented_ nature of modern programming languages. EdgeDB
sidesteps this problem by modeling data in an _object-relational_ way.

**Strongly typed**. EdgeQL is _inextricably tied_ to EdgeDB’s rigorous object-oriented type system. The type of all
expressions is statically inferred by EdgeDB.

**Designed for programmers**. EdgeQL prioritizes syntax over keywords; It uses{ curly braces }to define
scopes/structures and the _assignment operator_ :=to set values. The result is a query language that looks more like
code and less like word soup.

**Easy deep querying**. EdgeDB’s object-relational nature makes it painless to write deep, performant queries that
traverse links, noJOINsrequired.

**Composable**. Unlike SQL, EdgeQL’s syntax is readily composable; queries can be cleanly nested without worrying
about Cartesian explosion.

**Note:** For a detailed writeup on the design of SQL, see We Can Do Better Than SQL on the EdgeDB blog.

### 3.16 Follow along

The best way to learn EdgeQL is to play with it! Use the online EdgeQL shell to execute any and all EdgeQL snippets in
the following pages. Or follow the _Quickstart_ to spin up an EdgeDB instance on your computer, then open an _interactive
shell_.

**3.15. Design goals 203**


**204 Chapter 3. EdgeQL**


```
CHAPTER
```
### FOUR

### GUIDES

These guides contain tutorials introducing EdgeDB to newcomers and how-tos providing more experienced users with
examples and advice for tackling some common tasks.

If you are new to EdgeDB check out our _Quickstart_ guide!

### 4.1 Tutorials

#### 4.1.1 Next.js

```
edb-alt-title Building a simple blog application with EdgeDB and Next.js
```
We’re going to build a simple blog application with Next.js and EdgeDB. Let’s start by scaffolding our app with Next.js’s
create-next-apptool. We’ll be using TypeScript for this tutorial.

$ npx create-next-app --typescript nextjs-blog

This will take a minute to run. The scaffolding tool is creating a simple Next.js app and installing all our dependencies
for us. Once it’s complete, let’s navigate into the directory and start the dev server.

$ cd nextjs-blog
$ yarn dev

Open localhost:3000 to see the default Next.js homepage. At this point the app’s file structure looks like this:

README.md
tsconfig.json
package.json
next.config.js
next-env.d.ts
pages
_app.tsx
api
hello.ts
index.tsx
public
favicon.ico
vercel.svg
styles
Home.module.css
globals.css

```
205
```

There’s a custom App component defined inpages/_app.tsxthat loads some global CSS, plus the homepage at
pages/index.tsxand a single API route atpages/api/hello.ts. Thestylesandpublicdirectories contain
some other assets.

##### 4.1.1.1 Updating the homepage

Let’s start by implementing a simple homepage for our blog application using static data. Replace the contents of
pages/index.tsxwith the following.

// pages/index.tsx

import type {NextPage} from'next';
import Head from'next/head';
import styles from'../styles/Home.module.css';

type Post = {
id: string;
title: string;
content: string;
};

const HomePage: NextPage = () => {
const posts: Post[] = [
{
id:'post1',
title: 'This one weird trick makes using databases fun',
content:'Use EdgeDB',
},
{
id:'post2',
title: 'How to build a blog with EdgeDB and Next.js',
content: "Let's start by scaffolding our app with`create-next-app`.",
},
];

```
return (
<div className={styles.container}>
<Head>
<title>My Blog</title>
<meta name="description" content="An awesome blog" />
<link rel="icon" href="/favicon.ico" />
</Head>
```
```
<main className={styles.main}>
<h1 className={styles.title}>Blog</h1>
<div style={{height:'50px'}}></div>
{posts.map((post) => {
return (
<a href={`/post/${post.id}`} key={post.id}>
<div className={styles.card}>
<p>{post.title}</p>
</div>
</a>
(continues on next page)
```
**206 Chapter 4. Guides**


(continued from previous page)
);
})}
</main>
</div>
);
};

export default HomePage;

After saving, Next.js should hot-reload, and the homepage should look something like this.

##### 4.1.1.2 Initializing EdgeDB

Now let’s spin up a database for the app. First, install theedgedbCLI.

**Linux or macOS**

$ curl --proto'=https' --tlsv1.2 -sSf https://sh.edgedb.com | sh

**Windows Powershell**

PS> iwr https://ps1.edgedb.com -useb | iex

Then check that the CLI is available with theedgedb --versioncommand. If you get aCommand not founderror,
you may need to open a new terminal window before theedgedbcommand is available.

**4.1. Tutorials 207**


Once the CLI is installed, initialize a project from the application’s root directory. You’ll be presented with a series of
prompts.

$ edgedb project init
No `edgedb.toml` found in`~/nextjs-blog` or above
Do you want to initialize a new project? [Y/n]
> Y
Specify the name of EdgeDB instance to use with this project [default:
nextjs-blog]:
> nextjs-blog
Checking EdgeDB versions...
Specify the version of EdgeDB to use with this project [default: 2.x]:
>

```
Project directory ~/nextjs-blog
Project config ~/nextjs-blog/edgedb.toml
Schema dir (empty) ~/nextjs-blog/dbschema
Installation method portable package
Start configuration manual
Version 2.x
Instance name nextjs-blog
```
Initializing EdgeDB instance...
Applying migrations...
Everything is up to date. Revision initial.
Project initialized.

This process has spun up an EdgeDB instance callednextjs-blogand “linked” it with your current directory. As
long as you’re inside that directory, CLI commands and client libraries will be able to connect to the linked instance
automatically, without additional configuration.

To test this, run theedgedbcommand to open a REPL to the linked instance.

$ edgedb
EdgeDB 2.x (repl 2.x)
Type \help for help, \quit to quit.
edgedb> select 2 + 2;
{4}
>

From inside this REPL, we can execute EdgeQL queries against our database. But there’s not much we can do currently,
since our database is schemaless. Let’s change that.

The project initialization process also created a new subdirectory in our project calleddbschema. This is folder that
contains everything pertaining to EdgeDB. Currently it looks like this:

dbschema
default.esdl
migrations

Thedefault.esdlfile will contain our schema. Themigrationsdirectory is currently empty, but will contain our
migration files. Let’s update the contents ofdefault.esdlwith the following simple blog schema.

# dbschema/default.esdl

```
(continues on next page)
```
**208 Chapter 4. Guides**


```
(continued from previous page)
```
module default{
type BlogPost {
required propertytitle -> str;
required propertycontent -> str {
default:= ""
};
}
}

**Note:** EdgeDB lets you split up your schema into differentmodulesbut it’s common to keep your entire schema in
thedefaultmodule.

Save the file, then let’s create our first migration.

$ edgedb migration create
did you create object type'default::BlogPost'? [y,n,l,c,b,s,q,?]
> y
Created ./dbschema/migrations/00001.edgeql

Thedbschema/migrationsdirectory now contains a migration file called00001.edgeql. Currently though, we
haven’t applied this migration against our database. Let’s do that.

$ edgedb migrate
Applied m1fee6oypqpjrreleos5hmivgfqg6zfkgbrowx7sw5jvnicm73hqdq (00001.edgeql)

Our database now has a schema consisting of theBlogPosttype. We can create some sample data from the REPL.
Run theedgedbcommand to re-open the REPL.

$ edgedb
EdgeDB 2.x (repl 2.x)
Type \help for help, \quit to quit.
edgedb>

Then execute the followinginsertstatements.

edgedb>insertBlogPost {
....... title := "This one weird trick makes using databases fun",
....... content := "Use EdgeDB"
....... };
{default::BlogPost {id: 7f301d02-c780-11ec-8a1a-a34776e884a0}}
edgedb>insertBlogPost {
....... title := "How to build a blog with EdgeDB and Next.js",
....... content := "Let's start by scaffolding our app..."
....... };
{default::BlogPost {id: 88c800e6-c780-11ec-8a1a-b3a3020189dd}}

**4.1. Tutorials 209**


##### 4.1.1.3 Loading posts with an API route

Now that we have a couple posts in the database, let’s load them dynamically with a Next.js API route. To do that, we’ll
need theedgedbclient library. Let’s install that from NPM:

$ npm install edgedb

Then create a new file atpages/api/post.tsand copy in the following code.

// pages/api/post.ts

import type{NextApiRequest, NextApiResponse}from'next';
import {createClient}from'edgedb';

export constclient = createClient();

export default async functionhandler(
req: NextApiRequest,
res: NextApiResponse
) {
const posts =awaitclient.query(`select BlogPost {
id,
title,
content
};`);
res.status(200).json(posts);
}

This file initializes an EdgeDB client, which manages a pool of connections to the database and provides an API for
executing queries. We’re using the.query()method to fetch all the posts in the database with a simpleselect
statement.

If you visit localhost:3000/api/post in your browser, you should see a plaintext JSON representation of the blog posts
we inserted earlier.

To fetch these from the homepage, we’ll useuseState,useEffect, and the built-infetchAPI. At the top of the
HomePagecomponent inpages/index.tsx, replace the static data and add the missing imports.

// pages/index.tsx
+ import {useState, useEffect} from 'react';

```
type Post = {
id: string;
title: string;
content: string;
};
```
```
const HomePage: NextPage = () => {
```
- const posts: Post[] = [
- {
- id:'post1',
- title: 'This one weird trick makes using databases fun',
- content:'Use EdgeDB',
- },
- {
    (continues on next page)

**210 Chapter 4. Guides**


```
(continued from previous page)
```
- id:'post2',
- title: 'How to build a blog with EdgeDB and Next.js',
- content: "Let's start by scaffolding our app...",
- },
- ];

+ const [posts, setPosts] = useState<Post[] | null>(null);
+ useEffect(() => {
+ fetch(`/api/post`)
+ .then((result) => result.json())
+ .then(setPosts);
+ }, []);
+ if (!posts) return <p>Loading...</p>;

```
return <div>...</div>;
}
```
When you refresh the page, you should briefly see aLoading...indicator before the homepage renders the (dynami-
cally loaded!) blog posts.

##### 4.1.1.4 Generating the query builder

Since we’re using TypeScript, it makes sense to use EdgeDB’s powerful query builder. This provides a schema-aware
client API that makes writing strongly typed EdgeQL queries easy and painless. The result type of our queries will be
automatically inferred, so we won’t need to manually type something liketype Post = { id: string; ... }.

First, install the generator to your project.

$ yarn add --dev @edgedb/generate

Then generate the query builder with the following command.

$ npx @edgedb/generate edgeql-js
Generating query builder...
Detected tsconfig.json, generating TypeScript files.
To override this, use the --target flag.
Run`npx @edgedb/generate --help` for full options.
Introspecting database schema...
Writing files to ./dbschema/edgeql-js
Generation complete!
Checking the generated query builder into version control
is not recommended. Would you like to update .gitignore to ignore
the query builder directory? The following line will be added:

```
dbschema/edgeql-js
```
[y/n] (leave blank for "y")
> y

This command introspected the schema of our database and generated some code in thedbschema/edgeql-jsdirec-
tory. It also asked us if we wanted to add the generated code to our.gitignore; typically it’s not good practice to
include generated files in version control.

Back inpages/api/post.ts, let’s update our code to use the query builder instead.

**4.1. Tutorials 211**


```
// pages/api/post.ts
```
import type {NextApiRequest, NextApiResponse} from'next';
import {createClient} from 'edgedb';
+ import e, {$infer} from'../../dbschema/edgeql-js';

```
export const client = createClient();
```
+ const selectPosts = e.select(e.BlogPost, () => ({
+ id: true,
+ title: true,
+ content: true,
+ }));

+ export type Posts = $infer<typeof selectPosts>;

```
export default async function handler(
req: NextApiRequest,
res: NextApiResponse
) {
```
- const posts = await client.query(`select BlogPost {
- id,
- title,
- content
- };`);
+ const posts = await selectPosts.run(client);
    res.status(200).json(posts);
}

Instead of writing our query as a plain string, we’re now using the query builder to declare our query in a code-first way.
As you can see we import the query builder as a single default importefrom thedbschema/edgeql-jsdirectory.

We’re also using a utility called$inferto extract the inferred type of this query. In VSCode you can hover overPosts
to see what this type is.

Back inpages/index.tsx, let’s update our code to use the inferredPoststype instead of our manual type declaration.

**212 Chapter 4. Guides**


```
// pages/index.tsx
```
import type {NextPage} from'next';
import Head from'next/head';
import {useEffect, useState} from'react';
import styles from'../styles/Home.module.css';
+ import {Posts} from "./api/post";

- type Post = {
- id: string;
- title: string;
- content: string;
- };

```
const Home: NextPage = () => {
```
+ const [posts, setPosts] = useState<Posts | null>(null);
// ...

```
}
```
Now, when we update ourselectPostsquery, the type of our dynamically loadedpostsvariable will update auto-
matically—no need to keep our type definitions in sync with our API logic!

##### 4.1.1.5 Rendering blog posts

Our homepage renders a list of links to each of our blog posts, but we haven’t implemented the page that actually
displays the posts. Let’s create a new page atpages/post/[id].tsx. This is a dynamic route that includes anid
URL parameter. We’ll use this parameter to fetch the appropriate post from the database.

Createpages/post/[id].tsxand add the following code. We’re usinggetServerSidePropsto load the blog post
data server-side, to avoid loading spinners and ensure the page loads fast.

import React from'react';
import {GetServerSidePropsContext, InferGetServerSidePropsType} from'next';

import {client} from'../api/post';
import e from'../../dbschema/edgeql-js';

export const getServerSideProps = async (
context?: GetServerSidePropsContext
) => {
const post = await e
.select(e.BlogPost, (post) => ({
id: true,
title: true,
content: true,
filter_single: e.op(
post.id,
'=',
e.uuid(context!.params!.id as string)
),
}))
(continues on next page)

**4.1. Tutorials 213**


(continued from previous page)
.run(client);
return {props: {post: post!}};
};

export type GetPost = InferGetServerSidePropsType<typeof getServerSideProps>;

const Post: React.FC<GetPost> = (props) => {
return (
<div
style={{
margin:'auto',
width:'100%',
maxWidth:'600px',
}}
>
<h1 style={{padding:'50px 0px'}}>{props.post.title}</h1>
<p style={{color: '#666'}}>{props.post.content}</p>
</div>
);
};

export default Post;

InsidegetServerSidePropswe’re extracting theidparameter fromcontext.paramsand using it in our EdgeQL
query. The query is aselectquery that fetches theid,title, andcontentof the post with a matchingid.

We’re using Next’sInferGetServerSidePropsTypeutility to extract the inferred type of our query and pass it into
React.FC. Now, if we update our query, the type of the component props will automatically update too. In fact, this
entire application is end-to-end typesafe.

Now, click on one of the blog post links on the homepage. This should bring you to/post/<uuid>, which should
display something like this:

**214 Chapter 4. Guides**


##### 4.1.1.6 Deploying to Vercel

**#1 Deploy EdgeDB**

First deploy an EdgeDB instance on your preferred cloud provider:

- AWS
- Google Cloud
- Azure
- DigitalOcean
- Fly.io
- Docker (cloud-agnostic)

**#2. Find your instance’s DSN**

The DSN is also known as a connection string. It will have the format edgedb://
username:password@hostname:port. The exact instructions for this depend on which cloud you are deploying
to.

**#3 Apply migrations**

Use the DSN to apply migrations against your remote instance.

$ edgedb migrate --dsn <your-instance-dsn> --tls-security insecure

**Note:** You have to disable TLS checks with--tls-security insecure. All EdgeDB instances use TLS by default,
but configuring it is out of scope of this project.

Once you’ve applied the migrations, consider creating some sample data in your database. Open a REPL andinsert
some blog posts:

**4.1. Tutorials 215**


$ edgedb --dsn <your-instance-dsn> --tls-security insecure
EdgeDB 2.x (repl 2.x)
Type \help for help, \quit to quit.
edgedb> insert BlogPost { title := "Test post" };
{default::BlogPost {id: c00f2c9a-cbf5-11ec-8ecb-4f8e702e5789}}

**#4 Set up a`prebuild`script**

Add the followingprebuildscript to yourpackage.json. When Vercel initializes the build, it will trigger this script
which will generate the query builder. Thenpx @edgedb/generate edgeql-jscommand will read the value of the
EDGEDB_DSNvariable, connect to the database, and generate the query builder before Vercel starts building the project.

// package.json
"scripts": {
"dev": "next dev",
"build": "next build",
"start": "next start",
"lint": "next lint",
+ "prebuild": "npx @edgedb/generate edgeql-js"
},

**#5 Deploy to Vercel**

Deploy this app to Vercel with the button below.

When prompted:

- SetEDGEDB_DSNto your database’s DSN
- SetEDGEDB_CLIENT_TLS_SECURITYtoinsecure. This will disable EdgeDB’s default TLS checks; configur-
    ing TLS is beyond the scope of this tutorial.

**216 Chapter 4. Guides**


**#6 View the application**

Once deployment has completed, view the application at the deployment URL supplied by Vercel.

##### 4.1.1.7 Wrapping up

Admittedly this isn’t the prettiest blog of all time, or the most feature-complete. But this tutorial demonstrates how to
work with EdgeDB in a Next.js app, including data fetching with API routes andgetServerSideProps.

The next step is to add a/newpostpage with a form for writing new blog posts and saving them into EdgeDB. That’s
left as an exercise for the reader.

To see the final code for this tutorial, refer to github.com/edgedb/edgedb-examples/tree/main/nextjs-blog.

#### 4.1.2 FastAPI

```
edb-alt-title Building a REST API with EdgeDB and FastAPI
```
Because FastAPI encourages and facilitates strong typing, it’s a natural pairing with EdgeDB. Our Python code genera-
tion generates not only typed query functions but result types you can use to annotate your endpoint handler functions.

EdgeDB can help you quickly build REST APIs in Python without getting into the rigmarole of using ORM libraries
to handle your data effectively. Here, we’ll be using FastAPI to expose the API endpoints and EdgeDB to store the
content.

We’ll build a simple event management system where you’ll be able to fetch, create, update, and delete _events_ and _event
hosts_ via RESTful API endpoints.

**4.1. Tutorials 217**


Watch our video tour of this example project to get a preview of what you’ll be building in this guide:

##### 4.1.2.1 Prerequisites

Before we start, make sure you’ve _installed_ theedgedbcommand line tool. In this tutorial, we’ll use Python 3.10 and
take advantage of the asynchronous I/O paradigm to communicate with the database more efficiently. If you want to
skip ahead, the completed source code for this API can be found in our examples repo.

##### 4.1.2.1.1 Create a project directory

To get started, create a directory for your project and change into it.

$ mkdir fastapi-crud
$ cd fastapi-crud

##### 4.1.2.1.2 Install the dependencies

Create a Python 3.10 virtual environment, activate it, and install the dependencies with this command (in Linux/macOS;
see the following note for help with Windows):

$ python -m venv myvenv
$ source myvenv/bin/activate
$ pip install edgedb fastapi 'httpx[cli]' uvicorn

**Note:** Make sure you runsource myvenv/bin/activateany time you want to come back to this project to activate
its virtual environment. If not, you may start working under your system’s default Python environment which could be
the incorrect version or not have the dependencies installed. If you want to confirm you’re using the right environment,
runwhich python. You should see that the currentpythonis inside your venv directory.

**Note:** The commands will differ for Windows/Powershell users; this guide provides instructions for working with
virtual environments across a range of OSes, including Windows.

##### 4.1.2.1.3 Initialize the database

Now, let’s initialize an EdgeDB project. From the project’s root directory:

$ edgedb project init
No `edgedb.toml` found in`<project-path>` or above
Do you want to initialize a new project? [Y/n]
> Y
Specify the name of EdgeDB instance to use with this project [default:
fastapi_crud]:
> fastapi_crud
Checking EdgeDB versions...
Specify the version of EdgeDB to use with this project [default: 2.7]:
> 2.7

**218 Chapter 4. Guides**


Once you’ve answered the prompts, a new EdgeDB instance calledfastapi_crudwill be created and started. If you
seeProject initialized, you’re ready.

##### 4.1.2.1.4 Connect to the database

Let’s test that we can connect to the newly started instance. To do so, run:

$ edgedb

You should see this prompt indicating you are now connected to your new database instance:

EdgeDB 2.x (repl 2.x)
Type \help forhelp, \quit to quit.
edgedb>

You can start writing queries here. Since this database is empty, that won’t get you very far, so let’s start designing our
data model instead.

#### 4.1.2.2 Schema design

The event management system will have two entities: **events** and **users**. Each _event_ can have an optional link to a _user_
who is that event’s host. The goal is to create API endpoints that’ll allow us to fetch, create, update, and delete the
entities while maintaining their relationships.

EdgeDB allows us to declaratively define the structure of the entities. If you’ve worked with SQLAlchemy or Django
ORM, you might refer to these declarative schema definitions as _models_. In EdgeDB we call them “object types”.

The schema lives inside.esdlfiles in thedbschemadirectory. It’s common to declare the entire schema in a single
filedbschema/default.esdl. This file is created for you when you runedgedb project init, but you’ll need to
fill it with your schema. This is what our datatypes look like:

# dbschema/default.esdl

module default{
abstract type Auditable {
required propertycreated_at -> datetime {
readonly :=true;
default:= datetime_current();
}
}

```
type UserextendingAuditable {
required propertyname -> str {
constraint exclusive;
constraint max_len_value(50);
};
}
```
```
type EventextendingAuditable {
required propertyname -> str {
constraint exclusive;
constraint max_len_value(50);
}
(continues on next page)
```
**4.1. Tutorials 219**


(continued from previous page)
propertyaddress -> str;
propertyschedule -> datetime;
linkhost -> User;
}
}

Here, we’ve defined anabstracttype calledAuditableto take advantage of EdgeDB’s schema mixin system. This
allows us to add acreated_atproperty to multiple types without repeating ourselves. Abstract types don’t have any
concrete footprints in the database, as they don’t hold any actual data. Their only job is to propagate properties, links,
and constraints to the types that extend them.

TheUsertype extendsAuditableand inherits thecreated_atproperty as a result. Sincecreated_athas a
defaultvalue, it’s auto-filled with the return value of thedatetime_currentfunction. Along with the property
conveyed to it by the extended type, theUsertype defines its own concrete required property calledname. We impose
two constraints on this property: names should be unique (constraint exclusive) and shorter than 50 characters
(constraint max_len_value(50)).

We also define anEventtype that extends theAuditableabstract type. It contains its own concrete properties and
links:address,schedule, and an optional link calledhostthat corresponds to aUser.

#### 4.1.2.3 Run a migration

With the schema created, it’s time to lock it in. The first step is to create a migration.

$ edgedb migration create

When this step is successful, you’ll seeCreated dbschema/migrations/00001.edgeql.

Now run the migration we just created.

$ edgedb migrate

Once this is done, you’ll seeAppliedalong with the migration’s ID. I like to go one step further in verifying success
and see the schema applied to my database. To do that, first fire up the EdgeDB console:

$ edgedb

In the console, type\ds(for “describe schema”). If everything worked, we should output very close to the schema we
added in thedefault.esdlfile:

module default {
abstract type Auditable {
property created_at -> std::datetime {
default := (std::datetime_current());
readonly := true;
};
};
type Event extending default::Auditable {
link host -> default::User;
property address -> std::str;
required property name -> std::str {
constraint std::exclusive;
constraint std::max_len_value(50);
(continues on next page)

**220 Chapter 4. Guides**


(continued from previous page)
};
property schedule -> std::datetime;
};
type User extending default::Auditable {
required property name -> std::str {
constraint std::exclusive;
constraint std::max_len_value(50);
};
};
};

#### 4.1.2.4 Build the API endpoints

With the schema established, we’re ready to start building out the app. Let’s start by creating anappdirectory inside
our project:

$ mkdir app

Within thisappdirectory, we’re going to create three modules:events.pyandusers.pywhich represent the events
and users APIs respectively, andmain.pythat registers all the endpoints and exposes them to the uvicorn webserver.
We also need an__init__.pyto mark this directory as a package so we can easily import from it. Go ahead and
create that file now in your editor or via the command line like this (from the project root):

$ touch app/__init__.py

We’ll work on the users API first since it’s the simpler of the two.

##### 4.1.2.4.1 Users API

We want this app to be type safe, end to end. To achieve this, instead of hard-coding string queries into the app, we’ll
use code generation to generate typesafe functions from queries we write in.edgeqlfiles. These files are simple text
files containing the queries we want our app to be able to run.

The code generator will search through our project for all files with the.edgeqlextension and generate those functions
for us as individual Python modules. When you installed the EdgeDB client (viapip install edgedb), the code
generator was installed alongside it, so you’re already ready to go. We just need to write those queries!

We’ll write queries for one endpoint at a time to start so you can see how the pieces fit together. To keep things organized,
create a new directory insideappcalledqueries. Create a new file inapp/queriesnamedget_users.edgeqland
open it in your editor. Write the query into this file. It’s the same one we would have written inline in our Python code
as shown in the code block above:

select User {name, created_at};

We need one more query to finish off this endpoint. Create another file inside app/queries named
get_user_by_name.edgeqland open it in your editor. Add this query:

select User {name, created_at}
filter User.name = <str>$name

Save that file and get ready to kick off the magic that is code generation!

**4.1. Tutorials 221**


$ edgedb-py
Found EdgeDB project: <project-path>
Processing <project-path>/app/queries/get_user_by_name.edgeql
Processing <project-path>/app/queries/get_users.edgeql
Generating <project-path>/app/queries/get_user_by_name.py
Generating <project-path>/app/queries/get_users.py

The code generator creates one module per query file by default and places them at the same path as the query files.

With code generated, we’re ready to write an endpoint. Let’s create theGET /usersendpoint so that we can request
theUserobjects saved in the database. Create a new fileapp/users.py, open it in your editor, and add the following
code:

# app/users.py
from __future__ import annotations

import datetime
from http importHTTPStatus
from typing import List

import edgedb
from fastapi importAPIRouter, HTTPException, Query
from pydantic importBaseModel

from .queries importget_user_by_name_async_edgeqlas get_user_by_name_qry
from .queries importget_users_async_edgeqlas get_users_qry

router = APIRouter()
client = edgedb.create_async_client()

class RequestData(BaseModel):
name: str

@router.get("/users")
async def get_users(
name: str = Query(None, max_length=50)
) -> List[get_users_qry.GetUsersResult] | get_user_by_name_qry.GetUserByNameResult:

```
if notname:
users =awaitget_users_qry.get_users(client)
returnusers
else:
user =await get_user_by_name_qry.get_user_by_name(client, name=name)
returnuser
```
We’ve imported the generated code and aliased it (usingas <new-name>) to make the module names we use in our
code a bit neater.

TheAPIRouterinstance does the actual work of exposing the API. We also create an async EdgeDB client instance
to communicate with the database.

By default, this API will return a list of all users, but you can also filter the user objects by name. We have the
RequestDataclass to handle the data an API consumer will need to send in case they want to get only a single user.

**222 Chapter 4. Guides**


The types we’re using in the return annotation have been generated by the EdgeDB code generation based on the queries
we wrote and our database’s schema.

Note that we’re also calling the appropriate generated function based on whether or not the API consumer passes an
argument forname.

This nearly gets us there but not quite. We have one potential outcome not accounted for: a query for a user by name
that returns no results. In that case, we’ll want to return a 404 (not found).

To fix it, we’ll check in the else case whether we got anything back from the single user query. If not, we’ll go ahead
and raise an exception. This will send the 404 (not found) response to the user.

# app/users.py
...
if notname:
users =awaitget_users_qry.get_users(client)
return users
else:
user = awaitget_user_by_name_qry.get_user_by_name(client, name=name)
if notuser:
raiseHTTPException(
status_code=HTTPStatus.NOT_FOUND,
detail={"error": f"Username'{name}' does not exist."},
)
return user
...

To summarize, in theget_usersfunction, we use our generated code to perform asynchronous queries via theedgedb
client. Then we return the query results. Afterward, the JSON serialization part is taken care of by FastAPI.

Before we can use this endpoint, we need to expose it to the server. We’ll do that in themain.pymodule. Create
app/main.pyand open it in your editor. Here’s the content of the module:

# app/main.py
from __future__ import annotations

from fastapi importFastAPI
from starlette.middleware.cors importCORSMiddleware

from app importusers

fast_api = FastAPI()

# Set all CORS enabled origins.
fast_api.add_middleware(
CORSMiddleware,
allow_origins=["*"],
allow_credentials=True,
allow_methods=["*"],
allow_headers=["*"],
)

fast_api.include_router(users.router)

Here, we import everything we need, including our ownusersmodule containing the router and endpoint logic for

**4.1. Tutorials 223**


the users API. We instantiate the API, give it a permissive CORS configuration, and give it the users router.

To test the endpoint, go to the project root and run:

$ uvicorn app.main:fast_api --port 5001 --reload

This will start auvicornserver and you’ll be able to start making requests against it. Earlier, we installed the HTTPx
client library to make HTTP requests programmatically. It also comes with a neat command-line tool that we’ll use to
test our API.

While theuvicornserver is running, bring up a new console. Activate your virtual environment by runningsource
myenv/bin/activateand run:

$ httpx -m GET [http://localhost:5001/users](http://localhost:5001/users)

You’ll see the following output on the console:

HTTP/1.1 200 OK
date: Sat, 16 Apr 2022 22:58:11 GMT
server: uvicorn
content-length: 2
content-type: application/json

[]

**Note:** If you find yourself with a result you don’t expect when making a request to your API, switch over to the uvicorn
server console. You should find a traceback that will point you to the problem area in your code.

If you see this result, that means the API is working! It’s not especially useful though. Our request yields an empty
list because the database is currently empty. Let’s create thePOST /usersendpoint inapp/users.pyto start saving
users in the database. Before we do that though, let’s go ahead and create the new query we’ll need.

Create and openapp/queries/create_user.edgeqland fill it with this query:

select (insertUser {
name := <str>$name
}) {
name,
created_at
};

**Note:** We’re running ourinsertinside aselecthere so that we can return thenameandcreated_atproperties.
If we just ran theinsertbare, it would return only theid.

Save the file and runedgedb-pyto generate the new function. Now, we’re ready to openapp/users.pyagain and
add the POST endpoint. First, import the generated function for the new query:

# app/users.py
...
from .queries importcreate_user_async_edgeqlascreate_user_qry
from .queries importget_user_by_name_async_edgeqlas get_user_by_name_qry
from .queries importget_users_async_edgeqlas get_users_qry
...

**224 Chapter 4. Guides**


Then write the endpoint to call that function:

# app/users.py
...
@router.post("/users", status_code=HTTPStatus.CREATED)
async def post_user(user: RequestData) -> create_user_qry.CreateUserResult:

```
try:
created_user =await create_user_qry.create_user(client, name=user.name)
except edgedb.errors.ConstraintViolationError:
raiseHTTPException(
status_code=HTTPStatus.BAD_REQUEST,
detail={"error": f"Username'{user.name}' already exists."},
)
return created_user
```
In the above snippet, we ingest data with the shape dictated by theRequestDatamodel and return a payload of the
query results. Thetry...exceptblock gracefully handles the situation where the API consumer might try to create
multiple users with the same name. A successful request will yield the status code HTTP 201 (created) along with the
new user’sid,name, andcreated_atas JSON.

To test it out, make a request as follows:

$ httpx -m POST [http://localhost:5001/users](http://localhost:5001/users) \
--json'{"name" : "Jonathan Harker"}'

The output should look similar to this:

HTTP/1.1 201 Created
...
{
"id": "53771f56-6f57-11ed-8729-572f5fba7ddc",
"name": "Jonathan Harker",
"created_at": "2022-04-16T23:09:30.929664+00:00"
}

**Note:** Since IDs are generated, youridvalues probably won’t match the values in this guide. This is not a problem.

If you try to make the same request again, it’ll throw an HTTP 400 (bad request) error:

HTTP/1.1 400 Bad Request
...
{
"detail": {
"error": "Username 'Jonathan Harker'already exists."
}
}

Before we move on to the next step, create 2 more users calledCount DraculaandMina Murray. Once you’ve done
that, we can move on to the next step of building thePUT /usersendpoint to update existing user data.

We’ll start again with the query. Create a new file inapp/queriesnamedupdate_user.edgeql. Open it in your
editor and enter this query:

**4.1. Tutorials 225**


select (
update Userfilter.name = <str>$current_name
set{name := <str>$new_name}
) {name, created_at};

Save the file and generate again usingedgedb-py. Now, we’ll import that and add the endpoint over inapp/users.py.

# app/users.py
...
from .queries importcreate_user_async_edgeqlascreate_user_qry
from .queries importget_user_by_name_async_edgeqlas get_user_by_name_qry
from .queries importget_users_async_edgeqlas get_users_qry
from .queries importupdate_user_async_edgeqlasupdate_user_qry
...
@router.put("/users")
async def put_user(
user: RequestData, current_name: str
) -> update_user_qry.UpdateUserResult:
try:
updated_user =await update_user_qry.update_user(
client,
new_name=user.name,
current_name=current_name,
)
except edgedb.errors.ConstraintViolationError:
raiseHTTPException(
status_code=HTTPStatus.BAD_REQUEST,
detail={"error": f"Username'{user.name}' already exists."},
)

```
if notupdated_user:
raiseHTTPException(
status_code=HTTPStatus.NOT_FOUND,
detail={"error": f"User'{current_name}' was not found."},
)
return updated_user
```
Not much new happening here. We wrote our query with acurrent_nameparameter for finding the user to be updated.
Theuserargument will give us the changes to make to that user, which in this case can only be thenamesince that’s
the only property a user has. We pull the name out ofuserand pass it as ournew_nameargument to the generated
function. The endpoint calls the generated function passing the client and those two values, and the user is updated.

We’ve accounted for the possibility of a user trying to change a user’s name to a new name that conflicts with a different
user. That will return a 400 (bad request) error. We’ve also accounted for the possibility of a user trying to update a
user that doesn’t exist, which will return a 404 (not found).

Let’s save everything and test this out.

$ httpx -m PUT [http://localhost:5001/users](http://localhost:5001/users) \
-p 'current_name' 'Jonathan Harker'\
--json'{"name" : "Dr. Van Helsing"}'

This will return:

**226 Chapter 4. Guides**


HTTP/1.1 200 OK
...
[
{
"id": "53771f56-6f57-11ed-8729-572f5fba7ddc",
"name": "Dr. Van Helsing",
"created_at": "2022-04-16T23:09:30.929664+00:00"
}
]

If you try to change the name of a user to match that of an existing user, the endpoint will throw an HTTP 400 (bad
request) error:

$ httpx -m PUT [http://localhost:5001/users](http://localhost:5001/users) \
-p 'current_name' 'Count Dracula' \
--json'{"name" : "Dr. Van Helsing"}'

This returns:

HTTP/1.1 400 Bad Request
...
{
"detail": {
"error": "Username'Dr. Van Helsing'already exists."
}
}

Since we’ve verified that endpoint is working, let’s move on to theDELETE /usersendpoint. It’ll allow us to query
the name of the targeted object to delete it.

Start by creatingapp/queries/delete_user.edgeqland filling it with this query:

select (
delete Userfilter.name = <str>$name
) {name, created_at};

Generate the new function by again runningedgeql-py. Then re-openapp/users.py. This endpoint’s code will
look similar to the endpoints we’ve already written:

# app/users.py
...
from .queries importcreate_user_async_edgeqlascreate_user_qry
from .queries importdelete_user_async_edgeqlasdelete_user_qry
from .queries importget_user_by_name_async_edgeqlas get_user_by_name_qry
from .queries importget_users_async_edgeqlas get_users_qry
from .queries importupdate_user_async_edgeqlasupdate_user_qry
...
@router.delete("/users")
async def delete_user(name: str) -> delete_user_qry.DeleteUserResult:
try:
deleted_user =await delete_user_qry.delete_user(
client,
name=name,
)
(continues on next page)

**4.1. Tutorials 227**


```
(continued from previous page)
except edgedb.errors.ConstraintViolationError:
raiseHTTPException(
status_code=HTTPStatus.BAD_REQUEST,
detail={"error": "User attached to an event. Cannot delete."},
)
```
```
if notdeleted_user:
raiseHTTPException(
status_code=HTTPStatus.NOT_FOUND,
detail={"error": f"User'{name}' was not found."},
)
return deleted_user
```
This endpoint will simply delete the requested user if the user isn’t attached to any event. If the targeted object _is_
attached to an event, the API will throw an HTTP 400 (bad request) error and refuse to delete the object. To test it out
by deletingCount Dracula, on your console, run:

$ httpx -m DELETE [http://localhost:5001/users](http://localhost:5001/users) \
-p 'name' 'Count Dracula'

If it worked, you should see this result:

HTTP/1.1 200 OK

[
{
"id": "e6837562-6f55-11ed-8744-ff1b295ed864",
"name": "Count Dracula",
"created_at": "2022-04-16T23:23:56.630101+00:00"
}
]

With that, you’ve written the entire users API! Now, we move onto the events API which is slightly more complex.
(Nothing you can’t handle though. )

##### 4.1.2.4.2 Events API

Let’s start with thePOST /eventsendpoint, and then we’ll fetch the objects created via POST using theGET /events
endpoint.

First, we need a query. Create a fileapp/queries/create_event.edgeqland drop this query into it:

withname := <str>$name,
address := <str>$address,
schedule := <str>$schedule,
host_name := <str>$host_name

select (
insert Event {
name := name,
address := address,
schedule := <datetime>schedule,
(continues on next page)

**228 Chapter 4. Guides**


(continued from previous page)
host := assert_single(
(select detached Userfilter.name = host_name)
)
}
) {name, address, schedule, host: {name}};

Runedgedb-pyto generate a function from that query.

Create a file inappnamedevents.pyand open it in your editor. It’s time to code up the endpoint to use that freshly
generated query.

# app/events.py
from __future__ import annotations

from http importHTTPStatus
from typing import List

import edgedb
from fastapi importAPIRouter, HTTPException, Query
from pydantic importBaseModel

from .queries importcreate_event_async_edgeqlas create_event_qry

router = APIRouter()
client = edgedb.create_async_client()

class RequestData(BaseModel):
name: str
address: str
schedule: str
host_name: str

@router.post("/events", status_code=HTTPStatus.CREATED)
async def post_event(event: RequestData) -> create_event_qry.CreateEventResult:
try:
created_event = awaitcreate_event_qry.create_event(
client,
name=event.name,
address=event.address,
schedule=event.schedule,
host_name=event.host_name,
)

```
except edgedb.errors.InvalidValueError:
raiseHTTPException(
status_code=HTTPStatus.BAD_REQUEST,
detail={
"error": "Invalid datetime format. "
"Datetime string must look like this: "
"'2010-12-27T23:59:59-07:00'",
},
(continues on next page)
```
**4.1. Tutorials 229**


```
(continued from previous page)
)
```
```
except edgedb.errors.ConstraintViolationError:
raiseHTTPException(
status_code=HTTPStatus.BAD_REQUEST,
detail=f"Event name'{event.name}'already exists,",
)
```
```
return created_event
```
Like thePOST /usersendpoint, the incoming and outgoing shape of thePOST /eventsendpoint’s data are defined
by theRequestDatamodel and the generatedCreateEventResultmodel respectively. Thepost_eventsfunction
asynchronously inserts the data into the database and returns the fields defined in theselectquery we wrote earlier,
along with the new event’sid.

The exception handling logic validates the shape of the incoming data. For example, just as before in the users API, the
events API will complain if you try to create multiple events with the same name. Also, the fieldscheduleaccepts
data as an ISO 8601 timestamp string. Values not adhering to that will incur an HTTP 400 (bad request) error.

It’s almost time to test, but before we can do that, we need to expose this new API inapp/main.py. Open that file,
and update the import on line 6 to also importevents:

# app/main.py
...
from app importusers, events
...

Drop down to the bottom ofmain.pyand include the events router:

# app/main.py
...
fast_api.include_router(events.router)

Let’s try it out. Here’s how you’d create an event:

$ httpx -m POST [http://localhost:5001/events](http://localhost:5001/events) \
--json'{
"name":"Resuscitation",
"address":"Britain",
"schedule":"1889-07-27T23:59:59-07:00",
"host_name":"Mina Murray"
}'

If everything worked, you’ll see output like this:

HTTP/1.1 200 OK
...
{
"id": "0b1847f4-6f3d-11ed-9f27-6fcdf20ffe22",
"name": "Resuscitation",
"address": "Britain",
"schedule": "1889-07-28T06:59:59+00:00",
"host": {
"name": "Mina Murray"
(continues on next page)

**230 Chapter 4. Guides**


(continued from previous page)
}
}

To speed this up a bit, we’ll go ahead and write all the remaining queries in one shot. Then we can flip back toapp/
events.pyand code up all the endpoints. Start by creating a file inapp/queriesnamedget_events.edgeql. This
one is really straightforward:

select Event {name, address, schedule, host : {name}};

Save that one and createapp/queries/get_event_by_name.edgeqlwith this query:

select Event {
name, address, schedule,
host : {name}
}filter .name = <str>$name;

Those two will handle queries forGET /events. Next, createapp/queries/update_event.edgeqlwith this query:

withcurrent_name := <str>$current_name,
new_name := <str>$name,
address := <str>$address,
schedule := <str>$schedule,
host_name := <str>$host_name

select (
update Eventfilter .name = current_name
set{
name := new_name,
address := address,
schedule := <datetime>schedule,
host := (select Userfilter.name = host_name)
}
) {name, address, schedule, host: {name}};

That query will handle PUT requests. The last method left is DELETE. Createapp/queries/delete_event.edgeql
and put this query in it:

select (
delete Eventfilter .name = <str>$name
) {name, address, schedule, host : {name}};

Runedgedb-pyto generate the new functions. Openapp/events.pyso we can start getting these functions im-
plemented in the API! We’ll start by coding GET. Import the newly generated queries and write the GET endpoint in
events.py:

# app/events.py
...
from .queries importcreate_event_async_edgeqlas create_event_qry
from .queries importdelete_event_async_edgeqlas delete_event_qry
from .queries importget_event_by_name_async_edgeqlas get_event_by_name_qry
from .queries importget_events_async_edgeql asget_events_qry
from .queries importupdate_event_async_edgeqlas update_event_qry
...
(continues on next page)

**4.1. Tutorials 231**


```
(continued from previous page)
```
@router.get("/events")
async def get_events(
name: str = Query(None, max_length=50)
) -> List[get_events_qry.GetEventsResult] | get_event_by_name_qry.GetEventByNameResult:
if notname:
events =awaitget_events_qry.get_events(client)
returnevents
else:
event =awaitget_event_by_name_qry.get_event_by_name(client, name=name)
if notevent:
raiseHTTPException(
status_code=HTTPStatus.NOT_FOUND,
detail={"error": f"Event'{name}' does not exist."},
)
returnevent

Save that file and test it like this:

$ httpx -m GET [http://localhost:5001/events](http://localhost:5001/events)

We should get back an array containing all our events (which, at the moment, is just the one):

HTTP/1.1 200 OK
...
[
{
"id": "0b1847f4-6f3d-11ed-9f27-6fcdf20ffe22",
"name": "Resuscitation",
"address": "Britain",
"schedule": "1889-07-28T06:59:59+00:00",
"host": {
"name": "Mina Murray"
}
}
]

You can also use theGET /eventsendpoint to return a single event object by name. To locate theResuscitation
event, you’d use thenameparameter with the GET API as follows:

$ httpx -m GET [http://localhost:5001/events](http://localhost:5001/events) \
-p 'name' 'Resuscitation'

That’ll return a result that looks like the response we just got without thenameparameter, except that it’s a single object
instead of an array.

HTTP/1.1 200 OK
...
{
"id": "0b1847f4-6f3d-11ed-9f27-6fcdf20ffe22",
"name": "Resuscitation",
"address": "Britain",
"schedule": "1889-07-28T06:59:59+00:00",
"host": {
(continues on next page)

**232 Chapter 4. Guides**


(continued from previous page)
"name": "Mina Murray"
}
}

If we’d had multiple events, the response to our first test would have given us all of them.

Let’s finish off the events API with the PUT and DELETE endpoints. Openapp/events.pyand add this code:

# app/events.py
...
@router.put("/events")
async def put_event(
event: RequestData, current_name: str
) -> update_event_qry.UpdateEventResult:
try:
updated_event = awaitupdate_event_qry.update_event(
client,
current_name=current_name,
name=event.name,
address=event.address,
schedule=event.schedule,
host_name=event.host_name,
)

```
except edgedb.errors.InvalidValueError:
raiseHTTPException(
status_code=HTTPStatus.BAD_REQUEST,
detail={
"error": "Invalid datetime format. "
"Datetime string must look like this:'2010-12-27T23:59:59-07:00'",
},
)
```
```
except edgedb.errors.ConstraintViolationError:
raiseHTTPException(
status_code=HTTPStatus.BAD_REQUEST,
detail={"error": f"Event name'{event.name}'already exists."},
)
```
```
if notupdated_event:
raiseHTTPException(
status_code=HTTPStatus.INTERNAL_SERVER_ERROR,
detail={"error": f"Update event'{event.name}' failed."},
)
```
```
return updated_event
```
@router.delete("/events")
async def delete_event(name: str) -> delete_event_qry.DeleteEventResult:
deleted_event = awaitdelete_event_qry.delete_event(client, name=name)

```
if notdeleted_event:
(continues on next page)
```
**4.1. Tutorials 233**


```
(continued from previous page)
raiseHTTPException(
status_code=HTTPStatus.INTERNAL_SERVER_ERROR,
detail={"error": f"Delete event'{name}' failed."},
)
```
```
return deleted_event
```
The events API is now ready to handle updates and deletion. Let’s try out a cool alternative way to test these new
endpoints.

##### 4.1.2.4.3 Browse the endpoints using the native OpenAPI doc

FastAPI automatically generates OpenAPI schema from the API endpoints and uses those to build the API docs. While
theuvicornserver is running, go to your browser and head over to [http://localhost:5001/docs.](http://localhost:5001/docs.) You should see an API
navigator like this:

This documentation allows you to play with the APIs interactively. Let’s try to make a request to thePUT /events.
Click on the API that you want to try and then click on the **Try it out** button. You can do it in the UI as follows:

**234 Chapter 4. Guides**


Clicking the **execute** button will make the request and return the following payload:

You can do the same to testDELETE /events, just make sure you give it whatever name you set for the event in your
previous test of the PUT method.

**4.1. Tutorials 235**


#### 4.1.2.5 Wrapping up

Now you have a fully functioning events API in FastAPI backed by EdgeDB. If you want to see all the source code for
the completed project, you’ll find it in our examples repo. If you’re stuck or if you just want to show off what you’ve
built, come talk to us on Discord. It’s a great community of helpful folks, all passionate about being part of the next
generation of databases.

If you like what you see and want to dive deeper into EdgeDB and what it can do, check out our Easy EdgeDB book. In
it, you’ll get to learn more about EdgeDB as we build an imaginary role-playing game based on Bram Stoker’s Dracula.

### 4.1.3 Flask

```
edb-alt-title Building a REST API with EdgeDB and Flask
```
The EdgeDB Python client makes it easy to integrate EdgeDB into your preferred web development stack. In this
tutorial, we’ll see how you can quickly start building RESTful APIs with Flask and EdgeDB.

We’ll build a simple movie organization system where you’ll be able to fetch, create, update, and delete _movies_ and
_movie actors_ via RESTful API endpoints.

#### 4.1.3.1 Prerequisites

Before we start, make sure you’ve _installed_ theedgedbcommand-line tool. Here, we’ll use Python 3.10 and a few of
its latest features while building the APIs. A working version of this tutorial can be found on Github.

##### 4.1.3.1.1 Install the dependencies

To follow along, clone the repository and head over to theflask-cruddirectory.

$ git clone git@github.com:edgedb/edgedb-examples.git
$ cd edgedb-examples/flask-crud

Create a Python 3.10 virtual environment, activate it, and install the dependencies with this command:

$ python -m venv myvenv
$ source myvenv/bin/activate
$ pip install edgedb flask'httpx[cli]'

##### 4.1.3.1.2 Initialize the database

Now, let’s initialize an EdgeDB project. From the project’s root directory:

$ edgedb project init
Initializing project...

Specify the name of EdgeDB instance to use with this project
[default: flask_crud]:
> flask_crud

Do you want to start instance automatically on login? [y/n]
> y
Checking EdgeDB versions...

**236 Chapter 4. Guides**


Once you’ve answered the prompts, a new EdgeDB instance calledflask_crudwill be created and started.

##### 4.1.3.1.3 Connect to the database

Let’s test that we can connect to the newly started instance. To do so, run:

$ edgedb

You should be connected to the database instance and able to see a prompt similar to this:

EdgeDB 2.x (repl 2.x)
Type \help forhelp, \quit to quit.
edgedb>

You can start writing queries here. However, the database is currently empty. Let’s start designing the data model.

#### 4.1.3.2 Schema design

The movie organization system will have two object types— **movies** and **actors**. Each _movie_ can have links to multi-
ple _actors_. The goal is to create API endpoints that’ll allow us to fetch, create, update, and delete the objects while
maintaining their relationships.

EdgeDB allows us to declaratively define the structure of the objects. The schema lives inside.esdlfile in the
dbschemadirectory. It’s common to declare the entire schema in a single filedbschema/default.esdl. This is
how our datatypes look:

# dbschema/default.esdl

module default{
abstract type Auditable {
propertycreated_at -> datetime {
readonly :=true;
default:= datetime_current();
}
}

```
type ActorextendingAuditable {
required propertyname -> str {
constraint max_len_value(50);
}
propertyage -> int16 {
constraint min_value(0);
constraint max_value(100);
}
propertyheight -> int16 {
constraint min_value(0);
constraint max_value(300);
}
}
```
```
type MovieextendingAuditable {
required propertyname -> str {
constraint max_len_value(50);
(continues on next page)
```
**4.1. Tutorials 237**


(continued from previous page)
}
propertyyear -> int16{
constraint min_value(1850);
};
multi linkactors -> Actor;
}
}

Here, we’ve defined anabstracttype calledAuditableto take advantage of EdgeDB’s schema mixin system. This
allows us to add acreated_atproperty to multiple types without repeating ourselves.

TheActortype extendsAuditableand inherits thecreated_atproperty as a result. This property is auto-filled via
thedatetime_currentfunction. Along with the inherited type, the actor type also defines a few additional properties
like calledname,age, andheight. The constraints on the properties make sure that actor names can’t be longer than
50 characters, age must be between 0 to 100 years, and finally, height must be between 0 to 300 centimeters.

We also define aMovietype that extends theAuditableabstract type. It also contains some additional concrete
properties and links:name,year, and an optional multi-link calledactorswhich refers to theActorobjects.

#### 4.1.3.3 Build the API endpoints

The API endpoints are defined in theappdirectory. The directory structure looks as follows:

app
__init__.py
actors.py
main.py
movies.py

Theactors.pyandmovies.pymodules contain the code to build theActorandMovieAPIs respectively. The
main.pymodule then registers all the endpoints and exposes them to the webserver.

##### 4.1.3.3.1 Fetch actors

Since theActortype is simpler, we’ll start with that. Let’s create aGET /actorsendpoint so that we can see the
Actorobjects saved in the database. You can create the API in Flask like this:

# flask-crud/app/actors.py
from __future__ import annotations

import json
from http importHTTPStatus

import edgedb
from flask importBlueprint, request

actor = Blueprint("actor", __name__)
client = edgedb.create_client()

@actor.route("/actors", methods=["GET"])
defget_actors() -> tuple[dict, int]:
(continues on next page)

**238 Chapter 4. Guides**


```
(continued from previous page)
filter_name = request.args.get("filter_name")
```
```
if notfilter_name:
actors = client.query_json(
"""
select Actor {
name,
age,
height
}
"""
)
else:
actors = client.query_json(
"""
select Actor {
name,
age,
height
}
filter .name = <str>$filter_name
""",
filter_name=filter_name,
)
```
```
response_payload = {"result": json.loads(actors)}
return response_payload, HTTPStatus.OK
```
TheBlueprintinstance does the actual work of exposing the API. We also create a blocking EdgeDB client instance
to communicate with the database. By default, this API will return a list of actors, but you can also filter the objects by
name.

In theget_actorsfunction, we perform the database query via theedgedbclient. Here, theclient.query_json
method conveniently returnsJSONserialized objects. We deserialize the returned data in theresponse_payload
dictionary and then return it. Afterward, the final JSON serialization part is taken care of by Flask. This endpoint is
exposed to the server in themain.pymodule. Here’s the content of the module:

# flask-crud/app/main.py
from __future__ import annotations

from flask importFlask

from app.actors import actor
from app.movies import movie

app = Flask(__name__)

app.register_blueprint(actor)
app.register_blueprint(movie)

To test the endpoint, go to theflask-cruddirectory and run:

**4.1. Tutorials 239**


$ export FLASK_APP=app.main:app && flask run --reload

This will start the development server and make it accessible via port 5000. Earlier, we installed the HTTPx client
library to make HTTP requests programmatically. It also comes with a neat command-line tool that we’ll use to test
our API.

While the development server is running, on a new console, run:

$ httpx -m GET [http://localhost:5000/actors](http://localhost:5000/actors)

You’ll see the following output on the console:

HTTP/1.1 200 OK
Server: Werkzeug/2.1.1 Python/3.10.4
Date: Wed, 27 Apr 2022 18:58:38 GMT
Content-Type: application/json
Content-Length: 2

{
"result": []
}

Our request yielded an empty list because the database is currently empty. Let’s create thePOST /actorsendpoint to
start saving actors in the database.

##### 4.1.3.3.2 Create actor

The POST endpoint can be built similarly:

# flask-crud/app/actors.py
...
@actor.route("/actors", methods=["POST"])
defpost_actor() -> tuple[dict, int]:
incoming_payload = request.json

```
# Data validation.
if notincoming_payload:
return{
"error": "Bad request"
}, HTTPStatus.BAD_REQUEST
```
```
if not(name := incoming_payload.get("name")):
return{
"error": "Field'name'is required."
}, HTTPStatus.BAD_REQUEST
```
```
if len(name) > 50:
return{
"error": "Field'name'cannot be longer than 50 "
"characters."
}, HTTPStatus.BAD_REQUEST
```
```
if age := incoming_payload.get("age"):
(continues on next page)
```
**240 Chapter 4. Guides**


```
(continued from previous page)
if 0 <= age <= 100:
return{
"error": "Field'age' must be between 0 "
"and 100."
}, HTTPStatus.BAD_REQUEST
```
```
if height := incoming_payload.get("height"):
if not0 <= height <= 300:
return{
"error": "Field'height'must between 0 and "
"300 cm."
}, HTTPStatus.BAD_REQUEST
```
```
# Create object.
actor = client.query_single_json(
"""
with
name := <str>$name,
age := <optional int16>$age,
height := <optional int16>$height
select (
insert Actor {
name := name,
age := age,
height := height
}
){ name, age, height };
""",
name=name,
age=age,
height=height,
)
response_payload = {"result": json.loads(actor)}
return response_payload, HTTPStatus.CREATED
```
In the above snippet, we perform data validation in the conditional blocks and then make the query to create the object
in the database. For now, we’ll only allow creating a single object per request. Theclient.query_single_json
ensures that we’re creating and returning only one object. Inside the query string, notice, how we’re using<optional
type>to deal with the optional fields. If the user doesn’t provide the value of an optional field likeageorheight,
it’ll be defaulted tonull.

To test it out, make a request as follows:

$ httpx -m POST [http://localhost:5000/actors](http://localhost:5000/actors) \
-j '{"name" : "Robert Downey Jr."}'

The output should look similar to this:

HTTP/1.1 201 CREATED
...

{
"result": {
(continues on next page)

**4.1. Tutorials 241**


(continued from previous page)
"age": null,
"height": null,
"name": "Robert Downey Jr."
}
}

Before we move on to the next step, create 2 more actors calledChris EvansandNatalie Portman. Now that we
have some data in the database, let’s make aGETrequest to see the objects:

$ httpx -m GET [http://localhost:5000/actors](http://localhost:5000/actors)

The response looks as follows:

HTTP/1.1 200 OK
...

{
"result": [
{
"age": null,
"height": null,
"name": "Robert Downey Jr."
},
{
"age": null,
"height": null,
"name": "Chris Evans"
},
{
"age": null,
"height": null,
"name": "Natalie Portman"
}
]
}

You can filter the output of theGET /actorsbyname. To do so, use thefilter_namequery parameter like this:

$ httpx -m GET [http://localhost:5000/actors](http://localhost:5000/actors) \
-p filter_name "Robert Downey Jr."

Doing this will only display the data of a single object:

HTTP/1.1 200 OK

{
"result": [
{
"age": null,
"height": null,
"name": "Robert Downey Jr."
}
(continues on next page)

**242 Chapter 4. Guides**


(continued from previous page)
]
}

Once you’ve done that, we can move on to the next step of building thePUT /actorsendpoint to update the actor data.

##### 4.1.3.3.3 Update actor

It can be built like this:

# flask-crud/app/actors.py

# ...

@actor.route("/actors", methods=["PUT"])
defput_actors() -> tuple[dict, int]:
incoming_payload = request.json
filter_name = request.args.get("filter_name")

```
# Data validation.
if notincoming_payload:
return{
"error": "Bad request"
}, HTTPStatus.BAD_REQUEST
```
```
if notfilter_name:
return{
"error": "Query parameter'filter_name'must "
"be provided",
}, HTTPStatus.BAD_REQUEST
```
```
if (name:=incoming_payload.get("name"))andlen(name) > 50:
return{
"error": "Field'name'cannot be longer than "
"50 characters."
}, HTTPStatus.BAD_REQUEST
```
```
if age := incoming_payload.get("age"):
if age <= 0:
return{
"error": "Field'age' cannot be less than "
"or equal to 0."
}, HTTPStatus.BAD_REQUEST
```
```
if height := incoming_payload.get("height"):
if not0 <= height <= 300:
return{
"error": "Field'height'must between 0 "
"and 300 cm."
}, HTTPStatus.BAD_REQUEST
```
```
# Update object.
(continues on next page)
```
**4.1. Tutorials 243**


```
(continued from previous page)
actors = client.query_json(
"""
with
filter_name := <str>$filter_name,
name := <optional str>$name,
age := <optional int16>$age,
height := <optional int16>$height
select (
update Actor
filter .name = filter_name
set {
name := name ?? .name,
age := age ?? .age,
height := height ?? .height
}
){ name, age, height };""",
filter_name=filter_name,
name=name,
age=age,
height=height,
)
response_payload = {"result": json.loads(actors)}
return response_payload, HTTPStatus.OK
```
Here, we’ll isolate the intended object that we want to update by filtering the actors with thefilter_nameparameter.
For example, if you wanted to update the properties ofRobert Downey Jr., the value of thefilter_namequery
parameter would beRobert Downey Jr.. The coalesce operator??in the query string makes sure that the API user
can selectively update the properties of the target object and the other properties keep their existing values.

The following command updates theageandheightofRobert Downey Jr..

$ httpx -m PUT [http://localhost:5000/actors](http://localhost:5000/actors) \
-p filter_name "Robert Downey Jr." \
-j '{"age": 57, "height": 173}'

This will return:

HTTP/1.1 200 OK
...
{
"result": [
{
"age": 57,
"height": 173,
"name": "Robert Downey Jr."
}
]
}

**244 Chapter 4. Guides**


##### 4.1.3.3.4 Delete actor

Another API that we’ll need to cover is theDELETE /actorsendpoint. It’ll allow us to query the name of the targeted
object and delete that. The code looks similar to the ones you’ve already seen:

# flask-crud/app/actors.py
...

@actor.route("/actors", methods=["DELETE"])
defdelete_actors() -> tuple[dict, int]:
if not(filter_name := request.args.get("filter_name")):
return{
"error": "Query parameter'filter_name'must "
"be provided",
}, HTTPStatus.BAD_REQUEST

```
try:
actors = client.query_json(
"""select (
delete Actor
filter .name = <str>$filter_name
) {name}
""",
filter_name=filter_name,
)
except edgedb.errors.ConstraintViolationError:
return(
{
"error": f"Cannot delete'{filter_name}. "
"Actor is associated with at least one movie."
},
HTTPStatus.BAD_REQUEST,
)
```
```
response_payload = {"result": json.loads(actors)}
return response_payload, HTTPStatus.OK
```
This endpoint will simply delete the requested actor if the actor isn’t attached to any movie. If the targeted object is
attached to a movie, then API will throw an HTTP 400 (bad request) error and refuse to delete the object. To delete
Natalie Portman, on your console, run:

$ httpx -m DELETE [http://localhost:5000/actors](http://localhost:5000/actors) \
-p filter_name "Natalie Portman"

That’ll return:

HTTP/1.1 200 OK
...

{
"result": [
{
"name": "Natalie Portman"
(continues on next page)

**4.1. Tutorials 245**


(continued from previous page)
}
]
}

Now let’s move on to building theMovieAPI.

##### 4.1.3.3.5 Create movie

Here’s how we’ll implement thePOST /movieendpoint:

# flask-crud/app/movies.py
from __future__ import annotations

import json
from http importHTTPStatus

import edgedb
from flask importBlueprint, request

movie = Blueprint("movie", __name__)
client = edgedb.create_client()

@movie.route("/movies", methods=["POST"])
defpost_movie() -> tuple[dict, int]:
incoming_payload = request.json

```
# Data validation.
if notincoming_payload:
return{
"error": "Bad request"
}, HTTPStatus.BAD_REQUEST
```
```
if not(name := incoming_payload.get("name")):
return{
"error": "Field'name'is required."
}, HTTPStatus.BAD_REQUEST
```
```
if len(name) > 50:
return{
"error": "Field'name'cannot be longer than "
"50 characters."
}, HTTPStatus.BAD_REQUEST
```
```
if year := incoming_payload.get("year"):
if year < 1850:
return{
"error": "Field'year'cannot be less "
"than 1850."
}, HTTPStatus.BAD_REQUEST
```
```
actor_names = incoming_payload.get("actor_names")
(continues on next page)
```
**246 Chapter 4. Guides**


```
(continued from previous page)
```
```
# Create object.
movie = client.query_single_json(
"""
with
name := <str>$name,
year := <optional int16>$year,
actor_names := <optional array<str>>$actor_names
select (
insert Movie {
name := name,
year := year,
actors := (
select Actor
filter .name in array_unpack(actor_names)
)
}
){ name, year, actors: {name, age, height} };
""",
name=name,
year=year,
actor_names=actor_names,
)
response_payload = {"result": json.loads(movie)}
return response_payload, HTTPStatus.CREATED
```
Like thePOST /actorsAPI, conditional blocks validate the shape of the incoming data and theclient.query_json
method creates the object in the database. EdgeQL allows us to perform insertion and selection of data fields at the
same time in a single query. One thing that’s different here is that thePOST /moviesAPI also accepts an optional
field calledactor_nameswhere the user can provide an array of actor names. The backend will associate the actors
with the movie object if those actors exist in the database.

Here’s how you’d create a movie:

$ httpx -m POST [http://localhost:5000/movies](http://localhost:5000/movies) \
-j '{ "name": "The Avengers", "year": 2012, "actor_names": [ "Robert Downey Jr.",
˓→"Chris Evans" ] }'

That’ll return:

HTTP/1.1 201 CREATED
...
{
"result": {
"actors": [
{
"age": null,
"height": null,
"name": "Chris Evans"
},
{
"age": 57,
"height": 173,
(continues on next page)

**4.1. Tutorials 247**


(continued from previous page)
"name": "Robert Downey Jr."
}
],
"name": "The Avengers",
"year": 2012
}
}

##### 4.1.3.3.6 Additional movie endpoints

The implementation of theGET /movie,PATCH /movieandDELETE /movieendpoints are provided in the sample
codebase inapp/movies.py. But try to write them on your own using the Actor endpoints as a starting point! Once
you’re done, you should be able to fetch a movie by its title from your database with thefilter_nameparameter and
the GET API as follows:

$ httpx -m GET [http://localhost:5000/movies](http://localhost:5000/movies) \
-p 'filter_name' 'The Avengers'

That’ll return:

HTTP/1.1 200 OK
...
{
"result": [
{
"actors": [
{
"age": null,
"name": "Chris Evans"
},
{
"age": 57,
"name": "Robert Downey Jr."
}
],
"name": "The Avengers",
"year": 2012
}
]
}

**248 Chapter 4. Guides**


#### 4.1.3.4 Conclusion

While building REST APIs, the EdgeDB client allows you to leverage EdgeDB with any microframework of your
choice. Whether it’s FastAPI, Flask, AIOHTTP, Starlette, or Tornado, the core workflow is quite similar to the one
demonstrated above; you’ll query and serialize data with the client and then return the payload for your framework to
process.

### 4.1.4 Phoenix

```
edb-alt-title Building a GitHub OAuth application
```
There is a community-supported Elixir driver for EdgeDB. In this tutorial, we’ll look at how you can create an appli-
cation with authorization through GitHub using Phoenix and EdgeDB.

This tutorial is a simplified version of the LiveBeats application from fly.io with EdgeDB instead of PostgreSQL, which
focuses on implementing authorization via GitHub. The completed implementation of this example can be found on
GitHub. The full version of LiveBeats version on EdgeDB can also be found on GitHub

#### 4.1.4.1 Prerequisites

For this tutorial we will need:

- EdgeDB CLI.
- Elixir version 1.13 or higher.
- Phoenix framework version 1.6 or higher.
- GitHub OAuth application.

Before discussing the project database schema, let’s generate a skeleton for our application. We will make sure that it
will use binary IDs for the Ecto schemas because EdgeDB uses UUIDs as primary IDs, which in Elixir are represented
as strings, and since it is basically a plain JSON API application, we will disable all the built-in Phoenix integrations.

$ mix phx.new phoenix-github_oauth --app github_oauth --module GitHubOAuth \
> --no-html --no-gettext --no-dashboard --no-live --no-mailer --binary-id
$ cd phoenix-github_oauth/

Let’s also get rid of some default things that were created by Phoenix and won’t be used by us.

$ # remove the module Ecto.Repo and the directory for Ecto migrations,
$ # because they will not be used
$ rm -r lib/github_oauth/repo.ex priv/repo/

And then add the EdgeDB driver, theEctohelper for it and theMintHTTP client for GitHub OAuth client as project
dependencies tomix.exs.

defmodule GitHubOAuth.MixProject do
# ...

```
defp depsdo
[
{:phoenix, "~> 1.6.9"},
{:phoenix_ecto, "~> 4.4"},
{:esbuild, "~> 0.4", runtime:Mix.env() == :dev},
{:telemetry_metrics, "~> 0.6"},
(continues on next page)
```
**4.1. Tutorials 249**


```
(continued from previous page)
{:telemetry_poller, "~> 1.0"},
{:jason, "~> 1.2"},
{:plug_cowboy, "~> 2.5"},
{:edgedb, "~> 0.3.0"},
{:edgedb_ecto, git: "https://github.com/nsidnev/edgedb_ecto"},
{:mint, "~> 1.0"} # we need mint to write the GitHub client
]
end
```
# ...
end

Now we need to download new dependencies.

$ mix deps.get

Next, we will create a module inlib/github_oauth/edgedb.exwhich will define a child specification for the
EdgeDB driver and use theEdgeDBEctohelper, which will inspect the queries that will be stored in thepriv/edgeql/
directory and generate Elixir code for them.

defmodule GitHubOAuth.EdgeDB do
use EdgeDBEcto,
name: __MODULE__,
queries: true,
otp_app: :github_oauth

def child_spec(_opts \\ [])do
%{
id: __MODULE__,
start: {EdgeDB, :start_link, [[name: __MODULE__]]}
}
end
end

Now we need to addGitHubOAuth.EdgeDBas a child for our application inlib/github_oauth/application.ex
(at the same time removing the child definition forEcto.Repofrom there).

defmodule GitHubOAuth.Application do
# ...

```
@impl true
def start(_type, _args)do
children = [
# Start the EdgeDB driver
GitHubOAuth.EdgeDB,
# Start the Telemetry supervisor
GitHubOAuthWeb.Telemetry,
# Start the PubSub system
{Phoenix.PubSub, name:GitHubOAuth.PubSub},
# Start the Endpoint (http/https)
GitHubOAuthWeb.Endpoint
# Start a worker by calling: GitHubOAuth.Worker.start_link(arg)
# {GitHubOAuth.Worker, arg}
(continues on next page)
```
**250 Chapter 4. Guides**


```
(continued from previous page)
]
```
```
# ...
end
```
# ...
end

Now we are ready to start working with EdgeDB! First, let’s initialize a new project for this application.

$ edgedb project init
No `edgedb.toml` found in`/home/<user>/phoenix-github_oauth`or above

Do you want to initialize a new project? [Y/n]
> Y

Specify the name of EdgeDB instance to use with this project
[default: phoenix_github_oauth]:
> github_oauth

Checking EdgeDB versions...
Specify the version of EdgeDB to use with this project [default: 2.x]:
> 2.x

Do you want to start instance automatically on login? [y/n]
> y

Great! Now we are ready to develop the database schema for the application.

#### 4.1.4.2 Schema design

This application will have 2 types:UserandIdentity. Thedefault::Userrepresents the system user and the
default::Identityrepresents the way the user logs in to the application (in this example via GitHub OAuth).

This schema will be stored in a single EdgeDB module inside thedbschema/default.esdlfile.

module default{
type User {
propertyname -> str;
required propertyusername -> str;
required propertyemail -> cistr;

```
propertyprofile_tagline -> str;
```
```
propertyavatar_url -> str;
propertyexternal_homepage_url -> str;
```
```
required propertyinserted_at -> cal::local_datetime {
default:= cal::to_local_datetime(datetime_current(), 'UTC');
}
```
```
required propertyupdated_at -> cal::local_datetime {
(continues on next page)
```
**4.1. Tutorials 251**


```
(continued from previous page)
default:= cal::to_local_datetime(datetime_current(), 'UTC');
}
```
```
index on(.email);
index on(.username);
}
```
```
type Identity {
required propertyprovider -> str;
required propertyprovider_token -> str;
required propertyprovider_login -> str;
required propertyprovider_email -> str;
required propertyprovider_id -> str;
```
```
required propertyprovider_meta ->json{
default:= <json>"{}";
}
```
```
required propertyinserted_at -> cal::local_datetime {
default:= cal::to_local_datetime(datetime_current(), 'UTC');
}
```
```
required propertyupdated_at -> cal::local_datetime {
default:= cal::to_local_datetime(datetime_current(), 'UTC');
}
```
```
required linkuser -> User {
on target delete delete source;
}
```
index on(.provider);
constraintexclusive on((.user, .provider));
}
}

After saving the file, we can create a migration for the schema and apply the generated migration.

$ edgedb migration create
did you create object type'default::User'? [y,n,l,c,b,s,q,?]
> y

did you create object type'default::Identity'? [y,n,l,c,b,s,q,?]
> y

Created ./dbschema/migrations/00001.edgeql, id:
m1yehm3jhj6jqwguelek54jzp4wqvvqgrcnvncxwb7676ult7nmcta

$ edgedb migrate

**252 Chapter 4. Guides**


#### 4.1.4.3 Ecto schemas

In this tutorial we will define 2Ecto.Schemamodules, fordefault::Useranddefault::Identitytypes, so that
we can work with EdgeDB in a more convenient way that is familiar to the world of Elixir.

Here is the definition for the user in thelib/accounts/user.exfile.

defmodule GitHubOAuth.Accounts.User do
use Ecto.Schema
use EdgeDBEcto.Mapper

```
alias GitHubOAuth.Accounts.Identity
```
```
@primary_key {:id, :binary_id, autogenerate: false}
```
```
schema "default::User" do
field :email, :string
field :name, :string
field :username, :string
field :avatar_url, :string
field :external_homepage_url, :string
```
```
has_many :identities,Identity
```
timestamps()
end
end

And here for identity inlib/accounts/identity.ex.

defmodule GitHubOAuth.Accounts.Identity do
use Ecto.Schema
use EdgeDBEcto.Mapper

```
alias GitHubOAuth.Accounts.User
```
```
@primary_key {:id, :binary_id, autogenerate: false}
```
```
schema "default::Identity" do
field :provider, :string
field :provider_token, :string
field :provider_email, :string
field :provider_login, :string
field :provider_name, :string, virtual: true
field :provider_id, :string
field :provider_meta, :map
```
```
belongs_to :user,User
```
timestamps()
end
end

**4.1. Tutorials 253**


#### 4.1.4.4 User authentication via GitHub

This part will be pretty big, as we’ll talk about usingEcto.Changesetwith the EdgeDB driver, as well as modules
and queries related to user registration via GitHub OAuth.

Ectoprovides “changesets” (viaEcto.Changeset), which are convenient to use when working withEcto.Schema
to validate external parameters. We could use them viaEdgeDBEctoinstead, though not quite as fully as we can with
the full-featured adapters forEcto.

First, we will update theGitHubOAuth.Accounts.Identitymodule so that it checks all the necessary parameters
when we are creating a user via a GitHub registration.

defmodule GitHubOAuth.Accounts.Identity do
# ...
import Ecto.Changeset

```
alias GitHubOAuth.Accounts.{Identity,User}
```
```
@github "github"
```
```
# ...
```
```
def github_registration_changeset(info, primary_email, emails, token)do
params = %{
"provider_token" => token,
"provider_id" => to_string(info["id"]),
"provider_login" => info["login"],
"provider_name" => info["name"] || info["login"],
"provider_email" => primary_email
}
```
%Identity{}
|> cast(params, [
:provider_token,
:provider_email,
:provider_login,
:provider_name,
:provider_id
])
|> put_change(:provider, @github)
|> put_change(:provider_meta, %{"user" => info, "emails" => emails})
|> validate_required([
:provider_token,
:provider_email,
:provider_name,
:provider_id
])
end
end

And now let’s define a changeset for user registration, which will use an already defined changeset fromGitHubOAuth.
Accounts.Identity.

defmodule GitHubOAuth.Accounts.User do
# ...
(continues on next page)

**254 Chapter 4. Guides**


```
(continued from previous page)
```
```
import Ecto.Changeset
```
```
alias GitHubOAuth.Accounts.{User,Identity}
```
```
# ...
```
```
def github_registration_changeset(info, primary_email, emails, token)do
%{
"login" => username,
"avatar_url" => avatar_url,
"html_url" => external_homepage_url
} = info
```
```
identity_changeset =
Identity.github_registration_changeset(
info,
primary_email,
emails,
token
)
```
```
if identity_changeset.valid?do
params = %{
"username" => username,
"email" => primary_email,
"name" => get_change(identity_changeset, :provider_name),
"avatar_url" => avatar_url,
"external_homepage_url" => external_homepage_url
}
```
```
%User{}
|> cast(params, [
:email,
:name,
:username,
:avatar_url,
:external_homepage_url
])
|> validate_required([:email, :name, :username])
|> validate_username()
|> validate_email()
|> put_assoc(:identities, [identity_changeset])
else
%User{}
|> change()
|> Map.put(:valid?, false)
|> put_assoc(:identities, [identity_changeset])
end
end
```
```
defp validate_email(changeset)do
(continues on next page)
```
**4.1. Tutorials 255**


```
(continued from previous page)
changeset
|> validate_required([:email])
|> validate_format(
:email,
~r/^[^\s]+@[^\s]+$/,
message: "must have the @ sign and no spaces"
)
|> validate_length(:email, max: 160)
end
```
defp validate_username(changeset)do
validate_format(changeset, :username, ~r/^[a-zA-Z0-9_-]{2,32}$/)
end
end

Now that we have the schemas and changesets defined, let’s define a set of the EdgeQL queries we need for the login
process.

There are 5 queries that we will need:

1. Search for a user by user ID.
2. Search for a user by email and by identity provider.
3. Update the identity token if the user from the 1st query exists.
4. Registering a user along with his identity data, if the 1st request did not return the user.
5. Querying a user identity before updating its token.

Before writing the queries themselves, let’s create a context modulelib/github_oauth/accounts.exthat will use
these queries, and the module itself will be used by Phoenix controllers.

defmodule GitHubOAuth.Accounts do
import Ecto.Changeset

```
alias GitHubOAuth.Accounts.{User,Identity}
```
```
def get_user(id)do
GitHubOAuth.EdgeDB.Accounts.get_user_by_id(id: id)
end
```
```
def register_github_user(primary_email, info, emails, token)do
if user = get_user_by_provider(:github, primary_email)do
update_github_token(user, token)
else
info
|> User.github_registration_changeset(primary_email, emails, token)
|> EdgeDBEcto.insert(
&GitHubOAuth.EdgeDB.Accounts.register_github_user/1,
nested: true
)
end
end
```
```
def get_user_by_provider(provider, email)when providerin[:github] do
(continues on next page)
```
**256 Chapter 4. Guides**


```
(continued from previous page)
GitHubOAuth.EdgeDB.Accounts.get_user_by_provider(
provider: to_string(provider),
email: String.downcase(email)
)
end
```
```
defp update_github_token(%User{} = user, new_token)do
identity =
GitHubOAuth.EdgeDB.Accounts.get_identity_for_user(
user_id: user.id,
provider: "github"
)
```
```
{:ok, _} =
identity
|> change()
|> put_change(:provider_token, new_token)
|> EdgeDBEcto.update(
&GitHubOAuth.EdgeDB.Accounts.update_identity_token/1
)
```
identity = %Identity{identity | provider_token: new_token}
{:ok, %User{user | identities: [identity]}}
end
end

Note that updating a token with a single query is quite easy, but we will use two separate queries, to show how to work
withEcto.Changesetin different ways.

Now that all the preparations are complete, we can start writing EdgeQL queries.

We start with thepriv/edgeql/accounts/get_user_by_provider.edgeqlfile, which defines a query to find an
user with a specified email provider.

# edgedb = :query_single!
# mapper = GitHubOAuth.Accounts.User

select User {
id,
name,
username,
email,
avatar_url,
external_homepage_url,
inserted_at,
updated_at,
}
filter
.<user[is Identity].provider = <str>$provider
and
str_lower(.email) = str_lower(<str>$email)
limit 1

It is worth noting the# edgedb = :query_single!and# mapper = GitHubOAuth.Accounts.Usercomments.

**4.1. Tutorials 257**


Both are special comments that will be used byEdgeDBEctowhen generating query functions. Theedgedbcomment
defines the driver function for requesting data. Information on all supported features can be found in the driver doc-
umentation. Themappercomment is used to define the module that will be used to map the result from EdgeDB to
some other form. OurEcto.Schemaschemas support this withuse EdgeDBEcto.Mapperexpression at the top of
the module definition.

The queries for getting the identity and getting the user by ID are quite similar to the above, so we will omit them here.
You can find these queries in the example repository.

Instead, let’s look at how to update the user identity. This will be described in thepriv/edgeql/accounts/
update_identity_token.edgeqlfile.

# edgedb = :query_required_single

withparams := <json>$params
update Identity
filter .id = <uuid>params["id"]
set{
provider_token := (
<str>json_get(params, "provider_token") ?? .provider_token
),
updated_at := cal::to_local_datetime(datetime_current(), 'UTC'),
}

As you can see, this query uses the named parameter$paramsinstead of two separate parameters such as$idand
$provider_token. This is because to update our identity we use the changeset in the moduleGitHubOAuth.
Accounts, which automatically monitors changes to the schema and will not give back the parameters, which will
not affect the state of the schema in update. SoEdgeDBEctoautomatically converts data from changesets when it is an
update or insert operation into a named$paramsparameter of type JSON. It also helps to work with nested changesets,
as we will see in the next query, which is defined in thepriv/edgeql/accounts/register_github_user.edgeql
file.

# edgedb = :query_single!
# mapper = GitHubOAuth.Accounts.User

with
params := <json>$params,
identities_params := params["identities"],
user := (
insert User {
email := <str>params["email"],
name := <str>params["name"],
username := <str>params["username"],
avatar_url := <optional str>json_get(params, "avatar_url"),
external_homepage_url := (
<str>json_get(params, "external_homepage_url")
),
}
),
identites := (
foridentity_params injson_array_unpack(identities_params) union(
insert Identity {
provider := <str>identity_params["provider"],
provider_token := <str>identity_params["provider_token"],
provider_email := <str>identity_params["provider_email"],
(continues on next page)

**258 Chapter 4. Guides**


(continued from previous page)
provider_login := <str>identity_params["provider_login"],
provider_id := <str>identity_params["provider_id"],
provider_meta := <json>identity_params["provider_meta"],
user := user,
}
)
)
select user {
id,
name,
username,
email,
avatar_url,
external_homepage_url,
inserted_at,
updated_at,
identities := identites,
}

Awesome! We’re almost done with our application!

As a final step in this tutorial, we will add 2 routes for the web application. The first will redirect the user to the GitHub
OAuth page if they’re not already logged in or will show their username otherwise. The second is for logging into the
application through GitHub.

Save the GitHub OAuth credentials from the _prerequisites_ step asGITHUB_CLIENT_IDandGITHUB_CLIENT_SECRET
environment variables.

And then modify yourconfig/dev.exsconfiguration file to use them.

# ...

config :github_oauth, :github,
client_id: System.fetch_env!("GITHUB_CLIENT_ID"),
client_secret: System.fetch_env!("GITHUB_CLIENT_SECRET")

# ...

First we create a filelib/github_oauth_web/controllers/user_controller.exwith a controller which will
show the name of the logged in user or redirect to the authentication page otherwise.

defmodule GitHubOAuthWeb.UserController do
use GitHubOAuthWeb, :controller

```
alias GitHubOAuth.Accounts
```
```
plug :fetch_current_user
```
```
def index(conn, _params)do
if conn.assigns.current_userdo
json(conn, %{name: conn.assigns.current_user.name})
else
redirect(conn, external:GitHubOAuth.GitHub.authorize_url())
end
(continues on next page)
```
**4.1. Tutorials 259**


```
(continued from previous page)
end
```
defp fetch_current_user(conn, _opts)do
user_id = get_session(conn, :user_id)
user = user_id &&Accounts.get_user(user_id)
assign(conn, :current_user, user)
end
end

Note that the implementation of theGitHubOAuth.GitHubmodule is not given here because it is relatively big and
not a necessary part of this guide. If you want to explore its internals, you can check out its implementation on GitHub.

Now add an authentication controller inlib/github_oauth_web/controllers/oauth_callback_controller.
ex.

defmodule GitHubOAuthWeb.OAuthCallbackController do
use GitHubOAuthWeb, :controller

```
alias GitHubOAuth.Accounts
```
```
require Logger
```
```
def new(
conn,
%{"provider" => "github", "code" => code, "state" => state}
) do
client = github_client(conn)
```
```
with {:ok, info} <-
client.exchange_access_token(code: code, state: state),
%{
info: info,
primary_email: primary,
emails: emails,
token: token
} = info,
{:ok, user} <-
Accounts.register_github_user(primary, info, emails, token)do
conn
|> log_in_user(user)
|> redirect(to: "/")
else
{:error, %Ecto.Changeset{} = changeset} ->
Logger.debug("failed GitHub insert #{inspect(changeset.errors)}")
```
```
error =
"We were unable to fetch the necessary information from " <>
"your GitHub account"
```
```
json(conn, %{error: error})
```
```
{:error, reason} ->
Logger.debug("failed GitHub exchange#{inspect(reason)}")
(continues on next page)
```
**260 Chapter 4. Guides**


```
(continued from previous page)
```
```
json(conn, %{
error: "We were unable to contact GitHub. Please try again later"
})
end
end
```
```
def new(conn, %{"provider" => "github", "error" => "access_denied"})do
json(conn, %{error: "Access denied"})
end
```
```
defp github_client(conn)do
conn.assigns[:github_client] ||GitHubOAuth.GitHub
end
```
defp log_in_user(conn, user)do
conn
|> assign(:current_user, user)
|> configure_session(renew: true)
|> clear_session()
|> put_session(:user_id, user.id)
end
end

Finally, we need to changelib/github_oauth_web/router.exand add new controllers there.

defmodule GitHubOAuthWeb.Router do
# ...

```
pipeline :api do
# ...
plug :fetch_session
end
```
```
scope "/", GitHubOAuthWeb do
pipe_through :api
```
```
get "/",UserController, :index
get "/oauth/callbacks/:provider",OAuthCallbackController, :new
end
```
# ...
end

**4.1. Tutorials 261**


#### 4.1.4.5 Running web server

That’s it! Now we are ready to run our application and check if everything works as expected.

$ mix phx.server
Generated github_oauth app
[info] Running GitHubOAuthWeb.Endpoint with cowboy 2.9.0 at 127.0.0.1:4000
(http)

[info] Access GitHubOAuthWeb.Endpoint at [http://localhost:4000](http://localhost:4000)

After going to [http://localhost:4000,](http://localhost:4000,) we will be greeted by the GitHub authentication page. And after confirming the
login we will be automatically redirected back to our local server, which will save the received user in the session and
return the obtained user name in the JSON response.

We can also verify that everything is saved correctly by manually checking the database data.

edgedb>selectUser {
....... name,
....... username,
....... avatar_url,
....... external_homepage_url,
....... };
{
default::User {
name:'Nik',
username:'nsidnev',
avatar_url:'https://avatars.githubusercontent.com/u/22559461?v=4',
external_homepage_url:'https://github.com/nsidnev'
},
}
edgedb>selectIdentity {
....... provider,
....... provider_login
....... }
.......filter.user.username ='nsidnev';
{default::Identity {provider:'github', provider_login:'nsidnev'}}

### 4.1.5 Strawberry

```
edb-alt-title Building a GraphQL API with EdgeDB and Strawberry
```
EdgeDB allows you to query your database with GraphQL via the built-in GraphQL extension. It enables you to
expose GraphQL-driven CRUD APIs for all object types, their properties, links, and aliases. This opens up the scope
for creating backend-less applications where the users will directly communicate with the database. You can learn
more about that in the GraphQL section of the docs.

However, as of now, EdgeDB is not ready to be used as a standalone backend. You shouldn’t expose your EdgeDB in-
stance directly to the application’s frontend; this is insecure and will give all users full read/write access to your database.
So, in this tutorial, we’ll see how you can quickly create a simple GraphQL API without using the built-in extension,
which will give the users restricted access to the database schema. Also, we’ll implement HTTP basic authentication
and demonstrate how you can write your own GraphQL validators and resolvers. This tutorial assumes you’re already
familiar with GraphQL terms like schema, query, mutation, resolver, validator, etc, and have used GraphQL with some
other technology before.

**262 Chapter 4. Guides**


We’ll build the same movie organization system that we used in the Flask tutorial and expose the objects and relation-
ships as a GraphQL API. Using the GraphQL interface, you’ll be able to fetch, create, update, and delete movie and
actor objects in the database. Strawberry is a Python library that takes a code-first approach where you’ll write your
object schema as Python classes. This allows us to focus more on how you can integrate EdgeDB into your workflow
and less on the idiosyncrasies of GraphQL itself. We’ll also use the EdgeDB client to communicate with the database,
FastAPI to build the authentication layer, and Uvicorn as the webserver.

#### 4.1.5.1 Prerequisites

Before we start, make sure you have _installed_ theedgedbcommand-line tool. Here, we’ll use Python 3.10 and a few
of its latest features while building the APIs. A working version of this tutorial can be found on Github.

##### 4.1.5.1.1 Install the dependencies

To follow along, clone the repository and head over to thestrawberry-gqldirectory.

$ git clone git@github.com:edgedb/edgedb-examples.git
$ cd edgedb-examples/strawberry-gql

Create a Python 3.10 virtual environment, activate it, and install the dependencies with this command:

$ python3.10 -m venv .venv
$ source .venv/bin/activate
$ pip install edgedb fastapi strawberry-graphql uvicorn[standard]

##### 4.1.5.1.2 Initialize the database

Now, let’s initialize an EdgeDB project. From the project’s root directory:

$ edgedb project init
Initializing project...

Specify the name of EdgeDB instance to use with this project
[default: strawberry_crud]:
> strawberry_crud

Do you want to start instance automatically on login? [y/n]
> y
Checking EdgeDB versions...

Once you’ve answered the prompts, a new EdgeDB instance calledstrawberry_crudwill be created and started.

**4.1. Tutorials 263**


##### 4.1.5.1.3 Connect to the database

Let’s test that we can connect to the newly started instance. To do so, run:

$ edgedb

You should be connected to the database instance and able to see a prompt similar to this:

EdgeDB 2.x (repl 2.x)
Type \help forhelp, \quit to quit.
edgedb>

You can start writing queries here. However, the database is currently empty. Let’s start designing the data model.

#### 4.1.5.2 Schema design

The movie organization system will have two object types— **movies** and **actors**. Each _movie_ can have links to multiple
_actors_. The goal is to create a GraphQL API suite that’ll allow us to fetch, create, update, and delete the objects while
maintaining their relationships.

EdgeDB allows us to declaratively define the structure of the objects. The schema lives inside.esdlfile in the
dbschemadirectory. It’s common to declare the entire schema in a single filedbschema/default.esdl. This is
how our datatypes look:

# dbschema/default.esdl

module default{
abstract type Auditable {
propertycreated_at -> datetime {
readonly :=true;
default:= datetime_current();
}
}

```
type ActorextendingAuditable {
required propertyname -> str {
constraint max_len_value(50);
}
propertyage -> int16 {
constraint min_value(0);
constraint max_value(100);
}
propertyheight -> int16 {
constraint min_value(0);
constraint max_value(300);
}
}
```
```
type MovieextendingAuditable {
required propertyname -> str {
constraint max_len_value(50);
}
propertyyear -> int16{
(continues on next page)
```
**264 Chapter 4. Guides**


(continued from previous page)
constraint min_value(1850);
};
multi linkactors -> Actor;
}
}

Here, we’ve defined anabstracttype calledAuditableto take advantage of EdgeDB’s schema mixin system. This
allows us to add acreated_atproperty to multiple types without repeating ourselves.

TheActortype extendsAuditableand inherits thecreated_atproperty as a result. This property is auto-filled via
thedatetime_currentfunction. Along with the inherited type, the actor type also defines a few additional properties
like calledname,age, andheight. The constraints on the properties make sure that actor names can’t be longer than
50 characters, age must be between 0 to 100 years, and finally, height must be between 0 to 300 centimeters.

We also define aMovietype that extends theAuditableabstract type. It also contains some additional concrete
properties and links:name,year, and an optional multi-link calledactorswhich refers to theActorobjects.

#### 4.1.5.3 Build the GraphQL API

The API endpoints are defined in theappdirectory. The directory structure looks as follows:

app
__init__.py
main.py
schemas.py

Theschemas.pymodule contains the code that defines the GraphQL schema and builds the queries and mutations for
ActorandMovieobjects. Themain.pymodule then registers the GraphQL schema, adds the authentication layer,
and exposes the API to the webserver.

##### 4.1.5.3.1 Write the GraphQL schema

Along with the database schema, to expose EdgeDB’s object relational model as a GraphQL API, you’ll also have to
define a GraphQL schema that mirrors the object structure in the database. Strawberry allows us to express this schema
via type annotated Python classes. We define the Strawberry schema in theschema.pyfile as follows:

# strawberry-gql/app/schema.py
from __future__ import annotations

import json# will be used later for serialization

import edgedb
import strawberry

client = edgedb.create_async_client()

@strawberry.type
class Actor:
name: str |None
age: int |None =None
height: int |None= None
(continues on next page)

**4.1. Tutorials 265**


```
(continued from previous page)
```
@strawberry.type
class Movie:
name: str |None
year: int |None=None
actors: list[Actor] |None= None

Here, the GraphQL schema mimics our database schema. Similar to theActorandMovietypes in the EdgeDB
schema, here, both theActorandMoviemodels have three attributes. Likewise, theactorsattribute in theMovie
model represents the link between movies and actors.

##### 4.1.5.3.2 Query actors

In this section, we’ll write the resolver to create the queries that’ll allow us to fetch the actor objects from the database.
You’ll need to write the query resolvers as methods in a class decorated with the@strawberry.typedecorator. Each
method will also need to be decorated with the@strawberry.fielddecorator to mark them as resolvers. Resolvers
can be either sync or async. In this particular case, we’ll write asynchronous resolvers that’ll act in a non-blocking
manner. The query to fetch the actors is built in theschema.pyfile as follows:

# strawberry-gql/app/schema.py
...

@strawberry.type
class Query:
@strawberry.field
async def get_actors(
self, filter_name: str |None=None
) -> list[Actor]:

```
if filter_name:
actors_json =awaitclient.query_json(
"""
select Actor {name, age, height}
filter .name=<str>$filter_name
""",
filter_name=filter_name,
)
else:
actors_json =awaitclient.query_json(
"""
select Actor {name, age, height}
"""
)
actors = json.loads(actors_json)
return[
Actor(name, age, height)
for(name, age, height)in (
d.values()ford inactors
)
]
(continues on next page)
```
**266 Chapter 4. Guides**


```
(continued from previous page)
```
# Register the Query.
schema = strawberry.Schema(query=Query)

Here, theget_actorsresolver method accepts an optionalfilter_nameparameter and returns a list ofActortype
objects. The optionalfilter_nameparameter allows us to build the capability of filtering the actor objects by name.
Inside the method, we use the EdgeDB client to asynchronously query the data. Theclient.query_jsonmethod
returns JSON serialized data which we use to create theActorinstances. Finally, we return the list of actor instances
and the rest of the work is done by Strawberry. Then in the last line of the above snippet, we register theQueryclass
to build theSchemainstance.

Afterward, in themain.pymodule, we use FastAPI to expose the/graphqlendpoint. Also, we add a basic HTTP
authentication layer to demonstrate how you can easily protect your GraphQL endpoint by leveraging FastAPI’s depen-
dency injection system. Here’s how the content of themain.pylooks:

# strawberry-gql/app/main.py
from __future__ import annotations

import secrets
from typing import Literal

from fastapi import(
Depends, FastAPI, HTTPException, Request,
Response, status
)
from fastapi.security importHTTPBasic, HTTPBasicCredentials
from strawberry.fastapi importGraphQLRouter

from app.schema import schema

app = FastAPI()
router = GraphQLRouter(schema)
security = HTTPBasic()

defauth(
credentials: HTTPBasicCredentials = Depends(security)
) -> Literal[True]:

```
"""Simple HTTP Basic Auth."""
```
```
correct_username = secrets.compare_digest(
credentials.username, "ubuntu"
)
correct_password = secrets.compare_digest(
credentials.password, "debian"
)
```
```
if not(correct_usernameandcorrect_password):
raiseHTTPException(
status_code=status.HTTP_401_UNAUTHORIZED,
detail="Incorrect email or password",
headers={"WWW-Authenticate": "Basic"},
(continues on next page)
```
**4.1. Tutorials 267**


```
(continued from previous page)
)
return True
```
@router.api_route("/", methods=["GET", "POST"])
async def graphql(request: Request) -> Response:
return awaitrouter.handle_graphql(request=request)

app.include_router(
router, prefix="/graphql", dependencies=[Depends(auth)]
)

First, we initialize theFastAPIapp instance which will communicate with the Uvicorn webserver. Then we attach
the initializedschemainstance to theGraphQLRouter. TheHTTPBasicclass provides the machinery required to add
the authentication layer. Theauthfunction houses the implementation details of how we’re comparing the incoming
and expected username and passwords as well as how the webserver is going to handle unauthorized requests. The
graphqlhandler function is the one that handles the incoming HTTP requests. Finally, the router instance and the
security handler are registered to the app instance via theapp.include_routermethod.

We can now start querying the/graphqlendpoint. We’ll use the built-in GraphiQL interface to perform the queries.
Before that, let’s start the Uvicorn webserver first. Run:

$ uvicorn app.main:app --port 5000 --reload

This exposes the webserver in port 5000. Now, in your browser, go to [http://localhost:5000/graphql.](http://localhost:5000/graphql.) Here, you’ll find
that the HTTP basic auth requires us to provide the username and password.

Currently, the allowed username and password isubuntuanddebianrespectively. Provide the credentials and you’ll
be taken to a page that looks like this:

**268 Chapter 4. Guides**


You can write your GraphQL queries here. Let’s write a query that’ll fetch all the actors in the database and show all
three of their attributes. The following query does that:

queryActorQuery {
getActors {
age
height
name
}
}

The following response will appear on the right panel of the GraphiQL explorer:

**4.1. Tutorials 269**


Since as of now, the database doesn’t have any data, the payload is returning an empty list. Let’s write a mutation and
create some actors.

##### 4.1.5.3.3 Mutate actors

Mutations are also written in theschema.pyfile. To write a mutation, you’ll have to create a separate class where
you’ll write the mutation resolvers. The resolver methods will need to be decorated with the@strawberry.mutation
decorator. You can write the mutation that’ll create an actor object in the database as follows:

# strawberry-gql/app/schema.py
...

@strawberry.type
class Mutation:
@strawberry.mutation
async def create_actor(
self, name: str,
age: int |None =None,
height: int |None= None
) -> ResponseActor:

```
actor_json =awaitclient.query_single_json(
"""
with new_actor := (
insert Actor {
name := <str>$name,
age := <optional int16>$age,
height := <optional int16>$height
}
)
select new_actor {name, age, height}
""",
(continues on next page)
```
**270 Chapter 4. Guides**


```
(continued from previous page)
name=name,
age=age,
height=height,
)
```
```
actor = json.loads(actor_json)
returnActor(
actor.get("name"),
actor.get("age"),
actor.get("height")
)
```
```
# Mutation class needs to be registered here.
schema = strawberry.Schema(query=Query, mutation=Mutation)
```
Creating a mutation also includes data validation. By type annotating theMutationclass, we’re implicitly asking
Strawberry to perform data validation on the incoming request payload. Strawberry will raise an HTTP 400 error if the
validation fails. Let’s create an actor. Submit the following GraphQL query in the GraphiQL interface:

mutationActorMutation {
__typename
createActor(
name: "Robert Downey Jr.",
age: 57,
height: 173
) {
age
height
name
}
}

In the above mutation,nameis a required field and the remaining two are optional fields. This mutation will create an
actor namedRobert Downey Jr.and show all three attributes—name,age, andheightof the created actor in the
response payload. Here’s the response:

**4.1. Tutorials 271**


Now that we’ve created an actor object, we can run the previously created query to fetch the actors. Running the
ActorQuerywill give you the following response:

You can also filter actors by their names. To do so, you’d leverage thefilterNameparameter of thegetActors
resolver:

queryActorQuery {
__typename
getActors(filterName: "Robert Downey Jr.") {
age
height
name
(continues on next page)

**272 Chapter 4. Guides**


(continued from previous page)
}
}

This will only display the filtered results. Similarly, as shown above, you can write the mutations to update and delete ac-
tors. Their implementations can be found in theschema.pyfile. Check outupdate_actorsanddelete_resolvers
to learn more about their implementation details. You can update one or more attributes of an actor with the following
mutation:

mutationActorMutation {
__typename
updateActors(filterName: "Robert Downey Jr.", age: 60) {
name
age
height
}
}

Running this mutation will update theageofRobert Downey Jr.. First, we filter the objects that we want to mutate
via thefilterNameparameter and then we update the relevant attributes; in this case, we updated theageof the object.
Finally, we show all the fields in the return payload. Use the GraphiQL explorer to interactively play with the full API
suite.

##### 4.1.5.3.4 Query movies

In theschema.pyfile, the query to fetch movies is constructed as follows:

# strawberry-gql/app/schema.py
...

@strawberry.type
class Query:
...

```
@strawberry.field
async def get_movies(
self, filter_name: str |None=None,
) -> list[Movie]:
```
```
if filter_name:
movies_json =awaitclient.query_json(
"""
select Movie {name, year, actors: {name, age, height}}
filter .name=<str>$filter_name
""",
filter_name=filter_name,
)
else:
movies_json =awaitclient.query_json(
"""
select Movie {name, year, actors: {name, age, height}}
"""
(continues on next page)
```
**4.1. Tutorials 273**


```
(continued from previous page)
)
```
```
# Deserialize.
movies = json.loads(movies_json)
foridx, moviein enumerate(movies):
actors = [
Actor(name)ford in movie.get("actors", [])
fornameind.values()
]
```
```
movies[idx] = Movie(
movie.get("name"),
movie.get("year"), actors
)
returnmovies
```
Similar to the actor query, this also allows you to either fetch all or filter movies by the movie names. Execute the
following query to see the movies in the database:

queryMovieQuery {
__typename
getMovies {
actors {
age
height
name
}
name
year
}
}

This will return an empty list since the database doesn’t contain any movies. In the next section, we’ll create a mutation
to create the movies and query them afterward.

##### 4.1.5.3.5 Mutate movies

Before running any query to fetch the movies, let’s see how you’d construct a mutation that allows you to create movies.
You can build the mutation similar to how we’ve constructed the create actor mutation. It looks like this:

# strawberry-gql/app/schema.py
...

@strawberry.type
class Mutation:
...

```
@strawberry.mutation
async def create_movie(
self,
name: str,
(continues on next page)
```
**274 Chapter 4. Guides**


```
(continued from previous page)
year: int |None=None,
actor_names: list[str] |None=None,
) -> Movie:
movie_json =awaitclient.query_single_json(
"""
with
name := <str>$name,
year := <optional int16>$year,
actor_names := <optional array<str>>$actor_names,
new_movie := (
insert Movie {
name := name,
year := year,
actors := (
select detached Actor
filter .name in array_unpack(actor_names)
)
}
)
select new_movie {
name,
year,
actors: {name, age, height}
}
""",
name=name,
year=year,
actor_names=actor_names,
)
```
```
movie = json.loads(movie_json)
actors = [
Actor(name)ford in movie.get("actors", [])
fornamein d.values()]
```
```
returnMovie(
movie.get("name"),
movie.get("year"),
actors
)
```
You can submit a request to this mutation to create a movie. While creating a movie, you must provide the name of the
movie as it’s a required field. Also, you can optionally provide theyearthe movie was released and an array containing
the names of the actors. If the values of theactor_namesfield match any existing actor in the database, the above
snippet makes sure that the movie will be linked with the corresponding actors. In the GraphiQL explorer, run the
following mutation to create a movie namedAvengersand link the actorRobert Downey Jr.with the movie:

mutationMovieMutation {
__typename
createMovie(
name: "Avengers",
actorNames: ["Robert Downey Jr."],
(continues on next page)

**4.1. Tutorials 275**


(continued from previous page)
year: 2012
) {
actors {
name
}
}
}

It’ll return:

Now you can fetch the movies with a simple query like this one:

queryMovieQuery {
__typename
getMovies {
name
year
actors {
name
}
}
}

You’ll then see an output similar to this:

**276 Chapter 4. Guides**


Take a look at theupdate_moviesanddelete_moviesresolvers to gain more insights into the implementation details
of those mutations.

#### 4.1.5.4 Conclusion

In this tutorial, you’ve seen how can use Strawberry and EdgeDB together to quickly build a fully-featured GraphQL
API. Also, you have seen how FastAPI allows you add an authentication layer and serve the API in a secure manner.
One thing to keep in mind here is, ideally, you’d only use GraphQL if you’re interfacing with something that already
expects a GraphQL API. Otherwise, EdgeQL is always going to be more powerful and expressive than GraphQL’s
query syntax.

## 4.2 Deployment

EdgeDB can be hosted on all major cloud hosting platforms. The guides below demonstrate how to spin up both a
managed PostgreSQL instance and a container running EdgeDB in Docker.

**Note:** Minimum requirements

As a rule of thumb, the EdgeDB Docker container requires 1GB RAM! Images with insufficient RAM may experience
unexpected issues during startup.

**4.2. Deployment 277**


### 4.2.1 AWS

```
edb-alt-title Deploying EdgeDB to AWS
```
In this guide we show how to deploy EdgeDB on AWS using Amazon Aurora and Elastic Container Service.

#### 4.2.1.1 Prerequisites

- AWS account with billing enabled (or a free trial)
- (optional)awsCLI (install)

#### 4.2.1.2 Quick Install with CloudFormation

We maintain a CloudFormation template for easy automated deployment of EdgeDB in your AWS account. The tem-
plate deploys EdgeDB to a new ECS service and connects it to a newly provisioned Aurora PostgreSQL cluster. The
created instance has a public IP address with TLS configured and is protected by a password you provide.

##### 4.2.1.2.1 CloudFormation Web Portal

Click here to start the deployment process using CloudFormation portal and follow the prompts. You’ll be prompted
to provide a value for the following parameters:

- DockerImage: defaults to the latest version (edgedb/edgedb), or you can specify a particular tag from the ones
    published to Docker Hub.
- InstanceName: Due to limitations with AWS, this must be 22 characters or less!
- SuperUserPassword: this will used as the password for the new EdgeDB instance. Keep track of the value you
    provide.

Once the deployment is complete, follow these steps to find the host name that has been assigned to your EdgeDB
instance:

1. Open the AWS Console and navigate to CloudFormation > Stacks. Click on the newly created Stack.
2. Wait for the status to readCREATE_COMPLETE—it can take 15 minutes or more.
3. Once deployment is complete, click theOutputstab. The value ofPublicHostnameis the hostname at which
    your EdgeDB instance is publicly available.
4. Copy the hostname and run the following command to open a REPL to your instance.

```
$ edgedb --dsn edgedb://edgedb:<password>@<hostname> --tls-security insecure
EdgeDB 2.x
Type \help for help, \quit to quit.
edgedb>
```
It’s often convenient to create an alias for the remote instance usingedgedb instance link.

$ edgedb instance link \
--trust-tls-cert \
--dsn edgedb://edgedb:<password>@<hostname>
my_aws_instance

**278 Chapter 4. Guides**


This aliases the remote instance tomy_aws_instance(this name can be anything). You can now use the-I
my_aws_instanceflag to run CLI commands against this instance, as with local instances.

**Note:** The command groupsedgedb instanceandedgedb projectare not intended to manage production in-
stances.

$ edgedb -I my_aws_instance
EdgeDB 2.x
Type \help for help, \quit to quit.
edgedb>

##### 4.2.1.2.2 CloudFormation CLI

Alternatively, if you prefer to use AWS CLI, run the following command in your terminal:

$ aws cloudformation create-stack \
--stack-name EdgeDB \
--template-url \
https://edgedb-deploy.s3.us-east-2.amazonaws.com/edgedb-aurora.yml \
--capabilities CAPABILITY_NAMED_IAM \
--parameters ParameterKey=SuperUserPassword,ParameterValue=<password>

#### 4.2.1.3 Manual Install with CLI

The following instructions produce a deployment that is very similar to the CloudFormation option above.

##### 4.2.1.3.1 Create a VPC

For convenience, assign a deployment name and region to environment variables. TheNAMEvariable will be used as
prefix for all the resources created throughout the process. It should only contain alphanumeric characters and hyphens.

$ NAME=your-deployment-name
$ REGION=us-west-2

Then create the VPC.

$ VPC_ID=$( \
aws ec2 create-vpc \
--region $REGION \
--output text \
--query "Vpc.VpcId" \
--cidr-block "10.0.0.0/16" \
--instance-tenancy default \
--tag-specifications \
"ResourceType=vpc,Tags=[{Key=Name,Value=${NAME}-vpc}]" \
)

$ aws ec2 modify-vpc-attribute \
--region $REGION \
(continues on next page)

**4.2. Deployment 279**


```
(continued from previous page)
--vpc-id $VPC_ID \
--enable-dns-support
```
$ aws ec2 modify-vpc-attribute \
--region $REGION \
--vpc-id $VPC_ID \
--enable-dns-hostnames

##### 4.2.1.3.2 Create a Gateway

Allow communication between the VPC and the internet by creating an Internet Gateway.

$ GATEWAY_ID=$( \
aws ec2 create-internet-gateway \
--region $REGION \
--output text \
--query "InternetGateway.InternetGatewayId" \
--tag-specifications \
"ResourceType=internet-gateway, \
Tags=[{Key=Name,Value=${NAME}-internet-gateway}]" \
)

$ aws ec2 attach-internet-gateway \
--region $REGION \
--internet-gateway-id $GATEWAY_ID \
--vpc-id $VPC_ID

##### 4.2.1.3.3 Create a Public Network ACL

A Network Access Control List will act as a firewall for a publicly accessible subnet.

$ PUBLIC_ACL_ID=$( \
aws ec2 create-network-acl \
--region $REGION \
--output text \
--query "NetworkAcl.NetworkAclId" \
--vpc-id $VPC_ID \
--tag-specifications \
"ResourceType=network-acl, \
Tags=[{Key=Name,Value=${NAME}-public-network-acl}]" \
)

$ aws ec2 create-network-acl-entry \
--region $REGION \
--network-acl-id $PUBLIC_ACL_ID \
--rule-number 99 \
--protocol 6 \
--port-range From=0,To=65535 \
--rule-action allow \
(continues on next page)

**280 Chapter 4. Guides**


```
(continued from previous page)
--ingress \
--cidr-block 0.0.0.0/0
```
$ aws ec2 create-network-acl-entry \
--region $REGION \
--network-acl-id $PUBLIC_ACL_ID \
--rule-number 99 \
--protocol 6 \
--port-range From=0,To=65535 \
--rule-action allow \
--egress \
--cidr-block 0.0.0.0/0

#### 4.2.1.3.4 Create a Private Network ACL

A second ACL will be the firewall for a private subnet to provide an extra boundary around the PostgreSQL cluster.

$ PRIVATE_ACL_ID="$( \
aws ec2 create-network-acl \
--region $REGION \
--output text \
--query "NetworkAcl.NetworkAclId" \
--vpc-id $VPC_ID \
--tag-specifications \
"ResourceType=network-acl, \
Tags=[{Key=Name,Value=${NAME}-private-network-acl}]" \
)"

$ aws ec2 create-network-acl-entry \
--region $REGION \
--network-acl-id $PRIVATE_ACL_ID \
--rule-number 99 \
--protocol -1 \
--rule-action allow \
--ingress \
--cidr-block 0.0.0.0/0

$ aws ec2 create-network-acl-entry \
--region $REGION \
--network-acl-id $PRIVATE_ACL_ID \
--rule-number 99 \
--protocol -1 \
--rule-action allow \
--egress \
--cidr-block 0.0.0.0/0

**4.2. Deployment 281**


#### 4.2.1.3.5 Create a Public Subnet in Availability Zone “A”

$ AVAILABILITY_ZONE_A="$( \
aws ec2 describe-availability-zones \
--region $REGION \
--output text \
--query "AvailabilityZones[0].ZoneName" \
)"

$ SUBNET_A_PUBLIC_ID=$( \
aws ec2 create-subnet \
--region $REGION \
--output text \
--query "Subnet.SubnetId" \
--availability-zone $AVAILABILITY_ZONE_A \
--cidr-block 10.0.0.0/20 \
--vpc-id $VPC_ID \
--tag-specifications \
"ResourceType=subnet, \
Tags=[{Key=Name,Value=${NAME}-subnet-a-public}, \
{Key=Reach,Value=public}]" \
)

$ aws ec2 replace-network-acl-association \
--region $REGION \
--network-acl-id $PUBLIC_ACL_ID \
--association-id $( \
aws ec2 describe-network-acls \
--region $REGION \
--output text \
--query " \
NetworkAcls[*].Associations[?SubnetId=='${SUBNET_A_PUBLIC_ID}'][] \
| [0].NetworkAclAssociationId" \
)

$ ROUTE_TABLE_A_PUBLIC_ID=$( \
aws ec2 create-route-table \
--region $REGION \
--output text \
--query "RouteTable.RouteTableId" \
--vpc-id $VPC_ID \
--tag-specifications \
"ResourceType=route-table, \
Tags=[{Key=Name,Value=${NAME}-route-table-a-public}]" \
)

$ aws ec2 create-route \
--region $REGION \
--route-table-id $ROUTE_TABLE_A_PUBLIC_ID \
--destination-cidr-block 0.0.0.0/0 \
--gateway-id $GATEWAY_ID

```
(continues on next page)
```
**282 Chapter 4. Guides**


```
(continued from previous page)
```
$ aws ec2 associate-route-table \
--region $REGION \
--route-table-id $ROUTE_TABLE_A_PUBLIC_ID \
--subnet-id $SUBNET_A_PUBLIC_ID

#### 4.2.1.3.6 Create a Private Subnet in Availability Zone “A”

$ SUBNET_A_PRIVATE_ID=$( \
aws ec2 create-subnet \
--region $REGION \
--output text \
--query "Subnet.SubnetId" \
--availability-zone $AVAILABILITY_ZONE_A \
--cidr-block 10.0.16.0/20 \
--vpc-id $VPC_ID \
--tag-specifications \
"ResourceType=subnet, \
Tags=[{Key=Name,Value=${NAME}-subnet-a-private}, \
{Key=Reach,Value=private}]" \
)

$ aws ec2 replace-network-acl-association \
--region $REGION \
--network-acl-id $PRIVATE_ACL_ID \
--association-id $( \
aws ec2 describe-network-acls \
--region $REGION \
--output text \
--query " \
NetworkAcls[*].Associations[?SubnetId =='${SUBNET_A_PRIVATE_ID}'\
][] | [0].NetworkAclAssociationId" \
)

$ ROUTE_TABLE_A_PRIVATE_ID=$( \
aws ec2 create-route-table \
--region $REGION \
--output text \
--query "RouteTable.RouteTableId" \
--vpc-id $VPC_ID \
--tag-specifications \
"ResourceType=route-table, \
Tags=[{Key=Name,Value=${NAME}-route-table-a-private}]" \
)

$ aws ec2 associate-route-table \
--region $REGION \
--route-table-id $ROUTE_TABLE_A_PRIVATE_ID \
--subnet-id $SUBNET_A_PRIVATE_ID

**4.2. Deployment 283**


#### 4.2.1.3.7 Create a Public Subnet in Availability Zone “B”

$ AVAILABILITY_ZONE_B="$( \
aws ec2 describe-availability-zones \
--region $REGION \
--output text \
--query "AvailabilityZones[1].ZoneName" \
)"

$ SUBNET_B_PUBLIC_ID=$( \
aws ec2 create-subnet \
--region $REGION \
--output text \
--query "Subnet.SubnetId" \
--availability-zone $AVAILABILITY_ZONE_B \
--cidr-block 10.0.32.0/20 \
--vpc-id $VPC_ID \
--tag-specifications \
"ResourceType=subnet, \
Tags=[{Key=Name,Value=${NAME}-subnet-b-public}, \
{Key=Reach,Value=public}]" \
)

$ aws ec2 replace-network-acl-association \
--region $REGION \
--network-acl-id $PUBLIC_ACL_ID \
--association-id $( \
aws ec2 describe-network-acls \
--region $REGION \
--output text \
--query " \
NetworkAcls[*].Associations[?SubnetId == '${SUBNET_B_PUBLIC_ID}'\
][] | [0].NetworkAclAssociationId" \
)

$ ROUTE_TABLE_B_PUBLIC_ID=$( \
aws ec2 create-route-table \
--region $REGION \
--output text \
--query "RouteTable.RouteTableId" \
--vpc-id $VPC_ID \
--tag-specifications \
"ResourceType=route-table, \
Tags=[{Key=Name,Value=${NAME}-route-table-b-public}]" \
)

$ aws ec2 create-route \
--region $REGION \
--route-table-id $ROUTE_TABLE_B_PUBLIC_ID \
--destination-cidr-block 0.0.0.0/0 \
--gateway-id $GATEWAY_ID

```
(continues on next page)
```
**284 Chapter 4. Guides**


```
(continued from previous page)
```
$ aws ec2 associate-route-table \
--region $REGION \
--route-table-id $ROUTE_TABLE_B_PUBLIC_ID \
--subnet-id $SUBNET_B_PUBLIC_ID

#### 4.2.1.3.8 Create a Private Subnet in Availability Zone “B”

$ SUBNET_B_PRIVATE_ID=$( \
aws ec2 create-subnet \
--region $REGION \
--output text \
--query "Subnet.SubnetId" \
--availability-zone $AVAILABILITY_ZONE_B \
--cidr-block 10.0.48.0/20 \
--vpc-id $VPC_ID \
--tag-specifications \
"ResourceType=subnet, \
Tags=[{Key=Name,Value=${NAME}-subnet-b-private}, \
{Key=Reach,Value=private}]" \
)

$ aws ec2 replace-network-acl-association \
--region $REGION \
--network-acl-id $PRIVATE_ACL_ID \
--association-id $( \
aws ec2 describe-network-acls \
--region $REGION \
--output text \
--query " \
NetworkAcls[*].Associations[?SubnetId=='${SUBNET_B_PRIVATE_ID}'][] \
| [0].NetworkAclAssociationId" \
)

$ ROUTE_TABLE_B_PRIVATE_ID=$( \
aws ec2 create-route-table \
--region $REGION \
--output text \
--query "RouteTable.RouteTableId" \
--vpc-id $VPC_ID \
--tag-specifications \
"ResourceType=route-table, \
Tags=[{Key=Name,Value=${NAME}-route-table-b-private}]" \
)

$ aws ec2 associate-route-table \
--region $REGION \
--route-table-id $ROUTE_TABLE_B_PRIVATE_ID \
--subnet-id $SUBNET_B_PRIVATE_ID

**4.2. Deployment 285**


#### 4.2.1.3.9 Create an EC2 security group

$ EC2_SECURITY_GROUP_ID=$( \
aws ec2 create-security-group \
--region $REGION \
--output text \
--query "GroupId" \
--group-name "${NAME}-ec2-security-group" \
--description "Controls access to ${NAME} stack EC2 instances." \
--vpc-id $VPC_ID \
--tag-specifications \
"ResourceType=security-group, \
Tags=[{Key=Name,Value=${NAME}-ec2-security-group}]" \
)

$ aws ec2 authorize-security-group-ingress \
--region $REGION \
--group-id $EC2_SECURITY_GROUP_ID \
--protocol tcp \
--cidr 0.0.0.0/0 \
--port 5656 \
--tag-specifications \
"ResourceType=security-group-rule, \
Tags=[{Key=Name,Value=${NAME}-ec2-security-group-ingress}]"

#### 4.2.1.3.10 Create an RDS Security Group

$ RDS_SECURITY_GROUP_ID=$( \
aws ec2 create-security-group \
--region $REGION \
--output text \
--query "GroupId" \
--group-name "${NAME}-rds-security-group" \
--description "Controls access to ${NAME} stack RDS instances." \
--vpc-id $VPC_ID \
--tag-specifications \
"ResourceType=security-group, \
Tags=[{Key=Name,Value=${NAME}-rds-security-group}]" \
)

$ aws ec2 authorize-security-group-ingress \
--region $REGION \
--group-id $RDS_SECURITY_GROUP_ID \
--protocol tcp \
--source-group $EC2_SECURITY_GROUP_ID \
--port 5432 \
--tag-specifications \
"ResourceType=security-group-rule, \
Tags=[{Key=Name,Value=${NAME}-rds-security-group-ingress}]"

$ RDS_SUBNET_GROUP_NAME="${NAME}-rds-subnet-group"
(continues on next page)

**286 Chapter 4. Guides**


```
(continued from previous page)
```
$ aws rds create-db-subnet-group \
--region $REGION \
--db-subnet-group-name "$RDS_SUBNET_GROUP_NAME" \
--db-subnet-group-description "EdgeDB RDS subnet group for ${NAME}" \
--subnet-ids $SUBNET_A_PRIVATE_ID $SUBNET_B_PRIVATE_ID

#### 4.2.1.3.11 Create an RDS Cluster

Use thereadcommand to securely assign a value to thePASSWORDenvironment variable.

$ echo -n "> " && read -s PASSWORD

Then use this password to create an AWS secret.

$ PASSWORD_ARN="$( \
aws secretsmanager create-secret \
--region $REGION \
--output text \
--query "ARN" \
--name "${NAME}-password" \
--secret-string "$PASSWORD" \
)"

$ DB_CLUSTER_IDENTIFIER="${NAME}-postgres-cluster"

$ DB_CLUSTER_ADDRESS="$( \
aws rds create-db-cluster \
--region $REGION \
--output text \
--query "DBCluster.Endpoint" \
--engine aurora-postgresql \
--engine-version 13.4 \
--db-cluster-identifier "$DB_CLUSTER_IDENTIFIER" \
--db-subnet-group-name "$RDS_SUBNET_GROUP_NAME" \
--master-username postgres \
--master-user-password "$PASSWORD" \
--port 5432 \
--vpc-security-group-ids "$RDS_SECURITY_GROUP_ID" \
)"

$ aws rds create-db-instance \
--region $REGION \
--availability-zone "$AVAILABILITY_ZONE_A" \
--engine "aurora-postgresql" \
--db-cluster-identifier "$DB_CLUSTER_IDENTIFIER" \
--db-instance-identifier "${NAME}-postgres-instance-a" \
--db-instance-class "db.t3.medium" \
--db-subnet-group-name "$RDS_SUBNET_GROUP_NAME"

$ aws rds create-db-instance \
(continues on next page)

**4.2. Deployment 287**


```
(continued from previous page)
--region $REGION \
--availability-zone "$AVAILABILITY_ZONE_B" \
--engine "aurora-postgresql" \
--db-cluster-identifier "$DB_CLUSTER_IDENTIFIER" \
--db-instance-identifier "${NAME}-postgres-instance-b" \
--db-instance-class "db.t3.medium" \
--db-subnet-group-name "$RDS_SUBNET_GROUP_NAME"
```
$ DSN_ARN="$( \
aws secretsmanager create-secret \
--region $REGION \
--output text \
--query "ARN" \
--name "${NAME}-backend-dsn" \
--secret-string \
"postgres://postgres:${PASSWORD}@${DB_CLUSTER_ADDRESS}:5432/postgres" \
)"

#### 4.2.1.3.12 Create a Load Balancer

Adding a load balancer will facilitate scaling the EdgeDB cluster.

$ TARGET_GROUP_ARN="$( \
aws elbv2 create-target-group \
--region $REGION \
--output text \
--query "TargetGroups[0].TargetGroupArn" \
--health-check-interval-seconds 10 \
--health-check-path "/server/status/ready" \
--health-check-protocol HTTPS \
--unhealthy-threshold-count 2 \
--healthy-threshold-count 2 \
--name "${NAME}-target-group" \
--port 5656 \
--protocol TCP \
--target-type ip \
--vpc-id $VPC_ID \
)"

$ LOAD_BALANCER_NAME="${NAME}-load-balancer"

$ LOAD_BALANCER_ARN="$( \
aws elbv2 create-load-balancer \
--region $REGION \
--output text \
--query "LoadBalancers[0].LoadBalancerArn" \
--type network \
--name "$LOAD_BALANCER_NAME" \
--scheme internet-facing \
--subnets "$SUBNET_A_PUBLIC_ID" "$SUBNET_B_PUBLIC_ID" \
)"
(continues on next page)

**288 Chapter 4. Guides**


```
(continued from previous page)
```
$ aws elbv2 create-listener \
--region $REGION \
--default-actions \
'[{"TargetGroupArn": "'"$TARGET_GROUP_ARN"'","Type": "forward"}]' \
--load-balancer-arn "$LOAD_BALANCER_ARN" \
--port 5656 \
--protocol TCP

#### 4.2.1.3.13 Create an ECS Cluster

The only thing left to do is create and ECS cluster and deploy the EdgeDB container in it.

$ EXECUTION_ROLE_NAME="${NAME}-execution-role"

$ EXECUTION_ROLE_ARN="$( \
aws iam create-role \
--region $REGION \
--output text \
--query "Role.Arn" \
--role-name "$EXECUTION_ROLE_NAME" \
--assume-role-policy-document \
"{ \
\"Version\": \"2012-10-17\", \
\"Statement\": [{ \
\"Effect\": \"Allow\", \
\"Principal\": {\"Service\": \"ecs-tasks.amazonaws.com\"}, \
\"Action\": \"sts:AssumeRole\" \
}] \
}" \
)"

$ SECRETS_ACCESS_POLICY_ARN="$( \
aws iam create-policy \
--region $REGION \
--output text \
--query "Policy.Arn" \
--policy-name "${NAME}-secrets-access-policy" \
--policy-document \
"{ \
\"Version\": \"2012-10-17\", \
\"Statement\": [{ \
\"Effect\": \"Allow\", \
\"Action\": \"secretsmanager:GetSecretValue\", \
\"Resource\": [ \
\"$PASSWORD_ARN\", \
\"$DSN_ARN\" \
] \
}] \
}" \
)"
(continues on next page)

**4.2. Deployment 289**


```
(continued from previous page)
```
$ aws iam attach-role-policy \
--region $REGION \
--role-name "$EXECUTION_ROLE_NAME" \
--policy-arn \
"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy"

$ aws iam attach-role-policy \
--region $REGION \
--role-name "$EXECUTION_ROLE_NAME" \
--policy-arn "$SECRETS_ACCESS_POLICY_ARN"

$ TASK_ROLE_ARN="$( \
aws iam create-role \
--region $REGION \
--output text \
--query "Role.Arn" \
--role-name "${NAME}-task-role" \
--assume-role-policy-document \
"{ \
\"Version\": \"2012-10-17\", \
\"Statement\": [{ \
\"Effect\": \"Allow\", \
\"Principal\": {\"Service\": \"ecs-tasks.amazonaws.com\"}, \
\"Action\": \"sts:AssumeRole\" \
}] \
}" \
)"

$ LOG_GROUP_NAME="/ecs/edgedb/$NAME"

$ aws logs create-log-group \
--region $REGION \
--log-group-name "$LOG_GROUP_NAME"

$ CLUSTER_NAME="${NAME}-server-cluster"

$ aws ecs create-cluster \
--region $REGION \
--cluster-name "$CLUSTER_NAME"

$ LOG_GROUP_ARN="$( \
aws logs describe-log-groups \
--region $REGION \
--output text \
--query "logGroups[0].arn" \
--log-group-name-prefix "$LOG_GROUP_NAME" \
)"

$ TASK_DEFINITION_ARN="$( \
aws ecs register-task-definition \
--region $REGION \
(continues on next page)

**290 Chapter 4. Guides**


```
(continued from previous page)
--output text \
--query "taskDefinition.taskDefinitionArn" \
--requires-compatibilities "FARGATE" \
--network-mode "awsvpc" \
--execution-role-arn "$EXECUTION_ROLE_ARN" \
--task-role-arn "$TASK_ROLE_ARN" \
--family "${NAME}-task-definition" \
--cpu 1024 \
--memory 2GB \
--container-definitions \
"[{ \
\"name\": \"$NAME\", \
\"image\": \"edgedb/edgedb\", \
\"portMappings\": [{\"containerPort\": 5656}], \
\"command\": [\"edgedb-server\"], \
\"environment\": [{ \
\"name\": \"EDGEDB_SERVER_GENERATE_SELF_SIGNED_CERT\", \
\"value\": \"1\" \
}], \
\"secrets\": [ \
{ \
\"name\": \"EDGEDB_SERVER_PASSWORD\", \
\"valueFrom\": \"$PASSWORD_ARN\" \
}, \
{ \
\"name\": \"EDGEDB_SERVER_BACKEND_DSN\", \
\"valueFrom\": \"$DSN_ARN\" \
} \
], \
\"logConfiguration\": { \
\"logDriver\": \"awslogs\", \
\"options\": { \
\"awslogs-region\": \"$REGION\", \
\"awslogs-group\": \"$LOG_GROUP_NAME\", \
\"awslogs-stream-prefix\": \"ecs\" \
} \
} \
}]" \
)"
```
$ aws ecs create-service \
--region $REGION \
--service-name "$NAME" \
--cluster "$CLUSTER_NAME" \
--task-definition "$TASK_DEFINITION_ARN" \
--deployment-configuration \
"minimumHealthyPercent=100,maximumPercent=200" \
--desired-count 2 \
--health-check-grace-period-seconds 120 \
--launch-type FARGATE \
--network-configuration \
"awsvpcConfiguration={ \
(continues on next page)

**4.2. Deployment 291**


```
(continued from previous page)
assignPublicIp=ENABLED, \
subnets=[$SUBNET_A_PUBLIC_ID,$SUBNET_B_PUBLIC_ID], \
securityGroups=[$EC2_SECURITY_GROUP_ID] \
}" \
--load-balancers \
"containerName=$NAME, \
containerPort=5656, \
targetGroupArn=$TARGET_GROUP_ARN"
```
#### 4.2.1.3.14 Create a local link to the new EdgeDB instance

Create an local alias to the remote EdgeDB instance withedgedb instance link:

$ printf $PASSWORD | edgedb instance link \
--password-from-stdin \
--trust-tls-cert \
--non-interactive \
--host "$( \
aws ec2 describe-network-interfaces \
--output text \
--region $REGION \
--query \
"NetworkInterfaces[?contains(Description, '$LOAD_BALANCER_NAME')] \
| [0].Association.PublicIp" \
)" \
aws

**Note:** The command groupsedgedb instanceandedgedb projectare not intended to manage production in-
stances.

You can now open a REPL to this instance

### 4.2.1.4 Health Checks

Using an HTTP client, you can perform health checks to monitor the status of your EdgeDB instance. Learn how to
use them with our _health checks guide_.

## 4.2.2 Azure

```
edb-alt-title Deploying EdgeDB to Azure
```
In this guide we show how to deploy EdgeDB using Azure’s Postgres Flexible Server as the backend.

**292 Chapter 4. Guides**


### 4.2.2.1 Prerequisites

- Valid Azure Subscription with billing enabled or credits (free trial).
- Azure CLI (install).

### 4.2.2.2 Provision an EdgeDB instance

Login to your Microsoft Azure account.

$ az login

Create a new resource group.

$ GROUP=my-group-name
$ az group create --name $GROUP --location westus

Provision a PostgreSQL server.

**Note:** If you already have a database provisioned you can skip this step.

For convenience, assign a value to thePG_SERVER_NAMEenvironment variable; we’ll use this variable in multiple later
commands.

$ PG_SERVER_NAME=postgres-for-edgedb

Use thereadcommand to securely assign a value to thePASSWORDenvironment variable.

$ echo -n "> " && read -s PASSWORD

Then create a Postgres Flexible server.

$ az postgres flexible-server create \
--resource-group $GROUP \
--name $PG_SERVER_NAME \
--location westus \
--admin-user edgedb \
--admin-password $PASSWORD \
--sku-name Standard_D2s_v3 \
--version 13 \
--yes

**Note:** If you get an error saying "Specified server name is already used." change the value of
PG_SERVER_NAMEand rerun the command.

Allow other Azure services access to the Postgres instance.

$ az postgres flexible-server firewall-rule create \
--resource-group $GROUP \
--name $PG_SERVER_NAME \
--rule-name allow-azure-internal \
(continues on next page)

**4.2. Deployment 293**


```
(continued from previous page)
--start-ip-address 0.0.0.0 \
--end-ip-address 0.0.0.0
```
EdgeDB requires Postgres’uuid-osspextension which needs to be enabled.

$ az postgres flexible-server parameter set \
--resource-group $GROUP \
--server-name $PG_SERVER_NAME \
--name azure.extensions \
--value uuid-ossp

Start an EdgeDB container.

$ PG_HOST=$(
az postgres flexible-server list \
--resource-group $GROUP \
--query "[?name=='$PG_SERVER_NAME'].fullyQualifiedDomainName | [0]" \
--output tsv
)
$ DSN="postgresql://edgedb:$PASSWORD@$PG_HOST/postgres?sslmode=require"
$ az container create \
--resource-group $GROUP \
--name edgedb-container-group \
--image edgedb/edgedb \
--dns-name-label edgedb \
--ports 5656 \
--secure-environment-variables \
"EDGEDB_SERVER_PASSWORD=$PASSWORD" \
"EDGEDB_SERVER_BACKEND_DSN=$DSN" \
--environment-variables \
EDGEDB_SERVER_TLS_CERT_MODE=generate_self_signed \

Persist the SSL certificate. We have configured EdgeDB to generate a self signed SSL certificate when it
starts. However, if the container is restarted a new certificate would be generated. To preserve the certificate
across failures or reboots copy the certificate files and use their contents in theEDGEDB_SERVER_TLS_KEYand
EDGEDB_SERVER_TLS_CERTenvironment variables.

$ key="$( az container exec \
--resource-group $GROUP \
--name edgedb-container-group \
--exec-command "cat /tmp/edgedb/edbprivkey.pem" \
| tr -d "\r" )"
$ cert="$( az container exec \
--resource-group $GROUP \
--name edgedb-container-group \
--exec-command "cat /tmp/edgedb/edbtlscert.pem" \
| tr -d "\r" )"
$ az container delete \
--resource-group $GROUP \
--name edgedb-container-group \
--yes
$ az container create \
--resource-group $GROUP \
(continues on next page)

**294 Chapter 4. Guides**


```
(continued from previous page)
--name edgedb-container-group \
--image edgedb/edgedb \
--dns-name-label edgedb \
--ports 5656 \
--secure-environment-variables \
"EDGEDB_SERVER_PASSWORD=$PASSWORD" \
"EDGEDB_SERVER_BACKEND_DSN=$DSN" \
"EDGEDB_SERVER_TLS_KEY=$key" \
--environment-variables \
"EDGEDB_SERVER_TLS_CERT=$cert"
```
To access the EdgeDB instance you’ve just provisioned on Azure from your local machine link the instance.

$ printf $PASSWORD | edgedb instance link \
--password-from-stdin \
--non-interactive \
--trust-tls-cert \
--host $( \
az container list \
--resource-group $GROUP \
--query "[?name=='edgedb-container-group'].ipAddress.fqdn | [0]" \
--output tsv ) \
azure

**Note:** The command groupsedgedb instanceandedgedb projectare not intended to manage production in-
stances.

You can now connect to your instance.

$ edgedb -I azure

### 4.2.2.3 Health Checks

Using an HTTP client, you can perform health checks to monitor the status of your EdgeDB instance. Learn how to
use them with our _health checks guide_.

## 4.2.3 DigitalOcean

```
edb-alt-title Deploying EdgeDB to DigitalOcean
```
In this guide we show how to deploy EdgeDB to DigitalOcean either with a One-click Deploy option or a _managed
PostgreSQL_ database as the backend.

**4.2. Deployment 295**


### 4.2.3.1 One-click Deploy

#### 4.2.3.1.1 Prerequisites

- edgedbCLI (install)
- DigitalOcean account

Click the button below and follow the droplet creation workflow on DigitalOcean to deploy an EdgeDB instance.

By default, the admin password isedgedbpassword; let’s change that to something more secure. First, find your
droplet’s IP address on the DigitalOcean dashboard and assign it to an environment variableIP.

$ IP=<your-droplet-ip>

Then use thereadcommand to securely assign a value to thePASSWORDenvironment variable.

$ echo -n "> " && read -s PASSWORD

Use these variables to change the password for the default roleedgedb.

$ printf edgedbpassword | edgedb query \
--host $IP \
--password-from-stdin \
--tls-security insecure \
"alter role edgedb set password :='${PASSWORD}'"
OK: ALTER ROLE

**Construct the DSN**

Let’s construct your instance’s DSN (also known as a “connection string”). We’ll write the value to a file calleddsn.
txtso it doesn’t get stored in shell logs.

$ echo edgedb://edgedb:$PASSWORD@$IP > dsn.txt

Copy the value fromdsn.txt. Run the following command to open a REPL to the new instance.

$ edgedb --dsn <dsn> --tls-security insecure
edgedb>

Success! You’re now connected to your remote instance.

It’s often useful to assign an alias to the remote instance usingedgedb instance link.

$ edgedb instance link \
--dsn <dsn> \
--trust-tls-cert \
--non-interactive \
my_instance
Authenticating to edgedb://edgedb@1.2.3.4:5656/edgedb
Trusting unknown server certificate:
SHA1:1880da9527be464e2cad3bdb20dfc430a6af5727
Successfully linked to remote instance. To connect run:
edgedb -I my_instance

**296 Chapter 4. Guides**


You can now use the-ICLI flag to execute commands against your remote instance:

$ edgedb -I my_instance
edgedb>

### 4.2.3.2 Deploy with Managed PostgreSQL

#### 4.2.3.2.1 Prerequisites

- edgedbCLI (install)
- DigitalOcean account
- doctlCLI (install)
- jq(install)

#### 4.2.3.2.2 Create a managed PostgreSQL instance

If you already have a PostgreSQL instance you can skip this step.

$ DSN="$( \
doctl databases create edgedb-postgres \
--engine pg \
--version 14 \
--size db-s-1vcpu-1gb \
--num-nodes 1 \
--region sfo3 \
--output json \
| jq -r'.[0].connection.uri')"

#### 4.2.3.2.3 Provision a droplet

Replace$SSH_KEY_IDSwith the ids for the ssh keys you want to ssh into the new droplet with. Separate multiple
values with a comma. You can list your keys withdoctl compute ssh-key list. If you don’t have any ssh keys in
your DigitalOcean account you can follow this guide to add one now.

$ IP="$( \
doctl compute droplet create edgedb \
--image edgedb \
--region sfo3 \
--size s-2vcpu-4gb \
--ssh-keys $SSH_KEY_IDS \
--format PublicIPv4 \
--no-header \
--wait )"

Configure the backend Postgres DSN. To simplify the initial deployment, let’s instruct EdgeDB to run in insecure mode
(with password authentication off and an autogenerated TLS certificate). We will secure the instance once things are
up and running.

**4.2. Deployment 297**


$ printf "EDGEDB_SERVER_BACKEND_DSN=${DSN} \
\nEDGEDB_SERVER_SECURITY=insecure_dev_mode\n" \
| ssh root@$IP -T "cat > /etc/edgedb/env"

$ ssh root@$IP "systemctl restart edgedb.service"

Set the superuser password.

$ echo -n "> " && read -s PASSWORD

$ edgedb -H $IP --tls-security insecure query \
"alter role edgedb set password :='$PASSWORD'"
OK: ALTER ROLE

Set the security policy to strict.

$ printf "EDGEDB_SERVER_BACKEND_DSN=${DSN} \
\nEDGEDB_SERVER_SECURITY=strict\n" \
| ssh root@$IP -T "cat > /etc/edgedb/env"

$ ssh root@$IP "systemctl restart edgedb.service"

**Note:** To upgrade an existing EdgeDB droplet to the latest point release,sshinto your droplet and run the following.

$ apt-get update && apt-get install --only-upgrade edgedb-server-2
$ systemctl restart edgedb

That’s it! Refer to the _Construct the DSN_ section above to connect to your instance.

**Note:** The command groupsedgedb instanceandedgedb projectare not intended to manage production in-
stances.

#### 4.2.3.2.4 Health Checks

Using an HTTP client, you can perform health checks to monitor the status of your EdgeDB instance. Learn how to
use them with our _health checks guide_.

## 4.2.4 Fly.io

```
edb-alt-title Deploying EdgeDB to Fly.io
```
In this guide we show how to deploy EdgeDB using a Fly.io PostgreSQL cluster as the backend. The deployment
consists of two apps: one running Postgres and the other running EdgeDB.

**Note:** At the moment, it isn’t possible to expose Fly-hosted EdgeDB instances to the public internet, only internally
to other Fly projects. As such your application must also be hosted on Fly.

**298 Chapter 4. Guides**


### 4.2.4.1 Prerequisites

- Fly.io account
- flyctlCLI (install)

### 4.2.4.2 Provision a Fly.io app for EdgeDB

Every Fly.io app must have a globally unique name, including service VMs like Postgres and EdgeDB. Pick a name
and assign it to a local environment variable calledEDB_APP. In the command below, replacemyorg-edgedbwith a
name of your choosing.

$ EDB_APP=myorg-edgedb
$ flyctl apps create --name $EDB_APP
New app created: myorg-edgedb

Now let’s use thereadcommand to securely assign a value to thePASSWORDenvironment variable.

$ echo -n "> " && read -s PASSWORD

Now let’s assign this password to a Fly secret, plus a few other secrets that we’ll need. There are a couple more
environment variables we need to set:

$ flyctl secrets set \
EDGEDB_PASSWORD="$PASSWORD" \
EDGEDB_SERVER_BACKEND_DSN_ENV=DATABASE_URL \
EDGEDB_SERVER_TLS_CERT_MODE=generate_self_signed \
EDGEDB_SERVER_PORT=8080 \
--app $EDB_APP
Secrets are staged for the first deployment

Let’s discuss what’s going on with all these secrets.

- TheEDGEDB_SERVER_BACKEND_DSN_ENVtells the EdgeDB container where to look for the PostgreSQL con-
    nection string (more on that below)
- TheEDGEDB_SERVER_TLS_CERT_MODEtells EdgeDB to auto-generate a self-signed TLS certificate.
    You may instead choose to provision a custom TLS certificate. In this case, you should instead create two other se-
    crets: assign your certificate toEDGEDB_SERVER_TLS_CERTand your private key toEDGEDB_SERVER_TLS_KEY.
- Lastly,EDGEDB_SERVER_PORTtells EdgeDB to listen on port 8080 instead of the default 5656, because Fly.io
    prefers 8080 for its default health checks.

Finally, let’s scale the VM as EdgeDB requires a little bit more than the default Fly.io VM side provides:

$ flyctl scale vm shared-cpu-1x --memory=1024 --app $EDB_APP
Scaled VM Type to
shared-cpu-1x
CPU Cores: 1
Memory: 1 GB

**4.2. Deployment 299**


### 4.2.4.3 Create a PostgreSQL cluster

Now we need to provision a PostgreSQL cluster and attach it to the EdgeDB app.

**Note:** If you have an existing PostgreSQL cluster in your Fly.io organization, you can skip to the attachment step.

Then create a new PostgreSQL cluster. This may take a few minutes to complete.

$ PG_APP=myorg-postgres
$ flyctl pg create --name $PG_APP --vm-size shared-cpu-1x
? Select region: sea (Seattle, Washington (US))
? Specify the initial cluster size: 1
? Volume size (GB): 10
Creating postgres cluster myorg-postgres in organization personal
Postgres cluster myorg-postgres created
Username: postgres
Password: <random password>
Hostname: myorg-postgres.internal
Proxy Port: 5432
PG Port: 5433
Save your credentials in a secure place, you won't be able to see them
again!
Monitoring Deployment
...
--> v0 deployed successfully

In the output, you’ll notice a line that saysMachine <machine-id> is created. The ID in that line is the ID
of the virtual machine created for your Postgres cluster. We now need to use that ID to scale the cluster since the
shared-cpu-1xVM doesn’t have enough memory by default. Scale it with this command:

$ flyctl machine update <machine-id> --memory 512 --app $PG_APP -y
Searching for image 'flyio/postgres:14.6' remotely...
image found: img_0lq747j0ym646x35
Image: registry-1.docker.io/flyio/postgres:14.6
Image size: 361 MB

Updating machine <machine-id>
Waiting for <machine-id> to become healthy (started, 3/3)
Machine <machine-id> updated successfully!
==> Monitoring health checks
Waiting for <machine-id> to become healthy (started, 3/3)
...

With the VM scaled sufficiently, we can now attach the PostgreSQL cluster to the EdgeDB app:

$ PG_ROLE=myorg_edgedb
$ flyctl pg attach "$PG_APP" \
--database-user "$PG_ROLE" \
--app $EDB_APP
Postgres cluster myorg-postgres is now attached to myorg-edgedb
The following secret was added to myorg-edgedb:
DATABASE_URL=postgres://...

**300 Chapter 4. Guides**


Lastly, EdgeDB needs the ability to create Postgres databases and roles, so let’s adjust the permissions on the role that
EdgeDB will use to connect to Postgres:

$ echo "alter role \"$PG_ROLE\" createrole createdb; \quit" \
| flyctl pg connect --app $PG_APP

ALTER ROLE

### 4.2.4.4 Start EdgeDB

Everything is set! Time to start EdgeDB.

$ flyctl deploy --image=edgedb/edgedb \
--remote-only --app $EDB_APP

1 desired, 1 placed, 1 healthy, 0 unhealthy
--> v0 deployed successfully

That’s it! You can now start using the EdgeDB instance located atedgedb://myorg-edgedb.internalin your
Fly.io apps.

If deploy did not succeed:

1. make sure you’ve scaled the EdgeDB VM
2. re-run thedeploycommand
3. check the logs for more information:flyctl logs --app $EDB_APP

### 4.2.4.5 Persist the generated TLS certificate

Now we need to persist the auto-generated TLS certificate to make sure it survives EdgeDB app restarts. (If you’ve
provided your own certificate, skip this step).

$ EDB_SECRETS="EDGEDB_SERVER_TLS_KEY EDGEDB_SERVER_TLS_CERT"
$ flyctl ssh console --app $EDB_APP -C \
"edgedb-show-secrets.sh --format=toml $EDB_SECRETS" \
| tr -d'\r'| flyctl secrets import --app $EDB_APP

### 4.2.4.6 Connecting to the instance

Let’s construct the DSN (AKA “connection string”) for our instance. DSNs have the following format:edgedb://
<username>:<password>@<hostname>:<port>. We can construct the DSN with the following components:

- <username>: the default value —edgedb
- <password>: the value we assigned to$PASSWORD
- <hostname>: the name of your EdgeDB app (stored in the$EDB_APPenvironment variable) suffixed with.
    internal. Fly uses this synthetic TLD to simplify inter-app communication. Ex:myorg-edgedb.internal.
- <port>: 8080 , which we configured earlier

We can construct this value and assign it to a new environment variable calledDSN.

**4.2. Deployment 301**


$ DSN=edgedb://edgedb:$PASSWORD@$EDB_APP.internal:8080

Consider writing it to a file to ensure the DSN looks correct. Remember to delete the file after you’re done. (Printing
this value to the terminal withechois insecure and can leak your password into shell logs.)

$ echo $DSN > dsn.txt
$ open dsn.txt
$ rm dsn.txt

#### 4.2.4.6.1 From a Fly.io app

To connect to this instance from another Fly app (say, an app that runs your API server) set the value of theEDGEDB_DSN
secret inside that app.

$ flyctl secrets set \
EDGEDB_DSN=$DSN \
--app my-other-fly-app

We’ll also set another variable that will disable EdgeDB’s TLS checks. Inter-application communication is secured by
Fly so TLS isn’t vital in this case; configuring TLS certificates is also beyond the scope of this guide.

$ flyctl secrets set EDGEDB_CLIENT_TLS_SECURITY=insecure \
--app my-other-fly-app

You can also set these values as environment variables inside yourfly.tomlfile, but using Fly’s built-in secrets
functionality is recommended.

#### 4.2.4.6.2 From external application

If you need to access EdgeDB from outside the Fly.io network, you’ll need to configure the Fly.io proxy to let external
connections in.

First, save the EdgeDB app config in an **empty directory** :

$ flyctl config save -a $EDB_APP

Afly.tomlfile will be created upon result. Let’s make sure our[[services]]section looks something like this:

[[services]]
http_checks = []
internal_port = 8080
processes = ["app"]
protocol = "tcp"
script_checks = []
[services.concurrency]
hard_limit = 25
soft_limit = 20
type = "connections"

```
[[services.ports]]
port = 5656
```
```
(continues on next page)
```
**302 Chapter 4. Guides**


```
(continued from previous page)
[[services.tcp_checks]]
grace_period = "1s"
interval = "15s"
restart_limit = 0
timeout = "2s"
```
In the same directory, _redeploy the EdgeDB app_. This makes the EdgeDB port available to the outside world. You can
now access the instance from any host via the following public DSN:edgedb://edgedb:$PASSWORD@$EDB_APP.
fly.dev.

To secure communication between the server and the client, you will also need to set theEDGEDB_TLS_CAenvironment
secret in your application. You can securely obtain the certificate content by running:

$ flyctl ssh console -a $EDB_APP \
-C "edgedb-show-secrets.sh --format=raw EDGEDB_SERVER_TLS_CERT"

#### 4.2.4.6.3 From your local machine

To access the EdgeDB instance from local development machine/laptop, install the Wireguard VPN and create a tunnel,
as described on Fly’s Private Networking docs.

Once it’s up and running, useedgedb instance linkto create a local alias to the remote instance.

$ edgedb instance link \
--trust-tls-cert \
--dsn $DSN \
--non-interactive \
fly
Authenticating to edgedb://edgedb@myorg-edgedb.internal:5656/edgedb
Successfully linked to remote instance. To connect run:
edgedb -I fly

You can now run CLI commands against this instance by specifying it by name with-I fly; for example, to apply
migrations:

**Note:** The command groupsedgedb instanceandedgedb projectare not intended to manage production in-
stances.

$ edgedb -I fly migrate

### 4.2.4.7 Health Checks

Using an HTTP client, you can perform health checks to monitor the status of your EdgeDB instance. Learn how to
use them with our _health checks guide_.

**4.2. Deployment 303**


## 4.2.5 Google Cloud

```
edb-alt-title Deploying EdgeDB to Google Cloud
```
In this guide we show how to deploy EdgeDB on GCP using Cloud SQL and Kubernetes.

### 4.2.5.1 Prerequisites

- Google Cloud account with billing enabled (or a free trial)
- gcloudCLI (install)
- kubectlCLI (install)

Make sure you are logged into Google Cloud.

$ gcloud init

### 4.2.5.2 Create a project

Set thePROJECTenvironment variable to the project name you’d like to use. Google Cloud only allow letters, numbers,
and hyphens.

$ PROJECT=edgedb

Then create a project with this name. Skip this step if your project already exists.

$ gcloud projects create $PROJECT

Then enable the requisite APIs.

$ gcloud services enable \
container.googleapis.com \
sqladmin.googleapis.com \
iam.googleapis.com \
--project=$PROJECT

### 4.2.5.3 Provision a Postgres instance

Use thereadcommand to securely assign a value to thePASSWORDenvironment variable.

$ echo -n "> " && read -s PASSWORD

Then create a Cloud SQL instance and set the password.

$ gcloud sql instances create ${PROJECT}-postgres \
--database-version=POSTGRES_13 \
--cpu=1 \
--memory=3840MiB \
--region=us-west2 \
--project=$PROJECT
$ gcloud sql users set-password postgres \
--instance=${PROJECT}-postgres \
(continues on next page)

**304 Chapter 4. Guides**


```
(continued from previous page)
--password=$PASSWORD \
--project=$PROJECT
```
### 4.2.5.4 Create a Kubernetes cluster

Create an empty Kubernetes cluster inside your project.

$ gcloud container clusters create ${PROJECT}-k8s \
--zone=us-west2-a \
--num-nodes=1 \
--project=$PROJECT

### 4.2.5.5 Configure service account

Create a new service account, configure its permissions, and generate acredentials.jsonfile.

$ gcloud iam service-accounts create ${PROJECT}-account \
--project=$PROJECT

$ MEMBER="${PROJECT}-account@${PROJECT}.iam.gserviceaccount.com"
$ gcloud projects add-iam-policy-binding $PROJECT \
--member=serviceAccount:${MEMBER} \
--role=roles/cloudsql.admin \
--project=$PROJECT

$ gcloud iam service-accounts keys create credentials.json \
--iam-account=${MEMBER}

Then use thiscredentials.jsonto authenticate the Kubernetes CLI toolkubectl.

$ kubectl create secret generic cloudsql-instance-credentials \
--from-file=credentials.json=credentials.json

$ INSTANCE_CONNECTION_NAME=$(
gcloud sql instances describe ${PROJECT}-postgres \
--format="value(connectionName)" \
--project=$PROJECT
)

$ DSN="postgresql://postgres:${PASSWORD}@127.0.0.1:5432"
$ kubectl create secret generic cloudsql-db-credentials \
--from-literal=dsn=$DSN \
--from-literal=password=$PASSWORD \
--from-literal=instance=${INSTANCE_CONNECTION_NAME}=tcp:5432

**4.2. Deployment 305**


### 4.2.5.6 Deploy EdgeDB

Download the starter EdgeDB Kubernetes configuration file. This file specifies a persistent volume, a container running
a Cloud SQL authorization proxy, and a container to run EdgeDB itself. It relies on the secrets we declared in the
previous step.

$ wget "https://raw.githubusercontent.com\
/edgedb/edgedb-deploy/dev/gcp/deployment.yaml"

$ kubectl apply -f deployment.yaml

Ensure the pods are running.

$ kubectl get pods
NAME READY STATUS RESTARTS AGE
edgedb-977b8fdf6-jswlw 0/2 ContainerCreating 0 16s

TheREADY 0/2tells us neither of the two pods have finished booting. Re-run the command until2/2pods areREADY.

If there were errors you can check EdgeDB’s logs with:

$ kubectl logs deployment/edgedb --container edgedb

### 4.2.5.7 Persist TLS Certificate

Now that our EdgeDB instance is up and running, we need to download a local copy of its self-signed TLS certificate
(which it generated on startup) and pass it as a secret into Kubernetes. Then we’ll redeploy the pods.

$ kubectl create secret generic cloudsql-tls-credentials \
--from-literal=tlskey="$(
kubectl exec deploy/edgedb -c=edgedb -- \
edgedb-show-secrets.sh --format=raw EDGEDB_SERVER_TLS_KEY
)" \
--from-literal=tlscert="$(
kubectl exec deploy/edgedb -c=edgedb -- \
edgedb-show-secrets.sh --format=raw EDGEDB_SERVER_TLS_CERT
)"

$ kubectl delete -f deployment.yaml

$ kubectl apply -f deployment.yaml

### 4.2.5.8 Expose EdgeDB

$ kubectl expose deploy/edgedb --type LoadBalancer

**306 Chapter 4. Guides**


### 4.2.5.9 Get your instance’s DSN

Get the public-facing IP address of your database.

$ kubectl get service
NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S)
edgedb LoadBalancer <ip> <ip> 5656:30841/TCP

Copy and paste theEXTERNAL-IPassociated with the service namededgedb. With this IP address, you can construct
your instance’s _DSN_ :

$ EDGEDB_IP=<copy IP address here>
$ EDGEDB_DSN="edgedb://edgedb:${PASSWORD}@${EDGEDB_IP}"

To print the final DSN, you canechoit. Note that you should only run this command on a computer you trust, like a
personal laptop or sandboxed environment.

$ echo $EDGEDB_DSN

The resuling DSN can be used to connect to your instance. To test it, try opening a REPL:

$ edgedb --dsn $EDGEDB_DSN --tls-security insecure
EdgeDB 2.x (repl 2.x)
Type \help for help, \quit to quit.
edgedb> select "hello world!";

#### 4.2.5.9.1 In development

To make this instance easier to work with during local development, create an alias usingedgedb instance link.

**Note:** The command groupsedgedb instanceandedgedb projectare not intended to manage production in-
stances.

$ echo $PASSWORD | edgedb instance link \
--dsn $EDGEDB_DSN \
--password-from-stdin \
--non-interactive \
--trust-tls-cert \
gcp_instance

You can now refer to the remote instance using the alias instance on your machine calledgcp_instance. You can use
this alias wherever an instance name is expected; for instance, you can open a REPL:

$ edgedb -I gcp_instance

Or apply migrations:

$ edgedb -I gcp_instance migrate

**4.2. Deployment 307**


#### 4.2.5.9.2 In production

To connect to this instance in production, set theEDGEDB_DSNenvironment variable wherever you deploy your appli-
cation server; EdgeDB’s client libraries read the value of this variable to know how to connect to your instance.

### 4.2.5.10 Health Checks

Using an HTTP client, you can perform health checks to monitor the status of your EdgeDB instance. Learn how to
use them with our _health checks guide_.

## 4.2.6 Heroku

```
edb-alt-title Deploying EdgeDB to Heroku
```
```
Warning: Deployment to Heroku is currently not working due to a change in Heroku’s Postgres extension schema.
We plan to implement changes to address this and will update this guide to remove this warning once we have done
so. See the relevant Github issue for more information or to subscribe to notifications.
```
In this guide we show how to deploy EdgeDB to Heroku using a Heroku PostgreSQL add-on as the backend.

Because of Heroku’s architecture EdgeDB must be deployed with a web app on Heroku. For this guide we will use a
todo app written in Node.

### 4.2.6.1 Prerequisites

- Heroku account
- herokuCLI (install)
- Node.js (install)

### 4.2.6.2 Setup

First copy the code, initialize a new git repo, and create a new heroku app.

$ npx degit'edgedb/simpletodo#main' simpletodo-heroku
$ cd simpletodo-heroku
$ git init --initial-branch main
$ heroku apps:create --buildpack heroku/nodejs
$ edgedb project init --non-interactive

If you are using the JS query builder for EdgeDB then you will need to check thedbschema/edgeql-jsdirectory in
to your git repo after runningyarn edgeql-js. Theedgeql-jscommand cannot be run during the build step on
Heroku because it needs access to a running EdgeDB instance which is not available at build time on Heroku.

$ yarn install && npx @edgedb/generate edgeql-js

Thedbschema/edgeql-jsdirectory was added to the.gitignorein the upstream project so we’ll remove it here.

$ sed -i'/^dbschema\/edgeql-js$/d'.gitignore

**308 Chapter 4. Guides**


### 4.2.6.3 Create a PostgreSQL Add-on

Heroku’s smallest PostgreSQL plan, Hobby Dev, limits the number of rows to 10,000, but EdgeDB’s standard library
uses more than 20,000 rows so we need to use a different plan. We’ll use the Standard 0 plan for this guide.

$ heroku addons:create heroku-postgresql:standard-0

### 4.2.6.4 Add the EdgeDB Buildpack

To run EdgeDB on Heroku we’ll add the EdgeDB buildpack.

$ heroku buildpacks:add \
--index 1 \
https://github.com/edgedb/heroku-buildpack-edgedb.git

### 4.2.6.5 Usestart-edgedbin the Procfile

To make EdgeDB available to a process prepend the command withstart-edgedbwhich is provided by the EdgeDB
buildpack. For the sample application in this guide, the web process is started with the commandnpm start. If you
have other processes in your application besides/instead of web that need to access EdgeDB those process commands
should be prepended withstart-edgedbtoo.

$ echo "web: start-edgedb npm start" > Procfile

#### 4.2.6.6 Deploy the App

Commit the changes and push to Heroku to deploy the app.

$ git add.
$ git commit -m "first commit"
$ git push heroku main

#### 4.2.6.7 Health Checks

Using an HTTP client, you can perform health checks to monitor the status of your EdgeDB instance. Learn how to
use them with our _health checks guide_.

### 4.2.7 Docker

```
edb-alt-title Deploying EdgeDB with Docker
```
**4.2. Deployment 309**


#### 4.2.7.1 When to use the edgedb/edgedb Docker image

This image is primarily intended to be used directly when there is a requirement to use Docker containers, such as in
production, or in a development setup that involves multiple containers orchestrated by Docker Compose or a similar
tool. Otherwise, using the _edgedb server_ CLI on the host system is the recommended way to install and run EdgeDB
servers.

#### 4.2.7.2 How to use this image

The simplest way to run the image (without data persistence) is this:

$ docker run --name edgedb -d \
-e EDGEDB_SERVER_SECURITY=insecure_dev_mode \
edgedb/edgedb

See the _Configuration_ section below for the meaning of theEDGEDB_SERVER_SECURITYvariable and other options.

Then, to authenticate to the EdgeDB instance and store the credentials in a Docker volume, run:

$ docker run -it --rm --link=edgedb \
-e EDGEDB_SERVER_PASSWORD=secret \
-v edgedb-cli-config:/.config/edgedb edgedb/edgedb-cli \
-H edgedb instance link my_instance

Now, to open an interactive shell to the database instance run this:

$ docker run -it --rm --link=edgedb \
-v edgedb-cli-config:/.config/edgedb edgedb/edgedb-cli \
-I my_instance

#### 4.2.7.3 Data Persistence

If you want the contents of the database to survive container restarts, you must mount a persistent volume at the path
specified byEDGEDB_SERVER_DATADIR(/var/lib/edgedb/databy default). For example:

$ docker run \
--name edgedb \
-e EDGEDB_SERVER_PASSWORD=secret \
-e EDGEDB_SERVER_TLS_CERT_MODE=generate_self_signed \
-v /my/data/directory:/var/lib/edgedb/data \
-d edgedb/edgedb

Note that on Windows you must use a Docker volume instead:

$ docker volume create --name=edgedb-data
$ docker run \
--name edgedb \
-e EDGEDB_SERVER_PASSWORD=secret \
-e EDGEDB_SERVER_TLS_CERT_MODE=generate_self_signed \
-v edgedb-data:/var/lib/edgedb/data \
-d edgedb/edgedb

It is also possible to run an edgedb container on a remote PostgreSQL cluster specified by
EDGEDB_SERVER_BACKEND_DSN. See below for details.

**310 Chapter 4. Guides**


#### 4.2.7.4 Schema Migrations

A derived image may include application schema and migrations in/dbschema, in which case the container will attempt
to apply the schema migrations found in/dbschema/migrations, unless theEDGEDB_DOCKER_APPLY_MIGRATIONS
environment variable is set tonever.

#### 4.2.7.5 Docker Compose

A simpledocker-composeconfiguration might look like this. With adocker-compose.yamlcontaining:

version: "3"
services:
edgedb:
image: edgedb/edgedb
environment:
EDGEDB_SERVER_SECURITY: insecure_dev_mode
volumes:

- "./dbschema:/dbschema"
ports:
- "5656:5656"

Once there is a _schema_ indbschema/a migration can be created with:

$ edgedb --tls-security=insecure -P 5656 migration create

Alternatively, if you don’t have the EdgeDB CLI installed on your host machine, you can use the CLI bundled with the
server container:

$ docker-compose exec edgedb edgedb --tls-security=insecure migration create

#### 4.2.7.6 Configuration

The Docker image supports the same set of enviroment variables as the EdgeDB server process, which are documented
under _Reference > Environment Variables_.

EdgeDB containers can be additionally configured using initialization scripts and some Docker-specific environment
variables, documented below.

**Note:** Seme variables support_ENVand_FILE _variants_ to support more advanced configurations.

##### 4.2.7.6.1 Initial configuration

When an EdgeDB container starts on the specified data directory or remote Postgres cluster for the first time, initial
instance setup is performed. This is called the _bootstrap phase_.

The following environment variables affect the bootstrap only and have no effect on subsequent container runs.

**4.2. Deployment 311**


**EDGEDB_SERVER_BOOTSTRAP_COMMAND**

Useful to fine-tune initial user and database creation, and other initial setup. If neither the
EDGEDB_SERVER_BOOTSTRAP_COMMAND variable or the EDGEDB_SERVER_BOOTSTRAP_SCRIPT_FILE are ex-
plicitly specified, the container will look for the presence of/edgedb-bootstrap.edgeqlin the container (which
can be placed in a derived image).

Maps directly to theedgedb-serverflag--default-auth-method. The*_FILEand*_ENVvariants are also sup-
ported.

**EDGEDB_SERVER_BOOTSTRAP_SCRIPT_FILE**

Deprecated in image version 2.8: useEDGEDB_SERVER_BOOTSTRAP_COMMAND_FILEinstead.

Run the script when initializing the database. The script is run by default user within default database.

**EDGEDB_SERVER_PASSWORD**

The password for the default superuser account will be set to this value. If no value is provided a password will not be
set, unless set viaEDGEDB_SERVER_BOOTSTRAP_COMMAND. (If a value forEDGEDB_SERVER_BOOTSTRAP_COMMANDis
provided, this variable will be ignored.)

The*_FILEand*_ENVvariants are also supported.

**EDGEDB_SERVER_PASSWORD_HASH**

A variant ofEDGEDB_SERVER_PASSWORD, where the specified value is a hashed password verifier instead of plain text.

IfEDGEDB_SERVER_BOOTSTRAP_COMMANDis set, this variable will be ignored.

The*_FILEand*_ENVvariants are also supported.

**EDGEDB_SERVER_GENERATE_SELF_SIGNED_CERT**

```
Warning: Deprecated: useEDGEDB_SERVER_TLS_CERT_MODE=generate_self_signedinstead.
```
Set this option to 1 to tell the server to automatically generate a self-signed certificate with key file in the
EDGEDB_SERVER_DATADIR(if present, see below), and echo the certificate content in the logs. If the certificate file
exists, the server will use it instead of generating a new one.

Self-signed certificates are usually used in development and testing, you should likely provide your own certificate and
key file with the variables below.

**312 Chapter 4. Guides**


**EDGEDB_SERVER_TLS_CERT/EDGEDB_SERVER_TLS_KEY**

The TLS certificate and private key data, exclusive withEDGEDB_SERVER_TLS_CERT_MODE=generate_self_signed.

The*_FILEand*_ENVvariants are also supported.

**Custom scripts in** /docker-entrypoint.d/

To perform additional initialization, a derived image may include one or more executable files in /
docker-entrypoint.d/, which will get executed by the container entrypoint _before_ any other processing takes place.

##### 4.2.7.6.2 Runtime configuration

**EDGEDB_DOCKER_LOG_LEVEL**

Determines the log verbosity level in the entrypoint script. Valid levels aretrace,debug,info,warning, anderror.
The default isinfo.

**Custom scripts in** /edgedb-bootstrap.d/ **and** /edgedb-bootstrap-late.d

To perform additional initialization, a derived image may include one or more*.edgeqlor*.shscripts, which
are executed in addition to and _after_ the initialization specified by the environment variables above or the/
edgedb-bootstrap.edgeqlscript. Parts in/edgedb-bootstrap.dare executed _before_ any schema migrations
are applied, and parts in/edgedb-bootstrap-late.dare executed _after_ the schema migration have been applied.

#### 4.2.7.7 Health Checks

Using an HTTP client, you can perform health checks to monitor the status of your EdgeDB instance. Learn how to
use them with our _health checks guide_.

### 4.2.8 Bare Metal

```
edb-alt-title Deploying EdgeDB to a Bare Metal Server
```
In this guide we show how to deploy EdgeDB to bare metal using your system’s package manager and systemd.

#### 4.2.8.1 Install the EdgeDB Package

The steps for installing the EdgeDB package will be slightly different depending on your Linux distribution. Once you
have the package installed you can jump to _Enable a systemd unit_.

**4.2. Deployment 313**


##### 4.2.8.1.1 Debian/Ubuntu LTS

Import the EdgeDB packaging key.

$ sudo mkdir -p /usr/local/share/keyrings && \
sudo curl --proto'=https'--tlsv1.2 -sSf \
-o /usr/local/share/keyrings/edgedb-keyring.gpg \
https://packages.edgedb.com/keys/edgedb-keyring.gpg

Add the EdgeDB package repository.

$ echo deb [signed-by=/usr/local/share/keyrings/edgedb-keyring.gpg] \
https://packages.edgedb.com/apt \
$(grep "VERSION_CODENAME=" /etc/os-release | cut -d= -f2) main \
| sudo tee /etc/apt/sources.list.d/edgedb.list

Install the EdgeDB package.

$ sudo apt-get update && sudo apt-get install edgedb-2

##### 4.2.8.1.2 CentOS/RHEL 7/8

Add the EdgeDB package repository.

$ sudo curl --proto '=https' --tlsv1.2 -sSfL \
https://packages.edgedb.com/rpm/edgedb-rhel.repo \
> /etc/yum.repos.d/edgedb.repo

Install the EdgeDB package.

$ sudo yum install edgedb-2

#### 4.2.8.2 Enable a systemd unit

The EdgeDB package comes bundled with a systemd unit that is disabled by default. You can start the server by enabling
the unit.

$ sudo systemctl enable --now edgedb-server-2

This will start the server on port 5656, and the data directory will be/var/lib/edgedb/1/data.

```
Warning: edgedb-servercannot be run as root.
```
**314 Chapter 4. Guides**


#### 4.2.8.3 Set environment variables

To set environment variables when running EdgeDB withsystemctl,

$ systemctl edit --full edgedb-server-2

This opens asystemdunit file. Set the desired environment variables under the[Service]section. View the sup-
ported environment variables at _Reference > Environment Variables_.

[Service]
Environment="EDGEDB_SERVER_TLS_CERT_MODE=generate_self_signed"
Environment="EDGEDB_SERVER_ADMIN_UI=enabled"

Save the file and exit, then restart the service.

$ systemctl restart edgedb-server-2

#### 4.2.8.4 Set a password

There is no default password. Set a password by connecting from localhost.

$ echo -n "> " && read -s PASSWORD
$ sudo edgedb --port 5656 --tls-security insecure --admin query \
"ALTER ROLE edgedb SET password :='$PASSWORD'"

The server listens on localhost by default. Changing this looks like this.

$ edgedb --port 5656 --tls-security insecure --password query \
"CONFIGURE INSTANCE SET listen_addresses := {'0.0.0.0'};"

The listen port can be changed from the default 5656 if your deployment scenario requires a different value.

$ edgedb --port 5656 --tls-security insecure --password query \
"CONFIGURE INSTANCE SET listen_port := 1234;"

You may need to restart the server after changing the listen port or addresses.

$ sudo systemctl restart edgedb-server-2

#### 4.2.8.5 Link the instance with the CLI

The following is an example of linking a bare metal instance that is running onlocalhost. This command assigns a
name to the instance, to make it more convenient to refer to when running CLI commands.

$ edgedb instance link \
--host localhost \
--port 5656 \
--user edgedb \
--database edgedb \
--trust-tls-cert \
bare_metal_instance

This allows connecting to the instance with its name.

**4.2. Deployment 315**


$ edgedb -I bare_metal_instance

#### 4.2.8.6 Upgrading EdgeDB

**Note:** The command groupsedgedb instanceandedgedb projectare not intended to manage production in-
stances.

When you want to upgrade to the newest point release upgrade the package and restart theedgedb-server-2unit.

##### 4.2.8.6.1 Debian/Ubuntu LTS

$ sudo apt-get update && sudo apt-get install --only-upgrade edgedb-2
$ sudo systemctl restart edgedb-server-2

##### 4.2.8.6.2 CentOS/RHEL 7/8

$ sudo yum update edgedb-2
$ sudo systemctl restart edgedb-server-2

#### 4.2.8.7 Health Checks

Using an HTTP client, you can perform health checks to monitor the status of your EdgeDB instance. Learn how to
use them with our _health checks guide_.

### 4.2.9 Health Checks

You may want to monitor the status of your EdgeDB instance. Is it up? Is it ready to take queries? This guide will
show you to perform health checks using HTTP and thealiveandreadyendpoints.

#### 4.2.9.1 Check Instance Aliveness

To check if the instance is alive, make a request to this endpoint:

[http://<hostname>:<port>/server/status/alive](http://<hostname>:<port>/server/status/alive)

To find your<port>, you can runedgedb instance listto see a table of all your instances along with their port
numbers.

The endpoint will respond with a 200 status code and"OK"as the payload if the server is alive. If not, you will receive
a50xcode or a network error.

**316 Chapter 4. Guides**


#### 4.2.9.2 Check Instance Readiness

To check if the instance is ready, make a request to this endpoint:

[http://<hostname>:<port>/server/status/ready](http://<hostname>:<port>/server/status/ready)

As with thealiveendpoint, you can find your<port>by runningedgedb instance listto see a table of all your
instances along with their port numbers.

The endpoint will respond with a 200 status code and"OK"as the payload if the server is ready. If not, you will receive
a50xcode or a network error.

## 4.3 Migration Patterns

### 4.3.1 Making a property required

This example shows how a property may evolve to be more and more strict over time by looking at a user name field.
However, similar evolution may be applicable to other properties that start off with few restrictions and gradually
become more constrained and formalized as the needs of the project evolve.

We’ll start with a fairly simple schema:

typeUser {
property name -> str;
}

typeUser {
name: str;
}

At this stage we don’t think that this property needs to be unique or even required. Perhaps it’s only used as a screen
name and not as a way of identifying users.

$ edgedb migration create
did you create object type'default::User'? [y,n,l,c,b,s,q,?]
> y
Created ./dbschema/migrations/00001.edgeql, id:
m14gwyorqqipfg7riexvbdq5dhgv7x6buqw2jaaulilcmywinmakzq
$ edgedb migrate
Applied m14gwyorqqipfg7riexvbdq5dhgv7x6buqw2jaaulilcmywinmakzq
(00001.edgeql)

We’ve got our first migration to set up the schema. Now after using that for a little while we realize that we want to
makenamea _required property_. So we make the following change in the schema file:

typeUser {
required property name -> str;
}

typeUser {
required name: str;
}

**4.3. Migration Patterns 317**


Next we try to migrate:

$ edgedb migration create
did you make property'name' of object type'default::User' required?
[y,n,l,c,b,s,q,?]
> y
Please specify an expression to populate existing objects in order to make
property'name' of object type'default::User' required:
fill_expr> 'change me'

Oh! That’s right, we can’t just makename _required_ because there could be existingUserobjects without anameat
all. So we need to provide some kind of placeholder value for those cases. We type'change me'(although any other
string would do, too). This is different from specifying adefaultvalue since it will be applied to _existing_ objects,
whereas thedefaultapplies to _new ones_. We then run _edgedb migrate_ to apply the changes.

Next we realize that we actually want to make names unique, perhaps to avoid confusion or to use them as reliable
human-readable identifiers (unlikeid). We update the schema again:

typeUser {
required property name -> str {
constraintexclusive;
}
}

typeUser {
required name: str {
constraintexclusive;
}
}

Now we proceed with the migration:

$ edgedb migration create
did you create constraint'std::exclusive' of property'name'?
[y,n,l,c,b,s,q,?]
> y
Created ./dbschema/migrations/00003.edgeql, id:
m1dxs3xbk4f3vhmqh6mjzetojafddtwlphp5a3kfbfuyvupjafevya
$ edgedb migrate
edgedb error: ConstraintViolationError: name violates exclusivity
constraint

Some objects must have the samename, so the migration can’t be applied. We have a couple of options for fixing this:

```
1) Review the existing data and manuallyupdatethe entries with duplicate names so that they are unique.
2) Edit the migration to add anupdatewhich will de-duplicatenamefor any potential existingUserobjects.
```
The first option is good for situations where we want to signal to any other maintainer of a copy of this project that they
need to make a decision about handling name duplicates in whatever way is appropriate to them without making an
implicit decision once and for all.

Here we will go with the second option, which is good for situations where we know enough about the situation that
we can make a decision now and never have to duplicate this effort for any other potential copies of our project.

We edit the last migration file00003.edgeql:

**318 Chapter 4. Guides**


CREATE MIGRATION m1dxs3xbk4f3vhmqh6mjzetojafddtwlphp5a3kfbfuyvupjafevya
ONTO m1ndhbxx7yudb2dv7zpypl2su2oygyjlggk3olryb5uszofrfml4uq
{
+ with U := default::User
+ update default::User
+ filter U.name = .name and U != default::User
+ set {
+ # De-duplicate names by appending a random uuid.
+ name := .name ++'_'++ <str>uuid_generate_v1mc()
+ };
+
ALTER TYPE default::User {
ALTER PROPERTY name {
CREATE CONSTRAINT std::exclusive;
};
};
};

And then we apply the migration:

$ edgedb migrate
edgedb error: could not read migrations in ./dbschema/migrations: could not
read migration file ./dbschema/migrations/00003.edgeql: migration name
should be`m1t6slgcfne35vir2lcgnqkmaxsxylzvn2hanr6mijbj5esefsp7za`but`
m1dxs3xbk4f3vhmqh6mjzetojafddtwlphp5a3kfbfuyvupjafevya` is used instead.
Migration names are computed from the hash of the migration contents. To
proceed you must fix the statement to read as:
CREATE MIGRATION m1t6slgcfne35vir2lcgnqkmaxsxylzvn2hanr6mijbj5esefsp7za
ONTO ...
if this migration is not applied to any database. Alternatively, revert the
changes to the file.

The migration tool detected that we’ve altered the file and asks us to update the migration name (acting as a checksum)
if this was deliberate. This is done as a precaution against accidental changes. Since we’ve done this on purpose, we
can update the file and run _edgedb migrate_ again.

Finally, we evolved our schema all the way from having an optional propertynameall the way to making it both _required_
and _exclusive_. We’ve worked with the EdgeDB _migration tools_ to iron out the kinks throughout the migration process.
At this point we take a quick look at the way duplicateUserobjects were resolved to decide whether we need to do
anything more. We can usere_test()to find names that look like they are ending in a UUID:

db>select User { name }
...filter
... re_test('.* [a-z0-9]{8}(-[a-z0-9]{4}){3}-[a-z0-9]{12}$', .name);
{
default::User {name:'change me bc30d45a-2bcf-11ec-a6c2-6ff21f33a302'},
default::User {name:'change me bc30d8a6-2bcf-11ec-a6c2-4f739d559598'},
}

Looks like the only duplicates are the users that had no names originally and that never updated the'change me'
placeholders, so we can probably let them be for now. In hindsight, it may have been a good idea to use UUID-based
names to populate the empty properties from the very beginning.

**4.3. Migration Patterns 319**


### 4.3.2 Adding backlinks

This example shows how to handle a schema that makes use of a backlink. We’ll use a linked-list structure to represent
a sequence of events.

We’ll start with this schema:

typeEvent {
required property name -> str;
link prev -> Event;

# ... more properties and links
}

typeEvent {
required name: str;
prev: Event;

# ... more properties and links
}

We specify aprevlink because that will make adding a newEventat the end of the chain easier, since we’ll be able
to specify the payload and the chain theEventshould be appended to in a singleinsert. Once we’ve updated the
schema file we proceed with our first migration:

$ edgedb migration create
did you create object type'default::Event'? [y,n,l,c,b,s,q,?]
> y
Created ./dbschema/migrations/00001.edgeql, id:
m1v3ahcx5f43y6mlsdmlz2agnf6msbc7rt3zstiqmezaqx4ev2qovq
$ edgedb migrate
Applied m1v3ahcx5f43y6mlsdmlz2agnf6msbc7rt3zstiqmezaqx4ev2qovq
(00001.edgeql)

We now have a way of chaining events together. We might create a few events like these:

db>select Event {
... name,
... prev: { name },
... };
{
default::Event {name: 'setup', prev: {}},
default::Event {name: 'work', prev: default::Event {name:'setup'}},
default::Event {name: 'cleanup', prev: default::Event {name:'work'}},
}

It seems like having anextlink would be useful, too. So we can define it as a computed link by using _backlink_ notation:

typeEvent {
required property name -> str;

link prev -> Event;
link next := .<prev[is Event];
}

**320 Chapter 4. Guides**


typeEvent {
required name: str;

prev: Event;
link next := .<prev[is Event];
}

The migration is straightforward enough:

$ edgedb migration create
did you create link 'next'of object type 'default::Event'?
[y,n,l,c,b,s,q,?]
> y
Created ./dbschema/migrations/00002.edgeql, id:
m1qpukyvw2m4lmomoseni7vdmevk4wzgsbviojacyrqgiyqjp5sdsa
$ edgedb migrate
Applied m1qpukyvw2m4lmomoseni7vdmevk4wzgsbviojacyrqgiyqjp5sdsa
(00002.edgeql)

Trying out the new link on our existing data gives us:

db>select Event {
... name,
... prev_name := .prev.name,
... next_name := .next.name,
... };
{
default::Event {
name:'setup',
prev_name: {},
next_name: {'work'},
},
default::Event {
name:'work',
prev_name:'setup',
next_name: {'cleanup'},
},
default::Event {
name:'cleanup',
prev_name:'work',
next_name: {},
},
}

That’s not quite right. The value ofnext_nameappears to be a set rather than a singleton. This is because the link
previs many-to-one and sonextis one-to-many, making it a _multi_ link. Let’s fix that by making the linkpreva
one-to-one, after all we’re interested in building event chains, not trees.

typeEvent {
required property name -> str;

```
link prev -> Event {
constraintexclusive;
(continues on next page)
```
**4.3. Migration Patterns 321**


(continued from previous page)
};
link next := .<prev[is Event];
}

typeEvent {
required name: str;

prev: Event {
constraintexclusive;
};
link next := .<prev[is Event];
}

Since thenextlink is computed, the migration should not need any additional user input even though we’re reducing
the link’s cardinality:

$ edgedb migration create
did you create constraint'std::exclusive' of link'prev'?
[y,n,l,c,b,s,q,?]
> y
Created ./dbschema/migrations/00003.edgeql, id:
m17or2bfywuckdqeornjmjh7c2voxgatspcewyefcd4p2vbdepimoa
$ edgedb migrate
Applied m17or2bfywuckdqeornjmjh7c2voxgatspcewyefcd4p2vbdepimoa
(00003.edgeql)

The newnextcomputed link is now inferred as asinglelink and so the query results fornext_nameandprev_name
are symmetrical:

db>select Event {
... name,
... prev_name := .prev.name,
... next_name := .next.name,
... };
{
default::Event {name: 'setup', prev_name: {}, next_name: 'work'},
default::Event {name: 'work', prev_name:'setup', next_name:'cleanup'},
default::Event {name: 'cleanup', prev_name:'work', next_name: {}},
}

### 4.3.3 Changing the type of a property

This example shows how to change the type of a property. We’ll use a character in an adventure game as the type of
data we will evolve.

Let’s start with this schema:

typeCharacter {
required property name -> str;
required property description -> str;
}

**322 Chapter 4. Guides**


typeCharacter {
required name: str;
required description: str;
}

We edit the schema file and perform our first migration:

$ edgedb migration create
did you create object type'default::Character'? [y,n,l,c,b,s,q,?]
> y
Created ./dbschema/migrations/00001.edgeql, id:
m1paw3ogpsdtxaoywd6pl6beg2g64zj4ykhd43zby4eqh64yjad47a
$ edgedb migrate
Applied m1paw3ogpsdtxaoywd6pl6beg2g64zj4ykhd43zby4eqh64yjad47a
(00001.edgeql)

The intent is for thedescriptionto provide some text which serves both as something to be shown to the player as
well as determining some game actions. Se we end up with something like this:

db>select Character {name, description};
{
default::Character {name:'Alice', description: 'Tall and strong'},
default::Character {name:'Billie', description: 'Smart and aloof'},
default::Character {name:'Cameron', description:'Dashing and smooth'},
}

However, as we keep developing our game it becomes apparent that this is less of a “description” and more of a
“character class”, so at first we just rename the property to reflect that:

typeCharacter {
required property name -> str;
required property class -> str;
}

typeCharacter {
required name: str;
required class: str;
}

The migration gives us this:

$ edgedb migration create
did you rename property 'description' of object type'default::Character'
to 'class'? [y,n,l,c,b,s,q,?]
> y
Created ./dbschema/migrations/00002.edgeql, id:
m1ljrgrofsqkvo5hsxc62mnztdhlerxp6ucdto262se6dinhuj4mqq
$ edgedb migrate
Applied m1ljrgrofsqkvo5hsxc62mnztdhlerxp6ucdto262se6dinhuj4mqq
(00002.edgeql)

EdgeDB detected that the change looked like a property was being renamed, which we confirmed. Since this was an
existing property being renamed, the data is all preserved:

**4.3. Migration Patterns 323**


db>select Character {name, class};
{
default::Character {name:'Alice', class:'Tall and strong'},
default::Character {name:'Billie', class:'Smart and aloof'},
default::Character {name:'Cameron', class:'Dashing and smooth'},
}

The contents of theclassproperty are a bit too verbose, so we decide to update them. In order for this update to be
consistently applied across several developers, we will make it in the form of a _data migration_ :

$ edgedb migration create --allow-empty
Created ./dbschema/migrations/00003.edgeql, id:
m1qv2pdksjxxzlnujfed4b6to2ppuodj3xqax4p3r75yfef7kd7jna

Now we can edit the file00003.edgeqldirectly:

CREATE MIGRATION m1qv2pdksjxxzlnujfed4b6to2ppuodj3xqax4p3r75yfef7kd7jna
ONTO m1ljrgrofsqkvo5hsxc62mnztdhlerxp6ucdto262se6dinhuj4mqq
{
+ update default::Character
+ set {
+ class :=
+ 'warrior' if .class ='Tall and strong'else
+ 'scholar' if .class ='Smart and aloof'else
+ 'rogue'
+ };
};

We’re ready to apply the migration:

$ edgedb migrate
edgedb error: could not read migrations in ./dbschema/migrations:
could not read migration file ./dbschema/migrations/00003.edgeql:
migration name should be
`m1ryafvp24g5eqjeu65zr4bqf6m3qath3lckfdhoecfncmr7zshehq`
but`m1qv2pdksjxxzlnujfed4b6to2ppuodj3xqax4p3r75yfef7kd7jna`is used
instead.
Migration names are computed from the hash of the migration
contents. To proceed you must fix the statement to read as:
CREATE MIGRATION m1ryafvp24g5eqjeu65zr4bqf6m3qath3lckfdhoecfncmr7zshehq
ONTO ...
if this migration is not applied to any database. Alternatively,
revert the changes to the file.

The migration tool detected that we’ve altered the file and asks us to update the migration name (acting as a checksum)
if this was deliberate. This is done as a precaution against accidental changes. Since we’ve done this on purpose, we
can update the file and run _edgedb migrate_ again.

As the game becomes more stable there’s no reason for theclassto be astranymore, instead we can use anenumto
make sure that we don’t accidentally use some invalid value for it.

scalar typeCharacterClassextending enum<warrior, scholar, rogue>;

typeCharacter {
(continues on next page)

**324 Chapter 4. Guides**


(continued from previous page)
required property name -> str;
required property class -> CharacterClass;
}

scalar typeCharacterClassextending enum<warrior, scholar, rogue>;

typeCharacter {
required name: str;
required class: CharacterClass;
}

Fortunately, we’ve already updated theclassstrings to match theenumvalues, so that a simple cast will convert all
the values. If we had not done this earlier we would need to do it now in order for the type change to work.

$ edgedb migration create
did you create scalar type'default::CharacterClass'? [y,n,l,c,b,s,q,?]
> y
did you alter the type of property'class' of object type
'default::Character'? [y,n,l,c,b,s,q,?]
> y
Created ./dbschema/migrations/00004.edgeql, id:
m1hc4yynkejef2hh7fvymvg3f26nmynpffksg7yvfksqufif6lulgq
$ edgedb migrate
Applied m1hc4yynkejef2hh7fvymvg3f26nmynpffksg7yvfksqufif6lulgq
(00004.edgeql)

The final migration converted all theclassproperty values:

db>select Character {name, class};
{
default::Character {name:'Alice', class: warrior},
default::Character {name:'Billie', class: scholar},
default::Character {name:'Cameron', class: rogue},
}

### 4.3.4 Changing a property to a link

This example shows how to change a property into a link. We’ll use a character in an adventure game as the type of
data we will evolve.

Let’s start with this schema:

scalar typeCharacterClassextending enum<warrior, scholar, rogue>;

typeCharacter {
required property name -> str;
required property class -> CharacterClass;
}

scalar typeCharacterClassextending enum<warrior, scholar, rogue>;

```
(continues on next page)
```
**4.3. Migration Patterns 325**


```
(continued from previous page)
```
typeCharacter {
required name: str;
required class: CharacterClass;
}

We edit the schema file and perform our first migration:

$ edgedb migration create
did you create scalar type'default::CharacterClass'? [y,n,l,c,b,s,q,?]
> y
did you create object type'default::Character'? [y,n,l,c,b,s,q,?]
> y
Created ./dbschema/migrations/00001.edgeql, id:
m1fg76t7fbvguwhkmzrx7jwki6jxr6dvkswzeepd5v66oxg27ymkcq
$ edgedb migrate
Applied m1fg76t7fbvguwhkmzrx7jwki6jxr6dvkswzeepd5v66oxg27ymkcq
(00001.edgeql)

The initial setup may look something like this:

db>select Character {name, class};
{
default::Character {name:'Alice', class: warrior},
default::Character {name:'Billie', class: scholar},
default::Character {name:'Cameron', class: rogue},
}

After some development work we decide to add more details about the available classes and encapsulate that information
into its own type. This way instead of a propertyclasswe want to end up with a linkclassto the new data structure.
Since we cannot justcasta scalar into an object, we’ll need to convert between the two explicitly. This means that we
will need to have both the old and the new “class” information to begin with:

scalar typeCharacterClassextending enum<warrior, scholar, rogue>;

typeNewClass {
required property name -> str;
multi property skills -> str;
}

typeCharacter {
required property name -> str;
required property class -> CharacterClass;
link new_class -> NewClass;
}

scalar typeCharacterClassextending enum<warrior, scholar, rogue>;

typeNewClass {
required name: str;
multi skills: str;
}

```
(continues on next page)
```
**326 Chapter 4. Guides**


```
(continued from previous page)
```
typeCharacter {
required name: str;
required class: CharacterClass;
new_class: NewClass;
}

We update the schema file and migrate to the new state:

$ edgedb migration create
did you create object type'default::NewClass'? [y,n,l,c,b,s,q,?]
> y
did you create link 'new_class'of object type 'default::Character'?
[y,n,l,c,b,s,q,?]
> y
Created ./dbschema/migrations/00002.edgeql, id:
m1uttd6f7fpiwiwikhdh6qyijb6pcji747ccg2cyt5357i3wsj3l3q
$ edgedb migrate
Applied m1uttd6f7fpiwiwikhdh6qyijb6pcji747ccg2cyt5357i3wsj3l3q
(00002.edgeql)

It makes sense to add a data migration as a way of consistently creatingNewClassobjects as well as populating
new_classlinks based on the existingclassproperty. So we first create an empty migration:

$ edgedb migration create --allow-empty
Created ./dbschema/migrations/00003.edgeql, id:
m1iztxroh3ifoeqmvxncy77whnaei6tp5j3sewyxtrfysronjkxgga

And then edit the00003.edgeqlfile to create and update objects:

CREATE MIGRATION m1iztxroh3ifoeqmvxncy77whnaei6tp5j3sewyxtrfysronjkxgga
ONTO m1uttd6f7fpiwiwikhdh6qyijb6pcji747ccg2cyt5357i3wsj3l3q
{
+ insert default::NewClass {
+ name :='Warrior',
+ skills := {'punch', 'kick', 'run','jump'},
+ };
+ insert default::NewClass {
+ name :='Scholar',
+ skills := {'read','write', 'analyze','refine'},
+ };
+ insert default::NewClass {
+ name :='Rogue',
+ skills := {'impress','sing','steal','run', 'jump'},
+ };
+
+ update default::Character
+ set {
+ new_class := assert_single((
+ select default::NewClass
+ filter .name ilike <str>default::Character.class
+ )),
+ };
};

**4.3. Migration Patterns 327**


Trying to apply the data migration will produce the following reminder:

$ edgedb migrate
edgedb error: could not read migrations in ./dbschema/migrations:
could not read migration file ./dbschema/migrations/00003.edgeql:
migration name should be
`m1e3d3eg3j2pr7acie4n5rrhaddyhkiy5kgckd5l7h5ysrpmgwxl5a`but
`m1iztxroh3ifoeqmvxncy77whnaei6tp5j3sewyxtrfysronjkxgga`is used
instead.
Migration names are computed from the hash of the migration
contents. To proceed you must fix the statement to read as:
CREATE MIGRATION m1e3d3eg3j2pr7acie4n5rrhaddyhkiy5kgckd5l7h5ysrpmgwxl5a
ONTO ...
if this migration is not applied to any database. Alternatively,
revert the changes to the file.

The migration tool detected that we’ve altered the file and asks us to update the migration name (acting as a checksum)
if this was deliberate. This is done as a precaution against accidental changes. Since we’ve done this on purpose, we
can update the file and run _edgedb migrate_ again.

We can see the changes after the data migration is complete:

db>select Character {
... name,
... class,
... new_class: {
... name,
... }
... };
{
default::Character {
name:'Alice',
class: warrior,
new_class: default::NewClass {name:'Warrior'},
},
default::Character {
name:'Billie',
class: scholar,
new_class: default::NewClass {name:'Scholar'},
},
default::Character {
name:'Cameron',
class: rogue,
new_class: default::NewClass {name:'Rogue'},
},
}

Everything seems to be in order. It is time to clean up the old property andCharacterClassenum:

typeNewClass {
required property name -> str;
multi property skills -> str;
}

```
(continues on next page)
```
**328 Chapter 4. Guides**


```
(continued from previous page)
```
typeCharacter {
required property name -> str;
link new_class -> NewClass;
}

typeNewClass {
required name: str;
multi skills: str;
}

typeCharacter {
required name: str;
new_class: NewClass;
}

The migration tools should have no trouble detecting the things we just removed:

$ edgedb migration create
did you drop property'class' of object type'default::Character'?
[y,n,l,c,b,s,q,?]
> y
did you drop scalar type'default::CharacterClass'? [y,n,l,c,b,s,q,?]
> y
Created ./dbschema/migrations/00004.edgeql, id:
m1jdnz5bxjj6kjz2pylvudli5rvw4jyr2ilpb4hit3yutwi3bq34ha
$ edgedb migrate
Applied m1jdnz5bxjj6kjz2pylvudli5rvw4jyr2ilpb4hit3yutwi3bq34ha
(00004.edgeql)

Now that the original property and scalar type are gone, we can rename the “new” components, so that they become
classlink andCharacterClasstype, respectively:

typeCharacterClass {
required property name -> str;
multi property skills -> str;
}

typeCharacter {
required property name -> str;
link class -> CharacterClass;
}

typeCharacterClass {
required name: str;
multi skills: str;
}

typeCharacter {
required name: str;
class: CharacterClass;
}

The migration tools pick up the changes without any issues again. It may seem tempting to combine the last two steps,

**4.3. Migration Patterns 329**


but deleting and renaming in a single step would cause the migration tools to report a name clash. As a general rule, it
is a good idea to never mix renaming and deleting of closely interacting entities in the same migration.

$ edgedb migration create
did you rename object type'default::NewClass' to
'default::CharacterClass'? [y,n,l,c,b,s,q,?]
> y
did you rename link 'new_class'of object type 'default::Character' to
'class'? [y,n,l,c,b,s,q,?]
> y
Created ./dbschema/migrations/00005.edgeql, id:
m1ra4fhx2erkygbhi7qjxt27yup5aw5hkr5bekn5y5jeam5yn57vsa
$ edgedb migrate
Applied m1ra4fhx2erkygbhi7qjxt27yup5aw5hkr5bekn5y5jeam5yn57vsa
(00005.edgeql)

Finally, we have replaced the originalclassproperty with a link:

db>select Character {
... name,
... class: {
... name,
... skills,
... }
... };
{
default::Character {
name:'Alice',
class: default::CharacterClass {
name: 'Warrior',
skills: {'punch', 'kick','run','jump'},
},
},
default::Character {
name:'Billie',
class: default::CharacterClass {
name: 'Scholar',
skills: {'read','write','analyze', 'refine'},
},
},
default::Character {
name:'Cameron',
class: default::CharacterClass {
name: 'Rogue',
skills: {'impress','sing', 'steal', 'run', 'jump'},
},
},
}

**330 Chapter 4. Guides**


### 4.3.5 Adding a required link

This example shows how to setup a required link. We’ll use a character in an adventure game as the type of data we
will evolve.

Let’s start with this schema:

typeCharacter {
required property name -> str;
}

typeCharacter {
required name: str;
}

We edit the schema file and perform our first migration:

$ edgedb migration create
did you create object type'default::Character'? [y,n,l,c,b,s,q,?]
> y
Created ./dbschema/migrations/00001.edgeql, id:
m1xvu7o4z5f5xfwuun2vee2cryvvzh5lfilwgkulmqpifo5m3dnd6a
$ edgedb migrate
Applied m1xvu7o4z5f5xfwuun2vee2cryvvzh5lfilwgkulmqpifo5m3dnd6a
(00001.edgeql)

This time around let’s practice performing a data migration and set up our character data. For this purpose we can
create an empty migration and fill it out as we like:

$ edgedb migration create --allow-empty
Created ./dbschema/migrations/00002.edgeql, id:
m1lclvwdpwitjj4xqm45wp74y4wjyadljct5o6bsctlnh5xbto74iq

We edit the00002.edgeqlfile by simply adding the query to add characters to it. We can useforto add multiple
characters like this:

CREATE MIGRATION m1lclvwdpwitjj4xqm45wp74y4wjyadljct5o6bsctlnh5xbto74iq
ONTO m1xvu7o4z5f5xfwuun2vee2cryvvzh5lfilwgkulmqpifo5m3dnd6a
{
+ for name in {'Alice','Billie', 'Cameron','Dana'}
+ union (
+ insert default::Character {
+ name := name
+ }
+ );
};

Trying to apply the data migration will produce the following reminder:

$ edgedb migrate
edgedb error: could not read migrations in ./dbschema/migrations:
could not read migration file ./dbschema/migrations/00002.edgeql:
migration name should be
`m1juin65wriqmb4vwg23fiyajjxlzj2jyjv5qp36uxenit5y63g2iq`but
(continues on next page)

**4.3. Migration Patterns 331**


```
(continued from previous page)
```
`m1lclvwdpwitjj4xqm45wp74y4wjyadljct5o6bsctlnh5xbto74iq`is used instead.
Migration names are computed from the hash of the migration contents. To
proceed you must fix the statement to read as:
CREATE MIGRATION m1juin65wriqmb4vwg23fiyajjxlzj2jyjv5qp36uxenit5y63g2iq
ONTO ...
if this migration is not applied to any database. Alternatively,
revert the changes to the file.

The migration tool detected that we’ve altered the file and asks us to update the migration name (acting as a checksum)
if this was deliberate. This is done as a precaution against accidental changes. Since we’ve done this on purpose, we
can update the file and run _edgedb migrate_ again.

- CREATE MIGRATION m1lclvwdpwitjj4xqm45wp74y4wjyadljct5o6bsctlnh5xbto74iq
+ CREATE MIGRATION m1juin65wriqmb4vwg23fiyajjxlzj2jyjv5qp36uxenit5y63g2iq
    ONTO m1xvu7o4z5f5xfwuun2vee2cryvvzh5lfilwgkulmqpifo5m3dnd6a
{
# ...
};

After we apply the data migration we should be able to see the added characters:

db>select Character {name};
{
default::Character {name:'Alice'},
default::Character {name:'Billie'},
default::Character {name:'Cameron'},
default::Character {name:'Dana'},
}

Let’s add a characterclassrepresented by a new type to our schema and data. Unlike in _this scenario_ , we will add the
required link classright away, without any intermediate properties. So we end up with a schema like this:

typeCharacterClass {
required property name -> str;
multi property skills -> str;
}

typeCharacter {
required property name -> str;
required link class -> CharacterClass;
}

typeCharacterClass {
required name: str;
multi skills: str;
}

typeCharacter {
required name: str;
required class: CharacterClass;
}

We go ahead and try to apply this new schema:

**332 Chapter 4. Guides**


$ edgedb migration create
did you create object type'default::CharacterClass'? [y,n,l,c,b,s,q,?]
> y
did you create link 'class'of object type 'default::Character'?
[y,n,l,c,b,s,q,?]
> y
Please specify an expression to populate existing objects in order to make
link'class'of object type'default::Character'required:
fill_expr>

Uh-oh! Unlike in a situation with a _required property_ , it’s not a good idea to justinserta newCharacterClass
object for every character. So we should abort this migration attempt and rethink our strategy. We need a separate step
where theclasslink is not _required_ so that we can write some custom queries to handle the character classes:

typeCharacterClass {
required property name -> str;
multi property skills -> str;
}

typeCharacter {
required property name -> str;
link class -> CharacterClass;
}

typeCharacterClass {
required name: str;
multi skills: str;
}

typeCharacter {
required name: str;
class: CharacterClass;
}

We can now create a migration for our new schema, but we won’t apply it right away:

$ edgedb migration create
did you create object type'default::CharacterClass'? [y,n,l,c,b,s,q,?]
> y
did you create link 'class'of object type 'default::Character'?
[y,n,l,c,b,s,q,?]
> y
Created ./dbschema/migrations/00003.edgeql, id:
m1jie3xamsm2b7ygqccwfh2degdi45oc7mwuyzjkanh2qwgiqvi2ya

We don’t need to create a blank migration to add data, we can add our modifications into the migration that adds the
classlink directly. Doing this makes sense when the schema changes seem to require the data migration and the two
types of changes logically go together. We will need to create someCharacterClassobjects as well asupdatethe
classlink on existingCharacterobjects:

```
CREATE MIGRATION m1jie3xamsm2b7ygqccwfh2degdi45oc7mwuyzjkanh2qwgiqvi2ya
ONTO m1juin65wriqmb4vwg23fiyajjxlzj2jyjv5qp36uxenit5y63g2iq
{
(continues on next page)
```
**4.3. Migration Patterns 333**


```
(continued from previous page)
CREATE TYPE default::CharacterClass {
CREATE REQUIRED PROPERTY name -> std::str;
CREATE MULTI PROPERTY skills -> std::str;
};
ALTER TYPE default::Character {
CREATE LINK class -> default::CharacterClass;
};
```
+ insert default::CharacterClass {
+ name :='Warrior',
+ skills := {'punch','kick','run', 'jump'},
+ };
+ insert default::CharacterClass {
+ name :='Scholar',
+ skills := {'read','write','analyze', 'refine'},
+ };
+ insert default::CharacterClass {
+ name :='Rogue',
+ skills := {'impress', 'sing', 'steal', 'run','jump'},
+ };
+ # All warriors
+ update default::Character
+ filter .name in {'Alice'}
+ set {
+ class := assert_single((
+ select default::CharacterClass
+ filter .name ='Warrior'
+ )),
+ };
+ # All scholars
+ update default::Character
+ filter .name in {'Billie'}
+ set {
+ class := assert_single((
+ select default::CharacterClass
+ filter .name ='Scholar'
+ )),
+ };
+ # All rogues
+ update default::Character
+ filter .name in {'Cameron','Dana'}
+ set {
+ class := assert_single((
+ select default::CharacterClass
+ filter .name ='Rogue'
+ )),
+ };
};

In a real game we might have a lot more characters and so a good way to update them all is to update characters of the
same class in bulk.

Just like before we’ll be reminded to fix the migration name since we’ve altered the migration file. After fixing the

**334 Chapter 4. Guides**


migration hash we can apply it. Now all our characters should have been assigned their classes:

db>select Character {
... name,
... class: {
... name
... }
... };
{
default::Character {
name:'Alice',
class: default::CharacterClass {name:'Warrior'},
},
default::Character {
name:'Billie',
class: default::CharacterClass {name:'Scholar'},
},
default::Character {
name:'Cameron',
class: default::CharacterClass {name:'Rogue'},
},
default::Character {
name:'Dana',
class: default::CharacterClass {name:'Rogue'},
},
}

We’re finally ready to make theclasslink _required_. We update the schema:

typeCharacterClass {
required property name -> str;
multi property skills -> str;
}

typeCharacter {
required property name -> str;
required link class -> CharacterClass;
}

typeCharacterClass {
required name: str;
multi skills: str;
}

typeCharacter {
required name: str;
required class: CharacterClass;
}

And we perform our final migration:

$ edgedb migration create
did you make link'class'of object type'default::Character'required?
[y,n,l,c,b,s,q,?]
(continues on next page)

**4.3. Migration Patterns 335**


```
(continued from previous page)
```
> y
Please specify an expression to populate existing objects in order to
make link'class'of object type 'default::Character'required:
fill_expr> assert_exists(.class)
Created ./dbschema/migrations/00004.edgeql, id:
m14yblybdo77c7bjtm6nugiy5cs6pl6rnuzo5b27gamy4zhuwjifia

The migration system doesn’t know that we’ve already assignedclassvalues to all theCharacterobjects, so it still
asks us for an expression to be used in case any of the objects need it. We can useassert_exists(.class)here
as a way of being explicit about the fact that we expect the values to already be present. Missing values would have
caused an error even without theassert_existswrapper, but being explicit may help us capture the intent and make
debugging a little easier if anyone runs into a problem at this step.

In fact, before applying this migration, let’s actually add a newCharacterto see what happens:

db>insert Character {name :='Eric'};
{
default::Character {
id: 9f4ac7a8-ac38-11ec-b076-afefd12d7e66,
},
}

Our attempt at migrating fails as we expected:

$ edgedb migrate
edgedb error: MissingRequiredError: missing value for required link
'class' of object type'default::Character'
Detail: Failing object id is 'ee604992-c1b1-11ec-ad59-4f878963769f'.

After removing the buggedCharacter, we can migrate without any problems:

$ edgedb migrate
Applied m14yblybdo77c7bjtm6nugiy5cs6pl6rnuzo5b27gamy4zhuwjifia
(00004.edgeql)

## 4.4 Cheatsheets

```
edb-alt-title Cheatsheets: EdgeDB by example
```
Just getting started? Keep an eye on this collection of cheatsheets with handy examples for what you’ll need to get started
with EdgeDB. After familiarizing yourself with them, feel free to dive into more EdgeDB via our longer interactive
tutorial and **much** longer Easy EdgeDB textbook.

EdgeQL:

- _select_ – Retrieve or compute a set of values.
- _insert_ – Create new database objects.
- _update_ – Update database objects.
- _delete_ – Remove objects from the database.
- _GraphQL_ – GraphQL queries supported natively out of the box.

Schema:

**336 Chapter 4. Guides**


- _Object Types_ – Make your own object and abstract types on top of existing system types.
- _User Defined Functions_ – Write and overload your own strongly typed functions.
- _Expression Aliases_ – Use aliases to create new types and modify existing ones on the fly.
- _Schema Annotations_ – Add human readable descriptions to items in your schema.

CLI/Admin:

- _CLI Usage_ – Getting your database started.
- _Interactive Shell_ – Shortcuts for frequently used commands in the EdgeDB Interactive Shell.
- _Administration_ – Database and role creation, passwords, port configuration, etc.

### 4.4.1 Selecting data

**Note:** The types used in these queries are defined _here_.

Select a Movie with associated actors and reviews with their authors:

select Movie {
id,
title,
year,
description,

```
actors: {
id,
full_name,
},
```
reviews := .<movie[is Review] {
id,
body,
rating,
author: {
id,
name,
}
},
}
filter .id = <uuid>'09c34154-4148-11ea-9c68-5375ca908326'

Select movies with Keanu Reeves:

select Movie {
id,
title,
year,
description,
(continues on next page)

**4.4. Cheatsheets 337**


```
(continued from previous page)
```
}
filter .actors.full_name ='Keanu Reeves'

Select all actors that share the last name with other actors and include the same-last-name actor list as well:

select Person {
id,
full_name,
same_last_name := (
with
P :=detachedPerson
selectP {
id,
full_name,
}
filter
# same last name
P.last_name = Person.last_name
and
# not the same person
P != Person
),
}
filter exists.same_last_name

The same query can be refactored moving thewithblock to the top-level:

with
# don't need detached at top-level
P := Person
select Person {
id,
full_name,
same_last_name := (
selectP {
id,
full_name,
}
filter
# same last name
P.last_name = Person.last_name
and
# not the same person
P != Person
),
}
filter exists.same_last_name

Select user names and the number of reviews they have:

**338 Chapter 4. Guides**


select (
User.name,
count(User.<author[is Review])
)

For every user and movie combination, select whether the user has reviewed the movie (beware, in practice this maybe
a very large result):

select (
User.name,
Movie.title,
Moviein User.<author[is Review].movie
)

Perform a set intersection of all actors with all directors:

with
# get the set of actors and set of directors
Actor := Movie.actors,
Director := Movie.director,
# set intersection is done via the filter clause
select Actorfilter Actorin Director;

To order a set of scalars first assign the set to a variable and use the variable in the order by clause.

select numbers := {3, 1, 2}order by numbers;

# alternatively
withnumbers := {3, 1, 2}
select numbersorder by numbers;

Selecting free objects.

It is also possible to package data into a _free object_. _Free objects_ are meant to be transient and used either to more
efficiently store some intermediate results in a query or for re-shaping the output. The advantage of using _free objects_
overtuplesis that it is easier to package data that potentially contains empty sets as links or properties of the _free
object_. The underlying type of a _free object_ isstd::FreeObject.

Consider the following query:

withU := (selectUserfilter .namelike'%user%')
select {
matches := U {name},
total := count(U),
total_users := count(User),
};

Thematchesare potentially{}, yet the query will always return a single _free object_ withresults,total, and
total_users. To achieve the same using anamed tuple, the query would have to be modified like this:

**4.4. Cheatsheets 339**


withU := (selectUserfilter .namelike'%user%')
select (
matches := array_agg(U {name}),
total := count(U),
total_users := count(User),
);

Without thearray_agg()the above query would return{}instead of the named tuple if nomatchesare found.

```
See also
EdgeQL > Select
Reference > Commands > Select
Tutorial > Basic Queries > Objects
Tutorial > Basic Queries > Filters
Tutorial > Basic Queries > Aggregates
Tutorial > Nested Structures > Shapes
Tutorial > Nested Structures > Polymorphism
```
### 4.4.2 Inserting data

**Note:** The types used in these queries are defined _here_.

Insert basic movie stub:

insert Movie {
title :='Dune',
year := 2020,
image :='dune2020.jpg',
directors := (
selectPerson
filter
.full_name ='Denis Villeneuve'
)
}

Alternatively, insert a movie using JSON input value:

with
# Cast the JSON $input into a tuple, which we will
# use to populate the Person record.
data := <tuple<
title: str,
year: int64,
image: str,
directors: array<str>,
actors: array<str>
>> <json>$input
(continues on next page)

**340 Chapter 4. Guides**


```
(continued from previous page)
```
insert Movie {
title := data.title,
year := data.year,
image := data.image,
directors := (
selectPerson
filter
.full_namein array_unpack(data.directors)
),
actors := (
selectPerson
filter
.full_namein array_unpack(data.actors)
)
}

Insert several nested objects at once:

# Create a new review and a new user in one step.
insert Review {
body :='Dune is cool',
rating := 5,
# The movie record already exists, so select it.
movie := (
selectMovie
filter
.title ='Dune'
and
.year = 2020
# the limit is needed to satisfy the single
# link requirement validation
limit 1
),
# This is a new user, so insert one.
author := (
insertUser {
name :='dune_fan_2020',
image :='default_avatar.jpg',
}
)
}

Sometimes it’s necessary to check whether some object exists and create it if it doesn’t. If this type of object has an
exclusive property, theunless conflictclause can make theinsertcommand indempotent. So running such a
command would guarantee that a copy of the object exists without the need for more complex logic:

# Try to create a new User
insert User {
name := "Alice",
(continues on next page)

**4.4. Cheatsheets 341**


(continued from previous page)
image := "default_avatar.jpg",
}
# and do nothing if a User with this name already exists
unless conflict

If more than one property is exclusive, it is possible to specify which one of them is considered when a conflict is
detected:

# Try to create a new User
insert User {
name := "Alice",
image := "default_avatar.jpg",
}
# and do nothing if a User with this name already exists
unless conflict on.name

“Upserts” can be performed by using theunless conflictclause and specifying what needs to be updated:

select (
# Try to create a new User,
insert User {
name := "Alice",
image := "my_face.jpg",
}

# but if a User with this name already exists,
unless conflict on.name
else(
# update that User's record instead.
updateUser
set{
image := "my_face.jpg"
}
)
) {
name,
image
}

Rather than acting as an “upsert”, theunless conflictclause can be used to insert or select an existing record,
which is handy for inserting nested structures:

# Create a new review and a new user in one step.
insert Review {
body :='Loved it!!!',
rating := 5,
# The movie record already exists, so select it.
movie := (
selectMovie
filter
(continues on next page)

**342 Chapter 4. Guides**


```
(continued from previous page)
.title ='Dune'
and
.year = 2020
# the limit is needed to satisfy the single
# link requirement validation
limit 1
),
```
```
# This might be a new user or an existing user. Some
# other part of the app handles authentication, this
# endpoint is used as a generic way to post a review.
author := (
# Try to create a new User,
insertUser {
name := "dune_fan_2020",
image := "default_avatar.jpg",
}
```
# but if a User with this name already exists,
unless conflict on.name
# just pick that existing User as the author.
elseUser
)
}

```
See also
EdgeQL > Insert
Reference > Commands > Insert
Tutorial > Data Mutations > Insert
Tutorial > Data Mutations > Upsert
```
### 4.4.3 Updating data

**Note:** The types used in these queries are defined _here_.

Flag all reviews to a specific movie:

update Review
filter
Review.movie.title ='Dune'
and
Review.movie.director.last_name ='Villeneuve'
set{
flag :=True
}

Add an actor with a specificlist_orderlink property to a movie:

**4.4. Cheatsheets 343**


update Movie
filter
.title ='Dune'
and
.directors.last_name ='Villeneuve'
set{
actors := (
insertPerson {
first_name :='Timothee',
last_name :='Chalamet',
image :='tchalamet.jpg',
@list_order := 1,
}
)
}

Using aforquery to set a specificlist_orderlink property for the actors list:

update Movie
filter
.title ='Dune'
and
.directors.last_name ='Villeneuve'
set{
actors := (
forxin {
('Timothee Chalamet', 1),
('Zendaya', 2),
('Rebecca Ferguson', 3),
('Jason Momoa', 4),
}
union(
selectPerson {@list_order := x.1}
filter.full_name = x.0
)
)
}

Updating a multi link by adding one more item:

update Movie
filter
.title ='Dune'
and
.directors.last_name ='Villeneuve'
set{
actors += (
insertPerson {
first_name :='Dave',
last_name :='Bautista',
(continues on next page)

**344 Chapter 4. Guides**


(continued from previous page)
image :='dbautista.jpg',
}
)
}

Updating a multi link by removing an item:

update Movie
filter
.title ='Dune'
and
.directors.last_name ='Villeneuve'
set{
actors -= (
selectPerson
filter
.full_name ='Jason Momoa'
)
}

Update thelist_orderlink property for a specific link:

update Movie
filter
.title ='Dune'
and
.directors.last_name ='Villeneuve'
set{
# The += operator will allow updating only the
# specified actor link.
actors += (
selectPerson {
@list_order := 5,
}
filter.full_name ='Jason Momoa'
)
}

```
See also
EdgeQL > Update
Reference > Commands > Update
Tutorial > Data Mutations > Update
```
**4.4. Cheatsheets 345**


### 4.4.4 Deleting data

**Note:** The types used in these queries are defined _here_.

Delete all reviews from a specific user:

delete Review
filter .author.name ='trouble2020'

Alternative way to delete all reviews from a specific user:

delete (
select User
filter .name ='troll2020'
).<author[is Review]

```
See also
EdgeQL > Delete
Reference > Commands > Delete
Tutorial > Data Mutations > Delete
```
### 4.4.5 Using link properties

```
index property
```
Links can contain **properties**. These are distinct from links themselves (which we refer to as simply “links”) and are
used to store metadata about a link. Due to how they’re persisted under the hood, link properties have a few additional
constraints: they’re always _single_ and _optional_.

**Note:** In practice, link properties are best used with many-to-many relationships (multilinks without any exclusive
constraints). For one-to-one, one-to-many, and many-to-one relationships the same data should be stored in object
properties instead.

#### 4.4.5.1 Declaration

Let’s a create aPerson.friendslink with astrengthproperty corresponding to the strength of the friendship.

typePerson {
required property name -> str {constraintexclusive };

multi link friends -> Person {
propertystrength -> float64;
}
}

**346 Chapter 4. Guides**


typePerson {
required name: str {constraint exclusive };

multi friends: Person {
strength: float64;
}
}

#### 4.4.5.2 Constraints

typePerson {
required property name -> str {constraintexclusive };

multi link friends -> Person {
propertystrength -> float64;
constraint expression on(
__subject__@strength >= 0
);
}
}

typePerson {
required name: str {constraint exclusive };

multi friends: Person {
strength: float64;
constraint expression on(
__subject__@strength >= 0
);
}
}

#### 4.4.5.3 Indexes

To index on a link property, you must declare an abstract link and extend it.

abstract linkfriendship {
property strength -> float64;
index on (__subject__@strength);
}

typePerson {
required property name -> str {constraintexclusive };
multi link friendsextendingfriendship -> Person;
}

abstract linkfriendship {
strength: float64;
index on (__subject__@strength);
}
(continues on next page)

**4.4. Cheatsheets 347**


```
(continued from previous page)
```
typePerson {
required name: str {constraint exclusive };
multi friends: Person {
extendingfriendship;
};
}

#### 4.4.5.4 Inserting

The@strengthproperty is specified in the _shape_ of theselectsubquery. This is only valid in a subquery _inside_ an
insertstatement.

insert Person {
name := "Bob",
friends := (
select detached Person {
@strength := 3.14
}
filter .name = "Alice"
)
}

**Note:** We are using thedetachedoperator to unbind thePersonreference from the scope of theinsertquery.

When doing a nested insert, link properties can be directly included in the innerinsertsubquery.

insert Person {
name := "Bob",
friends := (
insert Person {
name := "Jane",
@strength := 3.14
}
)
}

#### 4.4.5.5 Updating

update Person
filter .name = "Bob"
set{
friends += (
select .friends {
@strength := 3.7
}
filter .name = "Alice"
)
};

**348 Chapter 4. Guides**


The example updates the@strengthproperty of Bob’s friends link to Alice to 3.7.

In the context of multi links the += operator works like an an insert/update operator.

To update one or more links in a multi link, you can select from the current linked objects, as the example does. Use a
detachedselection if you want to insert/update a wider selection of linked objects instead.

#### 4.4.5.6 Querying

edgedb>selectPerson {
....... friends: {
....... name,
....... @strength
....... }
....... };
{
default::Person {name: 'Alice', friends: {}},
default::Person {
name:'Bob',
friends: {
default::Person {name: 'Alice', @strength: 3.7}
}
},
}

**Note:** Specifying link properties of a computed backlink in your shape is supported as of EdgeDB 3.0.

If you have this schema:

typePerson {
required name: str;
multi follows: Person {
followed: datetime {
default:= datetime_of_statement();
};
};
multi link followers := .<follows[is Person];
}

this query will work as of EdgeDB 3.0:

select Person {
name,
followers: {
name,
@followed
}
};

even though@followedis a link property offollowsand we are accessing is through the computed backlink
followersinstead.

If you need link properties on backlinks in earlier versions of EdgeDB, you can use this workaround:

**4.4. Cheatsheets 349**


select Person {
name,
followers := .<follows[isPerson] {
name,
followed := @followed
}
};

```
See also
Data Model > Links > Link properties
SDL > Properties
DDL > Properties
Introspection > Object Types
```
### 4.4.6 Working with booleans

Boolean expressions can be tricky sometimes, so here are a handful of tips and gotchas.

There’s a fundamental difference in how{}is treated byandandorvsall()andany(). The operatorsandandor
require both operands to produce a result, which means that an{}as one of the inputs necessarily produces an{}as
the output:

db>select false and<bool>{};
{}
db>select true or<bool>{};
{}

The functionsall()andany(), however, produce a result for all possible input sets, regardless of the number of
elements:

db>select all({false, {}});
{false}
db>select any({true, {}});
{true}

Note that expressions like{false, {}}are equivalent to{false}and so the above are just generalizations of boolean
operatorsandandorto a set of 1 element. So the result for 1 element is fairly intuitive. However, the results produced
by these functions for{}may be surprising (even though they are mathematically consistent):

db>select all(<bool>{});
{true}
db>select any(<bool>{});
{false}

There’s no direct analogue to the boolean operator “short-circuiting” that’s implemented in many other languages
because in EdgeQL the order of evaluation of subexpressions is generally not defined. However, there are expressions
that achieve the same end goal for which “short-circuiting” is used.

**350 Chapter 4. Guides**


The most basic filtering doesn’t even require any “short-circuiting” guards because these are already implied by
EdgeQL. For example, _“get all accounts that completed 5 steps of the process”_ :

select Accountfilter .steps = 5;

When there’s a need to express that a field is initialized, but not equal to some particular value “short-circuiting” is often
used to discard non-initialized values (e.g.acc.steps is not None and acc.steps != 5). This is another case
where EdgeQL doesn’t require any additional guards. For example _“get all initialized accounts that have not completed
5 steps of the process”_ :

select Accountfilter .steps != 5;

If the task boils down to annotating every element as opposed to selecting specific ones, the use of?=instead of the
plain=helps to deal with optional properties. For example, _“get all accounts and annotate them with their completeness
status”_ :

select Account {
completed := .steps ?= 5
};

Sometimes the condition that needs to be evaluated is not a simple equality comparison. The??can help out in these
cases. For example, _“get all accounts and annotate them on whether or not they are half-way completed”_ :

select Account {
completed := (.steps > 2) ?? false
};

The above trick can also be useful for filtering based on some boolean condition that’s not just a plain equality. For
example, _“get only the accounts that are less than half-way completed”_ :

select Account {
too_few_steps := (.steps <= 2) ??true
}filter .too_few_steps;

The above will end up including the computed flagtoo_few_stepsin the output, but this is sometimes undesirable.
In order to avoid including it, the query can be refactored like this:

select Account {
name,
email,
# whatever other relevant data is needed
}filter (.steps <= 2) ??true;

When using?=,?=, or??it is important to keep in mind how they interact with _path expressions_ that can sometimes
be{}. Basically, these operators don’t actually affect the path expression, they only act on the _results_ of the path
expression. Consider the following two queries:

**4.4. Cheatsheets 351**


select Account {
too_few_steps := (.steps <= 2) ??true
}.too_few_steps;

select (Account.steps <= 2) ??true;

The first query is going to outputtrueorfalsefor every account, based on the specified criteria. It’s important to
note that the number of the results is going to be exactly the same as the number of the accounts in the system. The
second query may look like a more compact version of the first query, but it behaves completely differently. If all of the
account are “uninitialized” (steps := {}) or there are no accounts at all, it will produce a single resulttrue. That’s
because the expressionAccount.steps <= 2produces an empty set in this case and so the??returns the second
operand. On the other hand, if there are any accounts with some concrete number ofsteps, then the expression
Account.steps <= 2will produce a result for _those accounts only_. The??won’t change that result because the
result is already non-empty and so no coalescing will take place.

Computeds in shapes get evaluated _for each object_ , whereas path expressions only produce as many values as are
_reachable_ by the path. So when all objects must be considered, computed links and properties in shapes are a good
way to handle complex expressions or filters. When only objects with specific properties are relevant, path expressions
are a good compact way of handling this.

There’s also another way to evaluate something on a per-object basis and that’s by using aforquery. For example,
let’s rewrite the query that outputstrueorfalsefor every account, based on the number of completed steps:

forAin Account
union(A.steps <= 2) ?? true;

Expressions specified in shapes,for, orfilterclauses are all evaluated on a per-item basis. The gotchas in these
cases can arise from using longer path expressions combined with??,?=, or?!=. For example, let’s say that in addition
to accounts and steps we also have different “projects” with a multi-link ofaccountsmarking progress in them. So
keeping that in mind, let’s try writing a query to _“get all projects that have linked accounts which made little progress
(fewer than 3``steps``)”_ :

select Project
filter .accounts.steps < 3;

Well, that’s not right. Projects that have accounts without anystepsof progress are not reported by the above query.
So maybe adding a??will help?

select Project
filter (.accounts.steps < 3) ??true;

This is better as the results now include projects where none of the accounts made any progress. However, any project
that has a mix of accounts that made more than 2 steps of progress and accounts that haven’t even started is still missing
from the results. So we can either use the trick we used before with shapes or we can add anotherforsubquery:

select Project
filter (
forAin .accounts
union(A.steps < 3) ??true
);

Note that the _filter_ clause behaves as an implicitany(). This means that the following are semantically equivalent:

**352 Chapter 4. Guides**


select User
filter .friends.name ='Alice';

select User
filter any(.friends.name ='Alice');

### 4.4.7 Object types

Define an abstract type:

abstract typeHasImage {
# just a URL to the image
required propertyimage -> str;
index on(.image);
}

abstract typeHasImage {
# just a URL to the image
requiredimage: str;
index on(.image);
}

Define a type extending from the abstract:

typeUserextending HasImage {
required propertyname -> str {
# Ensure unique name for each User.
constraintexclusive;
}
}

typeUserextending HasImage {
requiredname: str {
# Ensure unique name for each User.
constraintexclusive;
}
}

Define a type with constraints and defaults for properties:

typeReview {
required propertybody -> str;
required propertyrating -> int64 {
constraintmin_value(0);
constraintmax_value(5);
}
required propertyflag -> bool {
default:=False;
(continues on next page)

**4.4. Cheatsheets 353**


```
(continued from previous page)
}
```
```
required linkauthor -> User;
required linkmovie -> Movie;
```
required propertycreation_time -> datetime {
default:= datetime_current();
}
}

typeReview {
requiredbody: str;
requiredrating: int64 {
constraintmin_value(0);
constraintmax_value(5);
}
requiredflag: bool {
default:=False;
}

```
requiredauthor: User;
requiredmovie: Movie;
```
requiredcreation_time: datetime {
default:= datetime_current();
}
}

Define a type with a property that is computed from the combination of the other properties:

typePerson extendingHasImage {
required propertyfirst_name -> str {
default:='';
}
required propertymiddle_name -> str {
default:='';
}
required propertylast_name -> str;
propertyfull_name :=
(
(
(.first_name ++' ')
if .first_name !='' else
''
) ++
(
(.middle_name ++' ')
if .middle_name !='' else
''
) ++
(continues on next page)

**354 Chapter 4. Guides**


(continued from previous page)
.last_name
);
propertybio -> str;
}

typePerson extendingHasImage {
requiredfirst_name: str {
default:='';
}
requiredmiddle_name: str {
default:='';
}
requiredlast_name: str;
propertyfull_name :=
(
(
(.first_name ++' ')
if .first_name !='' else
''
) ++
(
(.middle_name ++' ')
if .middle_name !='' else
''
) ++
.last_name
);
bio: str;
}

Define an abstract links:

abstract linkcrew {
# Provide a way to specify some "natural"
# ordering, as relevant to the movie. This
# may be order of importance, appearance, etc.
propertylist_order -> int64;
}

abstract linkdirectors extendingcrew;

abstract linkactors extendingcrew;

abstract linkcrew {
# Provide a way to specify some "natural"
# ordering, as relevant to the movie. This
# may be order of importance, appearance, etc.
list_order: int64;
}

```
(continues on next page)
```
**4.4. Cheatsheets 355**


```
(continued from previous page)
```
abstract linkdirectors {
extendingcrew;
};

abstract linkactors {
extendingcrew;
};

Define a type using abstract links and a computed property that aggregates values from another linked type:

typeMovie extendingHasImage {
required propertytitle -> str;
required propertyyear -> int64;

```
# Add an index for accessing movies by title and year,
# separately and in combination.
index on(.title);
index on(.year);
index on((.title, .year));
```
```
propertydescription -> str;
```
```
multi linkdirectors extendingcrew -> Person;
multi linkactors extendingcrew -> Person;
```
propertyavg_rating := math::mean(.<movie[isReview].rating);
}

typeMovie extendingHasImage {
requiredtitle: str;
requiredyear: int64;

```
# Add an index for accessing movies by title and year,
# separately and in combination.
index on(.title);
index on(.year);
index on((.title, .year));
```
```
description: str;
```
```
multidirectors: Person {
extendingcrew;
};
multiactors: Person {
extendingcrew
};
```
propertyavg_rating := math::mean(.<movie[isReview].rating);
}

Define anauto-incrementingscalar type and an object type using it as a property:

**356 Chapter 4. Guides**


scalar typeTicketNoextendingsequence;

typeTicket {
propertynumber -> TicketNo {
constraintexclusive;
}
}

scalar typeTicketNoextendingsequence;

typeTicket {
number: TicketNo {
constraintexclusive;
}
}

```
See also
Schema > Object types
SDL > Object types
DDL > Object types
Introspection > Object types
```
### 4.4.8 Declaring functions

Define a function for counting reviews given a user name:

create function review_count(name: str) -> int64
using(
with module default
select count(
(
selectReview
filter.author.name = name
)
)
)

Drop a user-defined function:

drop functionreview_count(name: str);

Define and use polymorphic function:

db>create function make_name(name: str) -> str
...using('my_name_'++ name);
CREATE FUNCTION
db>create function make_name(name: int64) -> str
...using('my_name_'++ <str>name);
(continues on next page)

**4.4. Cheatsheets 357**


```
(continued from previous page)
```
CREATE FUNCTION
q> selectmake_name('Alice');
{'my_name_Alice'}
q> selectmake_name(42);
{'my_name_42'}

```
See also
Schema > Functions
SDL > Functions
DDL > Functions
Reference > Function calls
Introspection > Functions
Tutorial > Advanced EdgeQL > User-Defined Functions
```
### 4.4.9 Declaring aliases

Define an alias that merges some information from links as computed properties, this is a way of flattening a nested
structure:

aliasReviewAlias := Review {
# It will already have all the Review
# properties and links.
author_name := .author.name,
movie_title := .movie.title,
}

Define an alias for traversing a _backlink_ , this is especially useful for GraphQL access:

aliasMovieAlias := Movie {
# A computed link for accessing all the
# reviews for this movie.
reviews := .<movie[is Review]
}

**Note:** Aliases allow to use the full power of EdgeQL (expressions, aggregate functions, _backlink_ navigation) from
_GraphQL_.

The aliases defined above allow you to queryMovieAliaswith _GraphQL_.

```
See also
Schema > Aliases
SDL > Aliases
DDL > Aliases
```
**358 Chapter 4. Guides**


### 4.4.10 Declaring annotations

Use annotations to add descriptions to types and links:

typeLabel {
annotationdescription :=
'Special label to stick on reviews';
required propertycomments -> str;
linkreview -> Review {
annotationdescription :=
'This review needs some attention';
};
}

typeLabel {
annotationdescription :=
'Special label to stick on reviews';
requiredcomments: str;
review: Review {
annotationdescription :=
'This review needs some attention';
};
}

Retrieving the annotations can be done via an introspection query:

db>with module schema
...select ObjectType {
... name,
... annotations: {name, @value},
... links: {name, annotations: {name, @value}}
... }
...filter .name ='default::Label';
{
Object {
name:'default::Label',
annotations: {
Object{
name:'std::description',
@value:'Special label to stick on reviews'
}
},
links: {
Object{
name:'review',
annotations: {
Object{
name:'std::description',
@value:'Special label to stick on reviews'
}
}
},
(continues on next page)

**4.4. Cheatsheets 359**


(continued from previous page)
Object{ name:'__type__', annotations: {} }
}
}
}

Alternatively, the annotations can be viewed by the following REPL command:

db> \d+ Label
typedefault::Label {
annotationstd::description := 'Special label to stick on reviews';
required single link__type__ -> schema::Type {
readonly :=true;
};
single linkreview -> default::Review {
annotationstd::description := 'Special label to stick on reviews';
};
required single propertycomments -> std::str;
required single propertyid -> std::uuid {
readonly :=true;
constraintstd::exclusive;
};
};

```
See also
Schema > Annotations
SDL > Annotations
DDL > Annotations
Introspection > Object types
```
### 4.4.11 Using the CLI

To initialize a new project:

$ edgedb project init

If anedgedb.tomlfile exists in the current directory, it will initialize a new project according to the settings defined
in it.

Otherwise, a new project will be initialized and anedgedb.tomlfile anddbschemadirectory will be generated. For
details on using projects, see the _dedicated guide_.

Once initialized, you can run the CLI commands below without additional connection options. If you don’t set up a
project, you’ll need to use _flags_ to specify the target instance for each command.

Explicitly create a new EdgeDB instancemy_instance:

$ edgedb instance create my_instance

Create a database:

**360 Chapter 4. Guides**


$ edgedb database create special_db
OK: CREATE

Configure passwordless access (such as to a local development database):

$ edgedb configure insert Auth \
> --comment'passwordless access' \
> --priority 1 \
> --method Trust
OK: CONFIGURE INSTANCE

Configure access that checks password (with a higher priority):

$ edgedb configure insert Auth \
> --comment'password is required'\
> --priority 0 \
> --method SCRAM
OK: CONFIGURE INSTANCE

Connect to the default project database:

$ edgedb
EdgeDB 1.0-beta.2+ga7130d5c7.cv202104290000 (repl 1.0.0-beta.2)
Type \help for help, \quit to quit.
edgedb>

Connect to some specific database:

$ edgedb -d special_db
EdgeDB 1.0-beta.2+ga7130d5c7.cv202104290000 (repl 1.0.0-beta.2)
Type \help for help, \quit to quit.
special_db>

### 4.4.12 Using the REPL

Execute a query. To execute a query in the REPL, terminate the statement with a semicolon and press “ENTER”.

db>select 5;
{5}

Alternatively, you can run the query without a semicolon by hitting Alt-Enter on Windows/Linux, or Esc+Return on
macOS.

db>select 5
{5}

**4.4. Cheatsheets 361**


TypeAlt-Enterto run the query without having the cursor to the end of the query.

**Note:** This doesn’t work by default on macOS, however it’s possible to enable it with a quick fix.

- in Terminal.app: Settings→Profiles→Keyboard→Check “Use Option as Meta key”
- in iTerm: Settings→Profiles→Keys→Let Option key: ESC+

Alternatively you can use theesc+returnshortcut.

Use query parameters. If your query contains a parameter, you will be prompted for a value.

db>select 5 + <int64>$num;
Parameter <int64>$num: 6
{11}

#### 4.4.12.1 Commands

```
Options -v= verbose
-s= show system objects
-I= case-sensitive match
\d [-v] NAME Describe a schema object.
\ds, \describe schema Describe the entire schema.
\list databases
alias: \l
```
```
List databases.
```
```
\list scalars [-sI] [pattern]
alias: \ls
```
```
List scalar types.
```
```
\list types [-sI] [pattern]
alias: \lt
```
```
List object types.
```
```
\list roles [-I]
alias: \lr
```
```
List roles.
```
```
\list modules [-I]
alias: \lm
```
```
List modules.
```
```
\list aliases [-Isv] [pattern]
alias: \la
```
```
List expression aliases.
```
```
\list casts [-I] [pattern]
alias: \lc
```
```
List casts.
```
```
\list indexes [-Isv] [pattern]
alias: \li
```
```
List indexes.
```
```
\dump <filename> Dump the current database to file.
\restore <filename> Restore the database from a dump file.
\s, \history Show query history
\e, \edit [N] Spawn $EDITOR to edit history entry N.
Then use the output as the input.
\set [<option> [<value>]] View/change a setting.
Type\setto see all available settings.
\c, \connect [<dbname>] Connect to a particular database.
```
**362 Chapter 4. Guides**


#### 4.4.12.2 Sample usage

List databases:

db> \ls
Listof databases:
db
tutorial

Connect to a database:

db> \c my_new_project
my_new_project>

Describe an object type:

db> \d object Object
abstract typestd::Objectextendingstd::BaseObject {
required single link__type__ -> schema::Type {
readonly :=true;
};
required single propertyid -> std::uuid {
readonly :=true;
};
};

Describe a scalar type:

db> \d objectdecimal
scalar typestd::decimalextendingstd::anynumeric;

Describe a function:

db> \d objectsum
functionstd::sum(s:set of std::bigint) -> std::bigint {
volatility :='Immutable';
annotationstd::description := 'Return the sum of the set of numbers.';
usingsqlfunction'sum'
;};
functionstd::sum(s:set of std::int32) -> std::int64 {
volatility :='Immutable';
annotationstd::description := 'Return the sum of the set of numbers.';
usingsqlfunction'sum'
;};
functionstd::sum(s:set of std::decimal) -> std::decimal {
volatility :='Immutable';
annotationstd::description := 'Return the sum of the set of numbers.';
usingsqlfunction'sum'
(continues on next page)

**4.4. Cheatsheets 363**


```
(continued from previous page)
```
;};
functionstd::sum(s:set of std::float32) -> std::float32 {
volatility :='Immutable';
annotationstd::description := 'Return the sum of the set of numbers.';
usingsqlfunction'sum'
;};
functionstd::sum(s:set of std::int64) -> std::int64 {
volatility :='Immutable';
annotationstd::description := 'Return the sum of the set of numbers.';
usingsqlfunction'sum'
;};
functionstd::sum(s:set of std::float64) -> std::float64 {
volatility :='Immutable';
annotationstd::description := 'Return the sum of the set of numbers.';
usingsqlfunction'sum'
;};

#### 4.4.13 Administering an instance

Create a database:

db>create database my_new_project;
OK:CREATE DATABASE

Create a role:

db>create superuser roleproject;
OK:CREATE ROLE

Configure passwordless access (such as to a local development database):

db>configure instance insertAuth {
... # Human-oriented comment helps figuring out
... # what authentication methods have been setup
... # and makes it easier to identify them.
... comment :='passwordless access',
... priority := 1,
... method := (insert Trust),
... };
OK:CONFIGURE INSTANCE

Set a password for a role:

db>alter roleproject
... setpassword :='super-password';
OK:ALTER ROLE

**364 Chapter 4. Guides**


Configure access that checks password (with a higher priority):

db>configure instance insertAuth {
... comment :='password is required',
... priority := 0,
... method := (insert SCRAM),
... };
OK:CONFIGURE INSTANCE

Remove a specific authentication method:

db>configure instance resetAuth
...filter .comment ='password is required';
OK:CONFIGURE INSTANCE

Run a script from command line:

cat myscript.edgeql | edgedb [<connection-option>...]

### 4.5 Contributing

```
edb-alt-title Contributing to EdgeDB
```
EdgeDB is an open-source project, and we welcome contributions from our community. You can contribute by writing
code or by helping us improve our documentation.

#### 4.5.1 Code

```
edb-alt-title Developing EdgeDB
```
This section describes how to build EdgeDB locally, how to use its internal tools, and how to contribute to it.

```
Warning: Code-changing pull requests without adding new tests might take longer time to be reviewed and
merged.
```
##### 4.5.1.1 Building Locally

The following instructions should be used to create a “dev” build on Linux or macOS. Windows is not currently sup-
ported.

**4.5. Contributing 365**


**Build Requirements**

- GNU make version 3.80 or newer;
- C compiler (GCC or clang);
- Rust compiler and Cargo 1.65 or later;
- autotools;
- Python 3.10 dev package;
- Bison 1.875 or later;
- Flex 2.5.31 or later;
- Perl 5.8.3 or later;
- Zlib (zlibg1-dev on Ubuntu);
- Readline dev package;
- Libuuid dev package;
- Node.js 14 or later;
- Yarn 1

On Ubuntu 22.10, these can be installed by running:

$ apt install make gcc rust-all autotools-dev python3.11-dev \
python3.11-venv bison flex libreadline-dev perl zlib1g-dev \
uuid-dev nodejs npm
$ npm i -g corepack
$ corepack enable && corepack prepare yarn@stable --activate

**Instructions**

The easiest way to set up a development environment is to create a Python “venv” with all dependencies and commands
installed into it.

1. Make a new directory that will contain checkouts of edgedb and edgedb-python. The name of the directory is
    arbitrary, we will use “dev” in this guide:

```
$ mkdir ~/dev
$ cd ~/dev
```
2. Clone the edgedb repository using--recursiveto clone all submodules:

```
$ git clone --recursive https://github.com/edgedb/edgedb.git
```
3. Create a Python 3.10 virtual environment and activate it:

```
$ python3.10 -m venv edgedb-dev
$ source edgedb-dev/bin/activate
```
4. Build edgedb (the build will take a while):

```
$ cd edgedb
$ pip install -v -e ".[test]"
```
**366 Chapter 4. Guides**


```
In addition to compiling EdgeDB and all dependencies, this will also install theedbandedgedbcommand line
tools into the current Python virtual environment.
It will also install libraries used during development.
```
5. Run tests:

```
$ edb test
```
The new virtual environment is now ready for development and can be activated at any time.

##### 4.5.1.2 Running Tests

To run all EdgeDB tests simply use the$ edb testcommand without arguments.

The command also supports running a few selected tests. To run all tests in a test case file:

$ edb test tests/test_edgeql_calls.py

# or run two files:
$ edb test tests/test_edgeql_calls.py tests/test_edgeql_for.py

To pattern-match a test by its name:

$ edb test -k test_edgeql_calls_01

# or run all tests that contain "test_edgeql_calls":
$ edb test -k test_edgeql_calls

See$ edb test --helpfor more options.

##### 4.5.1.3 Dev Server

Use the$ edb servercommand to start the development server.

You can then use another terminal to open a REPL to the server using the$ edgedbcommand, or connect to it using
one of the language bindings.

##### 4.5.1.4 Test Databases

Use the$ edb inittestdbcommand to create and populate databases that are used by unit tests.

#### 4.5.2 Documentation

```
edb-alt-title Writing EdgeDB Documentation
```
We pride ourselves on having some of the best documentation around, but we want you to help us make it even better.
Documentation is a great way to get started contributing to EdgeDB. Improvements to our documentation create a
better experience for every developer coming through the door behind you.

Follow our general and style guidelines to make for a smooth contributing exprience, both for us and for you. You may
notice that the existing documentation doesn’t always follow the guidelines laid out here. They are aspirational, so there
are times when we intentionally break with them. Other times, bits of documentation may not be touched for a while
and so may not reflect our current guidelines. These are great “low-hanging fruit” opportunities for your contributions!

**4.5. Contributing 367**


##### 4.5.2.1 Guidelines

- **Avoid changes that don’t fix an obvious mistake or add clarity.** This is subjective, but try to look at your
    changes with a critical eye. Do they fix errors in the original like misspellings or typos? Do they make existing
    prose more clear or accessible while maintaining accuracy? If you answered “yes” to either of those questions,
    this might be a great addition to our docs! If not, consider starting a discussion instead to see if your changes
    might be the exception to this guideline before submitting.
- **Keep commits and pull requests small.** We get it. It’s more convenient to throw all your changes into a single
    pull request or even into a single commit. The problem is that, if some of the changes are good and others don’t
    quite work, having everything in one bucket makes it harder to filter out the great changes from those that need
    more work.
- **Make spelling and grammar fixes in a separate pull request from any content changes.** These changes are
    quick to check and important to anyone reading the docs. We want to make sure they hit the live documentation
    as quickly as possible without being bogged down by other changes that require more intensive review.

##### 4.5.2.2 Style

- **Lines should be no longer than 79 characters.** This is enforced by linters as part of our CI process. Linting
    _can be disabled_ , but this should not be used unless it’s necessary and only for as long as it is necessary.
- **Remove trailing whitespace or whitespace on empty lines.**
- **Surround references to parameter named with asterisks.** You may be tempted to surround parameter names
    with double backticks (``param``). We avoid that in favor of*param*, in order to distinguish between param-
    eter references and inline code (which _should_ be surrounded by double backticks).
- **EdgeDB is singular.** Choose “EdgeDB is” over “EdgeDB are” and “EdgeDB does” over “EdgeDB do.”
- **Use American English spellings.** Choose “color” over “colour” and “organize” over “organise.”
- **Use the Oxford comma.** When delineating a series, place a comma between each item in the series, even the
    one with the conjunction. Use “eggs, bacon, and juice” rather than “eggs, bacon and juice.”
- **Write in the simplest prose that is still accurate and expresses everything you need to convey.** You may be
    tempted to write documentation that sounds like a computer science textbook. Sometimes that’s necessary, but
    in most cases, it isn’t. Prioritize accuracy first and accessibility a close second.
- **Be careful using words that have a special meaning in the context of EdgeDB.** In casual speech or writing,
    you might talk about a “set” of something in a generic sense. Using the word this way in EdgeDB documentation
    might easily be interpreted as a reference to EdgeDB’s _sets_. Avoid this kind of casual usage of key terms.

##### 4.5.2.3 Where to Find It

Most of our documentation (including this guide) lives in the edgedb repository in the docs directory.

Documentation for some of our client libraries lives inside the client’s repo. If you don’t find it in the edgedb repo at
docs/clients, you’ll probably find it alongside the client itself. These clients will also have documentation stubs
inside the edgedb repository directing you to the documentation’s location.

The EdgeDB tutorial is part of our web site repository. You’ll find it in the tutorial directory.

Finally, our book for beginners titled Easy EdgeDB lives in its own repo.

**368 Chapter 4. Guides**


##### 4.5.2.4 How to Build It

###### 4.5.2.4.1 edgedb/edgedb

Theedgedbrepository contains all of its documentation in thedocs/directory. Runmake docsto build the docu-
mentation in the edgedb repo. The repository contains aMakefilefor all of Sphinx’s necessary build options. The
documentation will be built todocs/build.

To run tests, first _build EdgeDB locally_. Then runedb test -k doc.

Building the docs from this repo will not give you a high-fidelity representation of what users will see on the web site.
For that, you may want to do a full documentation build.

###### 4.5.2.4.2 Full Documentation Build

A full documentation build requires more setup, but it is the only way to see your documentation exactly as the user will
see it. This is not required, but it can be useful to help us review and approve your request more quickly by avoiding
mistakes that would be easier to spot when they are fully rendered.

To build, clone our website repository and follow the installation instructions. Then runyarn devto start a develop-
ment server which also triggers a build of all the documentation.

**Note:** The watch task builds documentation changes, but it cannot trigger auto-reload in the browser. You will need
to manually reload the browser to see changes made to the documentation.

##### 4.5.2.5 Sphinx and reStructuredText

Our documentation is first built through Sphinx and is written in reStructuredText. If you’re unfamiliar with reStruc-
turedText, the official primer is a good place to start. The official cheatsheet serves as a great companion reference
while you write. Sphinx also offers their own reStructuredText primer.

Sphinx not only builds the documentation but also extends reStructuredText to allow for a more ergonomic experience
when crafting docs.

ReStructuredText is an easy-to-learn markup language built for documentation. Here are the most commonly used
elements across our documentation.

###### 4.5.2.5.1 reStructuredText Basics

**Headings**

ReStructuredText headings are underlined (and sometimes overlined) with various characters. It’s flexible about which
characters map to which heading levels and will automatically assign heading levels to characters based on the hierarchy
of the document.

To make it easier to quickly discern the level of a heading across our documentation, we use a consistent hierarchy
across all pages.

1. =under and over- Used for the top-level heading which is usually the page title.
2. =under only
3. -

**4.5. Contributing 369**


4. ^

**Example**

==========
Page Title
==========

Section
=======

Sub-Section
-----------

Sub-Sub-Section
^^^^^^^^^^^^^^^

If you need additional heading levels, you may use the.. rubric::directive and pass it your heading by adding the
heading text on the same line.

**Example**

.. rubric:: Yet Another Heading

**Inline Formatting**

Text can be _italicized_ by surrounding it with asterisks.

*italicized*

**Bold** text by surrounding it with double asterisks.

**Bold**

**Labels and Links**

Labels make it easy to link across our documentation.

.. _ref_eql_select_objects:

All pages must have a label at the top, but inner labels are added only when we need to link to them. Feel free to add a
label to a section you need to link to. Follow the convention of_ref_<main-section>_<page>_<section>when
naming labels. Check the page’s main label at the top if you’re not sure how to name your label. Append an underscore
and the name of the section to the page’s label. If you create a page, make sure you add a main label to the top of it.

Create internal links using the:ref:role. First find the label you want to link to. Reference the label’s name in your
role inside backticks (\`) removing the leading underscore as in the example below.

**Example**

:ref:`ref_eql_select_objects`

**Rendered**

_Selecting objects_

**370 Chapter 4. Guides**


The label being linked can be on the same page as the link or on an entirely different page. Sphinx will find the label
and link to the appropriate page and section.

You may also customize the link text.

**Example**

:ref:`our documentation on selecting objects <ref_eql_select_objects>`

**Rendered**

_our documentation on selecting objects_

To link to documentation for EdgeQL functions, statements, types, operators, or keywords, see the instructions in
_Documenting EdgeQL_.

**Special Paragraphs**

Call out a paragraph as a note or warning using the appropriate directives.

**Example**

.. note::

```
This paragraphis a note.
```
**Rendered**

**Note:** This paragraph is a note.

**Example**

.. warning::

```
This paragraphis a warning.
```
**Rendered**

```
Warning: This paragraph is a warning.
```
You may also add a title to any of these paragraphs by passing it to the directive by placing it on the same line.

**Example**

.. note:: A Note

```
This paragraphis a note.
```
**Rendered**

**Note:** A Note

This paragraph is a note.

**4.5. Contributing 371**


**Reusing Documentation**

If you have documentation that will be reused in multiple contexts, you can write it in a separate.rstfile and include
that file everywhere it should appear.

.. include:: ../stdlib/constraint_table.rst

**Tables and Lists**

We use tables and lists in a few different contexts.

**Example**

.. list-table::

```
* - Arrays
```
- ``array<str>``
* - Tuples (unnamed)
- ``tuple<str, int64, bool>``
* - Tuples (named)
- ``tuple<name: str, age: int64, is_awesome: bool>``
* - Ranges
- ``range<float64>``

**Rendered**

```
Arrays array<str>
Tuples (unnamed) tuple<str, int64, bool>
Tuples (named) tuple<name: str, age: int64, is_awesome: bool>
Ranges range<float64>
```
**Example**

.. list-table::
:class: seealso

```
* - **See also**
* - :ref:`Schema > Access policies <ref_datamodel_access_policies>`
* - :ref:`SDL > Access policies <ref_eql_sdl_access_policies>`
```
**Rendered**

```
See also
Schema > Access policies
SDL > Access policies
```
**Note:** Theseealsoclass adds a spacer above the table to push the table away from the main page content.

**Example**

**372 Chapter 4. Guides**


====================================== =============================
Syntax Inferred type
====================================== =============================
:eql:code:`select 3;` :eql:type:`int64`
:eql:code:`select 3.14;` :eql:type:`float64`
:eql:code:`select 314e-2;` :eql:type:`float64`
:eql:code:`select 42n;` :eql:type:`bigint`
:eql:code:`select 42.0n;` :eql:type:`decimal`
:eql:code:`select 42e+100n;` :eql:type:`decimal`
====================================== =============================

**Rendered**

```
Syntax Inferred type
select 3; int64
select 3.14; float64
select 314e-2; float64
select 42n; bigint
select 42.0n; decimal
select 42e+100n; decimal
```
###### 4.5.2.5.2 Sphinx Basics

**Tables of Contents**

Sphinx requires that every page in the documentation be referenced from a table of contents. Use the.. toctree::
directive to create a table of contents.

**Example**

.. toctree::
:maxdepth: 3
:hidden:

```
code
documentation
```
Most of our tables of contents use the roles you see in this example to set a maximum depth of 3 and to hide the table
of contents. This is not required though if other options make sense in your context. Even though the tables are hidden,
their content still gets rendered in the left sidebar navigation.

We generally use relative references in thetoctreedirective which reference the pages relative to the location of
the page that contains the directive. The order of the references in the directive determines their order in the sidebar
navigation.

If any document is not included in anytoctree, it will cause Sphinx to error on the build unless you add the:orphan:
role to the top of the page. We don’t want to use this technique for most pages although there are exceptions.

**4.5. Contributing 373**


##### 4.5.2.6 Rendering Code

Use these tools to render code in your documentation contribution.

###### 4.5.2.6.1 Inline Code

Render inline code by surrounding it with double backticks:

**Example**

With the help of a``with``block, we can add filters, ordering, and
pagination clauses.

**Rendered**

With the help of awithblock, we can add filters, ordering, and pagination clauses.

```
Warning: Marking up inline code with single backticks a la Markdown will throw an error in Sphinx when
building the documentation.
```
###### 4.5.2.6.2 Code Blocks

.. code-block:: [<language>]

```
<code goes here>
```
Render a block of code. You can optionally provide a language argument. Below are the most common languages used
in our docs:

- bash- Include the prompt and optionally the output. When a user clicks the “copy” button to copy the code, it
    will copy only the input without the prompt and output.
    **Example**

```
.. code-block:: bash
```
```
$ edgedb configure set listen_addresses 127.0.0.1 ::1
```
```
Rendered
```
```
$ edgedb configure set listen_addresses 127.0.0.1 ::1
```
- edgeql- Used for queries.
    **Example**

```
.. code-block:: edgeql
```
```
select BlogPost filter .id = <uuid>$blog_id;
```
```
Rendered
```
```
select BlogPostfilter.id = <uuid>$blog_id;
```
**374 Chapter 4. Guides**


- edgeql-repl- An alternative to vanillaedgeql. Include the prompt and optionally the output. When a user
    clicks the “copy” button to copy the code, it will copy only the input without the prompt and output.
    **Example**

```
.. code-block:: edgeql-repl
```
```
db> insert Person { name := <str>$name };
Parameter <str>$name: Pat
{default::Person {id: e9009b00-8d4e-11ed-a556-c7b5bdd6cf7a}}
```
```
Rendered
```
```
db>insertPerson { name := <str>$name };
Parameter <str>$name: Pat
{default::Person {id: e9009b00-8d4e-11ed-a556-c7b5bdd6cf7a}}
```
- go
- javascript
- python
    **Example**

```
.. code-block:: javascript
```
```
awaitclient.query("select'I '++ <str>$name ++'!';", {
name: "rock and roll"
});
```
```
Rendered
```
```
awaitclient.query("select'I ' ++ <str>$name ++'!';", {
name: "rock and roll"
});
```
- sdl- Used for defining schema.
    **Example**

```
.. code-block:: sdl
```
```
module default {
type Person {
required property name -> str { constraint exclusive };
}
}
```
```
Rendered
```
```
module default{
type Person {
required propertyname -> str {constraint exclusive };
}
}
```
**4.5. Contributing 375**


- <language>-diff- Shows changes in a code block. Each line of code in these blocks must be prefixed by a
    character:+for an added line,-for a removed line, or an empty space for an unchanged line.
    **Example**

```
.. code-block:: sdl-diff
```
```
type Movie {
```
- property title -> str;
+ required property title -> str;
    multi link actors -> Person;
}

```
Rendered
```
```
type Movie {
```
- property title -> str;
+ required property title -> str;
    multi link actors -> Person;
}
- No language- Formats the text as a code block but without syntax highlighting. Use this for syntaxes that do not
offer highlighting or in cases where highlighting is unnecessary.
**Example**

```
.. code-block::
```
```
[
{"id": "ea7bad4c-35d6-11ec-9519-0361f8abd380"},
{"id": "6ddbb04a-3c23-11ec-b81f-7b7516f2a868"},
{"id": "b233ca98-3c23-11ec-b81f-6ba8c4f0084e"},
]
```
```
Rendered
```
```
[
{"id": "ea7bad4c-35d6-11ec-9519-0361f8abd380"},
{"id": "6ddbb04a-3c23-11ec-b81f-7b7516f2a868"},
{"id": "b233ca98-3c23-11ec-b81f-6ba8c4f0084e"},
]
```
```
Note: Code blocks without a language specified do not have a “copy” button.
```
**376 Chapter 4. Guides**


###### 4.5.2.6.3 Code Tabs

.. tabs::

Tabs are used to present code examples in multiple languages. This can be useful when you want to show a query in,
for example, both EdgeQL and the TypeScript query builder.

**Example**

.. tabs::

```
.. code-tab:: edgeql
```
```
insert Movie {
title :='Doctor Strange 2',
release_year := 2022
};
```
```
.. code-tab:: typescript
```
```
const query = e.insert(e.Movie, {
title: 'Doctor Strange 2',
release_year: 2022
});
```
```
const result =await query.run(client);
```
**Rendered**

```
Listing 1: edgeql
```
insert Movie {
title := 'Doctor Strange 2',
release_year := 2022
};

**4.5. Contributing 377**


```
Listing 2: typescript
```
constquery = e.insert(e.Movie, {
title: 'Doctor Strange 2',
release_year: 2022
});

constresult =await query.run(client);

##### 4.5.2.7 Documenting EdgeQL

Tools to help document EdgeQL are in the:eql:domain.

###### 4.5.2.7.1 Functions

To document a function use a.. eql:function::directive. Include these elements:

- Specify the full function signature with a fully qualified name on the same line as the directive.
- Add a description of each parameter using:param $<name>: description:. _$<name>_ must match the the
    name of the parameter in function’s signature. If a parameter is positional rather than named, its number should
    be used instead (e.g.$1).
- Add a type for each parameter using:paramtype $<name>: <type>. For example::paramtype $<name>:
    int64declares that the type of the _$<name>_ parameter isint64. If a parameter has more than one valid type,
    list them separated by “or” like this::paramtype $<name>: int64 or str.
- Document the return value of the function with:return:and:returntype:.:return:marks a description
    of the return value and:returntype:its type.
- Finish with a few descriptive paragraphs and code samples. The first paragraph must be a single sentence no
    longer than 79 characters describing the function.

**Example**

.. eql:function:: std::array_agg(set of any, $a: any) -> array<any>

```
:param $1: input set
:paramtype $1: set of any
```
```
:param $a: description of this param
:paramtype $a: int64 or str
```
```
:return: array made of input set elements
:returntype: array<any>
```
```
Return the array made from all of the input set elements.
```
```
The ordering of the input set will be preserved if specified.
```
You can link to a function’s documentation by using the:eql:func:role. For instance:

- :eql:func:`array_agg`;
- :eql:func:`std::array_agg`;

**378 Chapter 4. Guides**


These will link to a function using the function’s name as you have written in between the backticks followed by
parentheses. Here are the above links rendered:

- array_agg();
- std::array_agg();

You can customize a link’s label with this syntax::eql:func:`aggregate a set as an array <array_agg>`.
Here’s the rendered output:aggregate a set as an array

###### 4.5.2.7.2 Operators

Use the.. eql:operator::directive to document an operator. On the same line as the directive, provide a string
argument of the format<operator-id>: <operator-signature>

Add a:optype <operand-name>: <type>field for each of the operator signature’s operands to declare their types.

**Example**

.. eql:operator:: PLUS: A + B

```
:optype A: int64or stror bytes
:optype B: any
:resulttype: any
```
```
Arithmetic addition.
```
You can link to an operator’s documentation by using the:eql:op:role, followed by the operator’s ID you specified in
your argument to.. eql:operator::. For instance::eql:op:`plus`which renders asplus. You can customize
the link label like this::eql:op:`+ <plus>`, which renders as+.

###### 4.5.2.7.3 Statements

Use the:eql-statement:field to sections that describe a statement. Add the:eql-haswith:field if the statement
supports awithblock.

Select
======

:eql-statement:
:eql-haswith:

``select``--retrieve or compute a set of values.

.. eql:synopsis::

```
[ with <with-item> [, ...] ]
```
```
select <expr>
```
```
[ filter <filter-expr> ]
```
```
[ order by <order-expr> [direction] [then ...] ]
```
```
(continues on next page)
```
**4.5. Contributing 379**


```
(continued from previous page)
[ offset <offset-expr> ]
```
```
[ limit <limit-expr> ] ;
```
After laying out the formal syntax, describe the function of each clause with a synopsis like this:

:eql:synopsis:`filter <filter-expr>`
The optional``filter``clause, where :eql:synopsis:`<filter-expr>`
is any expression that has a result of type :eql:type:`bool`.
The condition is evaluated for every element in the set produced by
the``select``clause. The result of the evaluation of the
``filter``clause is a set of boolean values. If at least one value
in this set is``true``, the input element is included, otherwise
it is eliminated from the output.

These descriptions can each contain as many paragraphs as needed to adequately describe the clause. Follow the format
used in the PostgreSQL documentation. See the PostgreSQL SELECT statement reference page for an example.

Use:eql:stmt:`select`to link to the statement’s documentation. When rendered the link looks like this:select.
Customize the label with:eql:stmt:`the select statement <select>`which renders as this:the select
statement.

###### 4.5.2.7.4 Types

To document a type, use the.. eql:type::directive. Follow the directive with the fully-qualified name of the type
on the same line. The block should contain the type’s description.

.. eql:type:: std::bytes

```
A sequence of bytes.
```
To link to a type’s documentation, use:eql:type:`bytes`which renders asbytes. You may use the fully qualified
name in your reference —:eql:type:`std::bytes`— which renders asstd::bytes. Both forms reference the
same location in the documentation. Link labels can be customized with:eql:type:`the bytes type <bytes>`
which renders like this:the bytes type.

###### 4.5.2.7.5 Keywords

Document a keyword using the.. eql:keyword::directive.

.. eql:keyword:: with

```
The``with`` block in EdgeQL is used to define aliases.
```
If a keyword is compound use a hyphen between each word.

.. eql:keyword:: set-of

To link to a keyword’s documentation, use the:eql:kw: role like this::eql:kw:`detached`which renders as
detached. You can customize the link label like this::eql:kw:`the "detached" keyword <detached>`which
renders asthe "detached" keyword.

**380 Chapter 4. Guides**


##### 4.5.2.8 Documenting the EdgeQL CLI

Document a CLI command using thecli:synopsisdirective like this:

**Example**

.. cli:synopsis::

```
edgedb dump [<options>] <path>
```
**Rendered**

edgedb dump [<options>] <path>

The synopsis should follow the format used in the PostgreSQL documentation. See the PostgreSQL SELECT statement
reference page for an example.

You can then document arguments and options using the:cli:synopsis:role.

**Example**

:cli:synopsis:`<path>`
The name of the file to backup the database into.

**Rendered**

<path>The name of the file to backup the database into.

##### 4.5.2.9 Documentation Versioning

Since EdgeDB functionality is mostly consistent across versions, we offer a simple method of versioning documentation
using two directives.

```
Warning: Although these are directives included in Sphinx, we have customized them to behave differently. Please
read this documentation even if you’re already familiar with the Sphinx directives mentioned here.
```
###### 4.5.2.9.1 New in Version

Content addressing anything new in a given version are marked with theversionaddeddirective. Provide the appli-
cable version as an argument by placing it just after the directive on the same line.

The directive behaves differently depending on the context.

- When the directive has content (i.e., an indented paragraphs below the directive), that content will be shown or
    hidden based on the version switch.
- When the directive is placed immediately after a section header or inside a description block for a function, type,
    operator, statement, or keyword, that entire section or block is marked to be shown or hidden based on the version
    selected.
- When the directive is placed on the top line of any page before any content or reStructuredText labels (e.g.,..
    _ref_eql_select:), it applies to the entire page.

**Example with Content**

**4.5. Contributing 381**


.. versionadded:: 2.0

```
Thisis a new feature that was addedin EdgeDB 2.0.
```
**Rendered**

This is a new feature that was added in EdgeDB 2.0.

**Note:** Change the version in the version selector dropdown to see how the rendered example changes.

**Section Example**

Source deletion
^^^^^^^^^^^^^^^

.. versionadded:: 2.0

Source deletion policies determine what action should be taken when the
*source* of a given link is deleted. They are declared with the``on source
delete`` clause.
...

**Rendered**

See _the “Source deletion” section of the “Links” documentation_ for a rendered section example of ..
versionadded:: 2.0.

**Description Block Example**

.. eql:type:: cal::date_duration

```
.. versionadded:: 2.0
```
```
A type forrepresenting a span of time in days.
```
**Rendered**

Seecal::date_durationfor a rendered description block example of.. versionadded:: 2.0.

**Full-Page Example**

.. versionadded:: 2.0

.. _ref_datamodel_globals:

=======
Globals
=======
...

**Rendered**

See _the “Globals” documentation page_ for a full-page example of.. versionadded:: 2.0.

**382 Chapter 4. Guides**


###### 4.5.2.9.2 Changed in Version

Use theversionchangeddirective to mark content related to a change in existing functionality across EdgeDB ver-
sions. Provide the applicable version as an argument by placing it just after the directive on the same line.

Unlikeversionadded,versionchangedis always used with content to show or hide that content based on the user’s
selection in the version dropdown.

**Example**

.. versionchanged:: 3.0

```
Startingwiththe upcoming EdgeDB 3.0, access policy restrictions will
**not** apply to any access policy expression. This means that when
reasoning about access policies itis no longer necessary to take other
policies into account. Instead, all datais visibleforthe purpose of
*defining* an access policy.
```
**Rendered**

Starting with the upcoming EdgeDB 3.0, access policy restrictions will **not** apply to any access policy expression. This
means that when reasoning about access policies it is no longer necessary to take other policies into account. Instead,
all data is visible for the purpose of _defining_ an access policy.

**Note:** Change the version in the version selector dropdown to see how the rendered example changes.

##### 4.5.2.10 Other Useful Tricks

###### 4.5.2.10.1 Temporarily Disabling Linting

.. lint-offand.. lint-ontoggle linting off or on. In general, linting should stay on except in cases where it’s
impossible to keep it on. This might be when code or a URL must exceed the maximum line length of 79 characters.

You would typically use this by toggling linting off with.. lint-offjust before the offending block and back on
with.. lint-onafter the block.

**Example**

.. lint-off

.. code-block::

```
GET http://localhost:<port>/db/edgedb/edgeql?query=insert%20Person%20%7B%20name%20%3A
˓→%3D%20%3Cstr%3E$name%20%7D%3B&variables=%7B%22name%22%3A%20%22Pat%22%7D
```
.. lint-on

**Note:** This is actually a comment our linter pays attention to rather than a directive. As a result, it does not end with
a colon (:) like a directive would.

**Note:** This does not render any visible output.

**4.5. Contributing 383**


###### 4.5.2.10.2 Embedding a YouTube Video

Embed only videos from the EdgeDB YouTube channel

.. lint-off

.. raw:: html

```
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;␣
˓→max-width: 100%; height: auto;">
<iframe src="https://www.youtube.com/embed/OZ_UURzDkow" frameborder="0"␣
˓→allowfullscreen style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;
˓→"></iframe>
</div>
```
.. lint-on

###### 4.5.2.10.3 Displaying Illustrations

Using the.. eql:section-intro-page::directive, you can display one of several illustrations. Pass the name of
the illustration to the directive by placing it after the directive on the same line.

**Example**

.. eql:section-intro-page:: edgeql

**Rendered**

See the list of illustration names and view the images they map to.

To make sure the project can continue to improve quickly, we have a few guidelines designed to make it easier for your
contributions to make it into the project. General guidelines are presented here. You will find guidelines relevant only
to code or documentation in those sections of the guide.

These are guidelines rather than hard rules. If you want to submit a pull request that strays from these, it might be a
good idea to start a discussion about it first. Otherwise, it’s possible your pull request might not be merged.

#### 4.5.3 General Guidelines

- **Avoid making pull requests that do not have an associated Github Issue.** This could be an already existing
    issue or one you create yourself when you discover the problem. This will allow the team to help you scope your
    solution, warn you of potential gotchas, or give you a heads-up on solutions that are likely not feasible. It’s a good
    idea to mention in the issue that you’d like to contribute code to resolve the issue. **If you’re fixing something**
    **trivial like a typo,** an associated issue isn’t necessary.
- **Write good commit messages.** The subject of your commit message — that’s the first line — should tell us
    _what_ you did. The body of your message — that’s the rest of it — should tell us _why_ you did it (unless that’s
    self-evident).

**384 Chapter 4. Guides**


#### 4.5.4 Thank You!

Thank you for contributing to EdgeDB! We love our open source community and want to foster a healthy contributor
ecosystem. We’re happy to have you as a part of it.

**4.5. Contributing 385**


**386 Chapter 4. Guides**


```
CHAPTER
```
### FIVE

### STANDARD LIBRARY

### 5.1 Generic

```
edb-alt-title Generic Functions and Operators
```
```
anytype = anytype Compares two values for equality.
anytype != anytype Compares two values for inequality.
anytype ?= anytype Compares two (potentially empty) values for equality.
anytype ?!= anytype Compares two (potentially empty) values for inequality.
anytype < anytype Less than operator.
anytype > anytype Greater than operator.
anytype <= anytype Less or equal operator.
anytype >= anytype Greater or equal operator.
len() Returns the number of elements of a given value.
contains() Returns true if the given sub-value exists within the given value.
find() Returns the index of a given sub-value in a given value.
```
**Note:** In EdgeQL, any value can be compared to another as long as their types are compatible.

operator anytype = anytype -> bool
Compares two values for equality.

```
db>select3 = 3.0;
{true}
db>select3 = 3.14;
{false}
db>select[1, 2] = [1, 2];
{true}
db>select(1, 2) = (x := 1, y := 2);
{true}
db>select(x := 1, y := 2) = (a := 1, b := 2);
{true}
db>select'hello'= 'world';
{false}
```
```
387
```

operator anytype != anytype -> bool
Compares two values for inequality.

```
db>select3 != 3.0;
{false}
db>select3 != 3.14;
{true}
db>select[1, 2] != [2, 1];
{false}
db>select(1, 2) != (x := 1, y := 2);
{false}
db>select(x := 1, y := 2) != (a := 1, b := 2);
{false}
db>select'hello'!= 'world';
{true}
```
operator optional anytype ?= optional anytype -> bool
Compares two (potentially empty) values for equality.
This works the same as a regular=operator, but also allows comparing an empty{}set. Two empty sets are
considered equal.

```
db>select{1} ?= {1.0};
{true}
db>select{1} ?= <int64>{};
{false}
db>select<int64>{} ?= <int64>{};
{true}
```
operator optional anytype ?!= optional anytype -> bool
Compares two (potentially empty) values for inequality.
This works the same as a regular=operator, but also allows comparing an empty{}set. Two empty sets are
considered equal.

```
db>select{2} ?!= {2};
{false}
db>select{1} ?!= <int64>{};
{true}
db>select<bool>{} ?!= <bool>{};
{false}
```
operator anytype < anytype -> bool
Less than operator.
The operator returnstrueif the value of the left expression is less than the value of the right expression:

```
db>select1 < 2;
{true}
db>select2 < 2;
{false}
(continues on next page)
```
**388 Chapter 5. Standard Library**


```
(continued from previous page)
db>select'hello'< 'world';
{true}
db>select(1,'hello') < (1,'world');
{true}
```
operator anytype > anytype -> bool
Greater than operator.
The operator returnstrueif the value of the left expression is greater than the value of the right expression:

```
db>select1 > 2;
{false}
db>select3 > 2;
{true}
db>select'hello'> 'world';
{false}
db>select(1,'hello') > (1,'world');
{false}
```
operator anytype <= anytype -> bool
Less or equal operator.
The operator returnstrueif the value of the left expression is less than or equal to the value of the right expres-
sion:

```
db>select1 <= 2;
{true}
db>select2 <= 2;
{true}
db>select3 <= 2;
{false}
db>select'hello'<= 'world';
{true}
db>select(1,'hello') <= (1,'world');
{true}
```
operator anytype >= anytype -> bool
Greater or equal operator.
The operator returnstrueif the value of the left expression is greater than or equal to the value of the right
expression:

```
db>select1 >= 2;
{false}
db>select2 >= 2;
{true}
db>select3 >= 2;
{true}
db>select'hello'>= 'world';
(continues on next page)
```
**5.1. Generic 389**


```
(continued from previous page)
{false}
db>select(1,'hello') >= (1,'world');
{false}
```
function std::len→int64
function std::len→int64
function std::len→int64

```
Index Keywords length count array
Returns the number of elements of a given value.
This function works with thestr,bytesandarraytypes:
```
```
db>selectlen('foo');
{3}
```
```
db>selectlen(b'bar');
{3}
```
```
db>selectlen([2, 5, 7]);
{3}
```
function std::contains→bool
function std::contains→bool
function std::contains→bool
function std::contains→std::bool
function std::contains→std::bool

```
Index Keywords find strpos strstr position array
Returns true if the given sub-value exists within the given value.
When haystack is astror abytesvalue, this function will returntrueif it contains needle as a subsequence
within it orfalseotherwise:
```
```
db>selectcontains('qwerty', 'we');
{true}
```
```
db>selectcontains(b'qwerty', b' 42 ');
{false}
```
```
When haystack is anarray, the function will returntrueif the array contains the element specified as needle
orfalseotherwise:
```
```
db>selectcontains([2, 5, 7, 2, 100], 2);
{true}
```
```
When haystack is a range , the function will returntrueif it contains either the specified sub-range or element.
The function will returnfalseotherwise.
```
**390 Chapter 5. Standard Library**


```
db>selectcontains(range(1, 10), range(2,5));
{true}
```
```
db>selectcontains(range(1, 10), range(2,15));
{false}
```
```
db>selectcontains(range(1, 10), 2);
{true}
```
```
db>selectcontains(range(1, 10), 10);
{false}
```
function std::find→int64
function std::find→int64
function std::find→int64

```
Index Keywords find strpos strstr position array
Returns the index of a given sub-value in a given value.
When haystack is astror abytesvalue, the function will return the index of the first occurrence of needle in
it.
When haystack is anarray, this will return the index of the the first occurrence of the element passed as needle.
Forarrayinputs it is also possible to provide an optional from_pos argument to specify the position from which
to start the search.
If the needle is not found, return-1.
```
```
db>selectfind('qwerty', 'we');
{1}
```
```
db>selectfind(b'qwerty', b' 42 ');
{-1}
```
```
db>selectfind([2, 5, 7, 2, 100], 2);
{0}
```
```
db>selectfind([2, 5, 7, 2, 100], 2, 1);
{3}
```
### 5.2 Sets

```
edb-alt-title Set Functions and Operators
index set aggregate
```
**5.2. Sets 391**


```
distinct set Produces a set of all unique elements in the given set.
anytype in set Checks if a given element is a member of a given set.
set union set Merges two sets.
set intersect set Produces a set containing the common items between the given sets.
set except set Produces a set of all items in the first set which are not in the second.
exists set Determines whether a set is empty or not.
set if bool else set Produces one of two possible results based on a given condition.
optional anytype ?? set Produces the first of its operands that is not an empty set.
detached Detaches the input set reference from the current scope.
anytype [is type] Filters a set based on its type. Will return back the specified type.
assert_distinct() Checks that the input set contains only unique elements.
assert_single() Checks that the input set contains no more than one element.
assert_exists() Checks that the input set contains at least one element.
count() Returns the number of elements in a set.
array_agg() Returns an array made from all of the input set elements.
sum() Returns the sum of the set of numbers.
all() Returns true if none of the values in the given set are false.
any() Returns true if any of the values in the given set is true.
enumerate() Returns a set of tuples in the form of (index, element).
min() Returns the smallest value in the given set.
max() Returns the largest value in the given set.
math::mean() Returns the arithmetic mean of the input set.
math::stddev() Returns the sample standard deviation of the input set.
math::stddev_pop() Returns the population standard deviation of the input set.
math::var() Returns the sample variance of the input set.
math::var_pop() Returns the population variance of the input set.
```
operator distinct set of anytype -> set of anytype
Produces a set of all unique elements in the given set.
distinctis a set operator that returns a new set where no member is equal to any other member.

```
db>select distinct {1, 2, 2, 3};
{1, 2, 3}
```
operator anytype in set of anytype -> bool
operator anytype not in set of anytype -> bool

```
Index Keywords intersection
Checks if a given element is a member of a given set.
Set membership operatorsinandnot intest whether each element of the left operand is present in the right
operand. This means supplying a set as the left operand will produce a set of boolean results, one for each element
in the left operand.
```
```
db>select 1 in {1, 3, 5};
{true}
```
```
db>select'Alice'in User.name;
(continues on next page)
```
**392 Chapter 5. Standard Library**


```
(continued from previous page)
{true}
```
```
db>select{1, 2} in {1, 3, 5};
{true, false}
```
```
This operator can also be used to implement set intersection:
```
```
db>with
... A := {1, 2, 3, 4},
... B := {2, 4, 6}
...selectA filter Ain B;
{2, 4}
```
operator set of anytype union set of anytype -> set of anytype
Merges two sets.
Since EdgeDB sets are formally multisets,unionis a _multiset sum_ , so effectively it merges two multisets keeping
all of their members.
For example, applyingunionto{1, 2, 2}and{2}, results in{1, 2, 2, 2}.
If you need a distinct union, wrap it with thedistinctoperator.

operator
set of anytype intersect set of anytype -> set of anytype
Produces a set containing the common items between the given sets.

```
Note: The ordering of the returned set may not match that of the operands.
```
```
If you need a distinct intersection, wrap it with thedistinctoperator.
```
operator
set of anytype except set of anytype -> set of anytype
Produces a set of all items in the first set which are not in the second.

```
Note: The ordering of the returned set may not match that of the operands.
```
```
If you need a distinct set of exceptions, wrap it with thedistinctoperator.
```
operator
set of anytype if bool else set of anytype -> set of anytype

```
Index Keywords if else ifelse elif ternary
Produces one of two possible results based on a given condition.
```
```
<left_expr>if <condition>else <right_expr>
```
**5.2. Sets 393**


```
If the<condition>istrue, theif...elseexpression produces the value of the<left_expr>. If the
<condition>isfalse, however, theif...elseexpression produces the value of the<right_expr>.
```
```
db>select'hello'if 2 * 2 = 4 else'bye';
{'hello'}
```
```
if..elseexpressions can be chained when checking multiple conditions is necessary:
```
```
db>withcolor :='yellow'
...select'Apple'if color ='red' else
... 'Banana' if color ='yellow'else
... 'Orange' if color ='orange'else
... 'Other';
{'Banana'}
```
operator optional anytype ?? set of anytype -> set of anytype
Produces the first of its operands that is not an empty set.
This evaluates toAfor an non-emptyA, otherwise evaluates toB.
A typical use case of the coalescing operator is to provide default values for optional properties:

```
# Get a set of tuples (<issue name>, <priority>)
# for all issues.
select (Issue.name, Issue.priority.name ??'n/a');
```
```
Without the coalescing operator, the above query will skip anyIssuewithout priority.
```
operator detached set of anytype -> set of anytype
Detaches the input set reference from the current scope.
Adetachedexpression allows referring to some set as if it were defined in the top-levelwithblock.detached
expressions ignore all current scopes in which they are nested. This makes it possible to write queries that
reference the same set reference in multiple places.

```
update User
filter .name ='Dave'
set{
friends := (select detachedUserfilter .name ='Alice'),
coworkers := (select detached Userfilter .name ='Bob')
};
```
```
Withoutdetached, the occurrences ofUserinside thesetshape would be bound to the set of users named
"Dave". However, in this context we want to run an unrelated query on the “unbound”Userset.
```
```
# does not work!
update User
filter .name ='Dave'
set{
friends := (selectUserfilter .name ='Alice'),
coworkers := (select Userfilter.name ='Bob')
};
```
**394 Chapter 5. Standard Library**


```
Instead of explicitly detaching a set, you can create a reference to it in awithblock. All declarations inside a
withblock are implicitly detached.
```
```
withU1 := User,
U2 := User
update User
filter .name ='Dave'
set{
friends := (selectU1 filter .name ='Alice'),
coworkers := (select U2filter .name ='Bob')
};
```
operator exists set of anytype -> bool
Determines whether a set is empty or not.
existsis an aggregate operator that returns a singleton set{true}if the input set is not empty, and returns
{false}otherwise:

```
db>select exists{1, 2};
{true}
```
operator anytype [is type] -> anytype

```
Index Keywords is type intersection
Filters a set based on its type. Will return back the specified type.
The type intersection operator removes all elements from the input set that aren’t of the specified type. Addition-
ally, since it guarantees the type of the result set, all the links and properties associated with the specified type
can now be used on the resulting expression. This is especially useful in combination with backlinks.
Consider the following types:
```
```
typeUser {
required propertyname -> str;
}
```
```
abstract type Owned {
required linkowner -> User;
}
```
```
typeIssueextending Owned {
required propertytitle -> str;
}
```
```
typeCommentextending Owned {
required propertybody -> str;
}
```
```
typeUser {
requiredname: str;
}
```
```
(continues on next page)
```
**5.2. Sets 395**


```
(continued from previous page)
abstract type Owned {
requiredowner: User;
}
```
```
typeIssueextending Owned {
requiredtitle: str;
}
```
```
typeCommentextending Owned {
requiredbody: str;
}
```
```
The following expression will get allObjectsowned by all users (if there are any):
```
```
select User.<owner;
```
```
By default, backlinks don’t infer any type information beyond the fact that it’s anObject. To ensure that this
path specifically reachesIssue, the type intersection operator must then be used:
```
```
select User.<owner[is Issue];
```
```
# With the use of type intersection it's possible to refer to
# specific property of Issue now:
select User.<owner[is Issue].title;
```
function std::assert_distinct→set of anytype

```
Index Keywords multiplicity uniqueness
Checks that the input set contains only unique elements.
If the input set contains duplicate elements (i.e. it is not a proper set ), assert_distinct raises a
ConstraintViolationError. Otherwise, this function returns the input set.
This function is useful as a runtime distinctness assertion in queries and computed expressions that should always
return proper sets, but where static multiplicity inference is not capable enough or outright impossible. An
optional message named argument can be used to customize the error message:
```
```
db>selectassert_distinct(
... (selectUserfilter .groups.name = "Administrators")
... union
... (selectUserfilter .groups.name = "Guests")
... )
{default::User {id: ...}}
```
```
db>selectassert_distinct(
... (selectUserfilter .groups.name = "Users")
... union
... (selectUserfilter .groups.name = "Guests")
... )
ERROR: ConstraintViolationError: assert_distinct violation:expression
returned aset withduplicate elements.
```
```
(continues on next page)
```
**396 Chapter 5. Standard Library**


```
(continued from previous page)
db>selectassert_distinct(
... (selectUserfilter .groups.name = "Users")
... union
... (selectUserfilter .groups.name = "Guests"),
... message := "duplicate users!"
... )
ERROR: ConstraintViolationError: duplicate users!
```
function std::assert_single→set of anytype

```
Index Keywords cardinality singleton
Checks that the input set contains no more than one element.
If the input set contains more than one element,assert_singleraises aCardinalityViolationError.
Otherwise, this function returns the input set.
This function is useful as a runtime cardinality assertion in queries and computed expressions that should always
return sets with at most a single element, but where static cardinality inference is not capable enough or outright
impossible. An optional message named argument can be used to customize the error message.
```
```
db>selectassert_single((select Userfilter.name = "Unique"))
{default::User {id: ...}}
```
```
db>selectassert_single((select User))
ERROR: CardinalityViolationError: assert_single violation: more than
one element returnedby an expression
```
```
db>selectassert_single((select User), message := "too many users!")
ERROR: CardinalityViolationError: too many users!
```
function std::assert_exists→set of anytype

```
Index Keywords cardinality existence empty
Checks that the input set contains at least one element.
If the input set is empty,assert_existsraises aCardinalityViolationError. Otherwise, this function
returns the input set.
This function is useful as a runtime existence assertion in queries and computed expressions that should always
return sets with at least a single element, but where static cardinality inference is not capable enough or outright
impossible. An optional message named argument can be used to customize the error message.
```
```
db>selectassert_exists((select Userfilter.name = "Administrator"))
{default::User {id: ...}}
```
```
db>selectassert_exists((select Userfilter.name = "Nonexistent"))
ERROR: CardinalityViolationError: assert_exists violation:expression
returned anempty set.
```
```
db>selectassert_exists(
... (selectUserfilter .name = "Nonexistent"),
(continues on next page)
```
**5.2. Sets 397**


```
(continued from previous page)
... message := "no users!"
... )
ERROR: CardinalityViolationError: no users!
```
function std::count→int64

```
Index Keywords aggregate
Returns the number of elements in a set.
```
```
db>selectcount({2, 3, 5});
{3}
```
```
db>selectcount(User); # number of User objects in db
{4}
```
function std::sum→int64
function std::sum→int64
function std::sum→float32
function std::sum→float64
function std::sum→bigint
function std::sum→decimal

```
Index Keywords aggregate
Returns the sum of the set of numbers.
The result type depends on the input set type. The general rule of thumb is that the type of the input set is
preserved (as if a simple+was used) while trying to reduce the chance of an overflow (so all integers produce
int64sum).
```
```
db>selectsum({2, 3, 5});
{10}
```
```
db>selectsum({0.2, 0.3, 0.5});
{1.0}
```
function std::all→bool

```
Index Keywords aggregate
Returnstrueif none of the values in the given set arefalse.
The result istrueif all of the values aretrueor the set of values is{}, withfalsereturned otherwise.
```
```
db>select all(<bool>{});
{true}
```
```
db>select all({1, 2, 3, 4} < 4);
{false}
```
**398 Chapter 5. Standard Library**


function std::any→bool

```
Index Keywords aggregate
Returnstrueif any of the values in the given set istrue.
The result istrueif any of the values aretrue, withfalsereturned otherwise.
```
```
db>selectany(<bool>{});
{false}
```
```
db>selectany({1, 2, 3, 4} < 4);
{true}
```
function std::enumerate→set of tuple<int64, anytype>

```
Index Keywords enumerate
Returns a set of tuples in the form of(index, element).
Theenumerate()function takes any set and produces a set of tuples containing the zero-based index number
and the value for each element.
```
```
Note: The ordering of the returned set is not guaranteed, however, the assigned indexes are guaranteed to be in
order of the original set.
```
```
db>selectenumerate({2, 3, 5});
{(1, 3), (0, 2), (2, 5)}
```
```
db>selectenumerate(User.name);
{(0,'Alice'), (1,'Bob'), (2, 'Dave')}
```
function std::min→optional anytype

```
Index Keywords aggregate
Returns the smallest value in the given set.
```
```
db>selectmin({-1, 100});
{-1}
```
function std::max→optional anytype

```
Index Keywords aggregate
Returns the largest value in the given set.
```
```
db>selectmax({-1, 100});
{100}
```
**5.2. Sets 399**


### 5.3 Types

```
edb-alt-title Type Operators
```
```
is type Type checking operator.
type | type Type union operator.
<type> val Type cast operator.
typeof anytype Static type inference operator.
introspect type Static type introspection operator.
```
operator anytype is type -> bool
operator anytype is not type -> bool
Type checking operator.
Check ifAis an instance ofBor any ofB’s subtypes.
Type-checking operatorsisandis notthat test whether the left operand is of any of the types given by the
comma-separated list of types provided as the right operand.
Note thatBis special and is not any kind of expression, so it does not in any way participate in the interactions
of sets and longest common prefix rules.

```
db>select 1 is int64;
{true}
```
```
db>selectUser is notSystemUser
...filterUser.name ='Alice';
{true}
```
```
db>selectUser is(Text|Named);
{true, ..., true} # one for every user instance
```
operator type | type -> type

```
Index Keywords poly polymorphism polymorphic queries nested shapes
Type union operator.
This operator is only valid in contexts where type checking is done. The most obvious use case is with theis
andis not. The operator allows to refer to a union of types in order to check whether a value is of any of these
types.
```
```
db>selectUser is(Text|Named);
{true, ..., true} # one for every user instance
```
```
It can similarly be used when specifying a link target type. The same logic then applies: in order to be a valid
link target the object must satisfyobject is (A | B | C).
```
```
abstract type Named {
required propertyname -> str;
}
```
```
(continues on next page)
```
**400 Chapter 5. Standard Library**


```
(continued from previous page)
abstract type Text{
required propertybody -> str;
}
```
```
typeItemextending Named;
```
```
typeNoteextending Text;
```
```
typeUserextending Named {
multi linkstuff ->Named |Text;
}
```
```
abstract type Named {
requiredname: str;
}
```
```
abstract type Text{
requiredbody: str;
}
```
```
typeItemextending Named;
```
```
typeNoteextending Text;
```
```
typeUserextending Named {
multistuff: Named| Text;
}
```
```
With the above schema, the following would be valid:
```
```
db>insertItem {name := 'cube'};
{Object { id: <uuid>'...' }}
db>insertNote {body := 'some reminder'};
{Object { id: <uuid>'...' }}
db>insertUser {
... name :='Alice',
... stuff := Note, # all the notes
... };
{Object { id: <uuid>'...' }}
db>insertUser {
... name :='Bob',
... stuff := Item, # all the items
... };
{Object { id: <uuid>'...' }}
db>selectUser {
... name,
... stuff: {
... [is Named].name,
... [is Text].body
... }
... };
{
(continues on next page)
```
**5.3. Types 401**


```
(continued from previous page)
Object{
name:'Alice',
stuff: {Object{ name: {}, body:'some reminder'}}
},
Object{
name:'Bob',
stuff: {Object{ name:'cube', body: {} }}
}
}
```
operator < type > anytype -> anytype
Type cast operator.
A type cast operator converts the specified value to another value of the specified type:

```
"<" <type> ">" <expression>
```
```
The<type>must be a valid type expression denoting a non-abstract scalar or a container type.
Type cast is a run-time operation. The cast will succeed only if a type conversion was defined for the type pair,
and if the source value satisfies the requirements of a target type. EdgeDB allows casting any scalar.
It is illegal to cast oneObjectinto another. The only way to construct a newObjectis by usinginsert.
However, thetype intersectioncan be used to achieve an effect similar to casting for Objects.
When a cast is applied to an expression of a known type, it represents a run-time type conversion. The cast will
succeed only if a suitable type conversion operation has been defined.
Examples:
```
```
db># cast a string literal into an integer
...select<int64>"42";
{42}
```
```
db># cast an array of integers into an array of str
...select<array<str>>[1, 2, 3];
{[' 1 ', ' 2 ', ' 3 ']}
```
```
db># cast an issue number into a string
...select<str>example::Issue.number;
{' 142 '}
```
```
Casts also work for converting tuples or declaring different tuple element names for convenience.
```
```
db>select<tuple<int64, str>>(1, 3);
{[1,' 3 ']}
```
```
db>with
... # a test tuple set, that could be a result of
... # some other computation
... stuff := (1,'foo', 42)
...select(
... # cast the tuple into something more convenient
(continues on next page)
```
**402 Chapter 5. Standard Library**


```
(continued from previous page)
... <tuple<a: int64, name: str, b: int64>>stuff
... ).name; # access the'name'element
{'foo'}
```
```
An important use of casting is in defining the type of an empty set{}, which can be required for purposes of
type disambiguation.
```
```
with moduleexample
select Text{
name :=
Text[is Issue].nameIF Text is IssueELSE
<str>{},
# the cast to str is necessary here, because
# the type of the computed expression must be defined
body,
};
```
```
Casting empty sets is also the only situation where casting into anObjectis valid:
```
```
with moduleexample
select User {
name,
friends := <User>{}
# the cast is the only way to indicate that the
# computed link 'friends'is supposed to refer to
# a set of Users
};
```
```
For more information about casting between different types consult the casting table.
```
operator typeof anytype -> type

```
Index Keywords type introspect introspection
Static type inference operator.
This operator converts an expression into a type, which can be used withis,is not, andintrospect.
Currently,typeofoperator only supports scalars and objects , but not the collections as a valid operand.
Consider the following types using links and properties with names that don’t indicate their respective target
types:
```
```
typeFoo {
propertybar -> int16;
linkbaz -> Bar;
}
```
```
typeBarextendingFoo;
```
```
typeFoo {
bar: int16;
baz: Bar;
(continues on next page)
```
**5.3. Types 403**


```
(continued from previous page)
}
```
```
typeBarextendingFoo;
```
```
We can usetypeofto determine if certain expression has the same type as the propertybar:
```
```
db>insertFoo { bar := 1 };
{Object { id: <uuid>'...' }}
db>select(Foo.bar / 2) is typeofFoo.bar;
{false}
```
```
To determine the actual resulting type of an expression we can useintrospect:
```
```
db>select introspect(typeof Foo.bar).name;
{'std::int16'}
db>select introspect(typeof (Foo.bar / 2)).name;
{'std::float64'}
```
```
Similarly, we can usetypeofto discriminate between the differentFooobjects that can and cannot be targets of
linkbaz:
```
```
db>insertBar { bar := 2 };
{Object { id: <uuid>'...' }}
db>selectFoo {
... bar,
... can_be_baz := Foois typeof Foo.baz
... };
{
Object{ bar: 1, can_be_baz: false},
Object{ bar: 2, can_be_baz: true}
}
```
operator introspect type -> schema::Type

```
Index Keywords type typeof introspection
Static type introspection operator.
This operator returns the introspection type corresponding to type provided as operand. It works well in combi-
nation withtypeof.
Currently, theintrospectoperator only supports scalar types and object types , but not the collection types as
a valid operand.
Consider the following types using links and properties with names that don’t indicate their respective target
types:
```
```
typeFoo {
propertybar -> int16;
linkbaz -> Bar;
}
```
```
typeBarextendingFoo;
```
**404 Chapter 5. Standard Library**


```
typeFoo {
bar: int16;
baz: Bar;
}
```
```
typeBarextendingFoo;
```
```
db>select(introspectint16).name;
{'std::int16'}
db>select(introspectFoo).name;
{'default::Foo'}
db>select(introspect typeofFoo.bar).name;
{'std::int16'}
```
```
Note: For any object type SomeTypethe expressionsintrospect SomeTypeandintrospect typeof
SomeTypeare equivalent as the object type name is syntactically identical to the expression denoting the set
of those objects.
```
```
There’s an important difference between the combination ofintrospect typeof SomeTypeandSomeType.
__type__expressions when used with objects. introspect typeof SomeTypeis statically evaluated and
does not take in consideration the actual objects contained in theSomeTypeset. Conversely,SomeType.
__type__is the actual set of all the types reachable from all theSomeTypeobjects. Due to inheritance statically
inferred types and actual types may not be the same (although the actual types will always be a subtype of the
statically inferred types):
```
```
db># first let's make sure we don't have any Foo objects
...deleteFoo;
{ there may be some deleted objects here }
db>select(introspect typeofFoo).name;
{'default::Foo'}
db>selectFoo.__type__.name;
{}
db># let's add an object of type Foo
...insertFoo;
{Object { id: <uuid>'...' }}
db># Bar is also of type Foo
...insertBar;
{Object { id: <uuid>'...' }}
db>select(introspect typeofFoo).name;
{'default::Foo'}
db>selectFoo.__type__.name;
{'default::Bar', 'default::Foo'}
```
**5.3. Types 405**


### 5.4 Math

```
edb-alt-title Mathematical Functions
```
```
math::abs() Returns the absolute value of the input.
math::ceil() Rounds up a given value to the nearest integer.
math::floor() Rounds down a given value to the nearest integer.
math::ln() Returns the natural logarithm of a given value.
math::lg() Returns the base 10 logarithm of a given value.
math::log() Returns the logarithm of a given value in the specified base.
math::mean() Returns the arithmetic mean of the input set.
math::stddev() Returns the sample standard deviation of the input set.
math::stddev_pop() Returns the population standard deviation of the input set.
math::var() Returns the sample variance of the input set.
math::var_pop() Returns the population variance of the input set.
```
function math::abs→anyreal

```
Index Keywords absolute
Returns the absolute value of the input.
```
```
db>selectmath::abs(1);
{1}
db>selectmath::abs(-1);
{1}
```
function math::ceil→float64
function math::ceil→float64
function math::ceil→bigint
function math::ceil→decimal

```
Index Keywords round
Rounds up a given value to the nearest integer.
```
```
db>selectmath::ceil(1.1);
{2}
db>selectmath::ceil(-1.1);
{-1}
```
function math::floor→float64
function math::floor→float64
function math::floor→bigint
function math::floor→decimal

```
Index Keywords round
Rounds down a given value to the nearest integer.
```
**406 Chapter 5. Standard Library**


```
db>selectmath::floor(1.1);
{1}
db>selectmath::floor(-1.1);
{-2}
```
function math::ln→float64
function math::ln→float64
function math::ln→decimal

```
Index Keywords logarithm
Returns the natural logarithm of a given value.
```
```
db>select2.718281829 ^ math::ln(100);
{100.00000009164575}
```
function math::lg→float64
function math::lg→float64
function math::lg→decimal

```
Index Keywords logarithm
Returns the base 10 logarithm of a given value.
```
```
db>select10 ^ math::lg(42);
{42.00000000000001}
```
function math::log→decimal

```
Index Keywords logarithm
Returns the logarithm of a given value in the specified base.
```
```
db>select3 ^ math::log(15n, base := 3n);
{15.0000000000000005n}
```
function math::mean→float64
function math::mean→float64
function math::mean→decimal

```
Index Keywords average avg
Returns the arithmetic mean of the input set.
```
```
db>selectmath::mean({1, 3, 5});
{3}
```
function math::stddev→float64
function math::stddev→float64
function math::stddev→decimal

**5.4. Math 407**


```
Index Keywords average
Returns the sample standard deviation of the input set.
```
```
db>selectmath::stddev({1, 3, 5});
{2}
```
function math::stddev_pop→float64
function math::stddev_pop→float64
function math::stddev_pop→decimal

```
Index Keywords average
Returns the population standard deviation of the input set.
```
```
db>selectmath::stddev_pop({1, 3, 5});
{1.63299316185545}
```
function math::var→float64
function math::var→float64
function math::var→decimal

```
Index Keywords average
Returns the sample variance of the input set.
```
```
db>selectmath::var({1, 3, 5});
{4}
```
function math::var_pop→float64
function math::var_pop→float64
function math::var_pop→decimal

```
Index Keywords average
Returns the population variance of the input set.
```
```
db>selectmath::var_pop({1, 3, 5});
{2.66666666666667}
```
### 5.5 Strings

```
edb-alt-title String Functions and Operators
```
**408 Chapter 5. Standard Library**


```
str String
str[i] String indexing.
str[from:to] String slicing.
str ++ str String concatenation.
str like pattern Case-sensitive simple string matching.
str ilike pattern Case-insensitive simple string matching.
= != ?= ?!= < > <= >= Comparison operators
to_str() Return string representation of the input value.
len() Return string’s length.
contains() Test if a string contains a substring.
find() Find index of a substring.
str_lower() Return a lowercase copy of the input string.
str_upper() Return an uppercase copy of the input string.
str_title() Return a titlecase copy of the input string.
str_pad_start() Return the input string padded at the start to the length n.
str_pad_end() Return the input string padded at the end to the length n.
str_trim() Return the input string with trim characters removed from both ends.
str_trim_start() Return the input string with all trim characters removed from its start.
str_trim_end() Return the input string with all trim characters removed from its end.
str_repeat() Repeat the input string n times.
str_replace() Replace all occurrences of old substring with the new one.
str_reverse() Reverse the order of the characters in the string.
str_split() Split a string into an array using a delimiter.
re_match() Find the first regular expression match in a string.
re_match_all() Find all regular expression matches in a string.
re_replace() Replace matching substrings in a given string.
re_test() Test if a regular expression has a match in a string.
```
type str

```
Index Keywords continuation cont
A unicode string of text.
Any other type (exceptbytes) can becastto and from a string:
```
```
db>select<str>42;
{' 42 '}
db>select<bool>'true';
{true}
db>select"I EdgeDB";
{'I EdgeDB'}
```
```
Note that when astris cast into ajson, the result is a JSON string value. Same applies for casting back from
json- only a JSON string value can be cast into astr:
```
```
db>select<json>'Hello, world';
{'"Hello, world"'}
```
```
There are two kinds of string literals in EdgeQL: regular and raw. Raw string literals do not evaluate\, so\nin
in a raw string is two characters\andn.
The regular string literal syntax is'a string'or a"a string". Two raw string syntaxes are illustrated below:
```
**5.5. Strings 409**


```
db>selectr'a raw \\\ string';
{'a raw \\\ string'}
db>select$$something$$;
{'something'}
db>select$marker$something $$
... nested \!$$$marker$;
{'something $$
nested \!$$'}
```
```
Regular strings use\to indicate line continuation. When a line continuation symbol is encountered, the symbol
itself as well as all the whitespace characters up to the next non-whitespace character are omitted from the string:
```
```
db>select'Hello, \
... world';
{'"Hello, world"'}
```
```
Note: This type is subject to the Postgres maximum field size of 1GB.
```
operator str [ int64 ] -> str
String indexing.
Indexing starts at 0. Negative indexes are also valid and count from the _end_ of the string.

```
db>select'some text'[1];
{'o'}
db>select'some text'[-1];
{'t'}
```
```
It is an error to attempt to extract a character at an index outside the bounds of the string:
```
```
db>select'some text'[10];
InvalidValueError: stringindex 10 is outof bounds
```
operator str [ int64 : int64 ] -> str
String slicing.
Indexing starts at 0. Negative indexes are also valid and count from the _end_ of the string.

```
db>select'some text'[1:3];
{'om'}
db>select'some text'[-4:];
{'text'}
db>select'some text'[:-5];
{'some'}
db>select'some text'[5:-2];
{'te'}
```
```
It is perfectly acceptable to use indexes outside the bounds of a string in a slice :
```
**410 Chapter 5. Standard Library**


```
db>select'some text'[-4:100];
{'text'}
db>select'some text'[-100:-5];
{'some'}
```
operator str ++ str -> str
String concatenation.

```
db>select'some'++ 'text';
{'some text'}
```
operator str like str -> bool
operator str not like str -> bool
Case-sensitive simple string matching.
Returnstrueif the _value_ Vmatches the _pattern_ Pandfalseotherwise. The operatornot likeis the negation
oflike.
The pattern matching rules are as follows:

```
pattern interpretation
% matches zero or more characters
_ matches exactly one character
\% matches a literal “%”
\_ matches a literal “_”
any other character matches itself
```
```
In particular, this means that if there are no special symbols in the pattern , the operatorslikeandnot like
work identical to=and!=, respectively.
```
```
db>select'abc' like'abc';
{true}
db>select'abc' like'a%';
{true}
db>select'abc' like'_b_';
{true}
db>select'abc' like'c';
{false}
db>select'a%%c'not liker'a\%c';
{true}
```
operator str ilike str -> bool
operator str not ilike str -> bool
Case-insensitive simple string matching.
The operatorsilikeandnot ilikework the same way aslikeandnot like, except that the _pattern_ is
matched in a case-insensitive manner.

```
db>select'Abc' ilike'a%';
{true}
```
**5.5. Strings 411**


function std::str_lower→str
Return a lowercase copy of the input _string_.

```
db>selectstr_lower('Some Fancy Title');
{'some fancy title'}
```
function std::str_upper→str
Return an uppercase copy of the input _string_.

```
db>selectstr_upper('Some Fancy Title');
{'SOME FANCY TITLE'}
```
function std::str_title→str
Return a titlecase copy of the input _string_.
Every word in the _string_ will have the first letter capitalized and the rest converted to lowercase.

```
db>selectstr_title('sOmE fAnCy TiTlE');
{'Some Fancy Title'}
```
function std::str_pad_start→str
Return the input _string_ padded at the start to the length _n_.
If the _string_ is longer than _n_ , then it is truncated to the first _n_ characters. Otherwise, the _string_ is padded on the
left up to the total length _n_ using _fill_ characters (space by default).

```
db>selectstr_pad_start('short', 10);
{' short'}
db>selectstr_pad_start('much too long', 10);
{'much too l'}
db>selectstr_pad_start('short', 10, '.:');
{'.:.:.short'}
```
function std::str_pad_end→str
Return the input _string_ padded at the end to the length _n_.
If the _string_ is longer than _n_ , then it is truncated to the first _n_ characters. Otherwise, the _string_ is padded on the
right up to the total length _n_ using _fill_ characters (space by default).

```
db>selectstr_pad_end('short', 10);
{'short '}
db>selectstr_pad_end('much too long', 10);
{'much too l'}
db>selectstr_pad_end('short', 10,'.:');
{'short.:.:.'}
```
**412 Chapter 5. Standard Library**


function std::str_trim_start→str
Return the input string with all _trim_ characters removed from its start.
If the _trim_ specifies more than one character they will be removed from the beginning of the _string_ regardless of
the order in which they appear.

```
db>selectstr_trim_start(' data');
{'data'}
db>selectstr_trim_start('.....data', '.:');
{'data'}
db>selectstr_trim_start(':::::data', '.:');
{'data'}
db>selectstr_trim_start(':...:data', '.:');
{'data'}
db>selectstr_trim_start('.:.:.data', '.:');
{'data'}
```
function std::str_trim_end→str
Return the input string with all _trim_ characters removed from its end.
If the _trim_ specifies more than one character they will be removed from the end of the _string_ regardless of the
order in which they appear.

```
db>selectstr_trim_end('data ');
{'data'}
db>selectstr_trim_end('data.....','.:');
{'data'}
db>selectstr_trim_end('data:::::','.:');
{'data'}
db>selectstr_trim_end('data:...:','.:');
{'data'}
db>selectstr_trim_end('data.:.:.','.:');
{'data'}
```
function std::str_trim→str
Return the input string with _trim_ characters removed from both ends.
If the _trim_ specifies more than one character they will be removed from both ends of the _string_ regardless of the
order in which they appear. This is the same as applyingstr_ltrim()andstr_rtrim().

```
db>selectstr_trim(' data ');
{'data'}
db>selectstr_trim('::data.....','.:');
{'data'}
db>selectstr_trim('..data:::::','.:');
{'data'}
db>selectstr_trim('.:data:...:','.:');
{'data'}
db>selectstr_trim(':.:.data.:.','.:');
{'data'}
```
**5.5. Strings 413**


function std::str_repeat→str
Repeat the input _string n_ times.
If _n_ is zero or negative an empty string is returned.

```
db>selectstr_repeat('.', 3);
{'...'}
db>selectstr_repeat('foo', -1);
{''}
```
function std::str_replace→str
Replace all occurrences of _old_ substring with the _new_ one.
Given a string _s_ find all non-overlapping occurrences of the substring _old_ and replace them with the substring
_new_.

```
db>selectstr_replace('hello world', 'h', 'H');
{'Hello world'}
db>selectstr_replace('hello world', 'l', '[L]');
{'he[L][L]o wor[L]d'}
db>selectstr_replace('hello world', 'o', '');
{'hell wrld'}
```
function std::str_reverse→str
Reverse the order of the characters in the string.

```
db>selectstr_reverse('Hello world');
{'dlrow olleH'}
db>selectstr_reverse('Hello world');
{' dlrow olleH'}
```
function std::str_split→array<str>

```
Index Keywords split str_split explode
Split string into array elements using the supplied delimiter.
```
```
db>selectstr_split('1, 2, 3',',');
{[' 1 ', ' 2 ', ' 3 ']}
```
```
db>selectstr_split(' 123 ','');
{[' 1 ', ' 2 ', ' 3 ']}
```
function std::re_match→array<str>

```
Index Keywords regex regexp regular
Find the first regular expression match in a string.
Given an input string and a regular expression pattern find the first match for the regular expression within the
string. Return the match, each match represented by anarray<str>of matched groups.
```
**414 Chapter 5. Standard Library**


```
db>selectre_match(r'\w{4}ql','I edgeql');
{['edgeql']}
```
function std::re_match_all→set of array<str>

```
Index Keywords regex regexp regular
Find all regular expression matches in a string.
Given an input string and a regular expression pattern repeatedly match the regular expression within the string.
Return the set of all matches, each match represented by anarray<str>of matched groups.
```
```
db>selectre_match_all(r'a\w+', 'an abstract concept');
{['an'], ['abstract']}
```
function std::re_replace→str

```
Index Keywords regex regexp regular replace
Replace matching substrings in a given string.
Given an input string and a regular expression pattern replace matching substrings with the replacement string
sub. Optional flag arguments can be used to specify additional regular expression flags. Return the string result-
ing from substring replacement.
```
```
db>selectre_replace(r'l', r'L', 'Hello World',
... flags :='g');
{'HeLLo WorLd'}
```
function std::re_test→bool

```
Index Keywords regex regexp regular match
Test if a regular expression has a match in a string.
Given an input string and a regular expression pattern test whether there is a match for the regular expression
within the string. Returntrueif there is a match,falseotherwise.
```
```
db>selectre_test(r'a', 'abc');
{true}
```
function std::to_str→str
function std::to_str→str
function std::to_str→str
function std::to_str→str
function std::to_str→str
function std::to_str→str
function std::to_str→str
function std::to_str→str
function std::to_str→str
function std::to_str→str

```
Index Keywords stringify dumps join array_to_string
```
**5.5. Strings 415**


```
Return string representation of the input value.
This is a very versatile polymorphic function that is defined for many different input types. In general, there are
corresponding converter functions fromstrback to the specific types, which share the meaning of the format
argument fmt.
When convertingdatetime,cal::local_datetime,cal::local_date,cal::local_time,duration
this function is the inverse ofto_datetime(),cal::to_local_datetime(),cal::to_local_date(),
cal::to_local_time(),to_duration(), correspondingly.
For valid date and time formatting patterns see here.
```
```
db>selectto_str(<datetime>'2018-05-07 15:01:22.306916-05',
... 'FMDDth of FMMonth, YYYY');
{'7th of May, 2018'}
db>selectto_str(<cal::local_date>'2018-05-07','CCth "century"');
{'21st century'}
```
```
When converting one of the numeric types, this function is the reverse of: to_bigint(),to_decimal(),
to_int16(),to_int32(),to_int64(),to_float32(),to_float64().
For valid number formatting patterns see here.
See alsoto_json().
```
```
db>selectto_str(123,' 999999 ');
{' 123 '}
db>selectto_str(123,' 099999 ');
{' 000123 '}
db>selectto_str(123.45, 'S999.999');
{'+123.450'}
db>selectto_str(123.45e-20, '9.99EEEE');
{' 1.23e-18'}
db>selectto_str(-123.45n,'S999.99');
{'-123.45'}
```
```
When convertingjson, this function can take'pretty'as the optional fmt argument to produce a pretty-
formatted JSON string.
See alsoto_json().
```
```
db>selectto_str(<json>2);
{' 2 '}
```
```
db>selectto_str(<json>['hello', 'world']);
{'["hello", "world"]'}
```
```
db>selectto_str(<json>(a := 2, b := 'hello'), 'pretty');
{'{
"a": 2,
"b": "hello"
}'}
```
```
When convertingarrays, a delimiter argument is required:
```
```
db>selectto_str(['one', 'two', 'three'], ', ');
{'one, two, three'}
```
**416 Chapter 5. Standard Library**


```
Warning: There’s a deprecated version ofstd::to_strwhich operates on arrays, howeverarray_join()
should be used instead.
```
#### 5.5.1 Regular Expressions

EdgeDB supports Regular expressions (REs), as defined in POSIX 1003.2. They come in two forms: BRE (basic
RE) and ERE (extended RE). In addition, EdgeDB supports certain common extensions to the POSIX standard com-
monly known as ARE (advanced RE). More details about BRE, ERE, and ARE support can be found in PostgreSQL
documentation.

For convenience, here’s a table outlining the different options accepted as theflagsargument to various regular
expression functions, or as embedded options in the pattern itself, e.g.'(?i)fooBAR':

##### 5.5.1.1 Option Flags

```
Option Description
b rest of RE is a BRE
c case-sensitive matching (overrides operator type)
e rest of RE is an ERE
i case-insensitive matching (overrides operator type)
m historical synonym for n
n newline-sensitive matching
p partial newline-sensitive matching
q rest of RE is a literal (“quoted”) string, all ordinary characters
s non-newline-sensitive matching (default)
t tight syntax (default)
w inverse partial newline-sensitive (“weird”) matching
x expanded syntax ignoring white-space characters
```
#### 5.5.2 Formatting

Some of the type converter functions take an extra argument specifying the formatting (either for converting to astr
or parsing from one). The different formatting options are collected in this section.

##### 5.5.2.1 Date and time formatting options

```
Pattern Description
HH hour of day (01-12)
HH12 hour of day (01-12)
HH24 hour of day (00-23)
MI minute (00-59)
SS second (00-59)
continues on next page
```
**5.5. Strings 417**


```
Table 1 – continued from previous page
Pattern Description
MS millisecond (000-999)
US microsecond (000000-999999)
SSSS seconds past midnight (0-86399)
AM, am, PM or pm meridiem indicator (without periods)
A.M., a.m., P.M. or p.m. meridiem indicator (with periods)
Y,YYY year (4 or more digits) with comma
YYYY year (4 or more digits)
YYY last 3 digits of year
YY last 2 digits of year
Y last digit of year
IYYY ISO 8601 week-numbering year (4 or more digits)
IYY last 3 digits of ISO 8601 week- numbering year
IY last 2 digits of ISO 8601 week- numbering year
I last digit of ISO 8601 week-numbering year
BC, bc, AD or ad era indicator (without periods)
B.C., b.c., A.D. or a.d. era indicator (with periods)
MONTH full upper case month name (blank- padded to 9 chars)
Month full capitalized month name (blank- padded to 9 chars)
month full lower case month name (blank- padded to 9 chars)
MON abbreviated upper case month name (3 chars in English, localized lengths vary)
Mon abbreviated capitalized month name (3 chars in English, localized lengths vary)
mon abbreviated lower case month name (3 chars in English, localized lengths vary)
MM month number (01-12)
DAY full upper case day name (blank-padded to 9 chars)
Day full capitalized day name (blank- padded to 9 chars)
day full lower case day name (blank-padded to 9 chars)
DY abbreviated upper case day name (3 chars in English, localized lengths vary)
Dy abbreviated capitalized day name (3 chars in English, localized lengths vary)
dy abbreviated lower case day name (3 chars in English, localized lengths vary)
DDD day of year (001-366)
IDDD day of ISO 8601 week-numbering year (001-371; day 1 of the year is Monday of the first ISO week)
DD day of month (01-31)
D day of the week, Sunday (1) to Saturday (7)
ID ISO 8601 day of the week, Monday (1) to Sunday (7)
W week of month (1-5) (the first week starts on the first day of the month)
WW week number of year (1-53) (the first week starts on the first day of the year)
IW week number of ISO 8601 week-numbering year (01-53; the first Thursday of the year is in week 1)
CC century (2 digits) (the twenty-first century starts on 2001-01-01)
J Julian Day (integer days since November 24, 4714 BC at midnight UTC)
Q quarter
RM month in upper case Roman numerals (I-XII; I=January)
rm month in lower case Roman numerals (i-xii; i=January)
TZ upper case time-zone abbreviation (only supported in to_char)
tz lower case time-zone abbreviation (only supported in to_char)
TZH time-zone hours
TZM time-zone minutes
OF time-zone offset from UTC (only supported in to_char)
```
Some additional formatting modifiers:

**418 Chapter 5. Standard Library**


```
Modifier Description Example
FM prefix fill mode (suppress leading zeroes and padding blanks) FMMonth
TH suffix upper case ordinal number suffix DDTH, e.g., 12TH
th suffix lower case ordinal number suffix DDth, e.g., 12th
FX prefix fixed format global option (see usage notes) FX Month DD Day
```
Normally when parsing a string input whitespace is ignored, unless the _FX_ prefix modifier is used. For example:

db>select cal::to_local_date(
... '2000 JUN','YYYY MON');
{<cal::local_date>'2000-06-01'}
db>select cal::to_local_date(
... '2000 JUN','FXYYYY MON');
InternalServerError: invalid value " "for"MON"

##### 5.5.2.2 Number formatting options

```
Pattern Description
9 digit position (can be dropped if insignificant)
0 digit position (will not be dropped, even if insignificant)
```
. (period) decimal point
, (comma) group (thousands) separator
PR negative value in angle brackets
S sign anchored to number (uses locale)
L currency symbol (uses locale)
D decimal point (uses locale)
G group separator (uses locale)
MI minus sign in specified position (if number < 0)
PL plus sign in specified position (if number > 0)
SG plus/minus sign in specified position
RN Roman numeral (input between 1 and 3999)
TH or th ordinal number suffix
V shift specified number of digits (see notes)
EEEE exponent for scientific notation

Some additional formatting modifiers:

```
Modifier Description Example
FM prefix fill mode (suppress leading zeroes and padding blanks) FM99.99
TH suffix upper case ordinal number suffix 999TH
th suffix lower case ordinal number suffix 999th
```
**5.5. Strings 419**


### 5.6 Booleans

```
edb-alt-title Boolean Functions and Operators
```
```
bool Boolean type
bool or bool Evaluates true if either boolean is true.
bool and bool Evaluates true if both booleans are true.
not bool Logically negates a given boolean value.
= != ?= ?!= < > <= >= Comparison operators
all() Returns true if none of the values in the given set are false.
any() Returns true if any of the values in the given set is true.
assert() Checks that the input bool is true.
```
type bool
A boolean type of eithertrueorfalse.
EdgeQL has case-insensitive keywords and that includes the boolean literals:

```
db>select(True,true,TRUE);
{(true, true,true)}
db>select(False,false, FALSE);
{(false,false, false)}
```
```
These basic operators will always result in a boolean value:
```
- =
- !=
- ?=
- ?!=
- in
- not in
- <
- >
- <=
- >=
- like
- ilike
Some examples:

```
db>select true and 2 < 3;
{true}
db>select'!'IN {'hello','world'};
{false}
```
```
It’s possible to get a boolean by casting astrorjsonvalue into it:
```
**420 Chapter 5. Standard Library**


```
db>select<bool>('true');
{true}
db>select<bool>to_json('false');
{false}
```
```
Filter clauses must always evaluate to a boolean:
```
```
select User
filter .nameilike'alice';
```
operator bool or bool -> bool
Evaluatestrueif either boolean istrue.

```
db>select false or true;
{true}
```
operator bool and bool -> bool
Evaluatestrueif both booleans aretrue.

```
db>select false and true;
{false}
```
operator not bool -> bool
Logically negates a given boolean value.

```
db>select not false;
{true}
```
Theandandoroperators are commutative.

The truth tables are as follows:

```
a b aandb aorb nota
true true true true false
true false false true false
false true false true true
false false false false true
```
The operatorsand/orand the functionsall()/any()differ in the way they handle an empty set ({}). Bothandand
oroperators apply to the cross-product of their operands. If either operand is an empty set, the result will also be an
empty set. For example:

db>select {true,false} and<bool>{};
{}
db>select true and <bool>{};
{}

**5.6. Booleans 421**


Operating on an empty set withall()/any()does _not_ return an empty set:

db>select all(<bool>{});
{true}
db>select any(<bool>{});
{false}

all()returnstruebecause the empty set contains no false values.

any()returnsfalsebecause the empty set contains no true values.

Theall()andany()functions are generalized to apply to sets of values, including{}. Thus they have the following
truth table:

```
a b all({a, b}) any({a, b})
true true true true
true false false true
{} true true true
{} false false false
false true false true
false false false false
true {} true true
false {} false false
{} {} true false
```
Sinceall()andany()apply to sets as a whole, missing values (represented by{}) are just that - missing. They don’t
affect the overall result.

To understand the last line in the above truth table it’s useful to remember thatall({a, b}) = all(a) and all(b)
andany({a, b}) = any(a) or any(b).

For more customized handling of{}, use the??operator.

function std::assert→bool
Checks that the input bool istrue.
If the input bool isfalse,assertraises aQueryAssertionError. Otherwise, this function returnstrue.

```
db>selectassert(true);
{true}
```
```
db>selectassert(false);
edgedb error: QueryAssertionError: assertion failed
```
```
db>selectassert(false, message :='value is not true');
edgedb error: QueryAssertionError: valueis not true
```
```
assertcan be used in triggers to create more powerful constraints. In this schema, thePersontype has both
friendsandenemieslinks. You may not want aPersonto be both a friend and an enemy of the samePerson.
assertcan be used inside a trigger to easily prohibit this.
```
```
typePerson {
requiredname: str;
multi friends: User;
(continues on next page)
```
**422 Chapter 5. Standard Library**


```
(continued from previous page)
multi enemies: User;
```
```
trigger prohibit_frenemies after insert, update foreachdo (
assert(
not exists (__new__.friends intersect __new__.enemies),
message := "Invalid frenemies",
)
)
}
```
```
With this trigger in place, it is impossible to link the samePersonas both a friend and an enemy of any other
person.
```
```
db>insertPerson {name := 'Quincey Morris'};
{default::Person {id: e4a55480-d2de-11ed-93bd-9f4224fc73af}}
db>insertPerson {name := 'Dracula'};
{default::Person {id: e7f2cff0-d2de-11ed-93bd-279780478afb}}
db>updateUser
...filter.name ='Quincey Morris'
...set{
... enemies := (select Personfilter .name ='Dracula')
... };
{default::Person {id: e4a55480-d2de-11ed-93bd-9f4224fc73af}}
db>updateUser
...filter.name ='Quincey Morris'
...set{
... friends := (select Personfilter .name ='Dracula')
... };
edgedb error: EdgeDBError: Invalid frenemies
```
```
In the following examples, thesizeproperties of theFileobjects are 1024 , 1024 , and131,072.
```
```
db>forobjin(selectFile)
...union(assert(obj.size <= 128*1024, message := 'file too big'));
{true, true, true}
```
```
db>forobjin(selectFile)
...union(assert(obj.size <= 64*1024, message :='file too big'));
edgedb error: QueryAssertionError: file too big
```
```
You may callassertin theorder byclause of yourselectstatement. This will ensure it is called only on
objects that pass your filter.
```
```
db>selectFile { name, size }
...order byassert(.size <= 128*1024, message := "file too big");
{
default::File {name:'File 2', size: 1024},
default::File {name:'Asdf 3', size: 1024},
default::File {name:'File 1', size: 131072},
}
```
```
db>selectFile { name, size }
...order byassert(.size <= 64*1024, message := "file too big");
(continues on next page)
```
**5.6. Booleans 423**


```
(continued from previous page)
edgedb error: QueryAssertionError: file too big
```
```
db>selectFile { name, size }
...filter.size <= 64*1024
...order byassert(.size <= 64*1024, message := "file too big");
{
default::File {name:'File 2', size: 1024},
default::File {name:'Asdf 3', size: 1024}
}
```
### 5.7 Numbers

```
edb-alt-title Numerical Types, Functions, and Operators
```
```
int16 16-bit integer
int32 32-bit integer
int64 64-bit integer
float32 32-bit floating point number
float64 64-bit floating point number
bigint Arbitrary precision integer.
decimal Arbitrary precision number.
anyreal + anyreal Arithmetic addition.
anyreal - anyreal Arithmetic subtraction.
-anyreal Arithmetic negation.
anyreal * anyreal Arithmetic multiplication.
anyreal / anyreal Arithmetic division.
anyreal // anyreal Floor division.
anyreal % anyreal Remainder from division (modulo).
anyreal ^ anyreal Power operation.
= != ?= ?!= < > <= >= Comparison operators
sum() Returns the sum of the set of numbers.
min() Returns the smallest value in the given set.
max() Returns the largest value in the given set.
round() Rounds a given number to the nearest value.
random() Returns a pseudo-random number in the range of 0.0 <= x < 1.0.
```
**424 Chapter 5. Standard Library**


#### 5.7.1 Mathematical functions

```
math::abs() Returns the absolute value of the input.
math::ceil() Rounds up a given value to the nearest integer.
math::floor() Rounds down a given value to the nearest integer.
math::ln() Returns the natural logarithm of a given value.
math::lg() Returns the base 10 logarithm of a given value.
math::log() Returns the logarithm of a given value in the specified base.
math::mean() Returns the arithmetic mean of the input set.
math::stddev() Returns the sample standard deviation of the input set.
math::stddev_pop() Returns the population standard deviation of the input set.
math::var() Returns the sample variance of the input set.
math::var_pop() Returns the population variance of the input set.
```
#### 5.7.2 Bitwise functions

```
bit_and() Bitwise AND operator for 2 intergers.
bit_or() Bitwise OR operator for 2 intergers.
bit_xor() Bitwise exclusive OR operator for 2 intergers.
bit_not() Bitwise negation operator for 2 intergers.
bit_lshift() Bitwise left-shift operator for intergers.
bit_rshift() Bitwise arithemtic right-shift operator for intergers.
```
#### 5.7.3 String parsing

```
to_bigint() Returns a bigint value parsed from the given string.
to_decimal() Returns a decimal value parsed from the given string.
to_int16() Returns an int16 value parsed from the given string.
to_int32() Returns an int32 value parsed from the given string.
to_int64() Returns an int64 value parsed from the given string.
to_float32() Returns a float32 value parsed from the given string.
to_float64() Returns a float64 value parsed from the given string.
```
It’s possible to explicitlycastbetween all numeric types. All numeric types can also be cast to and fromstrand
json.

type int16

```
Index Keywords int integer
A 16-bit signed integer.
int16is capable of representing values from-32768to+32767(inclusive).
```
type int32

```
Index Keywords int integer
```
**5.7. Numbers 425**


```
A 32-bit signed integer.
int32is capable of representing values from-2147483648to+2147483647(inclusive).
```
type int64

```
Index Keywords int integer
A 64-bit signed integer.
int64is capable of representing values from-9223372036854775808to+9223372036854775807(inclu-
sive).
```
type float32

```
Index Keywords float
A variable precision, inexact number.
The minimal guaranteed precision is at least 6 decimal digits. The approximate range of afloat32spans from
-3.4e+38to+3.4e+38.
```
type float64

```
Index Keywords float double
A variable precision, inexact number.
The minimal guaranteed precision is at least 15 decimal digits. The approximate range of afloat64spans from
-1.7e+308to+1.7e+308.
```
type bigint

```
Index Keywords numeric bigint
An arbitrary precision integer.
Our philosophy is that use ofbigintshould always be an explicit opt-in and should never be implicit. Once used,
these values should not be accidentally cast to a different numerical type that could lead to a loss of precision.
In keeping with this philosophy, our mathematical functions are designed to maintain separation between big
integer values and the rest of our numeric types.
All of the following types can be explicitly cast into abiginttype:
```
- str
- json
- int16
- int32
- int64
- float32
- float64
- decimal

**426 Chapter 5. Standard Library**


```
A bigint literal is an integer literal, followed by ‘n’:
```
```
db>select42nis bigint;
{true}
```
```
To represent really big integers, it is possible to use the exponent notation (e.g. 1e20n instead of
100000000000000000000n) as long as the exponent is positive and there is no dot anywhere:
```
```
db>select1e+100nis bigint;
{true}
```
```
When a float literal is followed bynit will produce adecimalvalue instead:
```
```
db>select1.23n is decimal;
{true}
```
```
db>select1.0e+100n isdecimal;
{true}
```
```
Note: Use caution when castingbigintvalues intojson. The JSON specification does not have a limit on
significant digits, so abigintnumber can be losslessly represented in JSON. However, JSON decoders in many
languages will read all such numbers as some kind of 32-bit or 64-bit number type, which may result in errors
or precision loss. If such loss is unacceptable, then consider casting the value intostrand decoding it on the
client side into a more appropriate type.
```
type decimal

```
Index Keywords numeric float
Any number of arbitrary precision.
Our philosophy is that use ofdecimalshould always be an explicit opt-in and should never be implicit. Once
used, these values should not be accidentally cast to a different numerical type that could lead to a loss of preci-
sion.
In keeping with this philosophy, our mathematical functions are designed to maintain separation between
decimalvalues and the rest of our numeric types.
All of the following types can be explicitly cast into decimal:
```
- str
- json
- int16
- int32
- int64
- float32
- float64
- bigint
A decimal literal is a float literal, followed byn:

**5.7. Numbers 427**


```
The EdgeDB philosophy is that using a decimal type should be an explicit opt-in, but once used, the values should
not be accidentally cast into a numeric type with less precision.
In accordance with this the mathematical functions are designed to keep the separation between decimal values
and the rest of the numeric types.
All of the following types can be explicitly cast into decimal:str,json,int16,int32,int64,float32,
float64, andbigint.
A decimal literal is a float literal followed by ‘n’:
```
```
db>select1.23n is decimal;
{true}
```
```
db>select1.0e+100n isdecimal;
{true}
```
```
Note that an integer literal (without a dot or exponent) followed bynproduces abigintvalue. A literal without
a dot and with a positive exponent makes abigint, too:
```
```
db>select42nis bigint;
{true}
```
```
db>select12e+34nis bigint;
{true}
```
```
Note: Use caution when castingdecimalvalues intojson. The JSON specification does not have a limit
on significant digits, so adecimalnumber can be losslessly represented in JSON. However, JSON decoders in
many languages will read all such numbers as some kind of floating point values, which may result in precision
loss. If such loss is unacceptable, then consider casting the value into astrand decoding it on the client side
into a more appropriate type.
```
operator anyreal + anyreal -> anyreal

```
Index Keywords plus add
Arithmetic addition.
```
```
db>select2 + 2;
{4}
```
operator anyreal - anyreal -> anyreal

```
Index Keywords minus subtract
Arithmetic subtraction.
```
```
db>select3 - 2;
{1}
```
operator - anyreal -> anyreal

**428 Chapter 5. Standard Library**


```
Index Keywords unary minus subtract
Arithmetic negation.
```
```
db>select-5;
{-5}
```
operator anyreal * anyreal -> anyreal

```
Index Keywords multiply multiplication
Arithmetic multiplication.
```
```
db>select2 * 10;
{20}
```
operator anyreal / anyreal -> anyreal

```
Index Keywords divide division
Arithmetic division.
```
```
db>select10 / 4;
{2.5}
```
```
Division by zero will result in an error:
```
```
db>select10 / 0;
DivisionByZeroError: divisionby zero
```
operator anyreal // anyreal -> anyreal

```
Index Keywords floor divide division
Floor division.
In floor-based division, the result of a standard division operation is rounded down to its nearest integer. It is the
equivalent to using regular division and then applyingmath::floor()to the result.
```
```
db>select10 // 4;
{2}
db>selectmath::floor(10 / 4);
{2}
db>select-10 // 4;
{-3}
```
```
It also works onfloat,bigint, anddecimaltypes. The type of the result corresponds to the type of the
operands:
```
```
db>select3.7 // 1.1;
{3.0}
db>select3.7n // 1.1n;
{3.0n}
db>select37 // 11;
{3}
```
**5.7. Numbers 429**


```
Regular division, floor division, and%operations are related in the following way:A // B = (A - (A % B))
/ B.
```
operator anyreal % anyreal -> anyreal

```
Index Keywords modulo mod division
Remainder from division (modulo).
This is commonly referred to as a “modulo” operation.
This is the remainder from floor division. Just as is the case with//the result type of the remainder operator
corresponds to the operand type:
```
```
db>select10 % 4;
{2}
db>select10n % 4;
{2n}
db>select-10 % 4;
{2}
db># floating arithmetic is inexact, so
...# we get 0.3999999999999999 instead of 0.4
...select3.7 % 1.1;
{0.3999999999999999}
db>select3.7n % 1.1n;
{0.4n}
db>select37 % 11;
{4}
```
```
Regular division,//and%operations are related in the following way:A // B = (A - (A % B)) / B.
Modulo division by zero will result in an error:
```
```
db>select10 % 0;
DivisionByZeroError: divisionby zero
```
operator anyreal ^ anyreal -> anyreal

```
Index Keywords power pow
Power operation.
```
```
db>select2 ^ 4;
{16}
```
function std::round→float64
function std::round→float64
function std::round→bigint
function std::round→decimal
function std::round→decimal
Rounds a given number to the nearest value.
The function will round a.5value differently depending on the type of the parameter passed.
Thefloat64tie is rounded to the nearest even number:

**430 Chapter 5. Standard Library**


```
db>selectround(1.2);
{1}
```
```
db>selectround(1.5);
{2}
```
```
db>selectround(2.5);
{2}
```
```
But thedecimaltie is rounded away from zero:
```
```
db>selectround(1.2n);
{1n}
```
```
db>selectround(1.5n);
{2n}
```
```
db>selectround(2.5n);
{3n}
```
```
Additionally, when rounding adecimalvalue, you may pass the optional argument d to specify the precision of
the rounded result:
```
```
db>selectround(163.278n, 2);
{163.28n}
```
```
db>selectround(163.278n, 1);
{163.3n}
```
```
db>selectround(163.278n, 0);
{163n}
```
```
db>selectround(163.278n, -1);
{160n}
```
```
db>selectround(163.278n, -2);
{200n}
```
function std::random→float64
Returns a pseudo-random number in the range of0.0 <= x < 1.0.

```
db>selectrandom();
{0.62649393780157}
```
function std::bit_and→int16
function std::bit_and→int32
function std::bit_and→int64
Bitwise AND operator for 2 intergers.

```
db>selectbit_and(17, 3);
{1}
```
**5.7. Numbers 431**


function std::bit_or→int16
function std::bit_or→int32
function std::bit_or→int64
Bitwise OR operator for 2 intergers.

```
db>selectbit_or(17, 3);
{19}
```
function std::bit_xor→int16
function std::bit_xor→int32
function std::bit_xor→int64
Bitwise exclusive OR operator for 2 intergers.

```
db>selectbit_xor(17, 3);
{18}
```
function std::bit_not→int16
function std::bit_not→int32
function std::bit_not→int64
Bitwise negation operator for 2 intergers.
Bitwise negation for integers ends up similar to mathematical negation because typically the signed integers use
“two’s complement” representation. In this represenation mathematical negation is achieved by aplying bitwise
negation and adding 1.

```
db>selectbit_not(17);
{-18}
db>select-17 = bit_not(17) + 1;
{true}
```
function std::bit_lshift→int16
function std::bit_lshift→int32
function std::bit_lshift→int64
Bitwise left-shift operator for intergers.
The integer _val_ is shifted by _n_ bits to the left. The rightmost added bits are all 0. Shifting an integer by a number
of bits greater than the bit size of the integer results in 0.

```
db>selectbit_lshift(123, 2);
{492}
db>selectbit_lshift(123, 65);
{0}
```
```
Left-shifting an integer can change the sign bit:
```
```
db>selectbit_lshift(123, 60);
{-5764607523034234880}
```
```
In general, left-shifting an integer in small increments produces the same result as shifting it in one step:
```
**432 Chapter 5. Standard Library**


```
db>selectbit_lshift(bit_lshift(123, 1), 3);
{1968}
db>selectbit_lshift(123, 4);
{1968}
```
```
It is an error to attempt to shift by a negative number of bits:
```
```
db>selectbit_lshift(123, -2);
edgedb error: InvalidValueError: bit_lshift(): cannot shiftby
negative amount
```
function std::bit_rshift→int16
function std::bit_rshift→int32
function std::bit_rshift→int64
Bitwise arithemtic right-shift operator for intergers.
The integer _val_ is shifted by _n_ bits to the right. In the arithmetic right-shift, the sign is preserved. This means
that the leftmost added bits are 1 or 0 depending on the sign bit. Shifting an integer by a number of bits greater
than the bit size of the integer results in 0 for positive numbers or-1for negative numbers.

```
db>selectbit_rshift(123, 2);
{30}
db>selectbit_rshift(123, 65);
{0}
db>selectbit_rshift(-123, 2);
{-31}
db>selectbit_rshift(-123, 65);
{-1}
```
```
In general, right-shifting an integer in small increments produces the same result as shifting it in one step:
```
```
db>selectbit_rshift(bit_rshift(123, 1), 3);
{7}
db>selectbit_rshift(123, 4);
{7}
db>selectbit_rshift(bit_rshift(-123, 1), 3);
{-8}
db>selectbit_rshift(-123, 4);
{-8}
```
```
It is an error to attempt to shift by a negative number of bits:
```
```
db>selectbit_rshift(123, -2);
edgedb error: InvalidValueError: bit_rshift(): cannot shiftby
negative amount
```
function std::to_bigint→bigint

```
Index Keywords parse bigint
Returns abigintvalue parsed from the given string.
The function will use an optional format string passed as fmt. See the number formatting options for help writing
a format string.
```
**5.7. Numbers 433**


```
db>selectto_bigint('-000,012,345','S099,999,999,999');
{-12345n}
db>selectto_bigint('31st', '999th');
{31n}
```
function std::to_decimal→decimal

```
Index Keywords parse decimal
Returns adecimalvalue parsed from the given string.
The function will use an optional format string passed as fmt. See the number formatting options for help writing
a format string.
```
```
db>selectto_decimal('-000,012,345', 'S099,999,999,999');
{-12345.0n}
db>selectto_decimal('-012.345');
{-12.345n}
db>selectto_decimal('31st', '999th');
{31.0n}
```
function std::to_int16→int16

```
Index Keywords parse int16
Returns anint16value parsed from the given string.
The function will use an optional format string passed as fmt. See the number formatting options for help writing
a format string.
```
function std::to_int32→int32

```
Index Keywords parse int32
Returns anint32value parsed from the given string.
The function will use an optional format string passed as fmt. See the number formatting options for help writing
a format string.
```
function std::to_int64→int64

```
Index Keywords parse int64
Returns anint64value parsed from the given string.
The function will use an optional format string passed as fmt. See the number formatting options for help writing
a format string.
```
function std::to_float32→float32

```
Index Keywords parse float32
```
**434 Chapter 5. Standard Library**


```
Returns afloat32value parsed from the given string.
The function will use an optional format string passed as fmt. See the number formatting options for help writing
a format string.
```
function std::to_float64→float64

```
Index Keywords parse float64
Returns afloat64value parsed from the given string.
The function will use an optional format string passed as fmt. See the number formatting options for help writing
a format string.
```
### 5.8 JSON

```
edb-alt-title JSON Functions and Operators
```
```
json JSON scalar type
json[i] Accesses the element of the JSON string or array at a given index.
json[from:to] Produces a JSON value comprising a portion of the existing JSON value.
json ++ json Concatenates two JSON arrays, objects, or strings into one.
json[name] Accesses an element of a JSON object given its key.
= != ?= ?!= < > <= >= Comparison operators
to_json() Returns a JSON value parsed from the given string.
to_str() Render JSON value to a string.
json_get() Returns a value from a JSON object or array given its path.
json_set() Returns an updated JSON target with a new value.
json_array_unpack() Returns the elements of a JSON array as a set of json.
json_object_pack() Returns the given set of key/value tuples as a JSON object.
json_object_unpack() Returns the data in a JSON object as a set of key/value tuples.
json_typeof() Returns the type of the outermost JSON value as a string.
```
#### 5.8.1 Constructing JSON Values

JSON in EdgeDB is a _scalar type_. This type doesn’t have its own literal, and instead can be obtained by either casting
a value to thejsontype, or by using theto_json()function:

db>select to_json('{"hello": "world"}');
{Json("{\"hello\": \"world\"}")}
db>select <json>'hello world';
{Json("\"hello world\"")}

Any value in EdgeDB can be cast to ajsontype as well:

db>select <json>2019;
{Json("2019")}
db>select <json>cal::to_local_date(datetime_current(),'UTC');
{Json("\"2022-11-21\"")}

Thejson_object_pack()function provides one more way to construct JSON. It constructs a JSON object from an
array of key/value tuples:

**5.8. JSON 435**


db>select json_object_pack({("hello", <json>"world")});
{Json("{\"hello\": \"world\"}")}

Additionally, anyObjectin EdgeDB can be cast as ajsontype. This produces the same JSON value as the JSON-
serialized result of that said object. Furthermore, this result will be the same as the output of aselect expression
in _JSON mode_ , including the shape of that type:

db>select <json>(
... selectschema::Object {
... name,
... timestamp := cal::to_local_date(
... datetime_current(),'UTC')
... }
... filter.name ='std::bool');
{Json("{\"name\": \"std::bool\", \"timestamp\": \"2022-11-21\"}")}

JSON values can also be cast back into scalars. Casting JSON is symmetrical meaning that, if a scalar value can be
cast into JSON, a compatible JSON value can be cast into a scalar of that type. Some scalar types will have specific
conditions for casting:

- JSON strings can be cast to astrtype. Castinguuidand _date/time_ types to JSON results in a JSON string
    representing its original value. This means it is also possible to cast a JSON string back to those types. The
    value of the UUID or datetime string must be properly formatted to successfully cast from JSON, otherwise
    EdgeDB will raise an exception.
- JSON numbers can be cast to any _numeric type_.
- JSON booleans can be cast to abooltype.
- JSONnullis unique because it can be cast to an empty set ({}) of any type.
- JSON arrays can be cast to any valid array type, as long as the JSON array is homogeneous, does not contain
    nullas an element of the array, and does not contain another array.

A namedtupleis converted into a JSON object when cast as ajsonwhile a standardtupleis converted into a JSON
array. Unlike other casts to JSON, tuple casts to JSON are _not_ reversible (i.e., it is not possible to cast a JSON value
directly into atuple).

type json
Arbitrary JSON data.
Any other type can becastto and from JSON:

```
db>select<json>42;
{Json("42")}
db>select<bool>to_json('true');
{true}
```
```
Ajsonvalue can also be cast as astrtype, but only when recognized as a JSON string:
```
```
db>select<str>to_json('"something"');
{'something'}
```
```
Casting a JSON array of strings (["a", "b", "c"]) to astrwill result in an error:
```
**436 Chapter 5. Standard Library**


```
db>select<str>to_json('["a", "b", "c"]');
InvalidValueError: expectedjson stringor null; gotJSONarray
```
```
Instead, use theto_str()function to dump a JSON value to astrvalue. Use theto_json()function to parse
a JSON string to ajsonvalue:
```
```
db>selectto_json('[1, "a"]');
{Json("[1, \"a\"]")}
db>selectto_str(<json>[1, 2]);
{'[1, 2]'}
```
```
Note: This type is backed by the Postgresjsonbtype which has a size limit of 256MiB minus one byte. The
EdgeDBjsontype is also subject to this limitation.
```
operator json [ int64 ] -> json
Accesses the element of the JSON string or array at a given index.
The contents of JSON _arrays_ and _strings_ can also be accessed via[]:

```
db>select<json>'hello'[1];
{Json("\"e\"")}
db>select<json>'hello'[-1];
{Json("\"o\"")}
db>selectto_json('[1, "a", null]')[1];
{Json("\"a\"")}
db>selectto_json('[1, "a", null]')[-1];
{Json("null")}
```
```
This will raise an exception if the specified index is not valid for the base JSON value. To access an index that is
potentially out of bounds, usejson_get().
```
operator json [ int64 : int64 ] -> json
Produces a JSON value comprising a portion of the existing JSON value.
JSON _arrays_ and _strings_ can be sliced in the same way as regular arrays, producing a new JSON array or string:

```
db>select<json>'hello'[0:2];
{Json("\"he\"")}
db>select<json>'hello'[2:];
{Json("\"llo\"")}
db>selectto_json('[1, 2, 3]')[0:2];
{Json("[1, 2]")}
db>selectto_json('[1, 2, 3]')[2:];
{Json("[3]")}
db>selectto_json('[1, 2, 3]')[:1];
{Json("[1]")}
db>selectto_json('[1, 2, 3]')[:-2];
{Json("[1]")}
```
**5.8. JSON 437**


operator json ++ json -> json
Concatenates two JSON arrays, objects, or strings into one.
JSON arrays, objects and strings can be concatenated with JSON values of the same type into a new JSON value.
If you concatenate two JSON objects, you get a new object whose keys will be a union of the keys of the input
objects. If a key is present in both objects, the value from the second object is taken.

```
db>selectto_json('[1, 2]') ++ to_json('[3]');
{Json("[1, 2, 3]")}
db>selectto_json('{"a": 1}') ++ to_json('{"b": 2}');
{Json("{\"a\": 1, \"b\": 2}")}
db>selectto_json('{"a": 1, "b": 2}') ++ to_json('{"b": 3}');
{Json("{\"a\": 1, \"b\": 3}")}
db>selectto_json('"123"') ++ to_json('"456"');
{Json("\"123456\"")}
```
operator json [ str ] -> json
Accesses an element of a JSON object given its key.
The fields of JSON _objects_ can also be accessed via[]:

```
db>selectto_json('{"a": 2, "b": 5}')['b'];
{Json("5")}
db>selectj := <json>(schema::Type {
... name,
... timestamp := cal::to_local_date(datetime_current(),'UTC')
... })
...filterj['name'] = <json>'std::bool';
{Json("{\"name\": \"std::bool\", \"timestamp\": \"2022-11-21\"}")}
```
```
This will raise an exception if the specified field does not exist for the base JSON value. To access an index that
is potentially out of bounds, usejson_get().
```
function std::to_json→json

```
Index Keywords json parse loads
Returns a JSON value parsed from the given string.
```
```
db>selectto_json('[1, "hello", null]');
{Json("[1, \"hello\", null]")}
db>selectto_json('{"hello": "world"}');
{Json("{\"hello\": \"world\"}")}
```
function std::json_array_unpack→set of json

```
Index Keywords array unpack
Returns the elements of a JSON array as a set ofjson.
Calling this function on anything other than a JSON array will result in a runtime error.
This function should be used only if the ordering of elements is not important, or when the ordering of the set is
preserved (such as an immediate input to an aggregate function).
```
**438 Chapter 5. Standard Library**


```
db>selectjson_array_unpack(to_json('[1, "a"]'));
{Json("1"), Json("\"a\"")}
```
function std::json_get→optional json

```
Index Keywords safe navigation
Returns a value from a JSON object or array given its path.
This function provides “safe” navigation of a JSON value. If the input path is a valid path for the input JSON
object/array, the JSON value at the end of that path is returned:
```
```
db>selectjson_get(to_json('{
... "q": 1,
... "w": [2, "foo"],
... "e": true
... }'), 'w',' 1 ');
{Json("\"foo\"")}
```
```
This is useful when certain structure of JSON data is assumed, but cannot be reliably guaranteed. If the path
cannot be followed for any reason, the empty set is returned:
```
```
db>selectjson_get(to_json('{
... "q": 1,
... "w": [2, "foo"],
... "e": true
... }'), 'w',' 2 ');
{}
```
```
If you want to supply your own default for the case where the path cannot be followed, you can do so using the
coalesceoperator:
```
```
db>selectjson_get(to_json('{
... "q": 1,
... "w": [2, "foo"],
... "e": true
... }'), 'w',' 2 ') ?? <json>'mydefault';
{Json("\"mydefault\"")}
```
function std::json_set→optional json
Returns an updated JSON target with a new value.

```
db>selectjson_set(
... to_json('{"a": 10, "b": 20}'),
... 'a',
... value := <json>true,
... );
{Json("{\"a\": true, \"b\": 20}")}
db>selectjson_set(
... to_json('{"a": {"b": {}}}'),
... 'a','b', 'c',
... value := <json>42,
(continues on next page)
```
**5.8. JSON 439**


```
(continued from previous page)
... );
{Json("{\"a\": {\"b\": {\"c\": 42}}}")}
```
```
If create_if_missing is set tofalse, a new path for the value won’t be created:
```
```
db>selectjson_set(
... to_json('{"a": 10, "b": 20}'),
... '',
... value := <json>42,
... );
{Json("{\"a\": 10, \"b\": 20, \"\": 42}")}
db>selectjson_set(
... to_json('{"a": 10, "b": 20}'),
... '',
... value := <json>42,
... create_if_missing :=false,
... );
{Json("{\"a\": 10, \"b\": 20}")}
```
```
The empty_treatment parameter defines the behavior of the function if an empty set is passed as new_value. This
parameter can take these values:
```
- ReturnEmpty: return empty set, default
- ReturnTarget: returntargetunmodified
- Error: raise anInvalidValueError
- UseNull: use anullJSON value
- DeleteKey: delete the object key

```
db>selectjson_set(
... to_json('{"a": 10, "b": 20}'),
... 'a',
... value := <json>{}
... );
{}
db>selectjson_set(
... to_json('{"a": 10, "b": 20}'),
... 'a',
... value := <json>{},
... empty_treatment := JsonEmpty.ReturnTarget,
... );
{Json("{\"a\": 10, \"b\": 20}")}
db>selectjson_set(
... to_json('{"a": 10, "b": 20}'),
... 'a',
... value := <json>{},
... empty_treatment := JsonEmpty.Error,
... );
InvalidValueError: invalidempty JSON value
db>selectjson_set(
... to_json('{"a": 10, "b": 20}'),
... 'a',
(continues on next page)
```
**440 Chapter 5. Standard Library**


```
(continued from previous page)
... value := <json>{},
... empty_treatment := JsonEmpty.UseNull,
... );
{Json("{\"a\": null, \"b\": 20}")}
db>selectjson_set(
... to_json('{"a": 10, "b": 20}'),
... 'a',
... value := <json>{},
... empty_treatment := JsonEmpty.DeleteKey,
... );
{Json("{\"b\": 20}")}
```
function std::json_object_pack→json
Returns the given set of key/value tuples as a JSON object.

```
db>selectjson_object_pack({
... ("foo", to_json("1")),
... ("bar", to_json("null")),
... ("baz", to_json("[]"))
... });
{Json("{\"bar\": null, \"baz\": [], \"foo\": 1}")}
```
```
If the key/value tuples being packed have common keys, the last value for each key will make the final object.
```
```
db>selectjson_object_pack({
... ("hello", <json>"world"),
... ("hello", <json>true)
... });
{Json("{\"hello\": true}")}
```
function std::json_object_unpack→set of tuple<str, json>
Returns the data in a JSON object as a set of key/value tuples.
Calling this function on anything other than a JSON object will result in a runtime error.

```
db>selectjson_object_unpack(to_json('{
... "q": 1,
... "w": [2, "foo"],
... "e": true
... }'));
{('e', Json("true")), ('q',Json("1")), ('w', Json("[2, \"foo\"]"))}
```
function std::json_typeof→str

```
Index Keywords type
Returns the type of the outermost JSON value as a string.
Possible return values are:'object','array','string','number','boolean', or'null':
```
**5.8. JSON 441**


```
db>selectjson_typeof(<json>2);
{'number'}
db>selectjson_typeof(to_json('null'));
{'null'}
db>selectjson_typeof(to_json('{"a": 2}'));
{'object'}
```
### 5.9 UUIDs

```
uuid UUID type
= != ?= ?!= < > <= >= Comparison operators
uuid_generate_v1mc() Return a version 1 UUID.
uuid_generate_v4() Return a version 4 UUID.
```
type uuid
Universally Unique Identifiers (UUID).
For formal definition see RFC 4122 and ISO/IEC 9834-8:2005.
EveryObjecthas a globally unique propertyidrepresented by a UUID value.
A UUID can be cast to an object type if an object of that type with a matching ID exists.

```
db>select<Hero><uuid>'01d9cc22-b776-11ed-8bef-73f84c7e91e7';
{default::Hero {id: 01d9cc22-b776-11ed-8bef-73f84c7e91e7}}
```
function std::uuid_generate_v1mc→uuid
Return a version 1 UUID.
The algorithm uses a random multicast MAC address instead of the real MAC address of the computer.
The UUID will contain 47 random bits, 60 bits representing the current time, and 14 bits of clock sequence that
may be used to ensure uniqueness. The rest of the bits indicate the version of the UUID.
This is the default function used to populate theidcolumn.

```
db>selectuuid_generate_v1mc();
{1893e2b6-57ce-11e8-8005-13d4be166783}
```
function std::uuid_generate_v4→uuid
Return a version 4 UUID.
The UUID is derived entirely from random numbers: it will contain 122 random bits and 6 version bits.
It is permitted to override thedefaultof theidcolumn with a call to this function, but this should be done with
caution: fully random ids will be less clustered than time-based id, which may lead to worse index performance.

```
db>selectuuid_generate_v4();
{92673afc-9c4f-42b3-8273-afe0053f0f48}
```
**442 Chapter 5. Standard Library**


### 5.10 Enums

```
edb-alt-title Enum Type
```
type enum

```
Index Keywords enum
An enumerated type is a data type consisting of an ordered list of values.
An enum type can be declared in a schema by using the following syntax:
```
```
scalar typeColorextendingenum<Red, Green, Blue>;
```
```
Enum values can then be accessed directly:
```
```
db>selectColor.Red isColor;
{true}
```
```
Castingcan be used to obtain an enum value in an expression:
```
```
db>select'Red' is Color;
{false}
db>select<Color>'Red'is Color;
{true}
db>select<Color>'Red'= Color.Red;
{true}
```
```
Note: The enum values in EdgeQL are string-like in the fact that they can contain any characters that the
strings can. This is different from some other languages where enum values are identifier-like and thus cannot
contain some characters. For example, when working with GraphQL enum values that contain characters that
aren’t allowed in identifiers cannot be properly reflected. To address this, consider using only identifier-like enum
values in cases where such compatibility is needed.
```
### 5.11 Dates and Times

```
edb-alt-title Types, Functions, and Operators for Dates and Times
```
**5.10. Enums 443**


```
datetime Timezone-aware point in time
duration Absolute time span
cal::local_datetime Date and time w/o timezone
cal::local_date Date type
cal::local_time Time type
cal::relative_duration Relative time span
cal::date_duration Relative time span in days
dt + dt Adds a duration and any other datetime value.
dt - dt Subtracts two compatible datetime or duration values.
= != ?= ?!= < > <= >= Comparison operators
to_str() Render a date/time value to a string.
to_datetime() Create a datetime value.
cal::to_local_datetime() Create a cal::local_datetime value.
cal::to_local_date() Create a cal::local_date value.
cal::to_local_time() Create a cal::local_time value.
to_duration() Create a duration value.
cal::to_relative_duration() Create a cal::relative_duration value.
cal::to_date_duration() Create a cal::date_duration value.
datetime_get() Returns the element of a date/time given a unit name.
cal::time_get() Returns the element of a time value given a unit name.
cal::date_get() Returns the element of a date given a unit name.
duration_get() Returns the element of a duration given a unit name.
datetime_truncate() Truncates the input datetime to a particular precision.
duration_truncate() Truncates the input duration to a particular precision.
datetime_current() Returns the server's current date and time.
datetime_of_transaction() Returns the date and time of the start of the current transaction.
datetime_of_statement() Returns the date and time of the start of the current statement.
cal::duration_normalize_hours() Convert 24-hour chunks into days.
cal::duration_normalize_days() Convert 30-day chunks into months.
```
EdgeDB offers two ways of representing date/time values:

- a timezone-awarestd::datetimetype;
- a set of “local” date/time types, not attached to any particular timezone: cal::local_datetime,
    cal::local_date, andcal::local_time.

There are also two different ways of measuring duration:

- durationfor using absolute and unambiguous units;
- cal::relative_durationfor using fuzzy units like years, months and days in addition to the absolute units.

All related operators, functions, and type casts are designed to maintain a strict separation between timezone-aware
and “local” date/time values.

EdgeDB stores and outputs timezone-aware values in UTC format.

**Note:** All date/time types are restricted to years between 1 and 9999, including the years 1 and 9999.

Although many systems support ISO 8601 date/time formatting in theory, in practice the formatting before year 1 and
after 9999 tends to be inconsistent. As such, dates outside this range are not reliably portable.

**444 Chapter 5. Standard Library**


type datetime
Represents a timezone-aware moment in time.
All dates must correspond to dates that exist in the proleptic Gregorian calendar.
Castingis a simple way to obtain adatetimevalue in an expression:

```
select <datetime>'2018-05-07T15:01:22.306916+00';
select <datetime>'2018-05-07T15:01:22+00';
```
```
When castingdatetimefrom strings, the string must follow the ISO 8601 format with a timezone included.
```
```
db>select<datetime>'January 01 2019 UTC';
InvalidValueError: invalid input syntaxfor type
std::datetime:'January 01 2019 UTC'
Hint: Please use ISO8601 format. Alternatively "to_datetime"
functionprovides custom formatting options.
```
```
db>select<datetime>'2019-01-01T15:01:22';
InvalidValueError: invalid input syntaxfor type
std::datetime:'2019-01-01T15:01:22'
Hint: Please use ISO8601 format. Alternatively "to_datetime"
functionprovides custom formatting options.
```
```
Alldatetimevalues are restricted to the range from year 1 to 9999.
For more information regarding interacting with this type, seedatetime_get(), to_datetime(), and
to_str().
```
type cal::local_datetime
A type for representing a date and time without a timezone.
Castingis a simple way to obtain acal::local_datetimevalue in an expression:

```
select <cal::local_datetime>'2018-05-07T15:01:22.306916';
select <cal::local_datetime>'2018-05-07T15:01:22';
```
```
When castingcal::local_datetimefrom strings, the string must follow the ISO 8601 format without time-
zone:
```
```
db>select<cal::local_datetime>'2019-01-01T15:01:22+00';
InvalidValueError: invalid input syntaxfor type
cal::local_datetime:'2019-01-01T15:01:22+00'
Hint: Please use ISO8601 format. Alternatively
"cal::to_local_datetime"functionprovides custom formatting
options.
```
```
db>select<cal::local_datetime>'January 01 2019';
InvalidValueError: invalid input syntaxfor type
cal::local_datetime:'January 01 2019'
Hint: Please use ISO8601 format. Alternatively
"cal::to_local_datetime"functionprovides custom formatting
options.
```
```
Alldatetimevalues are restricted to the range from year 1 to 9999.
```
**5.11. Dates and Times 445**


```
For more information regarding interacting with this type, see datetime_get(),
cal::to_local_datetime(), andto_str().
```
type cal::local_date
A type for representing a date without a timezone.
Castingis a simple way to obtain acal::local_datevalue in an expression:

```
select <cal::local_date>'2018-05-07';
```
```
When castingcal::local_datefrom strings, the string must follow the ISO 8601 date format.
For more information regarding interacting with this type, seecal::date_get(),cal::to_local_date(),
andto_str().
```
type cal::local_time
A type for representing a time without a timezone.
Castingis a simple way to obtain acal::local_timevalue in an expression:

```
select <cal::local_time>'15:01:22.306916';
select <cal::local_time>'15:01:22';
```
```
When castingcal::local_timefrom strings, the string must follow the ISO 8601 time format.
For more information regarding interacting with this type, seecal::time_get(),cal::to_local_time(),
andto_str().
```
type duration
A type for representing a span of time.
Adurationis a fixed number of seconds and microseconds and isn’t adjusted by timezone, length of month, or
anything else in datetime calculations.
When converting from a string, only units of'microseconds','milliseconds','seconds','minutes',
and'hours'are valid:

```
db>select<duration>'45.6 seconds';
{<duration>'0:00:45.6'}
db>select<duration>'15 milliseconds';
{<duration>'0:00:00.015'}
db>select<duration>'48 hours 45 minutes';
{<duration>'48:45:00'}
db>select<duration>'11 months';
edgedb error: InvalidValueError: invalid input syntaxfor type
std::duration:'11 months'
Hint: Units bigger than hours cannot be used forstd::duration.
```
```
All date/time types support the+and-arithmetic operations with durations:
```
```
db>select<datetime>'2019-01-01T00:00:00Z'- <duration>'24 hours';
{<datetime>'2018-12-31T00:00:00+00:00'}
db>select<cal::local_time>'22:00'+ <duration>'1 hour';
{<cal::local_time>'23:00:00'}
```
**446 Chapter 5. Standard Library**


```
For more information regarding interacting with this type, seeto_duration(), andto_str()and date/time
operators.
```
type cal::relative_duration
A type for representing a relative span of time.
Unlikestd::duration,cal::relative_durationis an imprecise form of measurement. When months and
days are used, the same relative duration could have a different absolute duration depending on the date you’re
measuring from.
For example 2020 was a leap year and had 366 days. Notice how the number of hours in each year below is
different:

```
db>with
... first_day_of_2020 := <datetime>'2020-01-01T00:00:00Z',
... one_year := <cal::relative_duration>'1 year',
... first_day_of_next_year := first_day_of_2020 + one_year
...selectfirst_day_of_next_year - first_day_of_2020;
{<duration>'8784:00:00'}
db>with
... first_day_of_2019 := <datetime>'2019-01-01T00:00:00Z',
... one_year := <cal::relative_duration>'1 year',
... first_day_of_next_year := first_day_of_2019 + one_year
...selectfirst_day_of_next_year - first_day_of_2019;
{<duration>'8760:00:00'}
```
```
When converting from a string, only the following units are valid:
```
- 'microseconds'
- 'milliseconds'
- 'seconds'
- 'minutes'
- 'hours'
- 'days'
- 'weeks'
- 'months'
- 'years'
- 'decades'
- 'centuries'
- 'millennia'
Examples of units usage:

```
select <cal::relative_duration>'45.6 seconds';
select <cal::relative_duration>'15 milliseconds';
select <cal::relative_duration>'3 weeks 45 minutes';
select <cal::relative_duration>'-7 millennia';
```
```
All date/time types support the+and-arithmetic operations withrelative_duration:
```
**5.11. Dates and Times 447**


```
db>select<datetime>'2019-01-01T00:00:00Z'-
... <cal::relative_duration>'3 years';
{<datetime>'2016-01-01T00:00:00+00:00'}
db>select<cal::local_time>'22:00'+
... <cal::relative_duration>'1 hour';
{<cal::local_time>'23:00:00'}
```
```
If an arithmetic operation results in a day that doesn’t exist in the given month, the last day of the month will be
used instead:
```
```
db>select<cal::local_datetime>"2021-01-31T15:00:00" +
... <cal::relative_duration>"1 month";
{<cal::local_datetime>'2021-02-28T15:00:00'}
```
```
For arithmetic operations involving acal::relative_durationconsisting of multiple components (units),
higher-order components are applied first followed by lower-order components.
```
```
db>select<cal::local_datetime>"2021-04-30T15:00:00" +
... <cal::relative_duration>"1 month 1 day";
{<cal::local_datetime>'2021-05-31T15:00:00'}
```
```
If you add the same components split into separate durations, adding the higher-order units first followed by the
lower-order units, the calculation produces the same result as in the previous example:
```
```
db>select<cal::local_datetime>"2021-04-30T15:00:00" +
... <cal::relative_duration>"1 month" +
... <cal::relative_duration>"1 day";
{<cal::local_datetime>'2021-05-31T15:00:00'}
```
```
When the order of operations is reversed, the result may be different for some corner cases:
```
```
db>select<cal::local_datetime>"2021-04-30T15:00:00" +
... <cal::relative_duration>"1 day" +
... <cal::relative_duration>"1 month";
{<cal::local_datetime>'2021-06-01T15:00:00'}
```
```
Gotchas
```
```
Due to the implementation ofrelative_durationlogic, arithmetic operations may behave counterintuitively.
Non-associative
```
```
db>select<cal::local_datetime>'2021-01-31T00:00:00'+
... <cal::relative_duration>'1 month'+
... <cal::relative_duration>'1 month';
{<cal::local_datetime>'2021-03-28T00:00:00'}
db>select<cal::local_datetime>'2021-01-31T00:00:00'+
... (<cal::relative_duration>'1 month'+
... <cal::relative_duration>'1 month');
{<cal::local_datetime>'2021-03-31T00:00:00'}
```
```
Lossy
```
**448 Chapter 5. Standard Library**


```
db>withm := <cal::relative_duration>'1 month'
...select<cal::local_date>'2021-01-31'+ m
... =
... <cal::local_date>'2021-01-30'+ m;
{true}
```
```
Asymmetric
```
```
db>withm := <cal::relative_duration>'1 month'
...select<cal::local_date>'2021-01-31'+ m - m;
{<cal::local_date>'2021-01-28'}
```
```
Non-monotonic
```
```
db>withm := <cal::relative_duration>'1 month'
...select<cal::local_datetime>'2021-01-31T01:00:00'+ m
... <
... <cal::local_datetime>'2021-01-30T23:00:00'+ m;
{true}
db>withm := <cal::relative_duration>'2 month'
...select<cal::local_datetime>'2021-01-31T01:00:00'+ m
... <
... <cal::local_datetime>'2021-01-30T23:00:00'+ m;
{false}
```
```
For more information regarding interacting with this type, seecal::to_relative_duration(), and
to_str()and date/timeoperators.
```
type cal::date_duration
A type for representing a span of time in days.
This type is similar tocal::relative_duration, except it only uses 2 units: months and days. It is the result
of subtracting onecal::local_datefrom another. The purpose of this type is to allow performing+and-
operations on acal::local_dateand to produce acal::local_dateas the result:

```
db>select<cal::local_date>'2022-06-30'-
... <cal::local_date>'2022-06-25';
{<cal::date_duration>'P5D'}
db>select<cal::local_date>'2022-06-25'+
... <cal::date_duration>'5 days';
{<cal::local_date>'2022-06-30'}
db>select<cal::local_date>'2022-06-25'-
... <cal::date_duration>'5 days';
{<cal::local_date>'2022-06-20'}
```
```
When converting from a string, only the following units are valid:
```
- 'days',
- 'weeks',
- 'months',
- 'years',
- 'decades',

**5.11. Dates and Times 449**


- 'centuries',
- 'millennia'.

```
select <cal::date_duration>'45 days';
select <cal::date_duration>'3 weeks 5 days';
select <cal::date_duration>'-7 millennia';
```
```
In most cases,date_durationis fully compatible withcal::relative_durationand shares the same gen-
eral behavior and caveats. EdgeDB will apply type coercion in the event it expects acal::relative_duration
and finds acal::date_durationinstead.
For more information regarding interacting with this type, seecal::to_date_duration()and date/time
operators.
```
operator datetime + duration -> datetime
operator
datetime + cal::relative_duration -> cal::relative_duration
operator duration + duration -> duration
operator
duration + cal::relative_duration -> cal::relative_duration
operator
cal::relative_duration + cal::relative_duration -> cal::relative_duration
operator
cal::local_datetime + cal::relative_duration -> cal::relative_duration
operator cal::local_datetime + duration -> cal::local_datetime
operator
cal::local_time + cal::relative_duration -> cal::relative_duration
operator cal::local_time + duration -> cal::local_time
operator cal::local_date + cal::date_duration -> cal::local_date
operator
cal::date_duration + cal::date_duration -> cal::date_duration
operator
cal::local_date + cal::relative_duration -> cal::local_datetime
operator cal::local_date + duration -> cal::local_datetime
Adds a duration and any other datetime value.
This operator is commutative.

```
db>select<cal::local_time>'22:00'+ <duration>'1 hour';
{<cal::local_time>'23:00:00'}
db>select<duration>'1 hour' + <cal::local_time>'22:00';
{<cal::local_time>'23:00:00'}
db>select<duration>'1 hour' + <duration>'2 hours';
{10800s}
```
operator duration - duration -> duration
operator datetime - datetime -> duration
operator datetime - duration -> datetime
operator datetime - cal::relative_duration -> datetime
operator
cal::relative_duration - cal::relative_duration -> cal::relative_duration
operator
cal::local_datetime - cal::local_datetime -> cal::relative_duration

**450 Chapter 5. Standard Library**


operator
cal::local_datetime - cal::relative_duration -> cal::local_datetime
operator cal::local_datetime - duration -> cal::local_datetime
operator
cal::local_time - cal::local_time -> cal::relative_duration
operator
cal::local_time - cal::relative_duration -> cal::local_time
operator cal::local_time - duration -> cal::local_time
operator
cal::date_duration - cal::date_duration -> cal::date_duration
operator
cal::local_date - cal::local_date -> cal::date_duration
operator
cal::local_date - cal::date_duration -> cal::local_date
operator
cal::local_date - cal::relative_duration -> cal::local_datetime
operator cal::local_date - duration -> cal::local_datetime
operator
duration - cal::relative_duration -> cal::relative_duration
operator
cal::relative_duration - duration -> cal::relative_duration
Subtracts two compatible datetime or duration values.

```
db>select<datetime>'2019-01-01T01:02:03+00' -
... <duration>'24 hours';
{<datetime>'2018-12-31T01:02:03Z'}
db>select<datetime>'2019-01-01T01:02:03+00' -
... <datetime>'2019-02-01T01:02:03+00';
{-2678400s}
db>select<duration>'1 hour' -
... <duration>'2 hours';
{-3600s}
```
```
When subtracting acal::local_datetype from another, the result is given as a whole number of days using
thecal::date_durationtype:
```
```
db>select<cal::local_date>'2022-06-25'-
... <cal::local_date>'2019-02-01';
{<cal::date_duration>'P1240D'}
```
```
Note: Subtraction doesn’t make sense for some type combinations. You couldn’t subtract a point in time from
a duration, so neither can EdgeDB (although the inverse — subtracting a duration from a point in time — is
perfectly fine). You also couldn’t subtract a timezone-aware datetime from a local one or vice versa. If you
attempt any of these, EdgeDB will raise an exception as shown in these examples.
```
```
When subtracting a date/time object from a time interval, an exception will be raised:
```
```
db>select<duration>'1 day' -
... <datetime>'2019-01-01T01:02:03+00';
QueryError:operator'-' cannot beapplied to operands ...
```
```
An exception will also be raised when trying to subtract a timezone-awarestd::datetimetype from
cal::local_datetimeor vice versa:
```
**5.11. Dates and Times 451**


```
db>select<datetime>'2019-01-01T01:02:03+00' -
... <cal::local_datetime>'2019-02-01T01:02:03';
QueryError:operator'-' cannot beapplied to operands...
db>select<cal::local_datetime>'2019-02-01T01:02:03'-
... <datetime>'2019-01-01T01:02:03+00';
QueryError:operator'-' cannot beapplied to operands...
```
function std::datetime_current→datetime

```
Index Keywords now
Returns the server’s current date and time.
```
```
db>selectdatetime_current();
{<datetime>'2018-05-14T20:07:11.755827Z'}
```
```
This function is volatile since it always returns the current time when it is called. As a result, it cannot be used
in computed properties defined in schema. This does not apply to computed properties outside of schema.
```
function std::datetime_of_transaction→datetime

```
Index Keywords now
Returns the date and time of the start of the current transaction.
This function is non-volatile since it returns the current time when the transaction is started, not when the function
is called. As a result, it can be used in computed properties defined in schema.
```
function std::datetime_of_statement→datetime

```
Index Keywords now
Returns the date and time of the start of the current statement.
This function is non-volatile since it returns the current time when the statement is started, not when the function
is called. As a result, it can be used in computed properties defined in schema.
```
function std::datetime_get→float64
function std::datetime_get→float64
Returns the element of a date/time given a unit name.
You may pass any of these unit names for _el_ :

- 'epochseconds'- the number of seconds since 1970-01-01 00:00:00 UTC (Unix epoch) fordatetime
    or local time forcal::local_datetime. It can be negative.
- 'century'- the century according to the Gregorian calendar
- 'day'- the day of the month (1-31)
- 'decade'- the decade (year divided by 10 and rounded down)
- 'dow'- the day of the week from Sunday (0) to Saturday (6)
- 'doy'- the day of the year (1-366)

**452 Chapter 5. Standard Library**


- 'hour'- the hour (0-23)
- 'isodow'- the ISO day of the week from Monday (1) to Sunday (7)
- 'isoyear'- the ISO 8601 week-numbering year that the date falls in. See the'week'element for more
    details.
- 'microseconds'- the seconds including fractional value expressed as microseconds
- 'millennium'- the millennium. The third millennium started on Jan 1, 2001.
- 'milliseconds'- the seconds including fractional value expressed as milliseconds
- 'minutes'- the minutes (0-59)
- 'month'- the month of the year (1-12)
- 'quarter'- the quarter of the year (1-4)
- 'seconds'- the seconds, including fractional value from 0 up to and not including 60
- 'week'- the number of the ISO 8601 week-numbering week of the year. ISO weeks are defined to start on
    Mondays and the first week of a year must contain Jan 4 of that year.
- 'year'- the year

```
db>selectdatetime_get(
... <datetime>'2018-05-07T15:01:22.306916+00',
... 'epochseconds');
{1525705282.306916}
```
```
db>selectdatetime_get(
... <datetime>'2018-05-07T15:01:22.306916+00',
... 'year');
{2018}
```
```
db>selectdatetime_get(
... <datetime>'2018-05-07T15:01:22.306916+00',
... 'quarter');
{2}
```
```
db>selectdatetime_get(
... <datetime>'2018-05-07T15:01:22.306916+00',
... 'doy');
{127}
```
```
db>selectdatetime_get(
... <datetime>'2018-05-07T15:01:22.306916+00',
... 'hour');
{15}
```
function cal::time_get→float64
Returns the element of a time value given a unit name.
You may pass any of these unit names for _el_ :

- 'midnightseconds'
- 'hour'

**5.11. Dates and Times 453**


- 'microseconds'
- 'milliseconds'
- 'minutes'
- 'seconds'
For full description of what these elements extract seedatetime_get().

```
db>selectcal::time_get(
... <cal::local_time>'15:01:22.306916','minutes');
{1}
```
```
db>selectcal::time_get(
... <cal::local_time>'15:01:22.306916','milliseconds');
{22306.916}
```
function cal::date_get→float64
Returns the element of a date given a unit name.
Thecal::local_datescalar has the following elements available for extraction:

- 'century'- the century according to the Gregorian calendar
- 'day'- the day of the month (1-31)
- 'decade'- the decade (year divided by 10 and rounded down)
- 'dow'- the day of the week from Sunday (0) to Saturday (6)
- 'doy'- the day of the year (1-366)
- 'isodow'- the ISO day of the week from Monday (1) to Sunday (7)
- 'isoyear'- the ISO 8601 week-numbering year that the date falls in. See the'week'element for more
    details.
- 'millennium'- the millennium. The third millennium started on Jan 1, 2001.
- 'month'- the month of the year (1-12)
- 'quarter'- the quarter of the year (1-4) not including 60
- 'week'- the number of the ISO 8601 week-numbering week of the year. ISO weeks are defined to start on
    Mondays and the first week of a year must contain Jan 4 of that year.
- 'year'- the year

```
db>selectcal::date_get(
... <cal::local_date>'2018-05-07', 'century');
{21}
```
```
db>selectcal::date_get(
... <cal::local_date>'2018-05-07', 'year');
{2018}
```
```
db>selectcal::date_get(
... <cal::local_date>'2018-05-07', 'month');
{5}
(continues on next page)
```
**454 Chapter 5. Standard Library**


```
(continued from previous page)
```
```
db>selectcal::date_get(
... <cal::local_date>'2018-05-07', 'doy');
{127}
```
function std::duration_get→float64
function std::duration_get→float64
function std::duration_get→float64
Returns the element of a duration given a unit name.
You may pass any of these unit names asel:

- 'millennium'- number of 1000-year chunks rounded down
- 'century'- number of centuries rounded down
- 'decade'- number of decades rounded down
- 'year'- number of years rounded down
- 'quarter'- remaining quarters after whole years are accounted for
- 'month'- number of months left over after whole years are accounted for
- 'day'- number of days recorded in the duration
- 'hour'- number of hours
- 'minutes'- remaining minutes after whole hours are accounted for
- 'seconds'- remaining seconds, including fractional value after whole minutes are accounted for
- 'milliseconds'- remaining seconds including fractional value expressed as milliseconds
- 'microseconds'- remaining seconds including fractional value expressed as microseconds

```
Note: Only for units'month'or larger or for units'hour'or smaller will you receive a total across multiple
units expressed in the original duration. See Gotchas below for details.
```
```
Additionally, it’s possible to convert a given duration into seconds:
```
- 'totalseconds'- the number of seconds represented by the duration. It will be approximate for
    cal::relative_durationandcal::date_durationfor units'month'or larger because a month
    is assumed to be 30 days exactly.
Thedurationscalar has only'hour'and smaller units available for extraction.
Thecal::relative_durationscalar has all of the units available for extraction.
Thecal::date_durationscalar only has'date'and larger units available for extraction.

```
db>selectduration_get(
... <cal::relative_duration>'400 months','year');
{33}
db>selectduration_get(
... <cal::date_duration>'400 months','month');
{4}
db>selectduration_get(
(continues on next page)
```
**5.11. Dates and Times 455**


```
(continued from previous page)
... <cal::relative_duration>'1 month 20 days 30 hours',
... 'day');
{20}
db>selectduration_get(
... <cal::relative_duration>'30 hours', 'hour');
{30}
db>selectduration_get(
... <cal::relative_duration>'1 month 20 days 30 hours',
... 'hour');
{30}
db>selectduration_get(<duration>'30 hours', 'hour');
{30}
db>selectduration_get(
... <cal::relative_duration>'1 month 20 days 30 hours',
... 'totalseconds');
{4428000}
db>selectduration_get(
... <duration>'30 hours','totalseconds');
{108000}
```
```
Gotchas
```
```
This function will provide you with a calculated total for the unit passed asel, but only within the given “size
class” of the unit. These size classes exist because they are logical breakpoints that we can’t reliably convert
values across. A month might be 30 days long, or it might be 28 or 29 or 31. A day is generally 24 hours, but
with daylight savings, it might be longer or shorter.
As a result, it’s impossible to convert across these lines in a way that works in every situation. For some use
cases, assuming a 30 day month works fine. For others, it might not. The size classes are as follows:
```
- 'month'and larger
- 'day'
- 'hour'and smaller
For example, if you specify'day'as yourelargument, the function will return only the number of days ex-
pressed asN daysin your duration. It will not add another day to the returned count for every 24 hours (defined
as24 hours) in the duration, nor will it consider the months’ constituent day counts in the returned value. Spec-
ifying'decade'forelwill total up all decades represented in units'month'and larger, but it will not add a
decade’s worth of days to the returned value as an additional decade.
In this example, the duration represents more than a day’s time, but since'day'and'hour'are in different size
classes, the extra day stemming from the duration’s hours is not added.

```
db>selectduration_get(
... <cal::relative_duration>'1 day 36 hours','day');
{1}
```
```
In this counter example, both the decades and months are pooled together since they are in the same size class.
The return value is 5: the 2'decades'and the 3 decades in'400 months'.
```
**456 Chapter 5. Standard Library**


```
db>selectduration_get(
... <cal::relative_duration>'2 decades 400 months','decade');
{5}
```
```
If a unit from a smaller size class would contribute to your desired unit’s total, it is not added.
```
```
db>selectduration_get(
... <cal::relative_duration>'1 year 400 days','year');
{1}
```
```
When you request a unit in the smallest size class, it will be pooled with other durations in the same size class.
```
```
db>selectduration_get(
... <cal::relative_duration>'20 hours 3600 seconds', 'hour');
{21}
```
```
Seconds and smaller units always return remaining time in that unit after accounting for the next larger unit.
```
```
db>selectduration_get(
... <cal::relative_duration>'20 hours 3600 seconds', 'seconds');
{0}
db>selectduration_get(
... <cal::relative_duration>'20 hours 3630 seconds', 'seconds');
{30}
```
```
Normalization and truncation may help you deal with this. If your use case allows for making assump-
tions about the duration of a month or a day, you can make those conversions for yourself using the
cal::duration_normalize_hours()orcal::duration_normalize_days()functions. If you got back a
duration as a result of a datetime calculation and don’t need the level of granularity you have, you can truncate
the value withduration_truncate().
```
function std::datetime_truncate→datetime
Truncates the input datetime to a particular precision.
The valid units in order or decreasing precision are:

- 'microseconds'
- 'milliseconds'
- 'seconds'
- 'minutes'
- 'hours'
- 'days'
- 'weeks'
- 'months'
- 'quarters'
- 'years'
- 'decades'
- 'centuries'

**5.11. Dates and Times 457**


```
db>selectdatetime_truncate(
... <datetime>'2018-05-07T15:01:22.306916+00','years');
{<datetime>'2018-01-01T00:00:00Z'}
```
```
db>selectdatetime_truncate(
... <datetime>'2018-05-07T15:01:22.306916+00','quarters');
{<datetime>'2018-04-01T00:00:00Z'}
```
```
db>selectdatetime_truncate(
... <datetime>'2018-05-07T15:01:22.306916+00','days');
{<datetime>'2018-05-07T00:00:00Z'}
```
```
db>selectdatetime_truncate(
... <datetime>'2018-05-07T15:01:22.306916+00','hours');
{<datetime>'2018-05-07T15:00:00Z'}
```
function std::duration_truncate→duration
function std::duration_truncate→cal::relative_duration
Truncates the input duration to a particular precision.
The valid units fordurationare:

- 'microseconds'
- 'milliseconds'
- 'seconds'
- 'minutes'
- 'hours'
In addition to the above the following are also valid forcal::relative_duration:
- 'days'
- 'weeks'
- 'months'
- 'years'
- 'decades'
- 'centuries'

```
db>selectduration_truncate(
... <duration>'15:01:22','hours');
{<duration>'15:00:00'}
db>selectduration_truncate(
... <duration>'15:01:22.306916','minutes');
{<duration>'15:01:00'}
db>selectduration_truncate(
... <cal::relative_duration>'400 months','years');
{<cal::relative_duration>'P33Y'}
db>selectduration_truncate(
... <cal::relative_duration>'400 months','decades');
{<cal::relative_duration>'P30Y'}
```
**458 Chapter 5. Standard Library**


function std::to_datetime→datetime
function std::to_datetime→datetime
function std::to_datetime→datetime
function std::to_datetime→datetime
function std::to_datetime→datetime
function std::to_datetime→datetime

```
Index Keywords parse datetime
Create adatetimevalue.
Thedatetimevalue can be parsed from the inputstr s. By default, the input is expected to conform to ISO
8601 format. However, the optional argument fmt can be used to override the input format to other forms.
```
```
db>selectto_datetime('2018-05-07T15:01:22.306916+00');
{<datetime>'2018-05-07T15:01:22.306916Z'}
db>selectto_datetime('2018-05-07T15:01:22+00');
{<datetime>'2018-05-07T15:01:22Z'}
db>selectto_datetime('May 7th, 2018 15:01:22 +00',
... 'Mon DDth, YYYY HH24:MI:SS TZH');
{<datetime>'2018-05-07T15:01:22Z'}
```
```
Alternatively, thedatetimevalue can be constructed from acal::local_datetimevalue:
```
```
db>selectto_datetime(
... <cal::local_datetime>'2019-01-01T01:02:03','HKT');
{<datetime>'2018-12-31T17:02:03Z'}
```
```
Another way to construct a thedatetimevalue is to specify it in terms of its component parts: year , month ,
day , hour , min , sec , and timezone.
```
```
db>selectto_datetime(
... 2018, 5, 7, 15, 1, 22.306916,'UTC');
{<datetime>'2018-05-07T15:01:22.306916000Z'}
```
```
Finally, it is also possible to convert a Unix timestamp to adatetime
```
```
db>selectto_datetime(1590595184.584);
{<datetime>'2020-05-27T15:59:44.584000000Z'}
```
function cal::to_local_datetime→local_datetime
function cal::to_local_datetime→local_datetime
function cal::to_local_datetime→local_datetime

```
Index Keywords parse local_datetime
Create acal::local_datetimevalue.
Similar toto_datetime(), thecal::local_datetimevalue can be parsed from the inputstr s with an
optional fmt argument or it can be given in terms of its component parts: year , month , day , hour , min , sec.
For more details on formatting see here.
```
**5.11. Dates and Times 459**


```
db>selectcal::to_local_datetime('2018-05-07T15:01:22.306916');
{<cal::local_datetime>'2018-05-07T15:01:22.306916'}
db>selectcal::to_local_datetime('May 7th, 2018 15:01:22',
... 'Mon DDth, YYYY HH24:MI:SS');
{<cal::local_datetime>'2018-05-07T15:01:22'}
db>selectcal::to_local_datetime(
... 2018, 5, 7, 15, 1, 22.306916);
{<cal::local_datetime>'2018-05-07T15:01:22.306916'}
```
```
A timezone-awaredatetimetype can be converted to local datetime in the specified timezone:
```
```
db>selectcal::to_local_datetime(
... <datetime>'2018-12-31T22:00:00+08',
... 'US/Central');
{<cal::local_datetime>'2018-12-31T08:00:00'}
```
function cal::to_local_date→cal::local_date
function cal::to_local_date→cal::local_date
function cal::to_local_date→cal::local_date

```
Index Keywords parse local_date
Create acal::local_datevalue.
Similar toto_datetime(), thecal::local_datevalue can be parsed from the inputstr s with an optional
fmt argument or it can be given in terms of its component parts: year , month , day.
For more details on formatting see here.
```
```
db>selectcal::to_local_date('2018-05-07');
{<cal::local_date>'2018-05-07'}
db>selectcal::to_local_date('May 7th, 2018', 'Mon DDth, YYYY');
{<cal::local_date>'2018-05-07'}
db>selectcal::to_local_date(2018, 5, 7);
{<cal::local_date>'2018-05-07'}
```
```
A timezone-awaredatetimetype can be converted to local date in the specified timezone:
```
```
db>selectcal::to_local_date(
... <datetime>'2018-12-31T22:00:00+08',
... 'US/Central');
{<cal::local_date>'2019-01-01'}
```
function cal::to_local_time→local_time
function cal::to_local_time→local_time
function cal::to_local_time→local_time

```
Index Keywords parse local_time
Create acal::local_timevalue.
Similar toto_datetime(), thecal::local_timevalue can be parsed from the inputstr s with an optional
fmt argument or it can be given in terms of its component parts: hour , min , sec.
For more details on formatting see here.
```
**460 Chapter 5. Standard Library**


```
db>selectcal::to_local_time('15:01:22.306916');
{<cal::local_time>'15:01:22.306916'}
db>selectcal::to_local_time('03:01:22pm','HH:MI:SSam');
{<cal::local_time>'15:01:22'}
db>selectcal::to_local_time(15, 1, 22.306916);
{<cal::local_time>'15:01:22.306916'}
```
```
A timezone-awaredatetimetype can be converted to local date in the specified timezone:
```
```
db>selectcal::to_local_time(
... <datetime>'2018-12-31T22:00:00+08',
... 'US/Pacific');
{<cal::local_time>'06:00:00'}
```
function std::to_duration→duration

```
Index Keywords duration
Create adurationvalue.
This function usesnamed onlyarguments to create adurationvalue. The available duration fields are: hours ,
minutes , seconds , microseconds.
```
```
db>selectto_duration(hours := 1,
... minutes := 20,
... seconds := 45);
{4845s}
db>selectto_duration(seconds := 4845);
{4845s}
```
function std::duration_to_seconds→decimal
Return duration as total number of seconds in interval.

```
db>selectduration_to_seconds(<duration>'1 hour');
{3600.000000n}
db>selectduration_to_seconds(<duration>'10 second 123 ms');
{10.123000n}
```
function cal::to_relative_duration→cal::relative_duration

```
Index Keywords parse relative_duration
Create acal::relative_durationvalue.
This function usesnamed onlyarguments to create acal::relative_durationvalue. The available duration
fields are: years , months , days , hours , minutes , seconds , microseconds.
```
```
db>selectcal::to_relative_duration(years := 5, minutes := 1);
{<cal::relative_duration>'P5YT1S'}
db>selectcal::to_relative_duration(months := 3, days := 27);
{<cal::relative_duration>'P3M27D'}
```
**5.11. Dates and Times 461**


function cal::to_date_duration→cal::date_duration

```
Index Keywords parse date_duration
Create acal::date_durationvalue.
This function usesnamed onlyarguments to create acal::date_durationvalue. The available duration
fields are: years , months , days.
```
```
db>selectcal::to_date_duration(years := 1, days := 3);
{<cal::date_duration>'P1Y3D'}
db>selectcal::to_date_duration(days := 12);
{<cal::date_duration>'P12D'}
```
function cal::duration_normalize_hours→cal::relative_duration

```
Index Keywords justify_hours
Convert 24-hour chunks into days.
This function converts all 24-hour chunks into day units. The resultingcal::relative_durationis guaran-
teed to have less than 24 hours in total in the units smaler than days.
```
```
db>selectcal::duration_normalize_hours(
... <cal::relative_duration>'1312 hours');
{<cal::relative_duration>'P54DT16H'}
```
```
This is a lossless operation because 24 hours are always equal to 1 day incal::relative_durationunits.
This is sometimes used together withcal::duration_normalize_days().
```
function cal::duration_normalize_days→cal::relative_duration
function cal::duration_normalize_days→cal::date_duration

```
Index Keywords justify_days
Convert 30-day chunks into months.
This function converts all 30-day chunks into month units. The resultingcal::relative_durationor
cal::date_durationis guaranteed to have less than 30 day units.
```
```
db>selectcal::duration_normalize_days(
... <cal::relative_duration>'1312 days');
{<cal::relative_duration>'P3Y7M22D'}
```
```
db>selectcal::duration_normalize_days(
... <cal::date_duration>'1312 days');
{<cal::date_duration>'P3Y7M22D'}
```
```
This function is a form of approximation and does not preserve the exact duration.
This is often used together withcal::duration_normalize_hours().
```
**462 Chapter 5. Standard Library**


### 5.12 Arrays

```
edb-alt-title Array Functions and Operators
```
```
array[i] Accesses the array element at a given index.
array[from:to] Produces a sub-array from an existing array.
array ++ array Concatenates two arrays of the same type into one.
= != ?= ?!= < > <= >= Comparison operators
len() Returns the number of elements in the array.
contains() Checks if an element is in the array.
find() Finds the index of an element in the array.
array_join() Renders an array to a string.
array_fill() Returns an array of the specified size, filled with the provided value.
array_replace() Returns an array with all occurrences of one value replaced by another.
array_agg() Returns an array made from all of the input set elements.
array_get() Returns the element of a given array at the specified index.
array_unpack() Returns the elements of an array as a set.
```
Arrays store expressions of the _same type_ in an ordered list.

#### 5.12.1 Constructing arrays

An array constructor is an expression that consists of a sequence of comma-separated expressions _of the same type_
enclosed in square brackets. It produces an array value:

"[" <expr> [, ...] "]"

For example:

db>select [1, 2, 3];
{[1, 2, 3]}
db>select [('a', 1), ('b', 2), ('c', 3)];
{[('a', 1), ('b', 2), ('c', 3)]}

#### 5.12.2 Empty arrays

You can also create an empty array, but it must be done by providing the type information using type casting. EdgeDB
cannot infer the type of an empty array created otherwise. For example:

db>select [];
QueryError:expressionreturns value of indeterminatetype
Hint: Considerusing an explicittypecast.
### select [];
### ^

db>select <array<int64>>[];
{[]}

**5.12. Arrays 463**


#### 5.12.3 Reference

type array

```
Index Keywords array
An ordered list of values of the same type.
Array indexing starts at zero.
An array can contain any type except another array. In EdgeDB, arrays are always one-dimensional.
An array type is created implicitly when an array constructor is used:
```
```
db>select[1, 2];
{[1, 2]}
```
```
The array types themselves are denoted byarrayfollowed by their sub-type in angle brackets. These may appear
in cast operations:
```
```
db>select<array<str>>[1, 4, 7];
{[' 1 ', ' 4 ', ' 7 ']}
db>select<array<bigint>>[1, 4, 7];
{[1n, 4n, 7n]}
```
```
Array types may also appear in schema declarations:
```
```
typePerson {
propertystr_array -> array<str>;
propertyjson_array -> array<json>;
}
```
```
typePerson {
str_array: array<str>;
json_array: array<json>;
}
```
```
See also the list of standard array functions , as well as generic functions such aslen().
```
operator array<anytype> [ int64 ] -> anytype
Accesses the array element at a given index.
Example:

```
db>select[1, 2, 3][0];
{1}
db>select[(x := 1, y := 1), (x := 2, y := 3.3)][1];
{(x := 2, y := 3.3)}
```
```
This operator also allows accessing elements from the end of the array using a negative index:
```
```
db>select[1, 2, 3][-1];
{3}
```
```
Referencing a non-existent array element will result in an error:
```
**464 Chapter 5. Standard Library**


```
db>select[1, 2, 3][4];
InvalidValueError: arrayindex 4 isoutof bounds
```
operator array<anytype> [ int64 : int64 ] -> anytype
Produces a sub-array from an existing array.
Omitting the lower bound of an array slice will default to a lower bound of zero.
Omitting the upper bound will default the upper bound to the length of the array.
The lower bound of an array slice is inclusive while the upper bound is not.
Examples:

```
db>select[1, 2, 3][0:2];
{[1, 2]}
db>select[1, 2, 3][2:];
{[3]}
db>select[1, 2, 3][:1];
{[1]}
db>select[1, 2, 3][:-2];
{[1]}
```
```
Referencing an array slice beyond the array boundaries will result in an empty array (unlike a direct reference
to a specific index). Slicing with a lower bound less than the minimum index or a upper bound greater than the
maximum index are functionally equivalent to not specifying those bounds for your slice:
```
```
db>select[1, 2, 3][1:20];
{[2, 3]}
db>select[1, 2, 3][10:20];
{[]}
```
operator array<anytype> ++ array<anytype> -> array<anytype>
Concatenates two arrays of the same type into one.

```
db>select[1, 2, 3] ++ [99, 98];
{[1, 2, 3, 99, 98]}
```
function std::array_agg→array<anytype>

```
Index Keywords aggregate array set
Returns an array made from all of the input set elements.
The ordering of the input set will be preserved if specified:
```
```
db>selectarray_agg({2, 3, 5});
{[2, 3, 5]}
```
```
db>selectarray_agg(User.name order byUser.name);
{['Alice','Bob','Joe', 'Sam']}
```
**5.12. Arrays 465**


function std::array_get→optional anytype

```
Index Keywords array access get
Returns the element of a given array at the specified index.
If the index is out of the array’s bounds, the default argument or{}(empty set) will be returned.
This works the same as thearray indexing operator, except that if the index is out of bounds, an empty set
of the array element’s type is returned instead of raising an exception:
```
```
db>selectarray_get([2, 3, 5], 1);
{3}
db>selectarray_get([2, 3, 5], 100);
{}
db>selectarray_get([2, 3, 5], 100,default:= 42);
{42}
```
function std::array_unpack→set of anytype

```
Index Keywords set array unpack
Returns the elements of an array as a set.
```
```
Note: The ordering of the returned set is not guaranteed. However, if it is wrapped in a call toenumerate(),
the assigned indexes are guaranteed to match the array.
```
```
db>selectarray_unpack([2, 3, 5]);
{3, 2, 5}
```
```
db>selectenumerate(array_unpack([2, 3, 5]));
{(1, 3), (0, 2), (2, 5)}
```
function std::array_join→str

```
Index Keywords join array_to_string implode
Renders an array to a string.
Join a string array into a single string using a specified delimiter :
```
```
db>selectto_str(['one', 'two', 'three'], ', ');
{'one, two, three'}
```
function std::array_fill→array<anytype>

```
Index Keywords fill
Returns an array of the specified size, filled with the provided value.
Create an array of size n where every element has the value val.
```
**466 Chapter 5. Standard Library**


```
db>selectarray_fill(0, 5);
{[0, 0, 0, 0, 0]}
db>selectarray_fill('n/a', 3);
{['n/a','n/a', 'n/a']}
```
function std::array_replace→array<anytype>
Returns an array with all occurrences of one value replaced by another.
Return an array where every _old_ value is replaced with _new_.

```
db>selectarray_replace([1, 1, 2, 3, 5], 1, 99);
{[99, 99, 2, 3, 5]}
db>selectarray_replace(['h','e','l','l', 'o'], 'l','L');
{['h', 'e', 'L', 'L','o']}
```
### 5.13 Tuples

A tuple type is a heterogeneous sequence of other types. Tuples can be either _named_ or _unnamed_ (the default).

#### 5.13.1 Constructing tuples

A tuple constructor is an expression that consists of a sequence of comma-separated expressions enclosed in parenthe-
ses. It produces a tuple value:

"(" <expr> [, ... ] ")"

Declare a _named tuple_ :

"(" <identifier> := <expr> [, ... ] ")"

_All_ elements in a named tuple must have a name.

A tuple constructor automatically creates a corresponding _tuple type_.

#### 5.13.2 Accessing elements

An element of a tuple can be referenced in the form:

<expr>.<element-index>

Here,<expr>is any expression that has a tuple type, and<element-index>is either the _zero-based index_ of the
element or the name of an element in a named tuple.

Examples:

db>select (1,'EdgeDB').0;
{1}

db>select (number := 1, name :='EdgeDB').name;
(continues on next page)

**5.13. Tuples 467**


```
(continued from previous page)
```
{"EdgeDB"}

db>select (number := 1, name :='EdgeDB').1;
{"EdgeDB"}

#### 5.13.3 Nesting tuples

Tuples can be nested:

db>select (nested_tuple := (1, 2)).nested_tuple.0;
{1}

Referencing a non-existent tuple element will result in an error:

db>select (1, 2).5;
EdgeQLError: 5is not a memberof a tuple

---- query context ----

```
line 1
>select (1, 2).3;
```
#### 5.13.4 Type syntax

A tuple type can be explicitly declared in an expression or schema declaration using the following syntax:

tuple "<" <element-type>, [<element-type>, ...] ">"

A named tuple:

tuple "<" <element-name> : <element-type> [, ... ] ">"

Any type can be used as a tuple element type.

Here’s an example of using this syntax in a schema definition:

typeGameElement {
required propertyname -> str;
required propertyposition -> tuple<x: int64, y: int64>;
}

typeGameElement {
requiredname: str;
requiredposition: tuple<x: int64, y: int64>;
}

Here’s a few examples of using tuple types in EdgeQL queries:

db>select <tuple<int64, str>>(' 1 ', 3);
{(1,' 3 ')}
db>select <tuple<x: int64, y: int64>>(1, 2);
(continues on next page)

**468 Chapter 5. Standard Library**


```
(continued from previous page)
```
{(x := 1, y := 2)}
db>select (1,' 3 ') is(tuple<int64, str>);
{true}
db>select ([1, 2],'a') is(tuple<array<int64>, str>);
{true}

type tuple

```
Index Keywords tuple
A tuple type is a heterogeneous sequence of other types.
Tuple elements can optionally have names, in which case the tuple is called a named tuple.
Any type can be used as a tuple element type.
A tuple type is created implicitly when a tuple constructor is used:
```
```
db>select('foo', 42);
{('foo', 42)}
```
```
Two tuples are equal if all of their elements are equal and in the same order. Note that element names in named
tuples are not significant for comparison:
```
```
db>select(1, 2, 3) = (a := 1, b := 2, c := 3);
{true}
```
```
The syntax of a tuple type declaration can be found in this section.
```
### 5.14 Ranges

```
edb-alt-title Range Functions and Operators
```
Ranges represent some interval of values. The intervals can include or exclude their boundaries or can even omit one
or both boundaries. Only some scalar types have corresponding range types:

- range<int32>
- range<int64>
- range<float32>
- range<float64>
- range<decimal>
- range<datetime>
- range<cal::local_datetime>
- range<cal::local_date>

**5.14. Ranges 469**


#### 5.14.1 Constructing ranges

There’s a specialrange()constructor function for making range values. This is a little different from how scalars,
arrays and tuples are created typically in EdgeDB.

For example:

db>select range(1, 10);
{range(1, 10, inc_lower :=true, inc_upper := false)}
db>select range(2.2, 3.3);
{range(2.2, 3.3, inc_lower :=true, inc_upper :=false)}

Broadly there are two kinds of ranges: discreteandcontiguous. The discrete ranges arerange<int32>,
range<int64>, andrange<cal::local_date>. All ranges over discrete types get normalized such that the lower
bound is included (if present) and the upper bound is excluded:

db>select range(1, 10) = range(1, 9, inc_upper :=true);
{true}
db>select range(1, 10) = range(0, 10, inc_lower :=false);
{true}

Ranges over contiguous types don’t have the same normalization mechanism because the underlying types don’t have
granularity which could be used to easily include or exclude a boundary value.

Sometimes a range cannot contain any values, this is called an _empty_ range. These kinds of ranges can arise from
performing various operations on them, but they can also be constructed. There are basically two equivalent ways
of constructing an _empty_ range. It can be explicitly constructed by providing the same upper and lower bounds and
specifying that at least one of them is not _inclusive_ (which is the default for all range constructors):

db>select range(1, 1);
{range({}, empty:= true)}

Alternatively, it’s possible to specify{}as a boundary and also provide theempty := truenamed-only argument.
If the empty set is provided as a literal, it also needs to have a type cast, to specify which type of the range is being
constructed:

db>select range(<int64>{},empty := true);
{range({}, empty:= true)}

Since empty ranges contain no values, they are all considered to be equal to each other (as long as the types are
compatible):

db>select range(1, 1) = range(<int64>{},empty:= true);
{true}
db>select range(1, 1) = range(42.0, 42.0);
{true}

db>select range(1, 1) = range(<cal::local_date>{},empty:= true);
error: InvalidTypeError:operator'=' cannot beapplied to operandsof
type'range<std::int64>' and'range<cal::local_date>'
query:1:8

1 select range(1, 1) = range(<cal::local_date>{},empty:= true);
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Consider usingan explicittype cast ora conversion function.

**470 Chapter 5. Standard Library**


#### 5.14.2 JSON representation

Much like _arrays_ and _tuples_ , the range types cannot be directly cast to astr, but instead can be cast into ajson
structure:

db>select <json>range(1, 10);
{"inc_lower":true, "inc_upper": false, "lower": 1, "upper": 10}

It’s also possible to cast in the other direction - fromjsonto a specific range type:

db>select <range<int64>>to_json('{
... "lower": 1,
... "inc_lower": true,
... "upper": 10,
... "inc_upper": false
... }');
{range(1, 10, inc_lower :=true, inc_upper := false)}

Empty ranges have a shorthandjsonrepresentation:

db>select <json>range(<int64>{},empty:= true);
{"empty":true}

When casting fromjsonto an empty range, all other fields may be omitted, but if they are present, they must be
consistent with an empty range:

db>select <range<int64>>to_json('{"empty": true}');
{range({}, empty:= true)}

db>select <range<int64>>to_json('{
... "lower": 1,
... "inc_lower": true,
... "upper": 1,
... "inc_upper": false
... }');
{range({}, empty:= true)}

db>select <range<int64>>to_json('{
... "lower": 1,
... "inc_lower": true,
... "upper": 1,
... "inc_upper": false,
... "empty": true
... }');
{range({}, empty:= true)}

db>select <range<int64>>to_json('{
... "lower": 1,
... "inc_lower": true,
... "upper": 2,
... "inc_upper": false,
... "empty": true
... }');
edgedb error: InvalidValueError: conflicting arguments inrange
(continues on next page)

**5.14. Ranges 471**


```
(continued from previous page)
```
constructor: "empty"is ``true`` while the specified bounds suggest
otherwise

**Note:** When casting fromjsonto a range thelowerandupperfields are optional, but the _inclusivity_ fields
inc_lowerandinc_upperare _mandatory_. This is to address the fact that whether the range boundaries are in-
cluded by default can vary based on system or context and being explicit avoids subtle errors. The only exception to
this are empty ranges that can have just the"empty": truefield.

#### 5.14.3 Functions and operators

```
range < range One range is before the other.
range > range One range is after the other.
range <= range One range is before or same as the other.
range >= range One range is after or same as the other.
range + range Range union.
range - range Range subtraction.
range * range Range intersection.
range() Construct a range.
range_get_lower() Return lower bound value.
range_get_upper() Return upper bound value.
range_is_inclusive_lower() Check whether lower bound is inclusive.
range_is_inclusive_upper() Check whether upper bound is inclusive.
range_is_empty() Check whether a range is empty.
range_unpack() Return values from a range.
contains() Check if an element or a range is within another range.
overlaps() Check whether ranges overlap.
```
#### 5.14.4 Reference

operator range<anypoint> < range<anypoint> -> bool
One range is before the other.
Returnstrueif the lower bound of the first range is smaller than the lower bound of the second range. The
unspecified lower bound is considered to be smaller than any specified lower bound. If the lower bounds are
equal then the upper bounds are compared. Unspecified upper bound is considered to be greater than any specified
upper bound.

```
db>selectrange(1, 10) < range(2, 5);
{true}
db>selectrange(1, 10) < range(1, 15);
{true}
db>selectrange(1, 10) < range(1);
{true}
db>selectrange(1, 10) < range(<int64>{}, 10);
{false}
```
```
An empty range is considered to come before any non-empty range.
```
**472 Chapter 5. Standard Library**


```
db>selectrange(1, 10) < range(10, 10);
{false}
db>selectrange(1, 10) < range(<int64>{}, empty:= true);
{false}
```
```
This is also how theorder byclauses compares ranges.
```
operator range<anypoint> > range<anypoint> -> bool
One range is after the other.
Returnstrueif the lower bound of the first range is greater than the lower bound of the second range. The
unspecified lower bound is considered to be smaller than any specified lower bound. If the lower bounds are
equal then the upper bounds are compared. Unspecified upper bound is considered to be greater than any specified
upper bound.

```
db>selectrange(1, 10) > range(2, 5);
{false}
db>selectrange(1, 10) > range(1, 5);
{true}
db>selectrange(1, 10) > range(1);
{false}
db>selectrange(1, 10) > range(<int64>{}, 10);
{true}
```
```
An empty range is considered to come before any non-empty range.
```
```
db>selectrange(1, 10) > range(10, 10);
{true}
db>selectrange(1, 10) > range(<int64>{}, empty:= true);
{true}
```
```
This is also how theorder byclauses compares ranges.
```
operator range<anypoint> <= range<anypoint> -> bool
One range is before or same as the other.
Returnstrueif the ranges are identical or if the lower bound of the first range is smaller than the lower bound
of the second range. The unspecified lower bound is considered to be smaller than any specified lower bound. If
the lower bounds are equal then the upper bounds are compared. Unspecified upper bound is considered to be
greater than any specified upper bound.

```
db>selectrange(1, 10) <= range(1, 10);
{true}
db>selectrange(1, 10) <= range(2, 5);
{true}
db>selectrange(1, 10) <= range(1, 15);
{true}
db>selectrange(1, 10) <= range(1);
{true}
db>selectrange(1, 10) <= range(<int64>{}, 10);
{false}
```
```
An empty range is considered to come before any non-empty range.
```
**5.14. Ranges 473**


```
db>selectrange(1, 10) <= range(10, 10);
{false}
db>selectrange(1, 1) <= range(10, 10);
{true}
db>selectrange(1, 10) <= range(<int64>{}, empty:= true);
{false}
```
```
This is also how theorder byclauses compares ranges.
```
operator range<anypoint> >= range<anypoint> -> bool
One range is after or same as the other.
Returnstrueif the ranges are identical or if the lower bound of the first range is greater than the lower bound
of the second range. The unspecified lower bound is considered to be smaller than any specified lower bound. If
the lower bounds are equal then the upper bounds are compared. Unspecified upper bound is considered to be
greater than any specified upper bound.

```
db>selectrange(1, 10) >= range(2, 5);
{false}
db>selectrange(1, 10) >= range(1, 10);
{true}
db>selectrange(1, 10) >= range(1, 5);
{true}
db>selectrange(1, 10) >= range(1);
{false}
db>selectrange(1, 10) >= range(<int64>{}, 10);
{true}
```
```
An empty range is considered to come before any non-empty range.
```
```
db>selectrange(1, 10) >= range(10, 10);
{true}
db>selectrange(1, 1) >= range(10, 10);
{true}
db>selectrange(1, 10) >= range(<int64>{}, empty:= true);
{true}
```
```
This is also how theorder byclauses compares ranges.
```
operator range<anypoint> + range<anypoint> -> range<anypoint>

```
Index Keywords plus add
Range union.
Find the union of two ranges as long as the result is a single range without any discontinuities inside.
```
```
db>selectrange(1, 10) + range(5, 15);
{range(1, 15, inc_lower :=true, inc_upper := false)}
db>selectrange(1, 10) + range(5);
{range(1, {}, inc_lower :=true, inc_upper := false)}
```
operator range<anypoint> - range<anypoint> -> range<anypoint>

**474 Chapter 5. Standard Library**


```
Index Keywords minus subtract
Range subtraction.
Subtract one range from another. This is only valid if the resulting range does not have any discontinuities inside.
```
```
db>selectrange(1, 10) - range(5, 15);
{range(1, 5, inc_lower :=true, inc_upper :=false)}
db>selectrange(1, 10) - range(<int64>{}, 5);
{range(5, 10, inc_lower :=true, inc_upper := false)}
db>selectrange(1, 10) - range(0, 15);
{range({},empty := true)}
```
operator range<anypoint> * range<anypoint> -> range<anypoint>

```
Index Keywords intersect intersection
Range intersection.
Find the intersection of two ranges.
```
```
db>selectrange(1, 10) * range(5, 15);
{range(5, 10, inc_lower :=true, inc_upper := false)}
db>selectrange(1, 10) * range(-15, 15);
{range(1, 10, inc_lower :=true, inc_upper := false)}
db>selectrange(1) * range(-15, 15);
{range(1, 15, inc_lower :=true, inc_upper := false)}
db>selectrange(10) * range(<int64>{}, 1);
{range({},empty := true)}
```
function std::range→range<std::anypoint>
Construct a range.
Either one of _lower_ or _upper_ bounds can be set to{}to indicate an unbounded interval.
By default the _lower_ bound is included and the _upper_ bound is excluded from the range, but this can be controlled
explicitly via the _inc_lower_ and _inc_upper_ named-only arguments.

```
db>selectrange(1, 10);
{range(1, 10, inc_lower :=true, inc_upper := false)}
db>selectrange(1.5, 7.5, inc_lower := false);
{range(1.5, 7.5, inc_lower :=false, inc_upper :=false)}
```
```
Finally, an empty range can be created by using the empty named-only flag. The first argument still needs to be
passed as an{}so that the type of the range can be inferred from it.
```
```
db>selectrange(<int64>{},empty :=true);
{range({},empty := true)}
```
function std::range_get_lower→optional anypoint
Return lower bound value.
Return the lower bound of the specified range.

**5.14. Ranges 475**


```
db>selectrange_get_lower(range(1, 10));
{1}
db>selectrange_get_lower(range(1.5, 7.5));
{1.5}
```
function std::range_is_inclusive_lower→std::bool
Check whether lower bound is inclusive.
Returntrueif the lower bound is inclusive andfalseotherwise. If there is no lower bound, then it is never
considered inclusive.

```
db>selectrange_is_inclusive_lower(range(1, 10));
{true}
db>selectrange_is_inclusive_lower(
... range(1.5, 7.5, inc_lower :=false));
{false}
db>selectrange_is_inclusive_lower(range(<int64>{}, 10));
{false}
```
function std::range_get_upper→optional anypoint
Return upper bound value.
Return the upper bound of the specified range.

```
db>selectrange_get_upper(range(1, 10));
{10}
db>selectrange_get_upper(range(1.5, 7.5));
{7.5}
```
function std::range_is_inclusive_upper→std::bool
Check whether upper bound is inclusive.
Returntrueif the upper bound is inclusive andfalseotherwise. If there is no upper bound, then it is never
considered inclusive.

```
db>selectrange_is_inclusive_upper(range(1, 10));
{false}
db>selectrange_is_inclusive_upper(
... range(1.5, 7.5, inc_upper :=true));
{true}
db>selectrange_is_inclusive_upper(range(1));
{false}
```
function std::range_is_empty→bool
Check whether a range is empty.
Returntrueif the range contains no values andfalseotherwise.

**476 Chapter 5. Standard Library**


```
db>selectrange_is_empty(range(1, 10));
{false}
db>selectrange_is_empty(range(1, 1));
{true}
db>selectrange_is_empty(range(<int64>{}, empty:= true));
{true}
```
function std::range_unpack→set of anydiscrete
function std::range_unpack→set of anypoint
Return values from a range.
For a range of discrete values this function when called without indicating a _step_ value simply produces a set of
all the values within the range, in order.

```
db>selectrange_unpack(range(1, 10));
{1, 2, 3, 4, 5, 6, 7, 8, 9}
db>selectrange_unpack(range(
... <cal::local_date>'2022-07-01',
... <cal::local_date>'2022-07-10'));
{
<cal::local_date>'2022-07-01',
<cal::local_date>'2022-07-02',
<cal::local_date>'2022-07-03',
<cal::local_date>'2022-07-04',
<cal::local_date>'2022-07-05',
<cal::local_date>'2022-07-06',
<cal::local_date>'2022-07-07',
<cal::local_date>'2022-07-08',
<cal::local_date>'2022-07-09',
}
```
```
For any range type a step value can be specified. Then the values will be picked from the range, starting at the
lower boundary (skipping the boundary value itself if it’s not included in the range) and then producing the next
value by adding the step to the previous one.
```
```
db>selectrange_unpack(range(1.5, 7.5), 0.7);
{1.5, 2.2, 2.9, 3.6, 4.3, 5, 5.7, 6.4}
db>selectrange_unpack(
... range(
... <cal::local_datetime>'2022-07-01T00:00:00',
... <cal::local_datetime>'2022-12-01T00:00:00'
... ),
... <cal::relative_duration>'25 days 5 hours');
{
<cal::local_datetime>'2022-07-01T00:00:00',
<cal::local_datetime>'2022-07-26T05:00:00',
<cal::local_datetime>'2022-08-20T10:00:00',
<cal::local_datetime>'2022-09-14T15:00:00',
<cal::local_datetime>'2022-10-09T20:00:00',
<cal::local_datetime>'2022-11-04T01:00:00',
}
```
**5.14. Ranges 477**


function std::overlaps→std::bool
Check whether ranges overlap.
Returntrueif the ranges have any elements in common andfalseotherwise.

```
db>selectoverlaps(range(1, 10), range(5));
{true}
db>selectoverlaps(range(1, 10), range(10));
{false}
```
### 5.15 Bytes

```
edb-alt-title Bytes Functions and Operators
```
```
bytes Byte sequence
bytes[i] Accesses a byte at a given index.
bytes[from:to] Produces a bytes sub-sequence from an existing bytes value.
bytes ++ bytes Concatenates two bytes values into one.
= != ?= ?!= < > <= >= Comparison operators
len() Returns the number of bytes.
contains() Checks if the byte sequence contains a given subsequence.
find() Finds the index of the first occurrence of a subsequence.
bytes_get_bit() Returns the specified bit of the bytes value.
```
type bytes
A sequence of bytes representing raw data.
Bytes can be represented as a literal using this syntax:b''.

```
db>selectb'Hello, world';
{b'Hello, world'}
db>selectb'Hello,\x20world\x01';
{b'Hello, world\x01'}
```
```
There are also some generic functions that can operate on bytes:
```
```
db>selectcontains(b'qwerty', b' 42 ');
{false}
```
```
Bytes are rendered as base64-encoded strings in JSON. When you cast abytesvalue into JSON, that’s what
you’ll get. In order tocastajsonvalue into bytes, it must be a base64-encoded string.
```
```
db>select<json>b'Hello EdgeDB!';
{"\"SGVsbG8gRWRnZURCIQ==\""}
db>select<bytes>to_json("\"SGVsbG8gRWRnZURCIQ==\"");
{b'Hello EdgeDB!'}
```
operator bytes [ int64 ] -> bytes
Accesses a byte at a given index.
Examples:

**478 Chapter 5. Standard Library**


```
db>selectb'binary \x01\x02\x03\x04 ftw!'[2];
{b'n'}
db>selectb'binary \x01\x02\x03\x04 ftw!'[8];
{b'\x02'}
```
operator bytes [ int64 : int64 ] -> bytes
Produces a bytes sub-sequence from an existing bytes value.
Examples:

```
db>selectb'\x01\x02\x03\x04 ftw!'[2:-1];
{b'\x03\x04 ftw'}
db>selectb'some bytes'[2:-3];
{b'me by'}
```
operator bytes ++ bytes -> bytes
Concatenates two bytes values into one.

```
db>selectb'\x01\x02'++ b'\x03\x04';
{b'\x01\x02\x03\x04'}
```
function std::bytes_get_bit→int64
Returns the specified bit of the bytes value.
When looking for the _nth_ bit, this function will enumerate bits from least to most significant in each byte.

```
db>fornin {0, 1, 2, 3, 4, 5, 6, 7,
... 8, 9, 10, 11, 12, 13 ,14, 15}
...unionbytes_get_bit(b'ab', n);
{1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0}
```
### 5.16 Sequences

```
sequence Auto-incrementing sequence ofint64.
sequence_next() Increments the given sequence to its next value and returns that value.
sequence_reset() Resets a sequence to initial state or a given value, returning the value.
```
type sequence
An auto-incrementing sequence ofint64.
This type can be used to create auto-incrementing _properties_ :

**5.16. Sequences 479**


```
scalar typeTicketNoextendingsequence;
```
```
typeTicket {
propertynumber -> TicketNo {
constraintexclusive;
}
}
```
```
scalar typeTicketNoextendingsequence;
```
```
typeTicket {
number: TicketNo {
constraintexclusive;
}
}
```
```
A sequence is bound to the scalar type, not to the property, so if multiple properties use the same sequence, they
will share the same counter. For each distinct counter, a separate scalar type that is extendingsequenceshould
be used.
```
function std::sequence_next→int64
Increments the given sequence to its next value and returns that value.
See the note on _specifying your sequence_ for best practices on supplying the _seq_ parameter.
Sequence advancement is done atomically; each concurrent session and transaction will receive a distinct se-
quence value.

```
db>selectsequence_next(introspectMySequence);
{11}
```
function std::sequence_reset→int64
function std::sequence_reset→int64
Resets a sequence to initial state or a given value, returning the value.
See the note on _specifying your sequence_ for best practices on supplying the _seq_ parameter.
The single-parameter form resets the sequence to its initial state, where the nextsequence_next()call will
return the first value in sequence. The two-parameter form allows you to set the current value of the sequence.
The nextsequence_next()call will return the value after the one you passed tosequence_reset().

```
db>selectsequence_reset(introspectMySequence);
{1}
db>selectsequence_next(introspectMySequence);
{1}
db>selectsequence_reset(introspectMySequence, 22);
{22}
db>selectsequence_next(introspectMySequence);
{23}
```
**480 Chapter 5. Standard Library**


**Note:** To specify the sequence to be operated on by eithersequence_next()orsequence_reset(), you must pass
aschema::ScalarTypeobject. If the sequence argument is known ahead of time and does not change, we recommend
passing it by using theintrospectoperator:

select sequence_next(introspectMySequenceType);
# or
select sequence_next(introspect typeofMyObj.seq_prop);

This style of execution will ensure that the reference to a sequential type from a given expression is tracked properly to
guarantee schema referential integrity.

It doesn’t work in every use case, though. If in your use case, the sequence type must be determined at run time via a
query argument, you will need to query it from theschema::ScalarTypeset directly:

with
SeqType := (
select schema::ScalarType
filter .name = <str>$seq_type_name
)
select
sequence_next(SeqType);

```
Warning: Caution
To work efficiently in high concurrency without lock contention, asequence_next()execution is never rolled
back, even if the containing transaction is aborted. This may result in gaps in the generated sequence. Likewise,
the result of asequence_reset()call is not undone if the transaction is rolled back.
```
### 5.17 Base Objects

```
BaseObject Root object type
Object Root for user-defined object types
```
std::BaseObjectis the root of the object type hierarchy and all object types in EdgeDB, including system types,
extend it either directly or indirectly. User-defined object types extend fromstd::Objecttype, which is a subtype of
std::BaseObject.

type BaseObject
The root object type.
Definition:

```
abstract typestd::BaseObject {
# Universally unique object identifier
required propertyid -> uuid {
default:= (selectstd::uuid_generate_v1mc());
readonly :=true;
(continues on next page)
```
**5.17. Base Objects 481**


```
(continued from previous page)
constraintexclusive;
}
```
```
# Object type in the information schema.
requiredreadonlylink__type__ -> schema::ObjectType;
}
```
```
Subtypes may override theidproperty, but only with a valid UUID generation function. Currently, these are
uuid_generate_v1mc()anduuid_generate_v4().
```
type Object
The root object type for user-defined types.
Definition:

```
abstract typestd::Objectextendingstd::BaseObject;
```
### 5.18 Abstract Types

Abstract types are used to describe polymorphic functions, otherwise known as “generic functions,” which can be
called on a broad range of types.

type anytype

```
Index Keywords any anytype
A generic type.
It is a placeholder used in cases where no specific type requirements are needed, such as defining polymorphic
parameters in functions and operators.
```
type anyscalar

```
Index Keywords any anytype scalar
An abstract base scalar type.
All scalar types are derived from this type.
```
type anyenum

```
Index Keywords any anytype enum
An abstract base enumerated type.
Allenumtypes are derived from this type.
```
type anytuple

```
Index Keywords any anytype anytuple
```
**482 Chapter 5. Standard Library**


```
A generic tuple.
Similarly toanytype, this type is used to denote a generic tuple without detailing its component types. This is
useful when defining polymorphic parameters in functions and operators.
```
#### 5.18.1 Abstract Numeric Types

These abstract numeric types extendanyscalar.

type anyint

```
Index Keywords any anytype int
An abstract base scalar type forint16,int32, andint64.
```
type anyfloat

```
Index Keywords any anytype float
An abstract base scalar type forfloat32andfloat64.
```
type anyreal

```
Index Keywords any anytype
An abstract base scalar type foranyint,anyfloat, anddecimal.
```
#### 5.18.2 Abstract Range Types

There are some types that can be used to construct _ranges_. These scalar types are distinguished by the following abstract
types:

type anypoint

```
Index Keywords any anypoint anyrange
Abstract base type for all valid ranges.
Abstract base scalar type for int32, int64, float32, float64, decimal, datetime,
cal::local_datetime, andcal::local_date.
```
type anydiscrete

```
Index Keywords any anydiscrete anyrange discrete
An abstract base type for all valid discrete ranges.
This is an abstract base scalar type forint32,int64, andcal::local_date.
```
type anycontiguous

```
Index Keywords any anycontiguous anyrange
An abstract base type for all valid contiguous ranges.
This is an abstract base scalar type forfloat32,float64,decimal,datetime, andcal::local_datetime.
```
**5.18. Abstract Types 483**


### 5.19 Constraints

```
exclusive Enforce uniqueness among all instances of the containing type
expression Custom constraint expression
one_of A list of allowable values
max_value Maximum value numerically/lexicographically
max_ex_value Maximum value numerically/lexicographically (exclusive range)
max_len_value Maximum length (strings only)
min_value Minimum value numerically/lexicographically
min_ex_value Minimum value numerically/lexicographically (exclusive range)
min_len_value Minimum length (strings only)
regexp Regex constraint (strings only)
```
constraint std::expression
A constraint based on an arbitrary boolean expression.
Theexpressionconstraint may be used as in this example to create a custom scalar type:

```
scalar typestarts_with_aextendingstr {
constraint expression on(__subject__[0] ='A');
}
```
```
Example of using anexpressionconstraint based on a couple of object properties to restrict maximum mag-
nitude for a vector:
```
```
typeVector {
required propertyx -> float64;
required propertyy -> float64;
constraint expression on(
__subject__.x^2 + __subject__.y^2 < 25
);
}
```
```
typeVector {
requiredx: float64;
requiredy: float64;
constraint expression on(
__subject__.x^2 + __subject__.y^2 < 25
);
}
```
constraint std::one_of
Specifies a list of allowed values.
Example:

```
scalar typeStatusextending str {
constraintone_of ('Open','Closed','Merged');
}
```
constraint std::max_value
Specifies the maximum allowed value.
Example:

**484 Chapter 5. Standard Library**


```
scalar typemax_100extendingint64 {
constraintmax_value(100);
}
```
constraint std::max_ex_value
Specifies a non-inclusive upper bound for the value.
Example:

```
scalar typemaxex_100extendingint64 {
constraintmax_ex_value(100);
}
```
```
In the example above, in contrast to themax_valueconstraint, a value of themaxex_100type cannot be 100
since the valid range ofmax_ex_valuedoes not include the value specified in the constraint.
```
constraint std::max_len_value
Specifies the maximum allowed length of a value.
Example:

```
scalar typeUsernameextendingstr {
constraintmax_len_value(30);
}
```
constraint std::min_value
Specifies the minimum allowed value.
Example:

```
scalar typenon_negativeextendingint64 {
constraintmin_value(0);
}
```
constraint std::min_ex_value
Specifies a non-inclusive lower bound for the value.
Example:

```
scalar typepositive_floatextendingfloat64 {
constraintmin_ex_value(0);
}
```
```
In the example above, in contrast to themin_valueconstraint, a value of thepositive_floattype cannot be
0 since the valid range ofmix_ex_valuedoes not include the value specified in the constraint.
```
constraint std::min_len_value
Specifies the minimum allowed length of a value.
Example:

```
scalar typefour_decimal_placesextending int64 {
constraintmin_len_value(4);
}
```
constraint std::regexp

```
Index Keywords regex regexp regular
```
**5.19. Constraints 485**


```
Limits to string values matching a regular expression.
Example:
```
```
scalar typeLettersOnlyextending str {
constraintregexp(r'[A-Za-z]*');
}
```
```
See our documentation on regular expression patterns for more information on those.
```
constraint std::exclusive
Specifies that the link or property value must be exclusive (unique).
When applied to amultilink or property, the exclusivity constraint guarantees that for every object, the set of
values held by a link or property does not intersect with any other such set in any other object of this type.
This constraint is only valid for concrete links and properties. Scalar type definitions cannot include this con-
straint.
Example:

```
typeUser {
# Make sure user names are unique.
required propertyname -> str {
constraintexclusive;
}
```
```
# Make sure none of the "owned" items belong
# to any other user.
multi linkowns -> Item {
constraintexclusive;
}
}
```
```
typeUser {
# Make sure user names are unique.
requiredname: str {
constraintexclusive;
}
```
```
# Make sure none of the "owned" items belong
# to any other user.
multiowns: Item {
constraintexclusive;
}
}
```
```
Sometimes it’s necessary to create a type where each combination of properties is unique. This can be achieved
by defining anexclusiveconstraint for the type, rather than on each property:
```
```
typeUniqueCoordinates {
required propertyx -> int64;
required propertyy -> int64;
```
```
# Each combination of x and y must be unique.
(continues on next page)
```
**486 Chapter 5. Standard Library**


```
(continued from previous page)
constraintexclusive on( (.x, .y) );
}
```
```
typeUniqueCoordinates {
requiredx: int64;
requiredy: int64;
```
```
# Each combination of x and y must be unique.
constraintexclusive on( (.x, .y) );
}
```
```
In principle, many possible expressions can appear in theon (<expr>)clause of theexclusiveconstraint
with a few caveats:
```
- The expression can only contain references to the immediate properties or links of the type.
- No _backlinks_ or long paths are allowed.
- OnlyImmutablefunctions are allowed in the constraint expression.

```
Note: This constraint also has an additional effect of creating an implicit index on the link or property. This
means that in the above example there’s no need to add explicit indexes for thenameproperty.
```
```
See also
Schema > Constraints
SDL > Constraints
DDL > Constraints
Introspection > Constraints
Tutorial > Advanced EdgeQL > Constraints
```
### 5.20 System

```
edb-alt-title System Functions
```
```
sys::get_version() Return the server version as a tuple.
sys::get_version_as_str() Return the server version as a string.
sys::get_current_database() Return the name of the current database as a string.
```
function sys::get_version→tuple<major: int64, minor: int64, stage: sys::VersionStage, stage_no: int64, local:
array<str>>
Return the server version as a tuple.
Themajorandminorelements contain the major and the minor components of the version;stageis an enu-
meration value containing one of'dev','alpha','beta','rc'or'final';stage_nois the stage sequence
number (e.g. 2 in an alpha 2 release); andlocalcontains an arbitrary array of local version identifiers.

```
db>selectsys::get_version();
{(major := 1, minor := 0, stage := <sys::VersionStage>'alpha',
stage_no := 1, local := [])}
```
**5.20. System 487**


function sys::get_version_as_str→str
Return the server version as a string.

```
db>selectsys::get_version_as_str();
{'1.0-alpha.1'}
```
function sys::get_transaction_isolation→sys::TransactionIsolation
Return the isolation level of the current transaction.
Possible return values are given bysys::TransactionIsolation.

```
db>selectsys::get_transaction_isolation();
{sys::TransactionIsolation.Serializable}
```
function sys::get_current_database→str
Return the name of the current database as a string.

```
db>selectsys::get_current_database();
{'my_database'}
```
type sys::TransactionIsolation

```
Index Keywords enum transaction isolation
Enumindicating the possible transaction isolation modes.
This enum only accepts a value ofSerializable.
```
### 5.21 Config

Thecfgmodule contains a set of types and scalars used for configuring EdgeDB.

```
Type Description
cfg::Config The base type for all configuration objects. The properties of this type define the set of configu-
ruation settings supported by EdgeDB.
cfg::Auth An object type representing an authentication profile.
cfg::AuthMethodAn abstract object type representing a method of authentication
cfg::Trust A subclass ofAuthMethodindicating an “always trust” policy (no authentication).
cfg::SCRAM A subclass ofAuthMethodindicating password-based authentication.
cfg::memory A scalar type for storing a quantity of memory storage.
```
**488 Chapter 5. Standard Library**


#### 5.21.1 Configuration Parameters

```
edb-alt-title Available Configuration Parameters
```
##### 5.21.1.1 Connection settings

listen_addresses -> multi strSpecifies the TCP/IP address(es) on which the server is to listen for connections
from client applications. If the list is empty, the server does not listen on any IP interface at all.

listen_port -> int16The TCP port the server listens on; 5656 by default. Note that the same port number is
used for all IP addresses the server listens on.

##### 5.21.1.2 Resource usage

effective_io_concurrency -> int64Sets the number of concurrent disk I/O operations that can be executed
simultaneously. Corresponds to the PostgreSQL configuration parameter of the same name.

query_work_mem -> cfg::memoryThe amount of memory used by internal query operations such as sorting. Cor-
responds to the PostgreSQLwork_memconfiguration parameter.

shared_buffers -> cfg::memoryThe amount of memory the database uses for shared memory buffers. Corre-
sponds to the PostgreSQL configuration parameter of the same name. Changing this value requires server restart.

##### 5.21.1.3 Query planning

default_statistics_target -> int64Sets the default data statistics target for the planner. Corresponds to the
PostgreSQL configuration parameter of the same name.

effective_cache_size -> cfg::memorySets the planner’s assumption about the effective size of the disk cache
that is available to a single query. Corresponds to the PostgreSQL configuration parameter of the same name.

##### 5.21.1.4 Query behavior

allow_bare_ddl -> cfg::AllowBareDDLAllows for running bare DDL outside a migration. Possible values are
cfg::AllowBareDDL.AlwaysAllowandcfg::AllowBareDDL.NeverAllow.
When you create an instance, this is set tocfg::AllowBareDDL.AlwaysAllowuntil you run a migration. At
that point it is set tocfg::AllowBareDDL.NeverAllowbecause it’s generally a bad idea to mix migrations
with bare DDL.

apply_access_policies -> boolDetermines whether access policies should be applied when running queries.
Setting this tofalseeffectively puts you into super-user mode, ignoring any access policies that might otherwise
limit you on the instance.

```
Note: This setting can also be conveniently accessed via the “Config” dropdown menu at the top of the EdgeDB
UI (accessible by running the CLI commandedgedb uifrom within a project). The setting will apply only to
your UI session, so you won’t have to remember to re-enable it when you’re done.
```
**5.21. Config 489**


##### 5.21.1.5 Client connections

allow_user_specified_id -> boolMakes it possible to set the.idproperty when inserting new objects.

```
Enabling this feature introduces some security vulnerabilities:
```
1. An unprivileged user can discover ids that already exist in the database by trying to insert new values and
    noting when there is a constraint violation on.ideven if the user doesn’t have access to the relevant table.
2. It allows re-using object ids for a different object type, which the application might not expect.

session_idle_timeout -> std::durationSets the timeout for how long client connections can stay inactive
before being forcefully closed by the server.
Time spent on waiting for query results doesn’t count as idling. E.g. if the session idle timeout is set to 1
minute it would be OK to run a query that takes 2 minutes to compute; to limit the query execution time use the
query_execution_timeoutsetting.
The default is 60 seconds. Setting it to<duration>' 0 'disables the mechanism. Setting the timeout to less than
2 seconds is not recommended.
Note that the actual time an idle connection can live can be up to two times longer than the specified timeout.
This is a system-level config setting.

session_idle_transaction_timeout -> std::durationSets the timeout for how long client connections can
stay inactive while in a transaction.
The default is 10 seconds. Setting it to<duration>' 0 'disables the mechanism.

query_execution_timeout -> std::durationSets a time limit on how long a query can be run.

```
Setting it to<duration>' 0 'disables the mechanism. The timeout isn’t enabled by default.
```
type cfg::Config
An abstract type representing the configuration of an instance or database.
The properties of this object type represent the set of configuration options supported by EdgeDB (listed above).

type cfg::Auth
An object type designed to specify a client authentication profile.

```
edgedb>configure instance insert
....... Auth {priority := 0, method := (insertTrust)};
OK:CONFIGURE INSTANCE
```
```
Below are the properties of theAuthclass.
priority -> int64The priority of the authentication rule. The lower this number, the higher the priority.
user -> multi strThe name(s) of the database role(s) this rule applies to. If set to'*', then it applies to
all roles.
method -> cfg::AuthMethodThe name of the authentication method type. Expects an instance of
cfg::AuthMethod; Valid values are:Trustfor no authentication andSCRAMfor SCRAM-SHA-256 pass-
word authentication.
comment -> optional strAn optional comment for the authentication rule.
```
**490 Chapter 5. Standard Library**


type cfg::AuthMethod
An abstract object class that represents an authentication method.
It currently has two concrete subclasses, each of which represent an available authentication method:
cfg::Trustandcfg::SCRAM.

type cfg::Trust
Thecfg::Trustindicates an “always-trust” policy.
When active, it disables password-based authentication.

```
edgedb>configure instance insert
....... Auth {priority := 0, method := (insertTrust)};
OK:CONFIGURE INSTANCE
```
type cfg::SCRAM
Thecfg::SCRAMindicates password-based authentication.
This policy is implemented viaSCRAM-SHA-256.

```
edgedb>configure instance insert
....... Auth {priority := 0, method := (insertSCRAM)};
OK:CONFIGURE INSTANCE
```
type cfg::memory
A scalar type representing a quantity of memory storage.
As withuuid,datetime, and several other types,cfg::memoryvalues are declared by casting from an appro-
priately formatted string.

```
db>select<cfg::memory>'1B'; # 1 byte
{<cfg::memory>'1B'}
db>select<cfg::memory>'5KiB';# 5 kibibytes
{<cfg::memory>'5KiB'}
db>select<cfg::memory>'128MiB'; # 128 mebibytes
{<cfg::memory>'128MiB'}
```
```
The numerical component of the value must be a non-negative integer; the units must be one of
B|KiB|MiB|GiB|TiB|PiB. We’re using the explicitKiBunit notation (1024 bytes) instead ofkB(which is
ambiguous, and may mean 1000 or 1024 bytes).
```
### 5.22 Deprecated

```
edb-alt-title Deprecated Functions
```
```
str_lpad() Return the input string left-padded to the length n.
str_rpad() Return the input string right-padded to the length n.
str_ltrim() Return the input string with all leftmost trim characters removed.
str_rtrim() Return the input string with all rightmost trim characters removed.
```
**5.22. Deprecated 491**


function std::str_lpad→str
Return the input _string_ left-padded to the length _n_.

```
Warning: This function is deprecated. Usestd::str_pad_start()instead.
```
```
If the string is longer than n , then it is truncated to the first n characters. Otherwise, the string is padded on the
left up to the total length n using fill characters (space by default).
```
```
db>selectstr_lpad('short', 10);
{' short'}
db>selectstr_lpad('much too long', 10);
{'much too l'}
db>selectstr_lpad('short', 10, '.:');
{'.:.:.short'}
```
function std::str_rpad→str
Return the input _string_ right-padded to the length _n_.

```
Warning: This function is deprecated. Usestd::str_pad_end()instead.
```
```
If the string is longer than n , then it is truncated to the first n characters. Otherwise, the string is padded on the
right up to the total length n using fill characters (space by default).
```
```
db>selectstr_rpad('short', 10);
{'short '}
db>selectstr_rpad('much too long', 10);
{'much too l'}
db>selectstr_rpad('short', 10, '.:');
{'short.:.:.'}
```
function std::str_ltrim→str
Return the input string with all leftmost _trim_ characters removed.

```
Warning: This function is deprecated. Usestd::str_trim_start()instead.
```
```
If the trim specifies more than one character they will be removed from the beginning of the string regardless of
the order in which they appear.
```
```
db>selectstr_ltrim(' data');
{'data'}
db>selectstr_ltrim('.....data', '.:');
{'data'}
db>selectstr_ltrim(':::::data', '.:');
{'data'}
db>selectstr_ltrim(':...:data', '.:');
{'data'}
db>selectstr_ltrim('.:.:.data', '.:');
{'data'}
```
**492 Chapter 5. Standard Library**


function std::str_rtrim→str
Return the input string with all rightmost _trim_ characters removed.

```
Warning: This function is deprecated. Usestd::str_trim_end()instead.
```
```
If the trim specifies more than one character they will be removed from the end of the string regardless of the
order in which they appear.
```
```
db>selectstr_rtrim('data ');
{'data'}
db>selectstr_rtrim('data.....', '.:');
{'data'}
db>selectstr_rtrim('data:::::', '.:');
{'data'}
db>selectstr_rtrim('data:...:', '.:');
{'data'}
db>selectstr_rtrim('data.:.:.', '.:');
{'data'}
```
EdgeDB comes with a rigorously defined type system consisting of **scalar types** , **collection types** (like arrays and
tuples), and **object types**. There is also a library of built-in functions and operators for working with each datatype.

### 5.23 Scalar Types

_Scalar types_ store primitive data.

- _Strings_
- _Numbers_
- _Booleans_
- _Dates and times_
- _Enums_
- _JSON_
- _UUID_
- _Bytes_
- _Sequences_
- _Abstract types_ : these are the types that undergird the scalar hierarchy.

**5.23. Scalar Types 493**


### 5.24 Collection Types

_Collection types_ are special generic types used to group homogeneous or heterogeneous data.

- _Arrays_
- _Tuples_

### 5.25 Range Types

- _Range_

### 5.26 Object Types

- _Object Types_

### 5.27 Types and Sets

- _Sets_
- _Types_
- _Casting_

### 5.28 Utilities

- _Math_
- _Comparison_
- _Constraints_
- _System_

**494 Chapter 5. Standard Library**


```
CHAPTER
```
### SIX

### CLIENT LIBRARIES

**Official Client Libraries**

- Python
- TypeScript/JavaScript
- Go
- Rust
- .NET

**Community-Maintained Clients**

- Elixir

**HTTP Protocols**

- _EdgeQL over HTTP_
- _GraphQL over HTTP_

### 6.1 Connection

There are several ways to provide connection information to a client library.

- Use **projects**. This is the recommended approach for _local development_. Once the project is initialized, all client
    libraries that are running inside the project directory can auto-discover the project-linked instance, no need for
    environment variables or hard-coded credentials. Follow the _Using projects_ guide to get started.
- Set theEDGEDB_DSNenvironment variable to a valid DSN (connection string). This is the recommended approach
    in _production_. A DSN is a connection URL of the formedgedb://user:pass@host:port/database. For a
    guide to DSNs, see the _DSN Specification_.
- Set theEDGEDB_INSTANCEenvironment variable to a _name_ of a local or remote linked instance. You can create
    new instances manually with the _edgedb instance create_ command.
- Explicitly pass a DSN or _instance name_ into the client creation function: edgedb.createClientin JS,
    edgedb.create_client()in Python, andedgedb.CreateClientin Go.

```
constclient = edgedb.createClient({
dsn: "edgedb://..."
});
```
```
Only use this approach in development; it isn’t recommended to include sensitive information hard-coded in your
production source code. Use environment variables instead. Different languages, frameworks, cloud hosting
providers, and container-based workflows each provide various mechanisms for setting environment variables.
```
```
495
```

These are the most common ways to connect to an instance, however EdgeDB supports several other options for ad-
vanced use cases. For a complete reference on connection configuration, see _Reference > Connection Parameters_.

### 6.2 JavaScript

The documentation for the JavaScript client is automatically pulled from https://github.com/edgedb/edgedb-js/tree/
master/docs by the build pipeline of the edgedb.com website.

### 6.3 Python

The documentation for the Python client is automatically pulled from https://github.com/edgedb/edgedb-python/tree/
master/docs by the build pipeline of the edgedb.com website.

### 6.4 Go

The documentation for the Go client is automatically generated from https://github.com/edgedb/edgedb-go by the build
pipeline of the edgedb.com website.

### 6.5 Rust

```
edb-alt-title EdgeDB Rust Client
```
EdgeDB maintains an client library for Rust. View the full documentation.

#[tokio::main]
async fnmain() ->anyhow::Result<()> {
letconn = edgedb_tokio::create_client().await?;
letval = conn.query_required_single::<i64, _>(
"SELECT 7*8",
&(),
).await?;
println!("7*8 is: {}", val);
Ok(())
}

### 6.6 Dart

The documentation for the Dart client is automatically generated from https://github.com/edgedb/edgedb-dart by the
build pipeline of the edgedb.com website.

**496 Chapter 6. Client Libraries**


### 6.7 .NET

The documentation for the .NET client is automatically generated from https://github.com/edgedb/edgedb-net/tree/
dev/docs by the build pipeline of the edgedb.com website.

### 6.8 EdgeQL over HTTP

EdgeDB can expose an HTTP endpoint for EdgeQL queries. Since HTTP is a stateless protocol, no _DDL_ , _transaction
commands_ , can be executed using this endpoint. Only one query per request can be executed.

In order to set up HTTP access to the database add the following to the schema:

using extension edgeql_http;

Then create a new migration and apply it using _edgedb migration create_ and _edgedb migrate_ , respectively.

Your instance can now receive EdgeQL queries over HTTP at [http://<hostname>:<port>/db/](http://<hostname>:<port>/db/)
<database-name>/edgeql.

**Note:** Here’s how to determine your local EdgeDB instance’s HTTP server URL:

- Thehostnamewill belocalhost
- Find theportby runningedgedb instance list. This will print a table of all EdgeDB instances on your
    machine, including their associated port number.
- In most cases,database_namewill beedgedb. An EdgeDB _instance_ can contain multiple databases. On
    initialization, a default database callededgedbis created; all queries are executed against this database unless
    otherwise specified.

To determine the URL of a remote instance you have linked with the CLI, you can get both the hostname and port of
the instance from the “Port” column of theedgedb instance listtable (formatted as<hostname>:<port>). The
same guidance on local database names applies here.

#### 6.8.1 Protocol

EdgeDB supports GET and POST methods for handling EdgeQL over HTTP protocol. Both GET and POST methods
use the following fields:

- query- contains the EdgeQL query string
- variables- contains a JSON object where the keys are the parameter names from the query and the values are
    the arguments to be used in this execution of the query.
- globals- contains a JSON object where the keys are the fully qualified global names and the values are the
    desired values for those globals.

The protocol supports HTTP Keep-Alive.

**6.7. .NET 497**


##### 6.8.1.1 GET request

The HTTP GET request passes the fields as query parameters:querystring and JSON-encodedvariablesmapping.

##### 6.8.1.2 POST request

The POST request should useapplication/jsoncontent type and submit the following JSON-encoded form with
the necessary fields:

{
"query": "...",
"variables": { "varName": "varValue", ... },
"globals": {"default::global_name": "value"}
}

##### 6.8.1.3 Response

The response format is the same for both methods. The body of the response is JSON of the following form:

{
"data": [ ... ],
"error": {
"message": "Error message",
"type": "ErrorType",
"code": 123456
}
}

Thedataresponse field will contain the response set serialized as a JSON array.

Note that theerrorfield will only be present if an error actually occurred. Theerrorwill further contain themessage
field with the error message string, thetypefield with the name of the type of error and thecodefield with an integer
_error code_.

**Note:** Caution is advised when readingdecimalorbigintvalues using HTTP protocol because the results are
provides in JSON format. The JSON specification does not have a limit on significant digits, so adecimalor a
bigintnumber can be losslessly represented in JSON. However, JSON decoders in many languages will read all such
numbers as some kind of of 32- or 64-bit number type, which may result in errors or precision loss. If such loss is
unacceptable, then consider casting the value intostrand decoding it on the client side into a more appropriate type.

#### 6.8.2 Health Checks

EdgeDB exposes HTTP endpoints to check for aliveness and readiness of your database instance. You can make GET
requests to these endpoints to check the instance status.

**498 Chapter 6. Client Libraries**


##### 6.8.2.1 Aliveness

Check that your instance is alive by making a request tohttp://<hostname>:<port>/server/status/alive. If
your instance is alive, it will respond with a 200 status code and"OK"as the payload. Otherwise, it will respond with
a50xor a network error.

##### 6.8.2.2 Readiness

Check that your instance is ready by making a request tohttp://<hostname>:<port>/server/status/ready. If
your instance is ready, it will respond with a 200 status code and"OK"as the payload. Otherwise, it will respond with
a50xor a network error.

### 6.9 GraphQL

#### 6.9.1 Basics

For the purposes of this section, we will consider adefaultmodule containing the following schema:

typeAuthor {
propertyname -> str;
}

typeBook {
# to make the examples simpler only the title is
# a required property
required propertytitle -> str;
propertysynopsis -> str;
linkauthor -> Author;
propertyisbn -> str {
constraintmax_len_value(10);
}
}

From the schema above, EdgeDB will expose to GraphQL:

- object typesAuthorandBook
- scalarsStringandID

In addition to this, theQuerywill have two fields —Author, andBook— to query these types respectively.

##### 6.9.1.1 Queries

Consider this example:

**6.9. GraphQL 499**


```
GraphQL EdgeQL equivalent
```
```
{
Book {
title
synopsis
author {
name
}
}
}
```
```
select
Book {
title,
synopsis,
author: {
name
}
};
```
The top-level field of the GraphQL query must be a valid name of an object type or an expression alias of something
returning an object type. Nested fields must be valid links or properties.

There are some specific conventions as to how _arguments_ in GraphQL queries are used to allow filtering, ordering, and
paginating data.

###### 6.9.1.1.1 Filtering

Filtering the retrieved data is done by specifying afilterargument. Thefilterargument is customized to each
specific type based on the available fields. In case of the sample schema, here are the specifications for available filter
arguments for queryingBook:

# this is Book-specific
input FilterBook {
# basic boolean operators that combine conditions
and: [FilterBook!]
or: [FilterBook!]
not: FilterBook

# fields available for filtering (properties in EdgeQL)
title: FilterString
synopsis: FilterString
isbn: FilterString
author: NestedFilterAuthor
}

# this is Author-specific
input NestedFilterAuthor {
# instead of boolean operations, "exists" check is available
# for links
exists: Boolean

# fields available for filtering (properties in EdgeQL)
name: FilterString
}

# this is generic
input FilterString {
# "exists" check is available for every property, too
(continues on next page)

**500 Chapter 6. Client Libraries**


```
(continued from previous page)
exists: Boolean
```
```
# equality
eq: String
neq: String
```
```
# lexicographical comparison
gt: String
gte: String
lt: String
lte: String
```
# other useful operations
like: String
ilike: String
}

Here are some examples of using a filter:

```
GraphQL EdgeQL equivalent
```
```
{
Book(
filter: {
title: {
eq: "Spam"
}
}
) {
title
synopsis
}
}
```
```
select
Book {
title,
synopsis
}
filter
Book.title ='Spam';
```
```
{
Book(
filter: {
author: {
name: {
eq:
"Lewis Carroll"
}
}
}
) {
title
synopsis
}
}
```
```
select
Book {
title,
synopsis
}
filter
Book.author.name =
'Lewis Carroll';
```
It is legal to provide multiple input fields in the same input object. They are all implicitly combined using a logical

**6.9. GraphQL 501**


conjunction. For example:

```
GraphQL EdgeQL equivalent
```
```
{
Book(
filter: {
title: {
gte: "m",
lt: "o"
}
}
) {
title
}
}
```
```
select
Book {
title,
}
filter
Book.title >='m'
and
Book.title <'o';
```
It is possible to search for books that don’t specify the author:

```
GraphQL EdgeQL equivalent
```
```
{
Book(
filter: {
author: {
exists:false
}
}
) {
id
title
}
}
```
```
select
Book {
id,
title
}
filter
not exists
Book.author;
```
###### 6.9.1.1.2 Ordering

Ordering the retrieved data is done by specifying anorderargument. Theorderargument is customized to each spe-
cific type based on the available fields, much like thefilter. In case of the sample schema, here are the specifications
for the available filter arguments:

# this is Author-specific
input OrderAuthor {
# fields available for ordering (properties in EdgeQL)
name: Ordering
}

# this is Book-specific
input OrderBook {
# fields available for ordering (properties in EdgeQL)
title: Ordering
(continues on next page)

**502 Chapter 6. Client Libraries**


(continued from previous page)
synopsis: Ordering
isbn: Ordering
}

# this is generic
input Ordering {
dir: directionEnum
nulls: nullsOrderingEnum
}

enum directionEnum {
ASC
DESC
}

enum nullsOrderingEnum {
SMALLEST # null < any other value
BIGGEST # null > any other value
}

If the value ofnullsis not specified it is assumed to beSMALLEST.

```
GraphQL EdgeQL equivalent
```
```
{
Author(
order: {
name: {
dir: ASC,
nulls: BIGGEST
}
}
) {
name
}
}
```
```
select
Author {
name,
}
order by
Author.nameasc
empty last;
```
###### 6.9.1.1.3 Paginating

Paginating the retrieved data is done by providing one or more of the following arguments:first,last,before,
andafter. The pagination works in a similar way to Relay Connections. In case of the sample schema, here are the
specifications for the available filter arguments:

# a relevant Query definition snippet
type Query {
Author(
filter: FilterAuthor,
order: OrderAuthor,

```
after: String,
(continues on next page)
```
**6.9. GraphQL 503**


```
(continued from previous page)
before: String,
first: Int,
last: Int,
): [Author!]
```
# ... other Query fields
}

Theafterandbeforestrings are, in fact, string representations of numeric indices under the particular filter and
ordering (starting at “0”). This makes the usage fairly intuitive even without having Relay Connection edges and
cursors.

The objects corresponding to the indices specified bybeforeorafterare not included.

**504 Chapter 6. Client Libraries**


```
GraphQL EdgeQL equivalent
```
```
{
Author(
order: {
name: {
dir: ASC
}
},
first: 10
) {
name
}
}
```
```
select
Author {
name,
}
order by
Author.nameasc
limit 10;
```
```
{
Author(
order: {
name: {
dir: ASC
}
},
after: "19",
first: 10
) {
name
}
}
```
```
select
Author {
name,
}
order by
Author.nameasc
offset 20 limit 10;
```
```
{
Author(
order: {
name: {
dir: ASC
}
},
after: "19",
before: "30"
) {
name
}
}
```
```
select
Author {
name,
}
order by
Author.nameasc
offset 20 limit 10;
```
**6.9. GraphQL 505**


###### 6.9.1.1.4 Variables

It is possible to use variables within GraphQL queries. They are mapped to variables in EdgeQL.

```
GraphQL EdgeQL equivalent
```
```
query ($title: String!) {
Book(
filter: {
title: {
eq: $title
}
}
) {
title
synopsis
}
}
```
```
select
Book {
title,
synopsis,
}
filter
.title = $title;
```
#### 6.9.2 Mutations

EdgeDB provides GraphQL mutations to performdelete,insertandupdateoperations.

##### 6.9.2.1 Delete

The “delete” mutation is very similar in structure to a query. Basically, it works the same way as a query, using the
_filter_ , _order_ , and various _pagination parameters_ to define a set of objects to be deleted. These objects are also returned
as the result of the delete mutation. Each object type has a correspondingdelete_<type>mutation:

**506 Chapter 6. Client Libraries**


```
GraphQL EdgeQL equivalent
```
```
mutationdelete_all_books {
delete_Book {
title
synopsis
author {
name
}
}
}
```
```
select (
delete Book
) {
title,
synopsis,
author: {
name
}
};
```
```
mutationdelete_book_spam {
delete_Book(
filter: {
title: {
eq: "Spam"
}
}
) {
title
synopsis
}
}
```
```
select (
delete Book
filter
Book.title ='Spam'
) {
title,
synopsis
};
```
```
mutationdelete_one_book {
delete_Book(
filter: {
author: {
name: {
eq:
"Lewis Carroll"
}
}
},
order: {
title: {
dir: ASC
}
},
first: 1
) {
title
synopsis
}
}
```
```
select (
delete Book
filter
Book.author.name =
'Lewis Carroll'
order by
Book.title ASC
limit 1
) {
title,
synopsis
};
```
**6.9. GraphQL 507**


##### 6.9.2.2 Insert

The “insert” mutation exists for every object type. It allows creating new objects and supports nested insertions, too.
The objects to be inserted are specified via thedataparameter, which takes a list of specifications. Each such specifica-
tion has the same structure as the object being inserted with required and optional fields (although if a field is required
in the object but has a default, it’s optional in the insert specification):

```
GraphQL EdgeQL equivalent
```
```
mutationinsert_books {
insert_Book(
data: [{
title: "One"
}, {
title: "Two"
}]
) {
id
title
}
}
```
```
select {
(insert Book {
title := "One"
}),
(insert Book {
title := "Two"
})
} {
id,
title
};
```
It’s possible to insert a nested structure all at once (e.g., a new book and a new author):

```
GraphQL EdgeQL equivalent
```
```
mutationinsert_books {
insert_Book(
data: [{
title: "Three",
author: {
data: {
name:
"Unknown"
}
}
}]
) {
id
title
}
}
```
```
select (
insert Book {
title := "Three",
author := (
insert Author {
name :=
"Unknown"
}
)
}
) {
id,
title
};
```
It’s also possible to insert a new object that’s connected to an existing object (e.g. a new book by an existing author). In
this case the nested object is specified using _filter_ , _order_ , and various _pagination parameters_ to define a set of objects
to be connected:

**508 Chapter 6. Client Libraries**


```
GraphQL EdgeQL equivalent
```
```
mutationinsert_book {
insert_Book(
data: [{
title: "Four",
author: {
filter: {
name: {eq: "Unknown"}
}
}
}]
) {
id
title
}
}
```
```
select (
insert Book {
title := "Four",
author := (
select Author
filter
Author.name =
"Unknown"
)
}
) {
id,
title
};
```
##### 6.9.2.3 Update

The “update” mutation has features that are similar to both an “insert” mutation and a query. On one hand, the mutation
takes _filter_ , _order_ , and various _pagination parameters_ to define a set of objects to be updated. On the other hand, the
dataparameter is used to specify what and how should be updated.

Thedataparameter contains the fields that should be altered as well as what type of update operation must be performed
(set,increment,append, etc.). The particular operations available depend on the type of field being updated.

**6.9. GraphQL 509**


```
GraphQL EdgeQL equivalent
```
```
mutationupdate_book {
update_Book(
filter: {
title: {
eq: "One"
}
}
data: {
synopsis: {
set: "TBD"
}
author: {
set: {
filter: {
name: {
eq:
"Unknown"
}
}
}
}
}
) {
id
title
}
}
```
```
with
Upd := (
update Book
filter
Book.title =
"One"
set{
synopsis :=
"TBD",
author := (
select Author
filter
Author.name =
"Unknown"
)
}
)
select Upd {
id,
title
};
```
#### 6.9.3 Introspection

GraphQL introspection can be used to explore the exposed EdgeDB types and expresssion aliases. Note that there
are certain types liketuplethat cannot be expressed in terms of the GraphQL type system (atuplecan be like a
heterogeneous “List”).

Consider the following GraphQL introspection query:

{
__type(name: "Query") {
name
fields {
name
args {
name
type {
kind
name
}
}
}
(continues on next page)

**510 Chapter 6. Client Libraries**


(continued from previous page)
}
}

Produces:

{
"__type": {
"name": "Query",
"fields": [
{
"name": "Author",
"args": [
{
"name": "id",
"type": {
"kind": "SCALAR",
"name": "ID"
}
},
{
"name": "name",
"type": {
"kind": "SCALAR",
"name": "String"
}
}
]
},
{
"name": "Book",
"args": [
{
"name": "id",
"type": {
"kind": "SCALAR",
"name": "ID"
}
},
{
"name": "isbn",
"type": {
"kind": "SCALAR",
"name": "String"
}
},
{
"name": "synopsis",
"type": {
"kind": "SCALAR",
"name": "String"
}
},
(continues on next page)

**6.9. GraphQL 511**


(continued from previous page)
{
"name": "title",
"type": {
"kind": "SCALAR",
"name": "String"
} } ] } ] } }

The above example shows what has been exposed for querying with GraphQL.

#### 6.9.4 Cheatsheet

**Note:** The types used as examples in these queries are defined _in our “Object types” cheatsheet_.

In order to set up GraphQL access to the database, add the following to the schema:

using extension graphql;

Then create a new migration and apply it using _edgedb migration create_ and _edgedb migrate_ , respectively.

Select all users in the system:

{
User {
id
name
image
}
}

Select a movie by title and release year with associated actors ordered by last name:

{
Movie(
filter: {
title: {eq: "Dune"},
year: {eq: 2020}
}
) {
id
title
year
description
(continues on next page)

**512 Chapter 6. Client Libraries**


```
(continued from previous page)
```
```
directors {
id
full_name
}
```
actors(order: {last_name: {dir: ASC}}) {
id
full_name
}
}
}

Select movies with Keanu Reeves:

{
Movie(
filter: {
actors: {full_name: {eq: "Keanu Reeves"}}
}
) {
id
title
year
description
}
}

Select a movie by title and year with top 3 most recent reviews (this uses _MovieAlias_ in order to access reviews):

{
MovieAlias(
filter: {
title: {eq: "Dune"},
year: {eq: 2020}
}
) {
id
title
year
description
reviews(
order: {creation_time: {dir: DESC}},
first: 3
) {
id
body
rating
creation_time
(continues on next page)

**6.9. GraphQL 513**


(continued from previous page)
author {
id
name
}
}
}
}

Use _MovieAlias_ in order to find movies that have no reviews:

{
MovieAlias(
filter: {
reviews: {exists:false},
}
) {
id
title
year
description
}
}

Use a GraphQL _mutation_ to add a user:

mutationadd_user {
insert_User(
data: {name: "Atreides", image: "atreides.jpg"}
) {
id
}
}

Use a GraphQL _mutation_ to add a review by an existing user:

mutationadd_review {
insert_Review(
data: {
# Since the movie already exists,
# we select it using the same filter
# mechanism as for queries.
movie: {
filter: {title: {eq: "Dune"}, year: {eq: 2020}},
first: 1
},
body: "Yay!",
rating: 5,
# Similarly to the movie we select
(continues on next page)

**514 Chapter 6. Client Libraries**


(continued from previous page)
# the existing user.
author: {
filter: {name: {eq: "Atreides"}},
first: 1
}
}
) {
id
body
}
}

Use a GraphQL _mutation_ to add an actress to a movie:

mutationadd_actor {
update_Movie(
# Specify which movie needs to be updated.
filter: {title: {eq: "Dune"}, year: {eq: 2020}},
# Specify the movie data to be updated.
data: {
actors: {
add: [{
filter: {
full_name: {eq: "Charlotte Rampling"}
}
}]
}
}
) {
id
actors {
id
}
}
}

EdgeDB supports GraphQL queries via the built-ingraphqlextension. A full CRUD API for all object types, their
properties (both material and computed), their links, and all _aliases_ is reflected in the GraphQL schema.

#### 6.9.5 Setting up the extension

In order to set up GraphQL access to the database, add the following to the schema:

using extension graphql;

Then create a new migration and apply it.

$ edgedb migration create
$ edgedb migrate

Refer to the _connection docs_ for various methods of running these commands against remotely-hosted instances.

**6.9. GraphQL 515**


#### 6.9.6 Connection

Once you’ve activated the extension, your instance will listen for incoming GraphQL queries via HTTP at the following
URL.

[http://127.0.0.1:<instance-port>/db/<database-name>/graphql](http://127.0.0.1:<instance-port>/db/<database-name>/graphql)

The value of<database-name>is probablyedgedb, which is the name of the default database that is created when
an instance is first created. (If you’ve manually created additional databases, use the name of the database you’d like to
query instead.)

To find the port number associated with a local instance, runedgedb instance list.

$ edgedb instance list

```
Kind Name Port Version Status
```
```
local inst1 10700 2.x running
local inst2 10702 2.x running
local inst3 10703 2.x running
```
To execute a GraphQL query against the databaseedgedbon the instance namedinst2, we would send an HTTP
request tohttp://localhost:10702/db/edgedb/graphql.

**Note:** The endpoint also provides a GraphiQL interface to explore the GraphQL schema and write queries. Take
the GraphQL query endpoint, append/explore, and visit that URL in the browser. Under the above example, the
GraphiQL endpoint is available athttp://localhost:10702/db/edgedb/graphql/explore.

But what kind of HTTP request should this be? And what data should it contain?

#### 6.9.7 The protocol

EdgeDB can recieve GraphQL queries via bothGETandPOSTrequests. Requests can contain the following fields:

- query- the GraphQL query string
- variables- a JSON object containing a set of variables. **Optional** If the GraphQL query string contains
    variables, thevariablesobject is required.
- globals- a JSON object containing global variables. **Optional**. The keys must be the fully qualified names of
    the globals to set (e.g.,default::current_userfor the globalcurrent_userin thedefaultmodule).
- operationName- the name of the operation that must be executed. **Optional** If the GraphQL query contains
    several named operations, it is required.

**Note:** The protocol implementations conform to the official GraphQL HTTP protocol. The protocol supportsHTTP
Keep-Alive.

**516 Chapter 6. Client Libraries**


##### 6.9.7.1 POST request (recommended)

The POST request should useapplication/jsoncontent type and submit the following JSON-encoded form with
the necessary fields.

$ curl \
-H "Content-Type: application/json" \
-X POST [http://localhost:10787/db/edgedb/graphql](http://localhost:10787/db/edgedb/graphql) \
-d '{ "query": "query getMovie($title: String!) { Movie(filter: {title:{eq: $title}}
˓→) { id title }}", "variables": { "title": "The Batman" }, "globals": {
˓→"default::current_user": "04e52807-6835-4eaa-999b-952804ab40a5"}}'
{"data": {...}}

##### 6.9.7.2 GET request

When usingGETrequests, any values forquery,variables,globals, oroperationNameshould be passed as query
parameters in the URL.

$ curl \
-H application/x-www-form-urlencoded \
-X GET [http://localhost:10787/db/edgedb/graphql](http://localhost:10787/db/edgedb/graphql) \
-G \
--data-urlencode'query=query getMovie($title: String!) { Movie(filter: {title:{eq:
˓→$title}}) { id title }}'\
--data-urlencode'variables={ "title": "The Batman" }'
--data-urlencode'globals={ "default::current_user": "04e52807-6835-4eaa-999b-
˓→952804ab40a5" }'
{"data": {...}}

##### 6.9.7.3 Response format

The body of the response is JSON in the following format:

{
"data": { ... },
"errors": [
{ "message": "Error message"}, ...
]
}

Note that theerrorsfield will only be present if some errors actually occurred.

**Note:** Caution is advised when readingdecimalorbigintvalues (mapped ontoDecimalandBigintGraphQL
custom scalar types) using HTTP protocol because the results are provides in JSON format. The JSON specification
does not have a limit on significant digits, so adecimalor abigintnumber can be losslessly represented in JSON.
However, JSON decoders in many languages will read all such numbers as some kind of of 32- or 64-bit number type,
which may result in errors or precision loss. If such loss is unacceptable, then consider creating a computed property
which casts the value intostrand decoding it on the client side into a more appropriate type.

**6.9. GraphQL 517**


#### 6.9.8 Known limitations

We provide this GraphQL extension to support users who are accustomed to writing queries in GraphQL. That said,
GraphQL is quite limited and verbose relative to EdgeQL.

There are also some additional limitations:

- Variables can only correspond to _scalar types_ ; you can’t use GraphQLinputtypes. Under the hood, query
    variables are mapped onto EdgeQL parameters, which only support scalar types.
    As a consequence of this, you must declare top-level variables for each property for a GraphQL insertion muta-
    tion, which can make queries more verbose.
- Due to the differences between EdgeQL and GraphQL syntax,enumtypes which have values that cannot be rep-
    resented as GraphQL identifiers (e.g.`N/A`or`NOT APPLICABLE`) cannot be properly reflected into GraphQL
    enums.
- Inserting or updating tuple properties is not yet supported.
- _Link properties_ are not reflected, as GraphQL has no such concept.
- Every non-abstract EdgeDB object type is simultaneously an interface and an object in terms of the GraphQL
    type system, which means that, for every one object type name, two names are needed in reflected GraphQL. This
    potentially results in name clashes if the convention of using camel-case names for user types is not followed in
    EdgeDB.

**518 Chapter 6. Client Libraries**


```
CHAPTER
```
### SEVEN

### CLI

```
edb-alt-title The EdgeDB CLI
```
Theedgedbcommand-line interface (CLI) provides an idiomatic way to install EdgeDB, spin up local instances, open
a REPL, execute queries, manage auth roles, introspect schema, create migrations, and more.

You can install it with one shell command.

**Installation**

On Linux or MacOS, run the following in your terminal and follow the on-screen instructions:

$ curl --proto'=https' --tlsv1.2 -sSf https://sh.edgedb.com | sh

For Windows, the installation script is:

PS> iwr https://ps1.edgedb.com -useb | iex

- The script, inspired byrustup, will detect the OS and download the appropriate build of the EdgeDB CLI tool,
    edgedb.
- Theedgedbcommand is a single executable (it’s open source!)
- Once installed, theedgedbcommand can be used to install, uninstall, upgrade, and interact with EdgeDB server
    instances.
- You can uninstall EdgeDB server or remove theedgedbcommand at any time.

**Connection options**

All commands respect a common set of _connection options_ , which let you specify a target instance. This instance can
be local to your machine or hosted remotely.

**Nightly version**

To install the nightly version of the CLI (not to be confused with the nightly version of EdgeDB itself!) use this
command:

$ curl --proto'=https' --tlsv1.2 -sSf https://sh.edgedb.com | \
sh -s -- --nightly

```
519
```

**Uninstallation**

Command-line tools contain just one binary, so to remove it on Linux or macOS run:

$ rm "$(which edgedb)"

To remove all configuration files, runedgedb infoto list the directories where EdgeDB stores data, then userf -rf
<dir>to delete those directories.

If the command-line tool was installed by the user (recommended) then it will also remove the binary.

If you’ve usededgedbcommands you can also delete _instances_ and _server_ packages, prior to removing the tool:

$ edgedb instance destroy <instance_name>

To list instances and server versions use the following commands respectively:

$ edgedb instance status
$ edgedb server list-versions --installed-only

**Configure CLI and REPL**

You can customize the behavior of theedgedbCLI and REPL with a global configuration file. The file is called
cli.tomland its location differs between operating systems. Use _edgedb info_ to find the “Config” directory on your
system.

Thecli.tomlhas the following structure. All fields are optional:

[shell]
expand-strings = true # Stop escaping newlines in quoted strings
history-size = 10000 # Set number of entries retained in history
implicit-properties = false # Print implicit properties of objects
limit = 100 # Set implicit LIMIT
# Defaults to 100, specify 0 to disable
input-mode = "emacs" # Set input mode. One of: vi, emacs
output-format = "default" # Set output format.
# One of: default, json, json-pretty,
# json-lines
print-stats = "off" # Print statistics on each query.
# One of: off, query, detailed
verbose-errors = false # Print all errors with maximum verbosity

_Notes on network usage_

### 7.1 Connection flags

TheedgedbCLI supports a standard set of connection flags used to specify the _target_ of a given command. The CLI
always respects any connection parameters passed explicitly using flags.

- If no flags are provided, then environment variables will be used to determine the instance.
- If no environment variables are present, the CLI will check if the working directory is within an instance-linked
    project directory.
- If none of the above are present, the command fails.

**520 Chapter 7. CLI**


For a detailed breakdown of how connection information is resolved, read the _Connection Parameter Resolution_ docs.

#### 7.1.1 Connection flags

-I <name>, --instance=<name>Specifies the named instance to connect to. The actual connection parameters are
stored in<edgedb_config_dir>/credentialsand are usually created by _edgedb instance create_ or similar
commands. Runedgedb infoto see the location of<edgedb_config_dir>on your machine.
This option overrides host and port.

--dsn=<dsn>Specifies the DSN for EdgeDB to connect to.

```
This option overrides all other options except password.
```
--credentials-file /path/to/filePath to JSON file containing credentials.

-H <hostname>, --host=<hostname>Specifies the host name of the machine on which the server is running.
Defaults to the value of theEDGEDB_HOSTenvironment variable.

-P <port>, --port=<port>Specifies the TCP port on which the server is listening for connections. Defaults to
the value of theEDGEDB_PORTenvironment variable or, if not set, to 5656.

-u <username>, --user=<username>Connect to the database as the user<username>. Defaults to the value of
theEDGEDB_USERenvironment variable, or, if not set, to the login name of the current OS user.

-d <dbname>, --database=<dbname>Specifies the name of the database to connect to. Default to the value of the
EDGEDB_DATABASEenvironment variable, or, if not set, to the calculated value of<username>.

--password | --no-passwordIf--passwordis specified, forceedgedbto prompt for a password before con-
necting to the database. This is usually not necessary, sinceedgedbwill prompt for a password automatically if
the server requires it.
Specifying--no-passworddisables all password prompts.

--password-from-stdinUse the first line of standard input as the password.

--tls-ca-file /path/to/certCertificate to match server against.

```
This might either be full self-signed server certificate or certificate authority (CA) certificate that server certificate
is signed with.
```
--tls-security modeSet the TLS security mode.

```
defaultResolves tostrictif no custom certificate is supplied via--tls-ca-file, environment variable,
etc. Otherwise, resolves tono_host_verification.
strictVerify TLS certificate and hostname.
no_host_verificationThis allows using any certificate for any hostname. However, certificate must be
present and match the root certificate specified with--tls-ca-file, credentials file, or system root cer-
tificates.
insecureDisable all TLS security measures.
```
--wait-until-available=<wait_time>In case EdgeDB connection can’t be established, keep retrying up to
<wait_time>(e.g.30s).

--connect-timeout=<timeout>Specifies a<timeout>period. In case EdgeDB doesn’t respond for this period
the command will fail (or retry if--wait-until-availableis also specified). The<timeout>value must be
given using time units (e.g.hr,min,sec,ms, etc.). The default value is10s.

**7.1. Connection flags 521**


### 7.2 Network usage

Generally command-line tools connect only to the database host. But there are two exceptions:

1. When the command-line tool starts, it checks if its version is up to date. _Details_
2. The _edgedb server_ family of commands and _edgedb cli upgrade_ discover package versions and docker images
    and also invoke package managers and the docker engine to do _index updates and related data._

#### 7.2.1 Version Check

Version check checks the current version of command-line tool by fetchinghttps://packages.edgedb.com/.
jsonindexes/*.json.

Here is how such a request looks like:

GET /archive/.jsonindexes/linux-x86_64.json HTTP/1.1
host: packages.edgedb.com
content-length: 0
user-agent: edgedb

TheUser-Agentheader only specifies that request is done byedgedbcommand-line tool (without version number).
The platform, architecture and whether nightly is used can be devised from the URL of the query.

Latest version number is cached for the random duration from 16 to 32 hours (this randomization is done both for
spreading the load and for better anonymizing the data). A failure is cached for the random duration from 6 to 12
hours.

#### 7.2.2 Disabling Version Check

To disable version check do one of two things:

1. Use--no-cli-update-checkcommand-line parameter to disable just for this invocation
2. ExportEDGEDB_RUN_VERSION_CHECK=neverin the environment.

To verify that check is skipped and no network access is being done logging facility can be used:

$ export RUST_LOG=edgedb::version_check=debug
$ edgedb --no-cli-update-check
[..snip..] Skipping version check due to --no-cli-update-check
edgedb>
$ EDGEDB_RUN_VERSION_CHECK=never edgedb
[..snip..] Skipping version check due to EDGEDB_RUN_VERSION_CHECK=never
edgedb>

**522 Chapter 7. CLI**


#### 7.2.3 edgedb serverandedgedb self upgrade

Generally these commands do requests with exactly the headers like _version check_.

Data sources for the commands directly:

1. Package indexes and packages athttps://packages.edgedb.com
2. Docker image index athttps://registry.hub.docker.com

Data sources that can be used indirectly:

1. Docker engine may fetch indexes and images. Currently the only images used are at Docker Hub. More specifi-
    cally areedgedb/*andbusybox(Docker’s official image).
2. Package managers (currentlyapt-get,yum) can fetch indexes and install packages fromhttps://packages.
    edgedb.com. And as we use generic commands (e.g. apt-get update) and system dependencies, package
    manager can fetch package indexes and package data from any sources listed in repositories configured in the
    system.

To avoid reaching these hosts, avoid using:edgedb serverandedgedb self upgradesubcommands. These com-
mands only simplify installation and maintenance of the installations. All EdgeDB features are available without using
them.

### 7.3 edgedb

```
edb-alt-title edgedb — Interactive Shell
```
EdgeDB interactive shell:

edgedb [<connection-option>...]

It’s also possible to run an EdgeQL script by piping it into the EdgeDB shell. The shell will then run in non-interactive
mode and print all the responses into the standard output:

cat myscript.edgeql | edgedb [<connection-option>...]

#### 7.3.1 Description

edgedbis a terminal-based front-end to EdgeDB. It allows running queries and seeing results interactively.

#### 7.3.2 Options

-h, --helpShow help about the command and exit.

--help-connectShow all available _connection options_

-V, --versionPrint version.

--no-cli-update-checkDisable version check.

-I <name>, --instance=<name>Specifies the named instance to connect to. The actual connection parameters are
stored in<edgedb_config_dir>/credentialsand are usually created by _edgedb instance create_ or similar
commands. Runedgedb infoto see the location of<edgedb_config_dir>on your machine.
This option overrides host and port.

**7.3. edgedb 523**


--dsn=<dsn>Specifies the DSN for EdgeDB to connect to.

```
This option overrides all other options except password.
```
--credentials-file /path/to/filePath to JSON file containing credentials.

-H <hostname>, --host=<hostname>Specifies the host name of the machine on which the server is running.
Defaults to the value of theEDGEDB_HOSTenvironment variable.

-P <port>, --port=<port>Specifies the TCP port on which the server is listening for connections. Defaults to
the value of theEDGEDB_PORTenvironment variable or, if not set, to 5656.

-u <username>, --user=<username>Connect to the database as the user<username>. Defaults to the value of
theEDGEDB_USERenvironment variable, or, if not set, to the login name of the current OS user.

-d <dbname>, --database=<dbname>Specifies the name of the database to connect to. Default to the value of the
EDGEDB_DATABASEenvironment variable, or, if not set, to the calculated value of<username>.

--password | --no-passwordIf--passwordis specified, forceedgedbto prompt for a password before con-
necting to the database. This is usually not necessary, sinceedgedbwill prompt for a password automatically if
the server requires it.
Specifying--no-passworddisables all password prompts.

--password-from-stdinUse the first line of standard input as the password.

--tls-ca-file /path/to/certCertificate to match server against.

```
This might either be full self-signed server certificate or certificate authority (CA) certificate that server certificate
is signed with.
```
--tls-security modeSet the TLS security mode.

```
defaultResolves tostrictif no custom certificate is supplied via--tls-ca-file, environment variable,
etc. Otherwise, resolves tono_host_verification.
strictVerify TLS certificate and hostname.
no_host_verificationThis allows using any certificate for any hostname. However, certificate must be
present and match the root certificate specified with--tls-ca-file, credentials file, or system root cer-
tificates.
insecureDisable all TLS security measures.
```
--wait-until-available=<wait_time>In case EdgeDB connection can’t be established, keep retrying up to
<wait_time>(e.g.30s).

--connect-timeout=<timeout>Specifies a<timeout>period. In case EdgeDB doesn’t respond for this period
the command will fail (or retry if--wait-until-availableis also specified). The<timeout>value must be
given using time units (e.g.hr,min,sec,ms, etc.). The default value is10s.

#### 7.3.3 Backslash Commands

**Introspection**

The introspection commands share a few common options that are available to many of the commands:

- -v- Verbose
- -s- Show system objects
- -c- Case-sensitive pattern matching

\d [-v] OBJECT-NAME, \describe [-v] OBJECT-NAMEDescribe schema object specified by _OBJECT-NAME_.

**524 Chapter 7. CLI**


\ds, \d schema, \describe schemaDescribe the entire schema.

\l, \list databasesList databases.

\ls [-sc] [PATTERN], \list scalars [-sc] [PATTERN]List scalar types.

\lt [-sc] [PATTERN], \list types [-sc] [PATTERN]List object types.

\lr [-c] [PATTERN], \list roles [-c] [PATTERN]List roles.

\lm [-c] [PATTERN], \list modules [-c] [PATTERN]List modules.

\la [-vsc] [PATTERN], \list aliases [-vsc] [PATTERN]List expression aliases.

\lc [-c] [PATTERN], \list casts [-c] [PATTERN]List available conversions between types.

\li [-vsc] [PATTERN], \list indexes [-vsc] [PATTERN]List indexes.

**Database**

\database create [NAME]Create a new database.

**Query Analysis**

\analyze QUERY

```
Note: This backslash command is compatible with EdgeDB server 3.0 and above.
```
```
Run a query performance analysis on the given query.
```
**Data Operations**

\dump FILENAMEDump current database to a file at _FILENAME_.

\restore FILENAMERestore the database dump at _FILENAME_ into the currently connected database.

**Editing**

\s, \historyShow a history of commands executed in the shell.

\e, \edit [N]Spawn$EDITORto edit the most recent history entry or history entry _N_. History entries are negative
indexed with-1being the most recent command. Use the\historycommand (above) to see previous command
indexes.
The output of this will then be used as input into the shell.

**7.3. edgedb 525**


**Settings**

\set [OPTION [VALUE]]If _VALUE_ is omitted, the command will show the current value of _OPTION_. With _VALUE_ ,
the option named by _OPTION_ will be set to the provided value. Use\setwith no arguments for a listing of all
available options.

**Connection**

\c, \connect [DBNAME]Connect to database _DBNAME_.

**Migrations**

These migration commands are also accessible directly from the command line without first entering the EdgeDB shell.
Their counterpart commands are noted and linked in their descriptions if you want more detail.

\migration createCreate a migration script based on differences between the current database and the schema
file, just like running _edgedb migration create_.

\migrate, \migration applyApply your migration, just like running the _edgedb migrate_.

\migration editSpawn$EDITORon the last migration file and fixes the migration ID after the editor exits, just like
_edgedb migration edit_. This is typically used only on migrations that have not yet been applied.

\migration logShow the migration history, just like _edgedb migration log_.

\migration statusShow how the state of the schema in the EdgeDB instance compares to the migration stored in
the schema directory, just like _edgedb migration status_.

**Help**

\?, \h, \helpShow help on backslash commands.

\q, \quit, \exitQuit the REPL. You can also do this by pressing Ctrl+D.

### 7.4 edgedb dump

Backup an EdgeDB database to a file.

edgedb dump [<options>] <path>

#### 7.4.1 Description

edgedb dumpis a terminal command used to backup an EdgeDB database into a file.

**526 Chapter 7. CLI**


#### 7.4.2 Options

Thedumpcommand backups the database it is connected to. For specifying the connection target see _connection
options_.

<path>The name of the file to backup the database into.

--allDump all databases and the server configuration using the directory specified by the<path>.

--format=<format>Choose dump format. For normal dumps this parameter should be omitted. For--allonly
--format=diris required.

### 7.5 edgedb restore

Restore an EdgeDB database from a backup file.

edgedb restore [<options>] <path>

#### 7.5.1 Description

edgedb restoreis a terminal command used to restore an EdgeDB database from a backup file. An empty target
database must be created before using this command.

#### 7.5.2 Options

Therestorecommand restores the backup file into the database it is connected to. For specifying the connection
target see _connection options_.

<path>The name of the backup file to restore the database from.

--allRestore all databases and the server configuration using the directory specified by the<path>.

-v, --verboseVerbose output.

### 7.6 edgedb configure

Configure the EdgeDB server.

edgedb configure[<connection-options>] <action> \
[<parameter> <value>] \
[<parameter-class> --<property>=<value> ...]

**7.5. edgedb restore 527**


#### 7.6.1 Description

edgedb configureis a terminal command used to alter the configuration of an EdgeDB instance. There are three
types of configuration actions that can be performed.

#### 7.6.2 Actions

edgedb configure insertInsert a new configuration entry for a setting that supports multiple configuration ob-
jects (e.g. Auth or Port).

edgedb configure setSet a scalar configuration value.

edgedb configure resetReset an existing configuration entry or remove all values for an entry that supports mul-
tiple configuration objects.

#### 7.6.3 Options

Most of the options are the same across all of the different configuration actions.

<connection-options>See _connection options_.

<parameter>The name of a primitive configuration parameter. Available configuration parameters are described in
the _Config_ section.

<value>A value literal for a given configuration parameter or configuration object property.

<parameter-class>The name of a composite configuration value class. Available configuration classes are de-
scribed in the _Config_ section.

--<property>=<value>Set the<property>of a configuration object to<value>.

### 7.7 edgedb watch

**Note:** This CLI feature is compatible with EdgeDB server 3.0 and above.

Start a long-running process that watches for changes in schema files in your project’sdbschemadirectory and applies
those changes to your database in real time.

edgedb watch

**Note:** If a schema change cannot be applied, you will see an error in theedgedb watchconsole. You will also receive
the error when you try to run a query with any EdgeDB client binding.

To learn about our recommended development migration workflow usingedgedb watch, read our _intro to migrations_.

**528 Chapter 7. CLI**


### 7.8 edgedb migration

EdgeDB provides schema migration tools as server-side tools. This means that from the point of view of the application
migrations are language- and platform-agnostic and don’t require additional libraries.

Using the migration tools is the recommended way to make schema changes.

#### 7.8.1 edgedb migration create

The next step after setting up the desired target schema is creating a migration script. This is done by invoking the
following command:

edgedb migration create[<options>]

This will start an interactive tool that will provide the user with suggestions based on the differences between the current
database and the schema file. The prompts will look something like this:

did you create object type'default::User'? [y,n,l,c,b,s,q,?]
?

y - confirm the prompt, use the DDL statements
n - reject the prompt
l - list the DDL statements associated with prompt
c - list already confirmed EdgeQL statements
b - revert back to previous save point, perhaps previous question
s - stop and save changes (splits migration into multiple)
q - quit without saving changes
h or? - print help

##### 7.8.1.1 Options

Themigration createcommand runs on the database it is connected to. For specifying the connection target see
_connection options_.

--non-interactiveDo not prompt user for input. By default this works only if all the changes are “safe” unless
--allow-unsafeis also specified.

--allow-unsafeApply the most probable unsafe changes in case there are any. This is only useful in non-interactive
mode.

--allow-emptyCreate a new migration even if there are no changes. This is useful for creating migration stubs for
data-only migrations.

--schema-dir=<schema-dir>Directory where the schema files are located. Defaults to./dbschema.

--squash

```
Note: This CLI feature is compatible with EdgeDB server 3.0 and above.
```
```
Squashes all your migrations into a single migration.
```
**7.8. edgedb migration 529**


#### 7.8.2 edgedb migration apply

Once the migration scripts are in place the changes can be applied to the database by this command:

edgedb migrationapply [<options>]

The tool will find all the unapplied migrations indbschema/migrations/directory and sequentially run them on the
target instance.

##### 7.8.2.1 Options

Themigration applycommand runs on the database it is connected to. For specifying the connection target see
_connection options_.

--quietDo not print any messages, only indicate success by exit status.

--schema-dir=<schema-dir>Directory where the schema files are located. Defaults to./dbschema.

--to-revision=<to-revision>Upgrade to a specified revision.

```
Unique prefix of the revision can be specified instead of full revision name.
If this revision is applied, the command is no-op. The command ensures that this revision present, but it’s not an
error if more revisions are applied on top.
```
--dev-mode

```
Note: The--dev-modoption is compatible with EdgeDB server 3.0 and above.
```
```
Apply the current schema changes on top of the current migration history, without having created a new migra-
tion. This works the same way as edgedb watch but without starting a long-running watch task.
```
#### 7.8.3 edgedb migration log

Show all migration versions.

edgedb migrationlog [<options>]

The tool will display the migration history either by reading it from the EdgeDB instance or from the schema directory.

##### 7.8.3.1 Options

Themigration logcommand runs on the database it is connected to. For specifying the connection target see
_connection options_.

--from-fsPrint revisions from the schema directory (no database connection required). At least one of--from-db
or--from-fsis required formigration logcommand.

--from-dbPrint revisions from the database (no schema files required). At least one of--from-dbor--from-fs
is required formigration logcommand.

--newest-firstSort migrations starting from newer to older, by default older revisions go first.

--schema-dir=<schema-dir>Directory where the schema files are located. Defaults to./dbschema.

--limit=<N>Show maximum ofNrevisions (default is unlimited).

**530 Chapter 7. CLI**


### 7.8.4 edgedb migration status

Show current migration state.

edgedb migrationstatus [<options>]

The tool will show how the state of the schema in the EdgeDB instance compares to the migrations stored in the schema
directory.

#### 7.8.4.1 Options

Themigration statuscommand runs on the database it is connected to. For specifying the connection target see
_connection options_.

--quietDo not print any messages, only indicate success by exit status.

--schema-dir=<schema-dir>Directory where the schema files are located. Defaults to./dbschema.

### 7.8.5 edgedb migration edit

Edit migration file.

edgedb migrationedit [<options>]

Invokes$EDITORon the last migration file, and then fixes migration id after editor exits. Usually should be used for
migrations that haven’t been applied yet.

#### 7.8.5.1 Options

Themigration editcommand runs on the database it is connected to. For specifying the connection target see
_connection options_.

--schema-dir=<schema-dir>Directory where the schema files are located. Defaults to./dbschema.

--no-checkDo not check migration within the database connection.

--non-interactiveFix migration id non-interactively, and don’t run editor.

### 7.8.6 edgedb migration upgrade-check

Checks your schema against the new EdgeDB version. You can add--to-version <version>,--to-testing,
--to-nightly, or--to-channel <channel>to check against a specific version.

edgedb migration update-check[<options>]

**7.8. edgedb migration 531**


#### 7.8.6.1 Options

Themigration upgrade-checkcommand runs on the database it is connected to. For specifying the connection
target see _connection options_.

--schema-dir=<schema-dir>Directory where the schema files are located. Defaults to./dbschema.

--to-version <to_version>Check the upgrade to a specified version

--to-nightlyCheck the upgrade to a latest nightly version

--to-testingCheck the upgrade to a latest testing version

--to-channel <to_channel>Check the upgrade to the latest version in the channel [possible values: stable, testing,
nightly]

--watchMonitor schema changes and check again on change

### 7.8.7 Setup

First of all, the migration tools need a place to store the schema and migration information. By default they will look
indbschemadirectory, but it’s also possible to specify any other location by usingschema-diroption. Inside this
directory there should be an.esdlfile with _SDL_ schema description. It’s also possible to split the schema definition
across multiple.esdlfiles. The migration tools will read all of them and treat them as a single SDL document.

```
edgedb migration create Create a migration script
edgedb migration apply Bring current database to the latest or a specified revision
edgedb migration log Show all migration versions
edgedb migration status Show current migration state
edgedb migration edit Edit migration file
```
## 7.9 edgedb migrate

This command is an alias for _edgedb migration apply_. Once the migration scripts are in place the changes can be
applied to the database by this command.

## 7.10 edgedb database create

Create a new _database_.

edgedb database create[<options>] <name>

**532 Chapter 7. CLI**


### 7.10.1 Description

edgedb database createis a terminal command equivalent tocreate database.

### 7.10.2 Options

Thedatabase createcommand runs in the EdgeDB instance it is connected to. For specifying the connection target
see _connection options_.

<name>The name of the new database.

## 7.11 edgedb describe

Theedgedb describegroup of commands contains various schema introspection tools.

### 7.11.1 edgedb describe object

Describe a named schema object.

edgedb describe object[<options>] <name>

#### 7.11.1.1 Description

edgedb describeis a terminal command equivalent todescribe objectintrospection command.

#### 7.11.1.2 Options

Thedescribecommand runs in the database it is connected to. For specifying the connection target see _connection
options_.

--verboseThis is equivalent to runningdescribe object ... as text verbosecommand, which enables dis-
playing additional details, such as annotations and constraints, which are otherwise omitted.

<name>Name of the schema object to describe.

### 7.11.2 edgedb describe schema

Give an _SDL_ description of the schema of the database specified by the connection options.

edgedb describe schema[<options>]

**7.11. edgedb describe 533**


#### 7.11.2.1 Description

edgedb describe schemais a terminal command equivalent todescribe schema as sdlintrospection com-
mand.

#### 7.11.2.2 Options

Thedescribecommand runs in the database it is connected to. For specifying the connection target see _connection
options_.

```
edgedb describe object Describe a named schema object
edgedb describe schema Describe schema of the current database
```
## 7.12 edgedb list

List matching database objects by name and type.

edgedb list <type> [<options>] <pattern>

### 7.12.1 Description

Theedgedb listgroup of commands contains tools for listing database objects by matching name or type. The
sub-commands are organized by the type of the objects listed.

### 7.12.2 Types

edgedb list aliasesDisplay list of aliases defined in the schema.

edgedb list castsDisplay list of casts defined in the schema.

edgedb list databasesDisplay list of databases in the server instance.

edgedb list indexesDisplay list of indexes defined in the schema.

edgedb list modulesDisplay list of modules defined in the schema.

edgedb list rolesDisplay list of roles in the server instance.

edgedb list scalarsDisplay list of scalar types defined in the schema.

edgedb list typesDisplay list of object types defined in the schema.

### 7.12.3 Options

Thelistcommand runs in the database it is connected to. For specifying the connection target see _connection options_.

-c, --case-sensitiveIndicates that the pattern should be treated in a case-sensitive manner.

-s, --systemIndicates that built-in and objects should be included in the list.

-v, --verboseInclude more details in the output.

<pattern>The pattern that the name should match. If omitted all objects of a particular type will be listed.

**534 Chapter 7. CLI**


## 7.13 edgedb query

Execute one or more EdgeQL queries.

edgedb query [<options>] <edgeql-query>...

### 7.13.1 Description

edgedb queryis a terminal command used to execute EdgeQL queries provided as space-separated strings.

### 7.13.2 Options

Thequerycommand runs on the database it is connected to. For specifying the connection target see _connection
options_.

-F, --output-format=<output_format>Output format:json,json-pretty,json-lines,tab-separated.
Default isjson-pretty.

-f, --file=<file>Filename to execute queries from. Pass--file -to execute queries from stdin.

<edgeql-query>Any valid EdgeQL query to be executed.

## 7.14 edgedb analyze

**Note:** This CLI feature is compatible with EdgeDB server 3.0 and above.

Run a query performance analysis on the given query.

edgedb analyze[<options>] <query>

Here’s exampleanalyzeoutput from a simple query:

Contexts
analyze select Hero {name, secret_identity, villains: {name, nemesis: {name}}}
Shape
default::Hero (cost=20430.96)
.villains: default::Villain, default::Hero (cost=35.81)

### 7.14.1 Options

Theanalyzecommand runs on the database it is connected to. For specifying the connection target see _connection
options_.

<query>The query to analyze. Be sure to wrap the query in quotes.

--expandPrint expanded output of the query analysis

--debug-output-file <debug_output_file>Write analysis into the JSON file specified instead of formatting

--read-json <read_json>Read JSON file instead of executing a query

**7.13. edgedb query 535**


## 7.15 edgedb ui

Open the EdgeDB UI of the current instance in your default browser.

edgedb ui [<options>]

### 7.15.1 Description

edgedb uiis a terminal command used to open the EdgeDB UI in your default browser. Alternatively, it can be used
to print the UI URL with the--print-urloption.

The EdgeDB UI is a tool that allows you to graphically manage and query your EdgeDB databases. It contains a REPL,
a textual and graphical view of your database schemas, and a data explorer which allows for viewing your data as a
table.

**Note:** The UI is served by default by development instances. To enable the UI on a production instance, use the
--admin-uioption withedgedb-serveror set theEDGEDB_SERVER_ADMIN_UI _environment variable_ toenabled.

### 7.15.2 Options

Theuicommand runs on the database it is connected to. For specifying the connection target see _connection options_.

--print-urlPrint URL in console instead of opening in the browser. This is useful if you prefer to open the EdgeDB
UI in a browser other than your default browser.

--no-server-checkSkip probing the UI endpoint of the server instance. The endpoint probe is in place to provide
a friendly error if you try to connect to a UI on a remote instance that does not have the UI enabled.

## 7.16 edgedb info

Display information about the EdgeDB installation. Currently this command displays the filesystem paths used by
EdgeDB.

edgedb info [<options>]

### 7.16.1 Paths

EdgeDB uses several directories, each storing different kinds of information. The exact path to these directories is
determined by your operating system. Throughout the documentation, these paths are referred to as “EdgeDB config
directory”, “EdgeDB data directory”, etc.

- **Config** : contains auto-generated credentials for all local instances and project metadata.
- **Data** : contains the _contents_ of all local EdgeDB instances.
- **CLI Binary** : contains the CLI binary, if insatlled.
- **Service** : the home for running processes/daemons.
- **Cache** : a catchall for logs and various caches.

**536 Chapter 7. CLI**


#### 7.16.1.1 Options

--get <path-name>Return only a single path.<path-name>can be any ofconfig-dir,cache-dir,data-dir,
orservice-dir.

## 7.17 edgedb project

EdgeDB provides a way to quickly setup a project. This way the project directory gets associated with a specific
EdgeDB instance and thus makes it the default instance to connect to. This is done by creating anedgedb.tomlfile
in the project directory.

### 7.17.1 edgedb project init

Setup a new project.

edgedb project init [<options>]

#### 7.17.1.1 Description

This command sets up a new project, creating an instance and a schema directory for it. It can also be used to convert an
existing directory to a project directory, connecting the existing instance to the project. Typically this tool will prompt
for specific details about how the project should be setup.

##### 7.17.1.1.1 EdgeDB Cloud

Users with access to the EdgeDB Cloud beta may use this command to create a Cloud instance after logging in using
_edgedb cloud login_.

To create a Cloud instance, your instance name should be in the format<github-username>/<instance-name>.
Cloud instance names may contain alphanumeric characters and hyphens (i.e.,-). You can provide this Cloud in-
stance name through the interactive project initiation by runningedgedb project initor by providing it via the
--server-instanceoption.

#### 7.17.1.2 Options

--linkSpecifies whether the existing EdgeDB server instance should be linked with the project.

```
This option is useful for initializing a copy of a project freshly downloaded from a repository with a pre-existing
project database.
```
--no-migrationsSkip running migrations.

```
There are two main use cases for this option:
```
1. With--linkoption to connect to a datastore with existing data.
2. To initialize a new instance but then restore dump to it.

--non-interactiveRun in non-interactive mode (accepting all defaults).

--project-dir=<project-dir>The project directory can be specified explicitly. Defaults to the current directory.

--server-instance=<server-instance>Specifies the EdgeDB server instance to be associated with the project.

**7.17. edgedb project 537**


--server-version=<server-version>Specifies the EdgeDB server instance to be associated with the project.

```
By default, when you specify a version, the CLI will use the latest release in the major version specified. This
command, for example, will install the latest 2.x release:
```
```
$ edgedb project init --server-version 2.6
```
```
You may pin to a specific version by prepending the version number with an equals sign. This command will
install version 2.6:
```
```
$ edgedb project init --server-version =2.6
```
```
Note: Some shells like ZSH may require you to escape the equals sign (e.g.,\=2.6) or quote the version string
(e.g.,"=2.6").
```
### 7.17.2 edgedb project unlink

Remove association with and optionally destroy the linked EdgeDB instance.

edgedb project unlink [<options>]

#### 7.17.2.1 Description

This command unlinks the project directory from the instance. By default the EdgeDB instance remains untouched,
but it can also be destroyed with an explicit option.

#### 7.17.2.2 Options

-D, --destroy-server-instanceIf specified, the associated EdgeDB instance is destroyed by running _edgedb
instance destroy_.

--non-interactiveDo not prompts user for input.

--project-dir=<project-dir>The project directory can be specified explicitly. Defaults to the current directory.

### 7.17.3 edgedb project info

Display various metadata about the project.

edgedb project info [OPTIONS]

**538 Chapter 7. CLI**


#### 7.17.3.1 Description

This command provides information about the project instance, such as name and the project path.

#### 7.17.3.2 Options

--instance-nameDisplay only the instance name.

-j, --jsonOutput in JSON format.

--project-dir=<project-dir>The project directory can be specified explicitly. Defaults to the current directory.

### 7.17.4 edgedb project upgrade

Upgrade EdgeDB instance used for the current project

edgedb project upgrade [<options>]

#### 7.17.4.1 Description

This command has two modes of operation.

```
1) Upgrade instance to a version specified inedgedb.toml. This happens when the command is invoked without
any explicit target version.
2) Updateedgedb.tomlto a new version and upgrade the instance. Which happens when one of the options for
providing the target version is used.
```
In all cases your data is preserved and converted using dump/restore mechanism. This might fail if lower version is
specified (for example if upgrading from nightly to the stable version).

#### 7.17.4.2 Options

--forceForce upgrade process even if there is no new version.

--to-latestUpgrade to a latest stable version.

--to-nightlyUpgrade to a latest nightly version.

--to-version=<version>Upgrade to a specified major version.

--project-dir=<project-dir>The project directory can be specified explicitly. Defaults to the current directory.

-v, --verboseVerbose output.

```
edgedb project init Initialize a new or existing project
edgedb project unlink Clean-up the project configuration
edgedb project info Get various metadata about the project
edgedb project upgrade Upgrade EdgeDB instance used for the current project
```
**7.17. edgedb project 539**


## 7.18 edgedb instance

Theedgedb instancegroup of commands contains all sorts of tools for managing EdgeDB instances.

### 7.18.1 edgedb instance create

Initialize a new EdgeDB instance.

edgedb instance create[<options>] <name>

#### 7.18.1.1 Description

edgedb instance createis a terminal command for making a new EdgeDB instance and creating a cor-
responding credentials file in<edgedb_config_dir>/credentials. Run edgedb infoto see the path to
<edgedb_config_dir>on your machine.

##### 7.18.1.1.1 EdgeDB Cloud

Users with access to the EdgeDB Cloud beta may use this command to create a Cloud instance after logging in using
_edgedb cloud login_.

To create a Cloud instance, your instance name should be in the format<github-username>/<instance-name>.
Cloud instance names may contain alphanumeric characters and hyphens (i.e.,-).

#### 7.18.1.2 Options

<name>The new EdgeDB instance name.

--nightlyUse the nightly server for this instance.

--default-database=<default-database>Specifies the default database name (created during initialization,
and saved in credentials file). Defaults toedgedb.

--default-user=<default-user>Specifies the default user name (created during initialization, and saved in cre-
dentials file). Defaults to:edgedb.

--port=<port>Specifies which port should the instance be configured on. By default a random port will be used
and recorded in the credentials file.

--start-conf=<start-conf>Configures how the new instance should start:autofor automatic start with the
system or user session,manualto turn that off so that the instance can be manually started with _edgedb instance
start_ on demand. Defaults to:auto.

--version=<version>Specifies the version of the EdgeDB server to be used to run the new instance. To list the
currently available options use _edgedb server list-versions_.
By default, when you specify a version, the CLI will use the latest release in the major version specified. This
command, for example, will install the latest 2.x release:

```
$ edgedb instance create --version 2.6 demo26
```
```
You may pin to a specific version by prepending the version number with an equals sign. This command will
install version 2.6:
```
**540 Chapter 7. CLI**


```
$ edgedb instance create --version =2.6 demo26
```
```
Note: Some shells like ZSH may require you to escape the equals sign (e.g.,\=2.6) or quote the version string
(e.g.,"=2.6").
```
### 7.18.2 edgedb instance link

Authenticate a connection to a remote EdgeDB instance and assign an instance name to simplify future connections.

edgedb instance link[<options>] <name>

#### 7.18.2.1 Description

edgedb instance linkis a terminal command used to bind a set of connection credentials to an instance name.
This is typically used as a way to simplify connecting to remote EdgeDB database instances. Usually there’s no need
to do this for local instances as _edgedb project init_ will already set up a named instance.

#### 7.18.2.2 Options

Theinstance linkcommand uses the standard _connection options_ for specifying the instance to be linked.

<name>Specifies a new instance name to associate with the connection options. If not present, the interactive mode
will ask for the name.

--non-interactiveRun in non-interactive mode (accepting all defaults).

--quietReduce command verbosity.

--trust-tls-certTrust peer certificate.

--overwriteOverwrite existing credential file if any.

### 7.18.3 edgedb instance unlink

Unlink from a previously linked remote EdgeDB instance.

edgedb instanceunlink <name>

#### 7.18.3.1 Description

edgedb instance unlinkis a terminal command used to unlink a remote instance. This removes the instance name
from the list of valid instances.

**7.18. edgedb instance 541**


#### 7.18.3.2 Options

<name>Specifies the name of the remote instance to be unlinked.

### 7.18.4 edgedb instance list

Show all EdgeDB instances.

edgedb instancelist [<options>]

#### 7.18.4.1 Description

edgedb instance listis a terminal command that shows all the registered EdgeDB instances and some relevant
information about them (status, port, etc.).

#### 7.18.4.2 Options

--extendedOutput more debug info about each instance.

-j, --jsonOutput in JSON format.

### 7.18.5 edgedb instance logs

Show instance logs.

edgedb instancelogs [<options>] <name>

#### 7.18.5.1 Description

edgedb instance logsis a terminal command for displaying the logs for a given EdgeDB instance.

#### 7.18.5.2 Options

<name>The name of the EdgeDB instance.

-n, --tail=<tail>Number of the most recent lines to show.

-f, --followShow log’s tail and the continue watching for the new entries.

### 7.18.6 edgedb instance status

Show instance information.

edgedb instancestatus [<options>] [<name>]

**542 Chapter 7. CLI**


#### 7.18.6.1 Description

edgedb instance statusis a terminal command for displaying the information about EdgeDB instances.

#### 7.18.6.2 Options

<name>Show only the status of the specific EdgeDB instance.

--jsonFormat output as JSON.

--extendedOutput more debug info about each instance.

--serviceShow current systems service information.

### 7.18.7 edgedb instance start

Start an EdgeDB instance.

edgedb instance start[--foreground] <name>

#### 7.18.7.1 Description

edgedb instance startis a terminal command for starting a new EdgeDB instance.

#### 7.18.7.2 Options

<name>The EdgeDB instance name.

--foregroundStart the instance in the foreground rather than using systemd to manage the process (note you might
need to stop non-foreground instance first).

### 7.18.8 edgedb instance stop

Stop an EdgeDB instance.

edgedb instancestop <name>

#### 7.18.8.1 Description

edgedb instance stopis a terminal command for stopping a running EdgeDB instance. This is a necessary step
before _destroying_ an instance.

**7.18. edgedb instance 543**


#### 7.18.8.2 Options

<name>The EdgeDB instance name.

### 7.18.9 edgedb instance restart

Restart an EdgeDB instance.

edgedb instancerestart <name>

#### 7.18.9.1 Description

edgedb instance restartis a terminal command for restarting an EdgeDB instance.

#### 7.18.9.2 Options

<name>The EdgeDB instance name.

### 7.18.10 edgedb instance destroy

Remove an EdgeDB instance.

edgedb instancedestroy [<options>] <name>

#### 7.18.10.1 Description

edgedb instance destroyis a terminal command for removing an EdgeDB instance and all its data.

#### 7.18.10.2 Options

<name>The EdgeDB instance name.

--forceDestroy the instance even if it is referred to by a project.

-v, --verboseVerbose output.

### 7.18.11 edgedb instance revert

Revert a major instance upgrade.

edgedb instancerevert [<options>] <name>

**544 Chapter 7. CLI**


#### 7.18.11.1 Description

When _edgedb instance upgrade_ performs a major version upgrade on an instance the old instance data is kept around.
Theedgedb instance revertcommand removes the new instance version and replaces it with the old copy. It also
ensures that the previous version of EdgeDB server is used to run it.

#### 7.18.11.2 Options

<name>The name of the EdgeDB instance to revert.

--ignore-pid-checkDo not check if upgrade is in progress.

-y, --no-confirmDo not ask for a confirmation.

### 7.18.12 edgedb instance reset-password

Reset password for a user in the EdgeDB instance.

edgedb instance reset-password [<options>] <name>

#### 7.18.12.1 Description

edgedb instance reset-passwordis a terminal command for resetting or updating the password for a user of an
EdgeDB instance.

#### 7.18.12.2 Options

<name>The name of the EdgeDB instance.

--user=<user>User to change password for. Defaults to the user in the credentials file.

--passwordRead the password from the terminal rather than generating a new one.

--password-from-stdinRead the password from stdin rather than generating a new one.

--save-credentialsSave new user and password into a credentials file. By default credentials file is updated only
if user name matches.

--no-save-credentialsDo not save generated password into a credentials file even if user name matches.

--quietDo not print any messages, only indicate success by exit status.

### 7.18.13 edgedb instance upgrade

Upgrade EdgeDB instance or installation.

edgedb instanceupgrade [<options>] [<name>]

**7.18. edgedb instance 545**


#### 7.18.13.1 Description

This command is used to upgrade EdgeDB instances individually or in bulk.

#### 7.18.13.2 Options

<name>The EdgeDB instance name to upgrade.

--forceForce upgrade process even if there is no new version.

--to-latestUpgrade specified instance to the latest major version.

--to-nightlyUpgrade specified instance to a latest nightly version.

--local-minorUpgrade all local instances to the latest minor versions.

--to-version=<version>Upgrade to a specified major version.

-v, --verboseVerbose output.

```
edgedb instance create Initialize a new server instance
edgedb instance link Link a remote instance
edgedb instance unlink Unlink a remote instance
edgedb instance list Show all instances
edgedb instance logs Show logs of an instance
edgedb instance status Show statuses of all or of a matching instance
edgedb instance start Start an instance
edgedb instance stop Stop an instance
edgedb instance restart Restart an instance
edgedb instance destroy Destroy a server instance and remove the data stored
edgedb instance revert Revert a major instance upgrade
edgedb instance reset-password Reset password for a user in the instance
edgedb instance upgrade Upgrade installations and instances
```
## 7.19 edgedb server

Theedgedb servergroup of commands contains all sorts of tools for managing EdgeDB server versions.

### 7.19.1 edgedb server info

Show server information.

edgedb server info [<options>]

**546 Chapter 7. CLI**


#### 7.19.1.1 Description

edgedb server infois a terminal command for displaying the information about installed EdgeDB servers.

#### 7.19.1.2 Options

--jsonFormat output as JSON.

--nightlyDisplay the information about the nightly server version.

--latestDisplay the information about the latest server version.

--bin-pathDisplay only the server binary path (if applicable).

--version=<version>Display the information about a specific server version.

### 7.19.2 edgedb server install

Install EdgeDB server.

edgedb server install [<options>]

#### 7.19.2.1 Description

edgedb server installis a terminal command for installing a specific EdgeDB server version.

#### 7.19.2.2 Options

-i, --interactivePerforms the installation in interactive mode, similar to how _downloading and installing_ works.

--nightlyInstalls the nightly server version.

--version=<version>Specifies the version of the server to be installed. Defaults to the most recent release.

### 7.19.3 edgedb server list-versions

List available and installed versions of the EdgeDB server.

edgedb server list-versions [<options>]

#### 7.19.3.1 Description

edgedb server list-versionsis a terminal command for displaying all the available EdgeDB server versions
along with indicating whether or not and how they are currently installed.

**7.19. edgedb server 547**


#### 7.19.3.2 Options

--jsonFormat output as JSON.

--installed-onlyDisplay only the installed versions.

--column=<column>Format output as a single column displaying only one aspect of the server:major-version,
installed,available.

### 7.19.4 edgedb server uninstall

Uninstall EdgeDB server.

edgedb server uninstall [<options>]

#### 7.19.4.1 Description

edgedb server uninstallis a terminal command for removing a specific EdgeDB server version from your system.

#### 7.19.4.2 Options

--allUninstalls all server versions.

--nightlyUninstalls the nightly server version.

--unusedUninstalls server versions that are not used to run any instances.

--version=<version>Specifies the version of the server to be uninstalled.

-v, --verboseProduce a more verbose output.

```
edgedb server info Show server information
edgedb server install Install edgedb server
edgedb server list-versions List available and installed versions of the server
edgedb server uninstall Uninstall edgedb server
```
## 7.20 edgedb cloud

In addition to managing your own local and remote instances, the EdgeDB CLI offers tools to manage your instances
running on our EdgeDB Cloud.

### 7.20.1 edgedb cloud login

Authenticate to the EdgeDB Cloud and remember the secret key locally

edgedb cloud login

This command will launch your browser and start the EdgeDB Cloud authentication flow. Once authentication is
successful, the CLI will log a success message:

**548 Chapter 7. CLI**


Successfully logged into EdgeDB Cloud as <your-email>

If you are unable to complete authentication in the browser, you can interrupt the command by pressing Ctrl-C.

**Note:** During the Cloud beta, you will only be able to successfully complete authentication if you have been invited
to the beta.

### 7.20.2 edgedb cloud logout

Forget the stored access token

edgedb cloud logout [<options>]

#### 7.20.2.1 Options

--all-profilesLogout from all Cloud profiles

--forceForce log out from all profiles, even if linked to a project

--non-interactiveDo not ask questions, assume user wants to log out of all profiles not linked to a project

### 7.20.3 edgedb cloud secretkey

Manage your secret keys

#### 7.20.3.1 edgedb cloud secretkey create

Create a new secret key

edgedb cloud secretkeycreate [<options>]

**Note:** This command works only if you have already authenticated using _edgedb cloud login_.

##### 7.20.3.1.1 Options

--jsonOutput results as JSON

-n, --name <name>Friendly key name

--description <description>Long key description

--expires <<duration> | "never">Key expiration, in duration units, for example “1 hour 30 minutes”. If set
to “never”, the key would not expire.

--scopes <scopes>Comma-separated list of key scopes. Mutually exclusive with--inherit-scopes.

--inherit-scopesInherit key scopes from the currently used key. Mutually exclusive with--scopes.

**7.20. edgedb cloud 549**


-y, --non-interactiveDo not ask questions, assume default answers to all inputs that have a default. Re-
quires key TTL and scopes to be explicitly specified via--ttlor--no-expiration, and--scopesor
--inherit-scopes.

##### 7.20.3.2 edgedb cloud secretkey list

List existing secret keys

edgedb cloud secretkey list [<options>]

**Note:** This command works only if you have already authenticated using _edgedb cloud login_.

###### 7.20.3.2.1 Options

--jsonOutput results as JSON

##### 7.20.3.3 edgedb cloud secretkey revoke

Revoke a secret key

edgedb cloud secretkeyrevoke [<options>] --secret-key-id <secret-key-id>

**Note:** This command works only if you have already authenticated using _edgedb cloud login_.

###### 7.20.3.3.1 Options

--jsonOutput results as JSON

--secret-key-id <secret_key_id>Id of secret key to revoke

-y, --non-interactiveRevoke the key without asking for confirmation.

```
edgedb cloud secretkey create Create a new secret key
edgedb cloud secretkey list List existing secret keys
edgedb cloud secretkey revoke Revoke a secret key
```
**Note:** These commands work only if you have already authenticated using _edgedb cloud login_.

**550 Chapter 7. CLI**


#### 7.20.4 Usage

To use the CLI with EdgeDB Cloud, start by running _edgedb cloud login_. This will open a browser and allow you to
log in to EdgeDB Cloud.

**Note:** During the Cloud beta, you will only be able to successfully complete authentication if you have been invited
to the beta.

Once your login is complete, you may use the other CLI commands to create and interact with Cloud instances.

```
edgedb cloud login Authenticate to the EdgeDB Cloud and remember the access token locally
edgedb cloud logout Forget the stored access token
edgedb cloud secretkey Manage your secret keys
```
### 7.21 edgedb cli upgrade

Upgrade the CLI binary.

edgedb cli upgrade [<options>]

#### 7.21.1 Description

edgedb cli upgradeis a terminal command used to upgrade the CLI tools to keep them up-to-date.

#### 7.21.2 Options

--forceReinstall the CLI even if there is no newer version.

--quietDon’t show the progress bar.

--verboseEnable verbose output.

**7.21. edgedb cli upgrade 551**


**552 Chapter 7. CLI**


```
CHAPTER
```
### EIGHT

### REFERENCE

### 8.1 EdgeQL

Statements in EdgeQL are a kind of an _expression_ that has one or moreclausesand is used to retrieve or modify data
in a database.

Query statements:

- select
    Retrieve data from a database and compute arbitrary expressions.
- for
    Compute an expression for every element of an input set and concatenate the results.
- group
    Group data into subsets by keys.

Data modification statements:

- insert
    Create new object in a database.
- update
    Update objects in a database.
- delete
    Remove objects from a database.

Transaction control statements:

- start transaction
    Start a transaction.
- commit
    Commit the current transaction.
- rollback
    Abort the current transaction.
- declare savepoint
    Declare a savepoint within the current transaction.

```
553
```

- rollback to savepoint
    Rollback to a savepoint within the current transaction.
- release savepoint
    Release a previously declared savepoint.

Session state control statements:

- setandreset.

Introspection command:

- describe.

#### 8.1.1 Lexical structure

Every EdgeQL command is composed of a sequence of _tokens_ , terminated by a semicolon (;). The types of valid
tokens as well as their order is determined by the syntax of the particular command.

EdgeQL is case sensistive except for _keywords_ (in the examples the keywords are written in upper case as a matter of
convention).

There are several kinds of tokens: _keywords_ , _identifiers_ , _literals_ (constants) and _symbols_ (operators and punctuation).

Tokens are normally separated by whitespace (space, tab, newline) or comments.

##### 8.1.1.1 Identifiers

There are two ways of writing identifiers in EdgeQL: plain and quoted. The plain identifiers are similar to many other
languages, they are alphanumeric with underscores and cannot start with a digit. The quoted identifiers start and end
with a _backtick_ `quoted.identifier`and can contain any characters inside with a few exceptions. They must not
start with an ampersand (@) or contain a double colon (::). If there’s a need to include a backtick character as part of
the identifier name a double-backtick sequence (``) should be used:`quoted``identifier`will result in the actual
identifier beingquoted`identifier.

```
identifier ::= plain_ident| quoted_ident
plain_ident ::= ident_first ident_rest*
ident_first ::= <any letter, underscore>
ident_rest ::= <any letter, digits, underscore>
quoted_ident ::= "`"qident_first qident_rest* "`"
qident_first ::= <any character except "@">
qident_rest ::= <any character>
```
Quoted identifiers are usually needed to represent module names that contain a dot (.) or to distinguish _names_ from
_reserved keywords_ (for instance to allow referring to a link named “order” as`order`).

**554 Chapter 8. Reference**


##### 8.1.1.2 Names and keywords

There are a number of _reserved_ and _unreserved_ keywords in EdgeQL. Every identifier that is not a _reserved_ keyword
is a valid _name_. _Names_ are used to refer to concepts, links, link properties, etc.

```
short_name ::= not_keyword_ident |quoted_ident
not_keyword_ident ::= <any plain_identexcept forkeyword>
keyword ::= reserved_keyword | unreserved_keyword
reserved_keyword ::= case insensitive sequence matching any
of the following
"AGGREGATE" | "ALTER" | "AND" |
"ANY" | "COMMIT" | "CREATE" |
"DELETE" | "DETACHED" | "DISTINCT" |
"DROP" | "ELSE" | "EMPTY" | "EXISTS" |
"FALSE" | "FILTER" | "FUNCTION" |
"GET" | "GROUP" | "IF" | "ILIKE" |
"IN" | "INSERT" | "IS" | "LIKE" |
"LIMIT" | "MODULE" | "NOT" | "OFFSET" |
"OR" | "ORDER" | "OVER" |
"PARTITION" | "ROLLBACK" | "SELECT" |
"SET" | "SINGLETON" | "START" | "TRUE" |
"UPDATE" | "UNION" | "WITH"
unreserved_keyword ::= case insensitive sequence matching any
of the following
"ABSTRACT" | "ACTION" | "AFTER" |
"ARRAY" | "AS" | "ASC" | "ATOM" |
"ANNOTATION" | "BEFORE" | "BY" |
"CONCEPT" | "CONSTRAINT" |
"DATABASE" | "DESC" | "EVENT" |
"EXTENDING" | "FINAL" | "FIRST" |
"FOR" | "FROM" | "INDEX" |
"INITIAL" | "LAST" | "LINK" |
"MAP" | "MIGRATION" | "OF" | "ON" |
"POLICY" | "PROPERTY" |
"REQUIRED" | "RENAME" | "TARGET" |
"THEN" | "TO" | "TRANSACTION" |
"TUPLE" | "VALUE" | "VIEW"
```
Fully-qualified names consist of a module,::, and a short name. They can be used in most places where a short name
can appear (such as paths and shapes).

```
name ::= short_name |fq_name
fq_name ::= short_name "::"short_name |
short_name "::"unreserved_keyword
```
**8.1. EdgeQL 555**


##### 8.1.1.3 Constants

A number of scalar types have literal constant expressions.

###### 8.1.1.3.1 Strings

Production rules forstrliterals:

```
string ::= str| raw_str
str ::= "'"str_content* "'" |'"' str_content* '"'
raw_str ::= "r'"raw_content* "'" |
'r"'raw_content* '"'|
dollar_quote raw_content* dollar_quote
raw_content ::= <any character different from delimiting quote>
dollar_quote ::= "$"q_char0? q_char* "$"
q_char0 ::= "A"..."Z" | "a"..."z" | "_"
q_char ::= "A"..."Z" | "a"..."z" | "_" | "0"..."9"
str_content ::= <newline> |unicode|str_escapes
unicode ::= <any printable unicode character not preceded by "\">
str_escapes ::= <see below for details>
```
The inclusion of “high ASCII” character inedgeql:q_charin practice reflects the ability to use some of the letters
with diacritics likeòorüin the dollar-quote delimiter.

Here’s a list of validedgeql:str_escapes:

```
Escape Sequence Meaning
\[newline] Backslash and all whitespace up to next non-whitespace character is ignored
\\ Backslash (\)
\' Single quote (‘)
\" Double quote (“)
\b ASCII backspace (\x08)
\f ASCII form feed (\x0C)
\n ASCII newline (\x0A)
\r ASCII carriage return (\x0D)
\t ASCII tabulation (\x09)
\xhh Character with hex value hh
\uhhhh Character with 16-bit hex value hhhh
\Uhhhhhhhh Character with 32-bit hex value hhhhhhhh
```
Here’s some examples of regular strings using escape sequences

db>select 'hello
... world';
{'hello
world'}

db>select "hello\nworld";
{'hello
world'}

```
(continues on next page)
```
**556 Chapter 8. Reference**


```
(continued from previous page)
```
db>select 'hello \
... world';
{'hello world'}

db>select 'https://edgedb.com/\
... docs/edgeql/lexical\
... #constants';
{'https://edgedb.com/docs/edgeql/lexical#constants'}

db>select 'hello \\ world';
{'hello \ world'}

db>select 'hello \'world\'';
{"hello'world'"}

db>select 'hello \x77orld';
{'hello world'}

db>select 'hello \u0077orld';
{'hello world'}

Raw strings don’t have any specially interpreted symbols; they contain all the symbols between the quotes exactly as
typed.

db>select r'hello \\ world';
{'hello \\ world'}

db> select r'hello \
... world';
{'hello \
world'}

db> select r'hello
... world';
{'hello
world'}

**Dollar-quoted String Constants**

A special case of raw strings are _dollar-quoted_ strings. They allow using either kind of quote symbols'or"as part
of the string content without the quotes terminating the string. In fact, because the _dollar-quote_ delimiter sequences
can have arbitrary alphanumeric additional fillers, it is always possible to surround any content with _dollar-quotes_ in
an unambiguous manner:

db>select $$hello
... world$$;
{'hello
world'}

db>select $$hello\nworld$$;
{'hello\nworld'}
(continues on next page)

**8.1. EdgeQL 557**


```
(continued from previous page)
```
db>select $$"hello"'world'$$;
{"\"hello\"'world'"}

db>select $a$hello$$world$$$a$;
{'hello$$world$$'}

More specifically, a delimiter:

- Must start with an ASCII letter or underscore
- Has following characters that can be digits 0-9, underscores or ASCII letters

###### 8.1.1.3.2 Bytes

Production rules forbytesliterals:

```
bytes ::= "b'"bytes_content* "'" |'b"' bytes_content* '"'
bytes_content ::= <newline> |ascii |bytes_escapes
ascii ::= <any printable ascii character not preceded by "\">
bytes_escapes ::= <see below for details>
```
Here’s a list of validedgeql:bytes_escapes:

```
Escape Sequence Meaning
\\ Backslash (\)
\' Single quote (‘)
\" Double quote (“)
\b ASCII backspace (\x08)
\f ASCII form feed (\x0C)
\n ASCII newline (\x0A)
\r ASCII carriage return (\x0D)
\t ASCII tabulation (\x09)
\xhh Character with hex value hh
```
###### 8.1.1.3.3 Integers

There are two kinds of integer constants: limited size (int64) and unlimited size (bigint). Unlimited size integer
bigintliterals are similar to a regular integer literals with annsuffix. The production rules are as follows:

```
bigint ::= integer"n"
integer ::= "0" | non_zero digit*
non_zero ::= "1"..."9"
digit ::= "0"..."9"
```
By default all integer literals are interpreted asint64, while an explicit cast can be used to convert them toint16or
int32:

**558 Chapter 8. Reference**


db>select 0;
{0}

db>select 123;
{123}

db>select <int16>456;
{456}

db>select <int32>789;
{789}

Examples ofbigintliterals:

db>select 123n;
{123n}

db>select 12345678901234567890n;
{12345678901234567890n}

###### 8.1.1.3.4 Real Numbers

Just as for integers, there are two kinds of real number constants: limited precision (float64) and unlimited precision
(decimal). Thedecimalconstants have the same lexical structure asfloat64, but with annsuffix:

```
decimal ::= float "n"
float ::= float_wo_dec| float_w_dec
float_wo_dec ::= integer_part exp
float_w_dec ::= integer_part"."decimal_part? exp?
integer_part ::= "0" |non_zero digit*
decimal_part ::= digit+
exp ::= "e" ("+" | "-")?digit+
```
By default all float literals are interpreted asfloat64, while an explicit cast can be used to convert them tofloat32:

db>select 0.1;
{0.1}

db>select 12.3;
{12.3}

db>select 1e3;
{1000.0}

db>select 1.2e-3;
{0.0012}

db>select <float32>12.3;
{12.3}

Examples ofdecimalliterals:

**8.1. EdgeQL 559**


db>select 12.3n;
{12.3n}

db>select 12345678901234567890.12345678901234567890n;
{12345678901234567890.12345678901234567890n}

db>select 12345678901234567890.12345678901234567890e-3n;
{12345678901234567.89012345678901234567890n}

##### 8.1.1.4 Punctuation

EdgeQL uses;as a statement separator. It is idempotent, so multiple repetitions of;don’t have any additional effect.

##### 8.1.1.5 Comments

Comments start with a#character that is not otherwise part of a string literal and end at the end of line. Semantically,
a comment is equivalent to whitespace.

```
comment ::= "#" <any other characters until the end of line>
```
##### 8.1.1.6 Operators

EdgeQL operators listed in order of precedence from lowest to highest:

```
operator
union
if..else
or
and
not
=,!=,?=,?!=
<,>,<=,>=
like,ilike
in,not in
is,is not
+,-,++
*,/,//,%
??
distinct, unary-
^
type cast
array[],str[],json[],bytes[]
detached
```
**560 Chapter 8. Reference**


#### 8.1.2 Evaluation algorithm

EdgeQL is a functional language in the sense that every expression is a composition of one or more queries.

Queries can be _explicit_ , such as aselectstatement, or _implicit_ , as dictated by the semantics of a function, operator or
a statement clause.

An implicitselectsubquery is assumed in the following situations:

- expressions passed as an argument for an aggregate function parameter or operand;
- the right side of the assignment operator (:=) in expression aliases and _shape element declarations_ ;
- the majority of statement clauses.

A nested query is called a _subquery_. Here, the phrase “ _apearing directly in the query_ ” means “appearing directly in
the query rather than in the subqueries”.

A query is evaluated recursively using the following procedure:

1. Make a list of simple paths appearing directly the query. For every path in the list, find all paths which begin
    with the same set reference and treat their longest common prefix as an equivalent set reference.
    Example:

```
select (
User.firstname,
User.friends.firstname,
User.friends.lastname,
Issue.priority.name,
Issue.number,
Status.name
);
```
```
In the above query, the longest common prefixes are:User,User.friends,Issue, andStatus.name.
```
2. Make a _query input list_ of all unique set references which appear directly in the query (including the common
    path prefixes identified above). The set references and path prefixes in this list are called _input set references_ , and
    the sets they represent are called _input sets_. Order this list such that any input references come before any other
    input set reference for which it is a prefix (sorting lexicographically works).
3. Compute a set of _input tuples_.
    - Begin with a set containing a single empty tuple.
    - For each input set reference, we compute a _dependent_ Cartesian product of the input tuple set (X) so far and
       the input setYbeing considered. In this dependent product, we pair each tuplexin the input tuple setX
       with each element of the subset of the input setYcorresponding to the tuplex. (For example, in the above
       example, computing the dependent product of User and User.friends would pair each user with all of their
       friends.)
       (Mathematically,X'= {(x, y) | x X, y f(x)}, iff(x)selects the appropriate subset.)
       The set produced becomes the new input tuple set and we continue down the list.
    - As a caveat to the above, if an input set appears exclusively as an _optional_ argument, it produces pairs with
       a placeholder valueMissinginstead of an empty Cartesian product in the above set. (Mathematically, this
       corresponds to havingf(x) = {Missing}whenever it would otherwise produce an empty set.)
4. Iterate over the set of input tuples, and on every iteration:
    - in the query and its subqueries, replace each input set reference with the corresponding value from the input
       tuple or an empty set if the value isMissing;

**8.1. EdgeQL 561**


- evaluate the query expression in the order of precedence using the following rules:
    **-** subqueries are evaluated recursively from step 1;
    **-** a function or an operator is evaluated in a loop over a Cartesian product of its non-aggregate arguments
       (emptyoptionalarguments are excluded from the product); aggregate arguments are passed as a
       whole set; the results of the invocations are collected to form a single set.
5. Collect the results of all iterations to obtain the final result set.

#### 8.1.3 Shapes

A _shape_ is a powerful syntactic construct that can be used to describe type variants in queries, data ininsertand
updatestatements, and to specify the format of statement output.

Shapes always follow an expression, and are a list of _shape elements_ enclosed in curly braces:

<expr> "{"
<shape_element> [, ...]
"}"

Shape element has the following syntax:

[ "["is <object-type> "]" ] <pointer-spec>

If an optional<object-type>filter is used,<pointer-spec>will only apply to those objects in the<expr>set that
are instances of<object-type>.

<pointer-spec>is one of the following:

- a name of an existing link or property of a type produced by<expr>;
- a declaration of a computed link or property in the form

```
[@]<name> := <ptrexpr>
```
- a _subshape_ in the form

```
<pointer-name>: [ "["is <target-type> "]" ] "{" ... "}"`
```
```
The<pointer-name>is the name of an existing link or property, and<target-type>is an optional object
type that specifies the type of target objects selected or inserted, depending on the context.
```
##### 8.1.3.1 Shaping Query Results

At the end of the day, EdgeQL has two jobs that are similar, yet distinct:

```
1) Express the values that we want computed.
2) Arrange the values into a particular shape that we want.
```
Consider the task of getting “names of users and all of the friends’ names associated with the given user” in a database
defined by the following schema:

typeUser {
required propertyname -> str;
multi linkfriends -> User;
}

**562 Chapter 8. Reference**


typeUser {
requiredname: str;
multifriends: User;
}

If we only concern ourselves with getting the values, then a reasonable solution to this might be:

db>select (User.name, User.friends.name ??'');
{
('Alice', 'Cameron'),
('Alice', 'Dana'),
('Billie','Dana'),
('Cameron',''),
('Dana', 'Alice'),
('Dana', 'Billie'),
('Dana', 'Cameron'),
}

This particular solution is very similar to what one might get using SQL. It’s equivalent to a table with “user name”
and “friend name” columns. It gets the job done, albeit with some redundant repeating of “user names”.

We can improve things a little and reduce the repetition by aggregating all the friend names into an array:

db>select (User.name, array_agg(User.friends.name));
{
('Alice', ['Cameron', 'Dana']),
('Billie', ['Dana']),
('Cameron', []),
('Dana', ['Alice', 'Billie','Cameron']),
}

This achieves a couple of things: it’s easier to see which friends belong to which user and we no longer need the
placeholder''for those users who don’t have friends.

The recommended way to get this information in EdgeDB, however, is to use _shapes_ , because they mimic the structure
of the data and the output:

db>select User {
... name,
... friends: {
... name
... }
... };
{
default::User {
name:'Alice',
friends: {
default::User {name:'Cameron'},
default::User {name:'Dana'},
},
},
default::User {name:'Billie', friends: {default::User {name: 'Dana'}}},
default::User {name:'Cameron', friends: {}},
default::User {
(continues on next page)

**8.1. EdgeQL 563**


(continued from previous page)
name:'Dana',
friends: {
default::User {name:'Alice'},
default::User {name:'Billie'},
default::User {name:'Cameron'},
},
},
}

So far the expression for the data that we wanted was also acceptable for structuring the output, but what if that’s not
the case? Let’s add a condition and only show those users who have friends with either the letter “i” or “o” in their
names:

db>select User {
... name,
... friends: {
... name
... }
... }filter .friends.nameilike '%i%'or .friends.nameilike'%o%';
{
default::User {
name:'Alice',
friends: {
default::User {name:'Cameron'},
default::User {name:'Dana'},
},
},
default::User {
name:'Dana',
friends: {
default::User {name:'Alice'},
default::User {name:'Billie'},
default::User {name:'Cameron'},
},
},
}

Thatfilteris getting a bit bulky, so perhaps we can just factor these flags out as part of the shape’s computed
properties:

db>select User {
... name,
... friends: {
... name
... },
... has_i := .friends.nameilike '%i%',
... has_o := .friends.nameilike '%o%',
... }filter .has_i or.has_o;
{
default::User {
name:'Alice',
friends: {
(continues on next page)

**564 Chapter 8. Reference**


(continued from previous page)
default::User {name:'Cameron'},
default::User {name:'Dana'},
},
has_i: {false,false},
has_o: {true,false},
},
default::User {
name:'Dana',
friends: {
default::User {name:'Alice'},
default::User {name:'Billie'},
default::User {name:'Cameron'},
},
has_i: {true,true, false},
has_o: {false,false,true},
},
}

It looks like this refactoring came at the cost of putting extra things into the output. In this case we don’t want our
intermediate calculations to actually show up in the output, so what can we do? In EdgeDB the output structure is
determined _only_ by the expression appearing in the top-levelselect. This means that we can move our intermediate
calculations into thewithblock:

db>withU := (
... selectUser {
... has_i := .friends.nameilike'%i%',
... has_o := .friends.nameilike'%o%',
... }
... )
...select U {
... name,
... friends: {
... name
... },
... }filter .has_i or.has_o;
{
default::User {
name:'Alice',
friends: {
default::User {name:'Cameron'},
default::User {name:'Dana'},
},
},
default::User {
name:'Dana',
friends: {
default::User {name:'Alice'},
default::User {name:'Billie'},
default::User {name:'Cameron'},
},
},
}

**8.1. EdgeQL 565**


This way we can usehas_iandhas_oin our query without leaking them into the output.

##### 8.1.3.2 General Shaping Rules

In EdgeDB typically all shapes appearing in the top-levelselectshould be reflected in the output. This also applies
to shapes no matter where and how they are nested. Aside from other shapes, this includes nesting in arrays:

db>select array_agg(User {name});
{
[
default::User {name:'Alice'},
default::User {name:'Billie'},
default::User {name:'Cameron'},
default::User {name:'Dana'},
],
}

... or tuples:

db>select enumerate(User {name});
{
(0, default::User {name:'Alice'}),
(1, default::User {name:'Billie'}),
(2, default::User {name:'Cameron'}),
(3, default::User {name:'Dana'}),
}

You can safely access a tuple element and expect the output shape to be intact:

db>select enumerate(User{name}).1;
{
default::User {name:'Alice'},
default::User {name:'Billie'},
default::User {name:'Cameron'},
default::User {name:'Dana'},
}

Accessing array elements or working with slices also preserves output shape and is analogous to usingoffsetand
limitwhen working with sets:

db>select array_agg(User {name})[2];
{default::User {name:'Cameron'}}

##### 8.1.3.3 Losing Shapes

There are some situations where shape information gets completely or partially discarded. Any such operation also
prevents the altered shape from appearing in the output altogether.

In order for the shape to be preserved, the original expression type must be preserved. This means thatunioncan alter
the shape, because the result of aunionis aunion type. So you can still refer to the common properties, but not to
the properties that appeared in the shape.

As mentioned above, sinceunionpotentially alters the expression shape it never preserves output shape, even when
the underlying type wasn’t altered:

**566 Chapter 8. Reference**


db>select User{name}unionUser{name};
{
default::User {id: 7769045a-27bf-11ec-94ea-3f6c0ae59eb3},
default::User {id: 7b42ed20-27bf-11ec-94ea-7700ec77834e},
default::User {id: 7fcedbc4-27bf-11ec-94ea-73dcb6f297a4},
default::User {id: 82f52646-27bf-11ec-94ea-3718ffb8dd15},
default::User {id: 7769045a-27bf-11ec-94ea-3f6c0ae59eb3},
default::User {id: 7b42ed20-27bf-11ec-94ea-7700ec77834e},
default::User {id: 7fcedbc4-27bf-11ec-94ea-73dcb6f297a4},
default::User {id: 82f52646-27bf-11ec-94ea-3718ffb8dd15},
}

Listing several items inside a set{ ... }functions identically to aunionand so will also produce a union type and
remove shape from output.

Another subtle way for a type union to remove the shape from the output is by the??and theif..elseoperators.
Both of them determine the result type as the union of the left and right operands:

db>select <User>{} ?? User {name};
{
default::User {id: 7769045a-27bf-11ec-94ea-3f6c0ae59eb3},
default::User {id: 7b42ed20-27bf-11ec-94ea-7700ec77834e},
default::User {id: 7fcedbc4-27bf-11ec-94ea-73dcb6f297a4},
default::User {id: 82f52646-27bf-11ec-94ea-3718ffb8dd15},
}

Shapes survive array creation (either viaarray_agg()or by using[ ... ]), but they follow the same rules as for
unionfor arrayconcatenation. Basically the element type of the resulting array must be a union type and thus all
shape information is lost:

db>select array_agg(User{name}) ++ array_agg(User{name});
{
[
default::User {id: 7769045a-27bf-11ec-94ea-3f6c0ae59eb3},
default::User {id: 7b42ed20-27bf-11ec-94ea-7700ec77834e},
default::User {id: 7fcedbc4-27bf-11ec-94ea-73dcb6f297a4},
default::User {id: 82f52646-27bf-11ec-94ea-3718ffb8dd15},
default::User {id: 7769045a-27bf-11ec-94ea-3f6c0ae59eb3},
default::User {id: 7b42ed20-27bf-11ec-94ea-7700ec77834e},
default::User {id: 7fcedbc4-27bf-11ec-94ea-73dcb6f297a4},
default::User {id: 82f52646-27bf-11ec-94ea-3718ffb8dd15},
],
}

**Note:** Theforstatement preserves the shape given inside theunionclause, effectively applying the shape to its entire
result.

**8.1. EdgeQL 567**


#### 8.1.4 Paths

A _path expression_ (or simply a _path_ ) represents a set of values that are reachable when traversing a given sequence of
links or properties from some source set.

The result of a path expression depends on whether it terminates with a link or property reference.

```
a) if a path does not end with a property reference, then it represents a unique set of objects reachable from the set
at the root of the path;
b) if a path does end with a property reference, then it represents a list of property values for every element in the
unique set of objects reachable from the set at the root of the path.
```
The syntactic form of a path is:

<expression> <path-step> [ <path-step> ... ]

# where <path-step> is:
<step-direction> <pointer-name>

The individual path components are:

<expression>Any valid expression.

<step-direction>It can be one of the following:

- .for an outgoing link reference
- .<for an incoming or _backlink_ reference
- @for a link property reference

<pointer-name>This must be a valid link or link property name.

#### 8.1.5 Casts

There are different ways that casts appear in EdgeQL.

##### 8.1.5.1 Explicit Casts

A type cast expression converts the specified value to another value of the specified type:

"<" <type> ">" <expression>

The<type>must be a valid _type expression_ denoting a non-abstract scalar or a container type.

For example, the following expression casts an integer value into a string:

db>select <str>10;
{"10"}

See thetype cast operatorsection for more information on type casting rules.

You can cast a UUID into an object:

db>select <Hero><uuid>'01d9cc22-b776-11ed-8bef-73f84c7e91e7';
{default::Hero {id: 01d9cc22-b776-11ed-8bef-73f84c7e91e7}}

If you try to cast a UUID that no object of the type has as itsidproperty, you’ll get an error:

**568 Chapter 8. Reference**


db>select <Hero><uuid>'aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa';
edgedb error: CardinalityViolationError:'default::Hero'withid 'aaaaaaaa-aaaa-aaaa-
˓→aaaa-aaaaaaaaaaaa' doesnotexist

##### 8.1.5.2 Assignment Casts

_Assignment casts_ happen when inserting new objects. Numeric types will often be automatically cast into the specific
type corresponding to the property they are assigned to. This is to avoid extra typing when dealing with numeric value
using fewer bits:

# Automatically cast a literal 42 (which is int64
# by default) into an int16 value.
insert MyObject {
int16_val := 42
};

If _assignment_ casting is supported for a given pair of types, _explicit_ casting of those types is also supported.

##### 8.1.5.3 Implicit Casts

_Implicit casts_ happen automatically whenever the value type doesn’t match the expected type in an expression. This is
mostly supported for numeric casts that don’t incur any potential information loss (in form of truncation), so typically
from a less precise type, to a more precise one. Theint64tofloat64is a notable exception, which can suffer from
truncation of significant digits for very large integer values. There are a few scenarios when _implicit casts_ can occur:

```
1) Passing arguments that don’t match exactly the types in the function signature:
```
```
db>withx := <float32>12.34
...selectmath::ceil(x);
{13}
```
```
The functionmath::ceil()only takesint64,float64,bigint, ordecimalas its argument. So thefloat32
value will be implicitly cast into afloat64in order to match a valid signature.
2) Using operands that don’t match exactly the types in the operator signature (this works the same way as for
functions):
```
```
db>select1 + 2.3;
{3.3}
```
```
The operator+is defined only for operands of the same type, so in the expression above theint64value 1 is
implicitly cast into afloat64in order to match the other operand and produce a valid signature.
3) Mixing different numeric types in a set:
```
```
db>select{1, 2.3, <float32>4.5} isfloat64;
{true, true, true}
```
```
All elements in a set have to be of the same type, so the values are cast intofloat64as that happens to be the
common type to which all the set elements can be implicitly cast. This would work out the same way ifunion
was used instead:
```
```
db>select(1 union 2.3union <float32>4.5)is float64;
{true, true, true}
```
**8.1. EdgeQL 569**


If _implicit_ casting is supported for a given pair of types, _assignment_ and _explicit_ casting of those types is also supported.

##### 8.1.5.4 Casting Table

**Note:** The UUID-to-object cast is only available in EdgeDB 3.0+.

```
from
\
to
```
```
jsonstr float32float64int16int32int64bigintdecimalboolbytesuuiddatetimedurationlocal_datelocal_datetimelocal_timeob-
ject
```
```
json <> <> <> <> <> <> <> <> <> <> <> <> <> <> <>
str <> <> <> <> <> <> <> <> <> <> <> <> <> <> <>
float32<> <> impl <> <>* <>* <> <>
float64<> <> := <> <>* <>* <> <>
int16<> <> impl impl impl impl impl impl
int32<> <> impl <> impl impl impl
int64<> <> := impl := := impl impl
bigint impl
decimal<> <> <> <> <> <> <> <>
bool<> <>
bytes
uuid<> <> <>
datetime<> <>
duration<> <>
local_date<> <> <>
local_datetime<> <> <> <>
local_time<> <>
ob-
ject
```
- <>- can be cast explicitly
- :=- assignment cast is supported
- impl- implicit cast is supported
- *- When casting a float type to an integer type, the fractional value naturally cannot be preserved after the cast.
    When executing this cast, we round to the nearest integer, rounding ties to the nearest even (e.g., 1.5 is rounded
    up to 2; 2.5 is also rounded to 2).

#### 8.1.6 Function calls

EdgeDB provides a number of functions in the _standard library_. It is also possible for users to _define their own_ functions.

The syntax for a function call is as follows:

<function_name> "(" [<argument> [, <argument>, ...]] ")"

# where <argument> is:

<expr> | <identifier> := <expr>

**570 Chapter 8. Reference**


Here<function_name>is a possibly qualified name of a function, and<argument>is an _expression_ optionally
prefixed with an argument name and the assignment operator (:=) for _named only_ arguments.

For example, the following computes the length of a string'foo':

db>select len('foo');
{3}

And here’s an example of using a _named only_ argument to provide a default value:

db>select array_get(['hello','world'], 10,default:= 'n/a');
{'n/a'}

```
See also
Schema > Functions
SDL > Functions
DDL > Functions
Introspection > Functions
Cheatsheets > Functions
Tutorial > Advanced EdgeQL > User-Defined Functions
```
#### 8.1.7 Cardinality

The number of items in a set is known as its **cardinality**. A set with a cardinality of zero is referred to as an **empty set**.
A set with a cardinality of one is known as a **singleton**.

##### 8.1.7.1 Terminology

The term **cardinality** is used to refer to both the _exact_ number of elements in a given set or a _range_ of possible values.
Internally, EdgeDB tracks 5 different cardinality ranges:Empty(zero elements),One(a singleton set),AtMostOne
(zero or one elements),AtLeastOne(one or more elements), andMany(any number of elements).

EdgeDB uses this information to statically check queries for validity. For instance, when assigning to arequired
multilink, the value being assigned in question _must_ have a cardinality ofOneorAtLeastOne(as empty sets are not
permitted).

##### 8.1.7.2 Functions and operators

It’s often useful to think of EdgeDB functions/operators as either _element-wise_ or _aggregate_. Element-wise operations
are applied to _each item_ in a set. Aggregate operations operate on sets _as a whole_.

**Note:** This is a simplification, but it’s a useful mental model when getting started with EdgeDB.

**8.1. EdgeQL 571**


###### 8.1.7.2.1 Aggregate operations

An example of an aggregate function iscount(). It returns the number of elements in a given set. Regardless of the
size of the input set, the result is a singleton integer.

db>select count('hello');
{1}
db>select count({'this','is','a', 'set'});
{4}
db>select count(<str>{});
{0}

Another example isarray_agg(), which converts a _set_ of elements into a singleton array.

db>select array_agg({1,2,3});
{[1, 2, 3]}

###### 8.1.7.2.2 Element-wise operations

By contrast, thelen()function is element-wise; it computes the length of each string inside a set of strings; as such,
it converts a set ofstrinto an equally-sized set ofint64.

db>select len('hello');
{5}
db>select len({'hello', 'world'});
{5, 5}

###### 8.1.7.2.3 Cartesian products

In case of element-wise operations that accept multiple arguments, the operation is applied to a cartesian product of all
the input sets.

db>select {'aaa','bbb'} ++ {'ccc', 'ddd'};
{'aaaccc', 'aaaddd', 'bbbccc','bbbddd'}
db>select {true,false} or{true,false};
{true, true,true,false}

By extension, if any of the input sets are empty, the result of applying an element-wise function is also empty. In effect,
when EdgeDB detects an empty set, it “short-circuits” and returns an empty set without applying the operation.

db>select {} ++ {'ccc', 'ddd'};
{}
db>select {}or {true, false};
{}

**Note:** Certain functions and operators avoid this “short-circuit” behavior by marking their inputs as _optional_. A
notable example of an operator with optional inputs is the??operator.

db>select <str>{} ??'default';
{'default'}

**572 Chapter 8. Reference**


###### 8.1.7.2.4 Per-input cardinality

Ultimately, the distinction between “aggregate vs element-wise” operations is a false one. Consider theinoperation.

db>select {1, 4}in {1, 2, 3};
{true, false}

This operator takes two inputs. If it was “element-wise” we would expect the cardinality of the above operation to the
cartesian product of the input cardinalities:2 x 3 = 6. It it was aggregate, we’d expect a singleton output.

Instead, the cardinality is 2. This operator is element-wise with respect to the first input and aggregate with respect to the
second. The “element-wise vs aggregate” concept isn’t determined on a per-function/per-operator basis; it determined
on a per-input basis.

###### 8.1.7.2.5 Type qualifiers

When defining functions, all inputs are element-wise by default. Theset of _type qualifier_ is used to designate an
input as _aggregate_. Currently this modifier is not supported for user-defined functions, but it is used by certain standard
library functions.

Similarly theoptionalqualifier marks the input as optional; an operation will be executed is an optional input is
empty, whereas passing an empty set for a “standard” (non-optional) element-wise input will always result in an empty
set.

Similarly, the _output_ of a function _can be annotated_ withset ofandoptionalqualifiers.

###### 8.1.7.2.6 Cardinality computation

To compute the number of times a function/operator will be invoked, take the cardinality of each input and apply the
following transformations, based on the type qualifier (or lack thereof) for each:

element-wise: N -> N
optional: N -> max(1, N)
aggregate: N -> 1

The ultimate cardinality of the result is the union of the results of each invokation; as such, it depends on the _values
returned_ by each invokation.

#### 8.1.8 Select

```
eql-statement
eql-haswith
index order filter select offset limit with then asc desc first last empty
```
select–retrieve or compute a set of values.

[with <with-item> [, ...] ]

select <expr>

[filter <filter-expr> ]

```
(continues on next page)
```
**8.1. EdgeQL 573**


```
(continued from previous page)
```
[order by <order-expr> [direction] [then...] ]

[offset <offset-expr> ]

[limit <limit-expr> ] ;

filter <filter-expr>The optionalfilterclause, where<filter-expr>is any expression that has a result of
typebool. The condition is evaluated for every element in the set produced by theselectclause. The result of
the evaluation of thefilterclause is a set of boolean values. If at least one value in this set istrue, the input
element is included, otherwise it is eliminated from the output.

order by <order-expr> [direction] [then ...]The optionalorder byclause has this general form:

```
order by
<order-expr> [asc| desc] [empty{ first|last } ]
[then... ]
```
```
Theorder byclause produces a result set sorted according to the specified expression or expressions, which
are evaluated for every element of the input set.
If two elements are equal according to the leftmost expression , they are compared according to the next expression
and so on. If two elements are equal according to all expressions, the resulting order is undefined.
Each expression can be an arbitrary expression that results in a value of an orderable type. Primitive types are
orderable, object types are not. Additionally, the result of each expression must be an empty set or a singleton.
Using an expression that may produce more elements is a compile-time error.
An optionalascordesckeyword can be added after any expression. If not specifiedascis assumed by default.
Ifempty lastis specified, then input values that produce an empty set when evaluating an expression are sorted
after all other values; ifempty firstis specified, then they are sorted before all other values. If neither is
specified,empty firstis assumed whenascis specified or implied, andempty lastwhendescis specified.
```
offset <offset-expr>The optionaloffsetclause, where<offset-expr>is a _singleton expression_ of an integer
type. This expression is evaluated once and its result is used to skip the first _element-count_ elements of the input
set while producing the output. If _element-count_ evaluates to an empty set, it is equivalent tooffset 0, which is
equivalent to omitting theoffsetclause. If _element-count_ evaluates to a value that is larger then the cardinality
of the input set, an empty set is produced as the result.

limit <limit-expr>The optionallimitclause, where<limit-expr>is a _singleton expression_ of an integer type.
This expression is evaluated once and its result is used to include only the first _element-count_ elements of the
input set while producing the output. If _element-count_ evaluates to an empty set, it is equivalent to specifying
nolimitclause.

##### 8.1.8.1 Description

selectretrieves or computes a set of values. The data flow of aselectblock can be conceptualized like this:

with moduleexample

# select clause
select
<expr> # compute a set of things

# optional clause
(continues on next page)

**574 Chapter 8. Reference**


```
(continued from previous page)
```
filter
<expr> # filter the computed set

# optional clause
order by
<expr> # define ordering of the filtered set

# optional clause
offset
<expr> # slice the filtered/ordered set

# optional clause
limit
<expr> # slice the filtered/ordered set

Please note that theorder byclause defines ordering that can only be relied upon if the resulting set is not used in any
other operation.select,offsetandlimitclauses are the only exception to that rule as they preserve the inherent
ordering of the underlying set.

The first clause isselect. It indicates thatfilter,order by,offset, orlimitclauses may follow an expres-
sion, i.e. it makes an expression into aselectstatement. Without any of the optional clauses a(select Expr)is
completely equivalent toExprfor any expressionExpr.

Consider an example using thefilteroptional clause:

with moduleexample
select User {
name,
owned:= (select
User.<owner[isIssue] {
number,
body
}
)
}
filter User.namelike'Alice%';

The above example retrieves a single user with a specific name. The fact that there is only one such user is a detail
that can be well- known and important to the creator of the database, but otherwise non- obvious. However, forcing the
cardinality to be at most 1 by using thelimitclause ensures that a set with a single object or{}is returned. This way
any further code that relies on the result of this query can safely assume there’s only one result available.

with moduleexample
select User {
name,
owned:= (select
User.<owner[isIssue] {
number,
body
}
)
}
filter User.namelike'Alice%'
limit1;

**8.1. EdgeQL 575**


Next example makes use oforder byandlimitclauses:

with moduleexample
select Issue {
number,
body,
due_date
}
filter
exists Issue.due_date
and
Issue.status.name = 'Open'
order by
Issue.due_date
limit3;

The above query retrieves the top 3 open Issues with the closest due date.

##### 8.1.8.2 Filter

Thefilterclause cannot affect anything aggregate-like in the precedingselectclause. This is due to howfilter
clause works. It can be conceptualized as a function likefilter($input, set of $cond), where the$input
represents the value of the preceding clause, while the$condrepresents the filtering condition expression. Consider
the following:

with moduleexample
select count(User)
filter User.namelike'Alice%';

The above can be conceptualized as:

with moduleexample
select _filter(
count(User),
User.namelike'Alice%'
);

In this form it is more apparent thatUseris aset ofargument (ofcount()), whileUser.name like'Alice%'is
also aset ofargument (offilter). So the symbolUserin these two expressions exists in 2 parallel scopes. Contrast
it with:

# This will actually only count users whose name starts with
#'Alice'.

with moduleexample
select count(
(select User
filter User.namelike'Alice%')
);

# which can be represented as:
with moduleexample
select count(
(continues on next page)

**576 Chapter 8. Reference**


(continued from previous page)
_filter(User,
User.namelike'Alice%')
);

##### 8.1.8.3 Clause signatures

Here is a summary of clauses that can be used withselect:

- _A_ filterset of _B_
- _A_ order byset of _B_
- set of _A_ offsetset of _B_
- set of _A_ limitset of _B_

```
See also
EdgeQL > Select
Cheatsheets > Selecting data
```
#### 8.1.9 Insert

```
eql-statement
eql-haswith
```
insert– create a new object in a database

[with <with-spec> [ , ... ] ]
insert <expression> [ <insert-shape> ]
[unless conflict
[on <property-expr> [else<alternative> ] ]
] ;

##### 8.1.9.1 Description

insertinserts a new object into a database.

When evaluating aninsertstatement, _expression_ is used solely to determine the _type_ of the inserted object and is not
evaluated in any other way.

If a value for a _required_ link is evaluated to an empty set, an error is raised.

It is possible to insert multiple objects by putting theinsertinto aforstatement.

See _Usage of for statement_ for more details.

withAlias declarations.

```
Thewithclause allows specifying module aliases as well as expression aliases that can be referenced by the
updatestatement. See With block for more information.
```
<expression>An arbitrary expression returning a set of objects to be updated.

**8.1. EdgeQL 577**


```
insert <expression>
[ "{" <link> := <insert-value-expr> [, ...] "}" ]
```
unless conflict [ on <property-expr> ]

```
index unless conflict
Handler of conflicts.
This clause allows to handle specific conflicts arising during execution ofinsertwithout producing an error.
If the conflict arises due to exclusive constraints on the properties specified by property-expr , then instead of
failing with an error theinsertstatement produces an empty set (or an alternative result).
The exclusive constraint on<property-expr>cannot be defined on a parent type.
The specified property-expr may be either a reference to a property (or link) or a tuple of references to properties
(or links). Although versions prior to 2.10 do not supportunless conflicton multi properties , 2.10 adds
support for these.
A caveat, however, is thatunless conflictwill not prevent conflicts caused between multiple DML operations
in the same query; inserting two conflicting objects (through use offoror simply with twoinsertstatements)
will cause a constraint error.
Example:
```
```
insert User { email :='user@example.org' }
unless conflict on.email
```
```
insert User {first :='Jason',last:= 'Momoa'}
unless conflict on(.first, .last)
```
else <alternative>Alternative result in case of conflict.

```
This clause can only appear afterunless conflictclause. Any valid expression can be specified as the al-
ternative. When a conflict arises, the result of theinsertbecomes the alternative expression (instead of the
default{}).
In order to refer to the conflicting object in the alternative expression, the name used in theinsertmust be used
(see example below ).
```
##### 8.1.9.2 Outputs

The result of aninsertstatement used as an _expression_ is a singleton set containing the inserted object.

##### 8.1.9.3 Examples

Here’s a simple example of aninsertstatement creating a new user:

with moduleexample
insert User {
name :='Bob Johnson'
};

insertis not only a statement, but also an expression and as such is has a value of the set of objects that has been
created.

**578 Chapter 8. Reference**


with moduleexample
insert Issue {
number :=' 100 ',
body :='Fix errors in insert',
owner := (
selectUser filterUser.name ='Bob Johnson'
)
};

It is possible to create nested objects in a singleinsertstatement as an atomic operation.

with moduleexample
insert Issue {
number :=' 101 ',
body :='Nested insert',
owner := (
insertUser {
name :='Nested User'
}
)
};

The above statement will create a newIssueas well as a newUseras the owner of theIssue. It will also return the
newIssuelinked to the newUserif the statement is used as an expression.

It is also possible to create new objects based on some existing data either provided as an explicit list (possibly auto-
matically generated by some tool) or a query. Aforstatement is the basis for this use-case andinsertis simply the
expression in theunionclause.

# example of a bulk insert of users based on explicitly provided
# data
with moduleexample
forxin {'Alice','Bob','Carol','Dave'}
union(insertUser {
name := x
});

# example of a bulk insert of issues based on a query
with
module example,
Elvis := (select Userfilter .name ='Elvis'),
Open := (select Statusfilter .name ='Open')

forQin (select Userfilter .nameilike'A%')

union(insertIssue {
name := Q.name +'access problem',
body :='This user was affected by recent system glitch',
owner := Elvis,
status := Open
});

There’s an important use-case where it is necessary to either insert a new object or update an existing one identified

**8.1. EdgeQL 579**


with some key. This is what theunless conflictclause allows:

with modulepeople
select (
insert Person {
name := "Łukasz Langa", is_admin :=true
}
unless conflict on.name
else(
updatePerson
set{ is_admin :=true}
)
) {
name,
is_admin
};

**Note:** Statements in EdgeQL represent an atomic interaction with the database. From the point of view of a state-
ment all side-effects (such as database updates) happen after the statement is executed. So as far as each statement is
concerned, it is some purely functional expression evaluated on some specific input (database state).

```
See also
EdgeQL > Insert
Cheatsheets > Inserting data
```
#### 8.1.10 Update

```
eql-statement
eql-haswith
```
update– update objects in a database

[with <with-item> [, ...] ]

update <selector-expr>

[filter <filter-expr> ]

set<shape> ;

updatechanges the values of the specified links in all objects selected by _update-selector-expr_ and, optionally, filtered
by _filter-expr_.

withAlias declarations.

```
Thewithclause allows specifying module aliases as well as expression aliases that can be referenced by the
updatestatement. See With block for more information.
```
update <selector-expr>An arbitrary expression returning a set of objects to be updated.

filter <filter-expr>An expression of typeboolused to filter the set of updated objects.

```
<filter-expr>is an expression that has a result of typebool. Only objects that satisfy the filter expression
will be updated. See the description of thefilterclause of theselectstatement for more information.
```
**580 Chapter 8. Reference**


set <shape>A shape expression with the new values for the links of the updated object. There are three possible
assignment operations permitted within thesetshape:

```
set{ <field> := <update-expr> [, ...] }
```
```
set{ <field> += <update-expr> [, ...] }
```
```
set{ <field> -= <update-expr> [, ...] }
```
```
The most basic assignment is the:=, which just sets the<field>to the specified<update-expr>. The+=
and-=either add or remove the set of values specified by the<update-expr>from the current value of the
<field>.
```
##### 8.1.10.1 Output

On successful completion, anupdatestatement returns the set of updated objects.

##### 8.1.10.2 Examples

Here are a couple of examples of theupdatestatement with simple assignments using:=:

# update the user with the name'Alice Smith'
with moduleexample
update User
filter .name ='Alice Smith'
set{
name :='Alice J. Smith'
};

# update all users whose name is 'Bob'
with moduleexample
update User
filter .namelike'Bob%'
set{
name := User.name ++'*'
};

For usage of+=and-=consider the followingPosttype:

# ... Assume some User type is already defined
typePost {
required propertytitle -> str;
required propertybody -> str;
# A "tags" property containing a set of strings
multi propertytags -> str;
linkauthor -> User;
}

# ... Assume some User type is already defined
typePost {
requiredtitle: str;
requiredbody: str;
(continues on next page)

**8.1. EdgeQL 581**


(continued from previous page)
# A "tags" property containing a set of strings
multitags: str;
author: User;
}

The following queries add or remove tags from some user’s posts:

with moduleexample
update Post
filter .author.name ='Alice Smith'
set{
# add tags
tags += {'example', 'edgeql'}
};

with moduleexample
update Post
filter .author.name ='Alice Smith'
set{
# remove a tag, if it exist
tags -='todo'
};

The statementfor <x> in <expr>allows to express certain bulk updates more clearly. See _Usage of for statement_
for more details.

```
See also
EdgeQL > Update
Cheatsheets > Updating data
```
### 8.1.11 Delete

```
eql-statement
eql-haswith
```
delete– remove objects from a database.

[with <with-item> [, ...] ]

delete <expr>

[filter <filter-expr> ]

[order by <order-expr> [direction] [then...] ]

[offset <offset-expr> ]

[limit <limit-expr> ] ;

withAlias declarations.

**582 Chapter 8. Reference**


```
Thewithclause allows specifying module aliases as well as expression aliases that can be referenced by the
deletestatement. See With block for more information.
```
delete ...The entiredelete ...statement is syntactic sugar fordelete (select ...). Therefore, the base
<expr>and the followingfilter,order by,offset, andlimitclauses shape the set to be deleted the same
way an explicitselectwould.

#### 8.1.11.1 Output

On successful completion, adeletestatement returns the set of deleted objects.

#### 8.1.11.2 Examples

Here’s a simple example of deleting a specific user:

with moduleexample
delete User
filter User.name ='Alice Smith';

And here’s the equivalentdelete (select ...)statement:

with moduleexample
delete (selectUser
filterUser.name ='Alice Smith');

```
See also
EdgeQL > Delete
Cheatsheets > Deleting data
```
### 8.1.12 For

```
eql-statement
eql-haswith
index for union filter order offset limit
```
for–compute a union of subsets based on values of another set

[with <with-item> [, ...] ]

for<variable>in <iterator-expr>

union<output-expr> ;

for <variable> in <iterator-expr>Theforclause has this general form:

```
for<variable>in <iterator-expr>
```
```
where <iterator-expr> is a literal , a function call , a set constructor , a path , or any parenthesized expression
or statement.
```
union <output-expr>Theunionclause of theforstatement has this general form:

**8.1. EdgeQL 583**


```
union<output-expr>
```
```
Here,<output-expr>is an arbitrary expression that is evaluated for every element in a set produced by evalu-
ating theforclause. The results of the evaluation are appended to the result set.
```
#### 8.1.12.1 Usage offorstatement

forstatement has some powerful features that deserve to be considered in detail separately. However, the common
core is thatforiterates over elements of some arbitrary expression. Then for each element of the iterator some set is
computed and combined via aunionwith the other such computed sets.

The simplest use case is when the iterator is given by a set expression and it follows the general form offor x in A
...:

with moduleexample
# the iterator is an explicit set of tuples, so x is an
# element of this set, i.e. a single tuple
forxin {
(name :='Alice', theme :='fire'),
(name :='Bob', theme := 'rain'),
(name :='Carol', theme :='clouds'),
(name :='Dave', theme := 'forest')
}
# typically this is used with an INSERT, DELETE or UPDATE
union(
insert
User {
name := x.name,
theme := x.theme,
}
);

Sincexis an element of a set it is guaranteed to be a non-empty singleton in all of the expressions used by theunion
and later clauses offor.

Another variation this usage offoris a bulkupdate. There are cases when a bulk update involves a lot of external data
that cannot be derived from the objects being updated. That is a good use-case when aforstatement is appropriate.

# Here's an example of an update that is awkward to
# express without the use of FOR statement
with moduleexample
update User
filter .namein {'Alice','Bob', 'Carol', 'Dave'}
set{
theme :='red' if .name ='Alice'else
'star' if .name ='Bob' else
'dark' if .name ='Carol'else
'strawberry'
};

# Using a FOR statement, the above update becomes simpler to
# express or review for a human.
with moduleexample
(continues on next page)

**584 Chapter 8. Reference**


```
(continued from previous page)
```
forxin {
(name :='Alice', theme :='red'),
(name :='Bob', theme := 'star'),
(name :='Carol', theme :='dark'),
(name :='Dave', theme := 'strawberry')
}
union(
update User
filter .name = x.name
set{
theme := x.theme
}
);

When updating data that mostly or completely depends on the objects being updated there’s no need to use thefor
statement and it is not advised to use it for performance reasons.

with moduleexample
update User
filter .namein {'Alice','Bob', 'Carol', 'Dave'}
set{
theme :='halloween'
};

# The above can be accomplished with a for statement,
# but it is not recommended.
with moduleexample
forxin {'Alice','Bob','Carol','Dave'}
union(
update User
filter .name = x
set{
theme :='halloween'
}
);

Another example of using aforstatement is working with link properties. Specifying the link properties either at
creation time or in a later step with an update is often simpler with aforstatement helping to associate the link target
to the link property in an intuitive manner.

# Expressing this without for statement is fairly tedious.
with
module example,
U2 := User
forxin {
(
name :='Alice',
friends := [('Bob','coffee buff'),
('Carol', 'dog person')]
),
(
name :='Bob',
(continues on next page)

**8.1. EdgeQL 585**


(continued from previous page)
friends := [('Alice', 'movie buff'),
('Dave', 'cat person')]
)
}
union(
update User
filter .name = x.name
set{
friends := assert_distinct(
(
forfin array_unpack(x.friends)
union(
selectU2 {@nickname := f.1}
filterU2.name = f.0
)
)
)
}
);

```
See also
EdgeQL > For
```
### 8.1.13 Group

```
eql-statement
eql-haswith
index group using by
```
**Note:** Thegroupstatement is only available in EdgeDB 2.0 or later.

group–partition a set into subsets based on one or more keys

[with <with-item> [, ...] ]

group[<alias> := ] <expr>

[using <using-alias> := <expr>, [, ...] ]

by <grouping-element>, ... ;

# where a <grouping-element> is one of

```
<ref-or-list>
{ <grouping-element>, ... }
ROLLUP( <ref-or-list>, ... )
CUBE( <ref-or-list>, ... )
```
```
(continues on next page)
```
**586 Chapter 8. Reference**


```
(continued from previous page)
```
# where a <ref-or-list> is one of

```
()
<grouping-ref>
( <grouping-ref>, ... )
```
# where a <grouping-ref> is one of

```
<using-alias>
.<field-name>
```
group <expr>Thegroupclause sets up the input set that will be operated on.

```
Much like inselectit is possible to define an ad-hoc alias at this stage to make referring to the starting set
concisely.
```
using <using-alias> := <expr>Theusingclause defines one or more aliases which can then be used as part
of the grouping key.
If thebyclause only refers to.<field-name>theusingclause is optional.

by <grouping-element>Thebyclause sepecifies which parameters will be used to partition the starting set.

```
There are only two basic components for defining<grouping-element>: references to<using-alias>de-
fined in theusingclause or by references to the short-path format of.<field-name>. The.<field-name>
has to refer to properties or links immediately present on the type of starting set.
The basic building blocks can also be combined by using parentheses( )to indicate that partitioning will happen
based on several parameters at once.
It is also possible to specify grouping sets , which are denoted using curly braces{ }. The results will contain
different partitioning based on each of the grouping set elements. When there are multiple top-level grouping-
elements then the cartesian product of them is taken to determine the grouping set. Thusa, {b, c}is equivalent
to{(a, b), (a, c)}grouping sets.
ROLLUPandCUBEare a shorthand to specify particular grouping sets.ROLLUPgroups by all prefixes of a list
of elements, soROLLUP (a, b, c)is equivalent to{(), (a), (a, b), (a, b, c)}.CUBEgroups by all
elements of the power set, soCUBE (a, b)is equivalent to{(), (a), (b), (a, b)}.
```
#### 8.1.13.1 Output

Thegroupstatement partitions a starting set into subsets based on some specified parameters. The output is organized
into a set of _free objects_ of the following structure:

{
"key": { <using-alias> := <value> [, ...] },
"grouping": <setof keys used ingrouping>,
"elements": <the subset matching to the key>,
}

"key"The"key"contains another _free object_ , which contains all the aliases or field names used as the key together
with the specific values these parameters take for this particular subset.

"grouping"The"grouping"contains astrset of all the names of the parameters used as the key for this particular
subset. This is especially useful when using grouping sets and the parameters used in the key are not the same
for all partitionings.

**8.1. EdgeQL 587**


"elements"The"elements"contains the actual subset of values that match the"key".

#### 8.1.13.2 Examples

Here’s a simple example without using any aggregation or any further processing:

db>groupMovie {title} by.release_year;
{
{
key: {release_year: 2016},
grouping: {'release_year'},
elements: {
default::Movie {title: 'Captain America: Civil War'},
default::Movie {title: 'Doctor Strange'},
},
},
{
key: {release_year: 2017},
grouping: {'release_year'},
elements: {
default::Movie {title: 'Spider-Man: Homecoming'},
default::Movie {title: 'Thor: Ragnarok'},
},
},
{
key: {release_year: 2018},
grouping: {'release_year'},
elements: {default::Movie {title:'Ant-Man and the Wasp'}},
},
{
key: {release_year: 2019},
grouping: {'release_year'},
elements: {default::Movie {title:'Spider-Man: No Way Home'}},
},
{
key: {release_year: 2021},
grouping: {'release_year'},
elements: {default::Movie {title:'Black Widow'}},
},
...
}

Or we can group by an expression instead, such as whether the title starts with a vowel or not:

db>with
... # Apply the group query only to more recent movies
... M := (selectMovie filter.release_year > 2015)
...groupM {title}
...usingvowel := re_test('(?i)^[aeiou]', .title)
...by vowel;
{
{
key: {vowel:false},
(continues on next page)

**588 Chapter 8. Reference**


(continued from previous page)
grouping: {'vowel'},
elements: {
default::Movie {title: 'Thor: Ragnarok'},
default::Movie {title: 'Doctor Strange'},
default::Movie {title: 'Spider-Man: Homecoming'},
default::Movie {title: 'Captain America: Civil War'},
default::Movie {title: 'Black Widow'},
default::Movie {title: 'Spider-Man: No Way Home'},
},
},
{
key: {vowel:true},
grouping: {'vowel'},
elements: {default::Movie {title:'Ant-Man and the Wasp'}},
},
}

It is also possible to group scalars instead of objects, in which case you need to define an ad-hoc alias to refer to the
scalar set in order to specify how it will be grouped:

db>with
... # Apply the group query only to more recent movies
... M := (selectMovie filter.release_year > 2015)
...groupT := M.title
...usingvowel := re_test('(?i)^[aeiou]', T)
...by vowel;
{
{
key: {vowel:false},
grouping: {'vowel'},
elements: {
'Captain America: Civil War',
'Doctor Strange',
'Spider-Man: Homecoming',
'Thor: Ragnarok',
'Spider-Man: No Way Home',
'Black Widow',
},
},
{
key: {vowel:true},
grouping: {'vowel'},
elements: {'Ant-Man and the Wasp'}
},
}

Often the results ofgroupare immediately used in aselectstatement to provide some kind of analytical results:

db>with
... # Apply the group query only to more recent movies
... M := (selectMovie filter.release_year > 2015),
... groups := (
(continues on next page)

**8.1. EdgeQL 589**


```
(continued from previous page)
```
... groupM {title}
... usingvowel := re_test('(?i)^[aeiou]', .title)
... by vowel
... )
...select groups {
... starts_with_vowel := .key.vowel,
... count := count(.elements),
... mean_title_length :=
... round(math::mean(len(.elements.title)))
... };
{
{starts_with_vowel: false, count: 6, mean_title_length: 18},
{starts_with_vowel: true, count: 1, mean_title_length: 20},
}

It’s possible to group by more than one parameter. For example, we can add the release decade to whether thetitle
starts with a vowel:

db>with
... # Apply the group query only to more recent movies
... M := (selectMovie filter.release_year > 2015),
... groups := (
... groupM {title}
... using
... vowel := re_test('(?i)^[aeiou]', .title),
... decade := .release_year // 10
... by vowel, decade
... )
...select groups {
... key := .key {vowel, decade},
... count := count(.elements),
... mean_title_length :=
... math::mean(len(.elements.title))
... };
{
{
key: {vowel:false, decade: 201},
count: 5,
mean_title_length: 19.8,
},
{
key: {vowel:false, decade: 202},
count: 1,
mean_title_length: 11,
},
{
key: {vowel:true, decade: 201},
count: 1,
mean_title_length: 20
},
}

Having more than one grouping parameter opens up the possibility to using _grouping sets_ to see the way grouping

**590 Chapter 8. Reference**


parameters interact with the analytics we’re gathering:

db>with
... # Apply the group query only to more recent movies
... M := (selectMovie filter.release_year > 2015),
... groups := (
... groupM {title}
... using
... vowel := re_test('(?i)^[aeiou]', .title),
... decade := .release_year // 10
... by CUBE(vowel, decade)
... )
...select groups {
... key := .key {vowel, decade},
... grouping,
... count := count(.elements),
... mean_title_length :=
... (math::mean(len(.elements.title)))
... }order byarray_agg(.grouping);
{
{
key: {vowel: {}, decade: {}},
grouping: {},
count: 7,
mean_title_length: 18.571428571428573,
},
{
key: {vowel: {}, decade: 202},
grouping: {'decade'},
count: 1,
mean_title_length: 11,
},
{
key: {vowel: {}, decade: 201},
grouping: {'decade'},
count: 6,
mean_title_length: 19.833333333333332,
},
{
key: {vowel:true, decade: {}},
grouping: {'vowel'},
count: 1,
mean_title_length: 20,
},
{
key: {vowel:false, decade: {}},
grouping: {'vowel'},
count: 6,
mean_title_length: 18.333333333333332,
},
{
key: {vowel:false, decade: 201},
grouping: {'vowel', 'decade'},
(continues on next page)

**8.1. EdgeQL 591**


(continued from previous page)
count: 5,
mean_title_length: 19.8,
},
{
key: {vowel:true, decade: 201},
grouping: {'vowel', 'decade'},
count: 1,
mean_title_length: 20,
},
{
key: {vowel:false, decade: 202},
grouping: {'vowel', 'decade'},
count: 1,
mean_title_length: 11,
},
}

```
See also
EdgeQL > Group
```
### 8.1.14 With block

```
index alias module
```
keyword with
Thewithblock in EdgeQL is used to define aliases.
The expression aliases are evaluated in the lexical scope they appear in, not the scope where their alias is used.
This means that refactoring queries using aliases must be done with care so as not to alter the query semantics.

#### 8.1.14.1 Specifying a module

keyword module
Used inside awithblock to specify module names.

One of the more basic and common uses of thewithblock is to specify the default module that is used in a query.
with module <name>construct indicates that whenever an identifier is used without any module specified explicitly,
the module will default to<name>and then fall back to built-ins fromstdmodule.

The following queries are exactly equivalent:

with moduleexample
select User {
name,
owned:= (select
User.<owner[isIssue] {
number,
body
}
)
}
(continues on next page)

**592 Chapter 8. Reference**


```
(continued from previous page)
```
filter User.namelike'Alice%';

select example::User {
name,
owned:= (select
example::User.<owner[isexample::Issue] {
number,
body
}
)
}
filter example::User.namelike'Alice%';

It is also possible to define aliased modules in thewithblock. Consider the following query that needs to compare
objects corresponding to concepts defined in two different modules.

with
module example,
fas module foo
select User {
name
}
filter .name = f::Foo.name;

Another use case is for giving short aliases to long module names (especially if module names contain.).

with
module example,
fbzas modulefoo.bar.baz
select User {
name
}
filter .name = fbz::Baz.name;

#### 8.1.14.2 Local Expression Aliases

It is possible to define an alias for an arbitrary expression. The result set of an alias expression behaves as a completely
independent set of a given name. The contents of the set are determined by the expression at the point where the alias
is defined. In terms of scope, the alias expression in thewithblock is in a sibling scope to the rest of the query.

It may be useful to factor out a common sub-expression from a larger complex query. This can be done by assigning
the sub-expression a new symbol in thewithblock. However, care must be taken to ensure that this refactoring doesn’t
alter the meaning of the expression due to scope change.

All expression aliases defined in awithblock must be referenced in the body of the query.

# Consider a query to get all users that own Issues and the
# comments those users made.
with moduleexample
select Issue.owner {
name,
comments := Issue.owner.<owner[is Comment]
(continues on next page)

**8.1. EdgeQL 593**


```
(continued from previous page)
```
};

# The above query can be refactored like this:
with
module example,
U := Issue.owner
select U {
name,
comments := U.<owner[isComment]
};

An example of incorrect refactoring would be:

# This query gets a set of tuples of
# issues and their owners.
with
module example
select (Issue, Issue.owner);

# This query gets a set of tuples that
# result from a cartesian product of all issues
# with all owners. This is because``Issue``and``U``
# are considered independent sets.
with
module example,
U := Issue.owner
select (Issue, U);

#### 8.1.14.3 Detached

keyword detached
Thedetachedkeyword marks an expression as not belonging to any scope.

Adetachedexpression allows referring to some set as if it were defined in the top-levelwithblock. Basically,
detachedexpressions ignore all current scopes they are nested in and only take into account module aliases. The net
effect is that it is possible to refer to an otherwise related set as if it were unrelated:

with moduleexample
update User
filter .name ='Dave'
set{
friends := (select detachedUser filter.name ='Alice'),
coworkers := (select detached Userfilter .name ='Bob')
};

Here you can use thedetached Userexpression, rather than having to defineU := Userin thewithblock just to
allow it to be used in the body of theupdate. The goal is to indicate that theUserin theupdatebody is not in any
way related to theUserthat’s being updated.

```
See also
EdgeQL > With
```
**594 Chapter 8. Reference**


### 8.1.15 Start transaction

```
eql-statement
```
start transaction– start a transaction

start transaction<transaction-mode> [ , ... ] ;

# where <transaction-mode> is one of:

isolation serializable
read write |read only
deferrable |not deferrable

#### 8.1.15.1 Description

This command starts a new transaction block.

Any EdgeDB command outside of an explicit transaction block starts an implicit transaction block; the transaction is
then automatically committed if the command was executed successfully, or automatically rollbacked if there was an
error. This behavior is often called “autocommit”.

#### 8.1.15.2 Parameters

The<transaction-mode>can be one of the following:

isolation serializableAll statements of the current transaction can only see data changes committed before
the first query or data-modification statement was executed in this transaction. If a pattern of reads and writes
among concurrent serializable transactions would create a situation which could not have occurred for any serial
(one-at-a-time) execution of those transactions, one of them will be rolled back with a serialization_failure error.

read writeSets the transaction access mode to read/write.

```
This is the default.
```
read onlySets the transaction access mode to read-only. Any data modifications withinsert,update, ordelete
are disallowed. Schema mutations via _DDL_ are also disallowed.

deferrableThe transaction can be set to deferrable mode only when it isserializableandread only. When all
three of these properties are selected for a transaction, the transaction may block when first acquiring its snapshot,
after which it is able to run without the normal overhead of aserializabletransaction and without any risk
of contributing to or being canceled by a serialization failure. This mode is well suited for long-running reports
or backups.

#### 8.1.15.3 Examples

Start a new transaction and rollback it:

start transaction;
select 'Hello World!';
rollback;

Start a serializable deferrable transaction:

**8.1. EdgeQL 595**


start transaction isolation serializable, read only,deferrable;

```
See also
Reference > EdgeQL > Commit
Reference > EdgeQL > Rollback
Reference > EdgeQL > Declare savepoint
Reference > EdgeQL > Rollback to savepoint
Reference > EdgeQL > Release savepoint
```
### 8.1.16 Commit

```
eql-statement
```
commit– commit the current transaction

commit ;

#### 8.1.16.1 Example

Commit the current transaction:

commit;

#### 8.1.16.2 Description

Thecommitcommand commits the current transaction. All changes made by the transaction become visible to others
and are guaranteed to be durable if a crash occurs.

```
See also
Reference > EdgeQL > Start transaction
Reference > EdgeQL > Rollabck
Reference > EdgeQL > Declare savepoint
Reference > EdgeQL > Rollback to savepoint
Reference > EdgeQL > Release savepoint
```
### 8.1.17 Rollback

```
eql-statement
```
rollback– abort the current transaction

rollback;

**596 Chapter 8. Reference**


#### 8.1.17.1 Example

Abort the current transaction:

rollback;

#### 8.1.17.2 Description

Therollbackcommand rolls back the current transaction and causes all updates made by the transaction to be dis-
carded.

```
See also
Reference > EdgeQL > Start transaction
Reference > EdgeQL > Commit
Reference > EdgeQL > Declare savepoint
Reference > EdgeQL > Rollback to savepoint
Reference > EdgeQL > Release savepoint
```
### 8.1.18 Declare savepoint

```
eql-statement
```
declare savepoint– declare a savepoint within the current transaction

declare savepoint<savepoint-name> ;

#### 8.1.18.1 Description

savepointestablishes a new savepoint within the current transaction.

A savepoint is a special mark inside a transaction that allows all commands that are executed after it was established to
be rolled back, restoring the transaction state to what it was at the time of the savepoint.

It is an error to declare a savepoint outside of a transaction.

#### 8.1.18.2 Example

# Will select no objects:
select test::TestObject { name };

start transaction;

```
insert test::TestObject { name :='q1' };
insert test::TestObject { name :='q2' };
```
```
# Will select two TestObjects with names'q1'and'q2'
select test::TestObject { name };
```
```
declare savepointf1;
inserttest::TestObject { name:='w1'};
(continues on next page)
```
**8.1. EdgeQL 597**


```
(continued from previous page)
```
```
# Will select three TestObjects with names
#'q1''q2', and'w1'
selecttest::TestObject { name };
rollback to savepointf1;
```
```
# Will select two TestObjects with names'q1'and'q2'
select test::TestObject { name };
```
rollback;

```
See also
Reference > EdgeQL > Start transaction
Reference > EdgeQL > Commit
Reference > EdgeQL > Rollabck
Reference > EdgeQL > Rollback to savepoint
Reference > EdgeQL > Release savepoint
```
### 8.1.19 Release savepoint

```
eql-statement
```
release savepoint– release a previously declared savepoint

release savepoint<savepoint-name> ;

#### 8.1.19.1 Description

release savepointdestroys a savepoint previously defined in the current transaction.

Destroying a savepoint makes it unavailable as a rollback point, but it has no other user visible behavior. It does not undo
the effects of commands executed after the savepoint was established. (To do that, seerollback to savepoint.)

release savepointalso destroys all savepoints that were established after the named savepoint was established.

#### 8.1.19.2 Example

start transaction;
# ...
declare savepointf1;
# ...
release savepointf1;
# ...
rollback;

**598 Chapter 8. Reference**


```
See also
Reference > EdgeQL > Start transaction
Reference > EdgeQL > Commit
Reference > EdgeQL > Rollabck
Reference > EdgeQL > Declare savepoint
Reference > EdgeQL > Rollback to savepoint
```
### 8.1.20 Rollback to savepoint

```
eql-statement
```
rollback to savepoint– rollback to a savepoint within the current transaction

rollback to savepoint<savepoint-name> ;

#### 8.1.20.1 Description

Rollback all commands that were executed after the savepoint was established. The savepoint remains valid and can be
rolled back to again later, if needed.

rollback to savepointimplicitly destroys all savepoints that were established after the named savepoint.

#### 8.1.20.2 Example

start transaction;
# ...
declare savepointf1;
# ...
rollback to savepointf1;
# ...
rollback;

```
See also
Reference > EdgeQL > Start transaction
Reference > EdgeQL > Commit
Reference > EdgeQL > Rollabck
Reference > EdgeQL > Declare savepoint
Reference > EdgeQL > Release savepoint
```
### 8.1.21 Set

```
eql-statement
```
set– set one or multiple session-level parameters

set module <module> ;
set alias<alias>as module<module> ;
set global <name> := <expr> ;

**8.1. EdgeQL 599**


#### 8.1.21.1 Description

This command allows altering the configuration of the current session.

#### 8.1.21.2 Variations

set module <module>Set the default module for the current section to _module_.

```
For example, if a modulefoocontains typeFooType, the following is how the type can be referred to:
```
```
# Use the fully-qualified name.
select foo::FooType;
```
```
# Use the WITH clause to define the default module
# for the query.
with modulefooselectfoo::FooType;
```
```
# Set the default module for the current session ...
set modulefoo;
# ... and use an unqualified name.
select FooType;
```
set alias <alias> as module <module>Define<alias>for the<module>.

```
For example:
```
```
# Use the fully-qualified name.
select foo::FooType;
```
```
# Use the WITH clause to define a custom alias
# for the "foo" module.
withbaras modulefoo
select bar::FooType;
```
```
# Define "bar" as an alias for the "foo" module for
# the current session ...
set aliasbaras modulefoo;
# ... and use "bar" instead of "foo".
select bar::FooType;
```
set global <name> := <expr>Set the global variable _name_ to the specified value.

```
For example:
```
```
# Set the global variable "current_user_id".
set globalcurrent_user_id :=
<uuid>'00ea8eaa-02f9-11ed-a676-6bd11cc6c557';
```
```
# We can now use that value in a query.
select User { name }
filter .id =global current_user_id;
```
**600 Chapter 8. Reference**


#### 8.1.21.3 Examples

set module foo;

set aliasfooAS module std;

set global current_user_id :=
<uuid>'00ea8eaa-02f9-11ed-a676-6bd11cc6c557';

```
See also
Reference > EdgeQL > Reset
```
### 8.1.22 Reset

```
eql-statement
```
reset– reset one or multiple session-level parameters

reset module;
reset alias<alias> ;
reset alias* ;
reset global<name> ;

#### 8.1.22.1 Description

This command allows resetting one or many configuration parameters of the current session.

#### 8.1.22.2 Variations

reset moduleReset the default module name back to “default” for the current session.

```
For example, if a modulefoocontains typeFooType, the following is how thesetandresetcommands can
be used to alias it:
```
```
# Set the default module to "foo" for the current session.
set modulefoo;
```
```
# This query is now equivalent to "select foo::FooType".
select FooType;
```
```
# Reset the default module for the current session.
reset module;
```
```
# This query will now produce an error.
select FooType;
```
reset alias <alias>Reset<alias>for the current session.

```
For example:
```
**8.1. EdgeQL 601**


```
# Alias the "std" module as "foo".
set aliasfooas modulestd;
```
```
# Now "std::min()" can be called as "foo::min()" in
# the current session.
select foo::min({1});
```
```
# Reset the alias.
reset aliasfoo;
```
```
# Now this query will error out, as there is no
# module "foo".
select foo::min({1});
```
reset alias *Reset all aliases defined in the current session. This command affects aliases set withset alias
andset module. The default module will be set to “default”.
Example:

```
# Reset all custom aliases for the current session.
reset alias*;
```
reset global <name>Reset the global variable _name_ to its default value or{}if the variable has no default value
and isoptional.

#### 8.1.22.3 Examples

reset module;

reset aliasfoo;

reset alias*;

reset globalcurrent_user_id;

```
See also
Reference > EdgeQL > Set
```
### 8.1.23 Describe

```
eql-statement
```
describe– provide human-readable description of a schema or a schema object

describe schema [as {ddl|sdl| test [verbose]} ];

describe<schema-type> <name> [as {ddl| sdl|text[ verbose]} ];

# where <schema-type> is one of

```
object
(continues on next page)
```
**602 Chapter 8. Reference**


```
(continued from previous page)
annotation
constraint
function
link
module
property
scalar type
type
```
#### 8.1.23.1 Description

describegenerates a human-readable description of a schema object.

The output of adescribecommand is astr, although it cannot be used as an expression in queries.

There are three output formats to choose from:

as ddlProvide a valid _DDL_ definition.

```
The DDL generated is a complete valid definition of the particular schema object assuming all the other referenced
schema objects already exist.
This is the default format.
```
as sdlProvide an _SDL_ definition.

```
The SDL generated is a complete valid definition of the particular schema object assuming all the other referenced
schema objects already exist.
```
as text [verbose]Provide a human-oriented definition.

```
The human-oriented definition generated is similar to SDL , but it includes all the details that are inherited (if
any).
Theverbosemode enables displaying additional details, such as annotations and constraints , which are other-
wise omitted.
```
When thedescribecommand is used with theschemathe result is a definition of the entire database schema. Only
theas ddloption is available for schema description.

Thedescribecommand can specify the type of schema object that it should generate the description of:

object <name>Match any module level schema object with the specified _name_.

```
This is the most general use of thedescribecommand. It does not match modules (and other globals that cannot
be uniquely identified just by the name).
```
annotation <name>Match only _annotations_ with the specified _name_.

constraint <name>Match only _constraints_ with the specified _name_.

function <name>Match only _functions_ with the specified _name_.

link <name>Match only _links_ with the specified _name_.

module <name>Match only _modules_ with the specified _name_.

property <name>Match only _properties_ with the specified _name_.

scalar type <name>Match only _scalar types_ with the specified _name_.

type <name>Match only _object types_ with the specified _name_.

**8.1. EdgeQL 603**


#### 8.1.23.2 Examples

Consider the following schema:

abstract type Named {
required propertyname -> str {
delegated constraintexclusive;
}
}

typeUserextending Named {
required propertyemail -> str {
annotationtitle :='Contact email';
}
}

abstract type Named {
requiredname: str {
delegated constraintexclusive;
}
}

typeUserextending Named {
requiredemail: str {
annotationtitle :='Contact email';
}
}

Here are some examples of adescribecommand:

db>describe object User;
{
"create type default::User extending default::Named {
create required single property email -> std::str {
create annotation std::title :='Contact email';
};
};"
}
db>describe object Useras sdl;
{
"type default::User extending default::Named {
required single property email -> std::str {
annotation std::title :='Contact email';
};
};"
}
db>describe object Useras text;
{
'type default::User extending default::Named {
required single link __type__ -> schema::Type {
readonly := true;
};
required single property email -> std::str;
(continues on next page)

**604 Chapter 8. Reference**


(continued from previous page)
required single property id -> std::uuid {
readonly := true;
};
required single property name -> std::str;
};'
}
db>describe object Useras text verbose;
{
"type default::User extending default::Named {
required single link __type__ -> schema::Type {
readonly := true;
};
required single property email -> std::str {
annotation std::title :='Contact email';
};
required single property id -> std::uuid {
readonly := true;
constraint std::exclusive;
};
required single property name -> std::str {
constraint std::exclusive;
};
};"
}
db>describe schema;
{
"create module default if not exists;
create abstract type default::Named {
create required single property name -> std::str {
create delegated constraint std::exclusive;
};
};
create type default::User extending default::Named {
create required single property email -> std::str {
create annotation std::title :='Contact email';
};
};"
}

Thedescribecommand also warns you if there are standard library matches that are masked by some user-defined
object. Consider the following schema:

module default{
functionlen(v: tuple<float64, float64>) -> float64using(
select(v.0 ^ 2 + v.1 ^ 2) ^ 0.5
);
}

So within thedefaultmodule the user-defined functionlen(computing the length of a vector) masks the built-ins:

db>describe functionlenas text;
{
(continues on next page)

**8.1. EdgeQL 605**


(continued from previous page)
'function default::len(v: tuple<std::float64, std::float64>) ->
std::float64 using (select
(((v.0 ^ 2) + (v.1 ^ 2)) ^ 0.5)
);

# The following builtins are masked by the above:

# function std::len(array: array<anytype>) -> std::int64 {
# volatility := \'Immutable\';
# annotation std::description := \'A polymorphic function to calculate
a "length" of its first argument.\';
# using sql $$
# SELECT cardinality("array")::bigint
# $$
# ;};
# function std::len(bytes: std::bytes) -> std::int64 {
# volatility := \'Immutable\';
# annotation std::description := \'A polymorphic function to calculate
a "length" of its first argument.\';
# using sql $$
# SELECT length("bytes")::bigint
# $$
# ;};
# function std::len(str: std::str) -> std::int64 {
# volatility := \'Immutable\';
# annotation std::description := \'A polymorphic function to calculate
a "length" of its first argument.\';
# using sql $$
# SELECT char_length("str")::bigint
# $$
# ;};',
}

## 8.2 SDL

```
edb-alt-title Schema Definition Language
```
This section describes the high-level language used to define EdgeDB schema. It is called the EdgeDB _schema definition
language_ or _SDL_. There’s a correspondence between this declarative high-level language and the imperative low-level
_DDL_.

SDL is a declarative language optimized for human readability and expressing the state of the EdgeDB schema without
getting into the details of how to arrive at that state. Each _SDL_ block represents the complete schema state for a given
_database_.

Syntactically, an SDL declaration mirrors thecreateDDL for the corresponding entity, but with all of thecreate
andsetkeywords omitted. The typical SDL structure is to use _module blocks_ with the rest of the declarations being
nested in their respective modules.

EdgeDB 3.0 introduces a new SDL syntax which diverges slightly from DDL. The old SDL syntax is still fully sup-
ported, but the new syntax allows for cleaner and less verbose expression of your schemas.

- Pointers no longer require an arrow (->). You may instead use a colon after the name of the link or property.

**606 Chapter 8. Reference**


- Thelinkandpropertykeywords are now optional for non-computed pointers when the target type is explicitly
    specified.

That means that this type definition:

typeUser {
required property email -> str;
}

could be replaced with this equivalent one in EdgeDB 3+:

typeUser {
required email: str;
}

When reading our documentation, the version selection dropdown will update the syntax of most SDL examples to the
preferred syntax for the version selected. This is only true for versioned sections of the documentation.

Since SDL is declarative in nature, the specific order of declarations of module blocks or individual items does not
matter.

The built-in _migration tools_ expect the schema to be given in SDL format. For example:

# "default" module block
module default{
typeMovie {
required propertytitle -> str;
# the year of release
propertyyear -> int64;
required linkdirector -> Person;
required multi linkactors -> Person;
}
typePerson {
required propertyfirst_name -> str;
required propertylast_name -> str;
}
}

# "default" module block
module default{
typeMovie {
requiredtitle: str;
# the year of release
year: int64;
requireddirector: Person;
required multiactors: Person;
}
typePerson {
requiredfirst_name: str;
requiredlast_name: str;
}
}

It is possible to also omit the module blocks, but then individual declarations must use _fully-qualified names_ so that
they can be assigned to their respective modules. For example, the following is equivalent to the previous migration:

**8.2. SDL 607**


# no module block
typedefault::Movie {
required propertytitle -> str;
# the year of release
propertyyear -> int64;
required linkdirector -> default::Person;
required multi link actors -> default::Person;
}
typedefault::Person {
required propertyfirst_name -> str;
required propertylast_name -> str;
}

# no module block
typedefault::Movie {
requiredtitle: str;
# the year of release
year: int64;
requireddirector: default::Person;
required multiactors: default::Person;
}
typedefault::Person {
requiredfirst_name: str;
requiredlast_name: str;
}

### 8.2.1 Modules

This section describes the SDL commands pertaining to _modules_.

#### 8.2.1.1 Example

Declare an empty module:

module my_module {}

Declare a module with some content:

module my_module {
typeUser {
required propertyname -> str;
}
}

module my_module {
typeUser {
requiredname: str;
}
}

**608 Chapter 8. Reference**


#### 8.2.1.2 Syntax

Define a module corresponding to the _more explicit DDL commands_.

module <ModuleName> "{"
[ <schema-declarations> ]

"}"

Define a nested module.

module <ParentModuleName> "{"
[ <schema-declarations> ]
module <ModuleName> "{"
[ <schema-declarations> ]
"}"

"}"

#### 8.2.1.3 Description

The module block declaration defines a new module similar to thecreate modulecommand, but it also allows putting
the module content as nested declarations:

<schema-declarations>Define various schema items that belong to this module.

Unlikecreate modulecommand, a module block with the same name can appear multiple times in an SDL document.
In that case all blocks with the same name are merged into a single module under that name. For example:

module my_module {
abstract type Named {
required propertyname -> str;
}
}

module my_module {
typeUserextending Named;
}

module my_module {
abstract type Named {
requiredname: str;
}
}

module my_module {
typeUserextending Named;
}

The above is equivalent to:

module my_module {
abstract type Named {
(continues on next page)

**8.2. SDL 609**


```
(continued from previous page)
required propertyname -> str;
}
```
typeUserextending Named;
}

module my_module {
abstract type Named {
requiredname: str;
}

typeUserextending Named;
}

Typically, in the documentation examples of SDL the _module block_ is omitted and instead its contents are described
without assuming which specific module they belong to.

It’s also possible to declare modules implicitly. In this style SDL declaration uses _fully-qualified name_ for the item that
is being declared. The _module_ part of the _fully-qualified_ name implies that a module by that name will be automati-
cally created in the schema. The following declaration is equivalent to the previous examples, but it declares module
my_moduleimplicitly:

abstract typemy_module::Named {
required propertyname -> str;
}

typemy_module::User extendingmy_module::Named;

abstract typemy_module::Named {
requiredname: str;
}

typemy_module::User extendingmy_module::Named;

A module block can be nested inside another module block to create a nested module. If you want reference an en-
tity in a nested module by its fully-qualified name, you will need to reference all of the containing modules’ names:
<ParentModuleName>::<ModuleName>::<EntityName>

**610 Chapter 8. Reference**


### 8.2.2 Object Types

This section describes the SDL declarations pertaining to _object types_.

#### 8.2.2.1 Example

Consider aUsertype with a few properties:

typeUser {
# define some properties and a link
required propertyname -> str;
propertyaddress -> str;

```
multi linkfriends -> User;
```
# define an index for User based on name
index on(__subject__.name);
}

typeUser {
# define some properties and a link
requiredname: str;
address: str;

```
multifriends: User;
```
# define an index for User based on name
index on(__subject__.name);
}

An alternative way to define the sameUsertype could be by using abstract types. These abstract types can then be
re-used in other type definitions as well:

abstract type Named {
required propertyname -> str;
}

abstract typeHasAddress {
propertyaddress -> str;
}

typeUserextending Named, HasAddress {
# define some user-specific properties and a link
multi linkfriends -> User;

# define an index for User based on name
index on(__subject__.name);
}

abstract type Named {
requiredname: str;
}
(continues on next page)

**8.2. SDL 611**


```
(continued from previous page)
```
abstract typeHasAddress {
address: str;
}

typeUserextending Named, HasAddress {
# define some user-specific properties and a link
multifriends: User;

# define an index for User based on name
index on(__subject__.name);
}

Introducing abstract types opens up the possibility of _polymorphic queries_.

#### 8.2.2.2 Syntax

Define a new object type corresponding to the _more explicit DDL commands_.

[abstract] type<TypeName> [extending <supertype> [, ...] ]
[ "{"
[ <annotation-declarations> ]
[ <property-declarations> ]
[ <link-declarations> ]
[ <constraint-declarations> ]
[ <index-declarations> ]

```
"}" ]
```
#### 8.2.2.3 Description

This declaration defines a new object type with the following options:

abstractIf specified, the created type will be _abstract_.

<TypeName>The name (optionally module-qualified) of the new type.

extending <supertype> [, ...]Optional clause specifying the _supertypes_ of the new type.

```
Use ofextendingcreates a persistent type relationship between the new subtype and its supertype(s). Schema
modifications to the supertype(s) propagate to the subtype.
References to supertypes in queries will also include objects of the subtype.
If the same link name exists in more than one supertype, or is explicitly defined in the subtype and at least one
supertype, then the data types of the link targets must be compatible. If there is no conflict, the links are merged
to form a single link in the new type.
```
These sub-declarations are allowed in theTypeblock:

<annotation-declarations>Set object type _annotation_ to a given _value_.

<property-declarations>Define a concrete _property_ for this object type.

<link-declarations>Define a concrete _link_ for this object type.

**612 Chapter 8. Reference**


<constraint-declarations>Define a concrete _constraint_ for this object type.

<index-declarations>Define an _index_ for this object type.

```
See also
Schema > Object types
DDL > Object types
Introspection > Object types
Cheatsheets > Object types
```
### 8.2.3 Scalar Types

This section describes the SDL declarations pertaining to _scalar types_.

#### 8.2.3.1 Example

Declare a new non-negative integer type:

scalar typeposint64extendingint64 {
constraintmin_value(0);
}

#### 8.2.3.2 Syntax

Define a new scalar type corresponding to the _more explicit DDL commands_.

[abstract] scalar type<TypeName> [extending<supertype> [, ...] ]
[ "{"
[ <annotation-declarations> ]
[ <constraint-declarations> ]

```
"}" ]
```
### 8.2.3.3 Description

This declaration defines a new object type with the following options:

abstractIf specified, the created scalar type will be _abstract_.

<TypeName>The name (optionally module-qualified) of the new scalar type.

extending <supertype>Optional clause specifying the _supertype_ of the new type.

```
If<supertype>is anenumerated typedeclaration then an enumerated scalar type is defined.
Use ofextendingcreates a persistent type relationship between the new subtype and its supertype(s). Schema
modifications to the supertype(s) propagate to the subtype.
```
The valid SDL sub-declarations are listed below:

<annotation-declarations>Set scalar type _annotation_ to a given _value_.

<constraint-declarations>Define a concrete _constraint_ for this scalar type.

**8.2. SDL 613**


## 8.2.4 Links

This section describes the SDL declarations pertaining to _links_.

### 8.2.4.1 Examples

Declare an _abstract_ link “friends_base” with a helpful title:

abstract linkfriends_base {
# declare a specific title for the link
annotationtitle := 'Close contacts';
}

Declare a _concrete_ link “friends” within a “User” type:

typeUser {
required propertyname -> str;
propertyaddress -> str;
# define a concrete link "friends"
multi linkfriendsextending friends_base -> User;

index on(__subject__.name);
}

typeUser {
requiredname: str;
address: str;
# define a concrete link "friends"
multi linkfriends: User {
extendingfriends_base;
};

index on(__subject__.name);
}

#### 8.2.4.1.1 Overloading

Any time that the SDL declaration refers to an inherited link that is being overloaded (by adding more constraints
or changing the target type, for example), theoverloadedkeyword must be used. This is to prevent unintentional
overloading due to name clashes:

abstract typeFriendly {
# this type can have "friends"
multi linkfriends -> Friendly;
}

typeUserextending Friendly {
# overload the link target to be User, specifically
overloaded multi linkfriends -> User;
# ... other links and properties
}

**614 Chapter 8. Reference**


abstract typeFriendly {
# this type can have "friends"
multifriends: Friendly;
}

typeUserextending Friendly {
# overload the link target to be User, specifically
overloaded multifriends: User;
# ... other links and properties
}

### 8.2.4.2 Syntax

Define a new link corresponding to the _more explicit DDL commands_.

# Concrete link form used inside type declaration:
[overloaded ] [{required|optional}] [{single | multi}]
link <name>
[ extending<base> [, ...] ] -> <type>
[ "{"
[ default:= <expression> ; ]
[ readonly := {true|false} ; ]
[ on target delete<action> ; ]
[ <annotation-declarations> ]
[ <property-declarations> ]
[ <constraint-declarations> ]
...
"}" ]

# Computed link form used inside type declaration:
[{required |optional}] [{single |multi}]
link <name> := <expression>;

# Computed link form used inside type declaration (extended):
[overloaded ] [{required|optional}] [{single | multi}]
link <name>
[ extending<base> [, ...] ] [-> <type>]
[ "{"
using (<expression>) ;
[ <annotation-declarations> ]
[ <constraint-declarations> ]
...
"}" ]

# Abstract link form:
abstract link<name> [extending<base> [, ...]]
[ "{"
[ readonly := {true |false} ; ]
[ <annotation-declarations> ]
[ <property-declarations> ]
[ <constraint-declarations> ]
(continues on next page)

**8.2. SDL 615**


```
(continued from previous page)
[ <index-declarations> ]
...
"}" ]
```
# Concrete link form used inside type declaration:
[overloaded ] [{required|optional}] [{single | multi}]
[ link] <name> : <type>
[ "{"
[ extending<base> [, ...] ; ]
[ default:= <expression> ; ]
[ readonly := {true|false} ; ]
[ on target delete<action> ; ]
[ <annotation-declarations> ]
[ <property-declarations> ]
[ <constraint-declarations> ]
...
"}" ]

# Computed link form used inside type declaration:
[{required |optional}] [{single |multi}]
link <name> := <expression>;

# Computed link form used inside type declaration (extended):
[overloaded ] [{required|optional}] [{single | multi}]
link <name> [: <type>]
[ "{"
using (<expression>) ;
[ extending<base> [, ...] ; ]
[ <annotation-declarations> ]
[ <constraint-declarations> ]
...
"}" ]

# Abstract link form:
abstract link<name>
[ "{"
[extending<base> [, ...] ; ]
[ readonly := {true |false} ; ]
[ <annotation-declarations> ]
[ <property-declarations> ]
[ <constraint-declarations> ]
[ <index-declarations> ]
...
"}" ]

**616 Chapter 8. Reference**


### 8.2.4.3 Description

There are several forms of link declaration, as shown in the syntax synopsis above. The first form is the canonical
definition form, the second form is used for defining a _computed link_ , and the last form is used to define an abstract
link. The abstract form allows declaring the link directly inside a _module_. Concrete link forms are always used as
sub-declarations of an _object type_.

The following options are available:

overloadedIf specified, indicates that the link is inherited and that some feature of it may be altered in the current
object type. It is an error to declare a link as _overloaded_ if it is not inherited.

requiredIf specified, the link is considered _required_ for the parent object type. It is an error for an object to have a
required link resolve to an empty value. Child links **always** inherit the _required_ attribute, i.e it is not possible to
make a required link non-required by extending it.

optionalThis is the default qualifier assumed when no qualifier is specified, but it can also be specified explicitly.
The link is considered _optional_ for the parent object type, i.e. it is possible for the link to resolve to an empty
value.

multiSpecifies that there may be more than one instance of this link in an object, in other words,Object.linkmay
resolve to a set of a size greater than one.

singleSpecifies that there may be at most _one_ instance of this link in an object, in other words,Object.linkmay
resolve to a set of a size not greater than one. singleis assumed if nethermultinorsinglequalifier is
specified.

extending <base> [, ...]Optional clause specifying the _parents_ of the new link item.

```
Use ofextendingcreates a persistent schema relationship between the new link and its parents. Schema mod-
ifications to the parent(s) propagate to the child.
If the same property name exists in more than one parent, or is explicitly defined in the new link and at least one
parent, then the data types of the property targets must be compatible. If there is no conflict, the link properties
are merged to form a single property in the new link item.
As of EdgeDB 3.0, theextendedclause is now a sub-declaration of the link and included inside the curly braces
rather than an option as in earlier versions.
```
<type>The type must be a valid _type expression_ denoting an object type.

The valid SDL sub-declarations are listed below:

default := <expression>Specifies the default value for the link as an EdgeQL expression. The default value is
used in aninsertstatement if an explicit value for this link is not specified.

readonly := {true | false}Iftrue, the link is considered _read-only_. Modifications of this link are prohibited
once an object is created. All of the derived links **must** preserve the original _read-only_ value.

<annotation-declarations>Set link _annotation_ to a given _value_.

<property-declarations>Define a concrete _property_ on the link.

<constraint-declarations>Define a concrete _constraint_ on the link.

<index-declarations>Define an _index_ for this abstract link. Note that this index can only refer to link properties.

```
See also
Schema > Links
DDL > Links
Introspection > Object types
```
**8.2. SDL 617**


## 8.2.5 Properties

This section describes the SDL declarations pertaining to _properties_.

### 8.2.5.1 Examples

Declare an _abstract_ property “address_base” with a helpful title:

abstract propertyaddress_base {
# declare a specific title for the link
annotationtitle := 'Mailing address';
}

Declare _concrete_ properties “name” and “address” within a “User” type:

typeUser {
# define concrete properties
required propertyname -> str;
propertyaddressextendingaddress_base -> str;

```
multi linkfriends -> User;
```
index on(__subject__.name);
}

typeUser {
# define concrete properties
requiredname: str;
propertyaddress: str {
extendingaddress_base;
};

```
multifriends: User;
```
index on(__subject__.name);
}

Any time that the SDL declaration refers to an inherited property that is being overloaded (by adding more constraints,
for example), theoverloadedkeyword must be used. This is to prevent unintentional overloading due to name clashes:

abstract type Named {
propertyname -> str;
}

typeUserextending Named {
# define concrete properties
overloaded required property name -> str;
# ... other links and properties
}

abstract type Named {
name: str;
(continues on next page)

**618 Chapter 8. Reference**


```
(continued from previous page)
```
}

typeUserextending Named {
# define concrete properties
overloaded required name: str;
# ... other links and properties
}

### 8.2.5.2 Syntax

Define a new property corresponding to the _more explicit DDL commands_.

# Concrete property form used inside type declaration:
[overloaded ] [{required|optional}] [{single | multi}]
property <name>
[ extending<base> [, ...] ] -> <type>
[ "{"
[ default:= <expression> ; ]
[ readonly := {true|false} ; ]
[ <annotation-declarations> ]
[ <constraint-declarations> ]
...
"}" ]

# Computed property form used inside type declaration:
[{required |optional}] [{single |multi}]
property <name> := <expression>;

# Computed property form used inside type declaration (extended):
[overloaded ] [{required|optional}] [{single | multi}]
property <name>
[ extending<base> [, ...] ] [-> <type>]
[ "{"
using (<expression>) ;
[ <annotation-declarations> ]
[ <constraint-declarations> ]
...
"}" ]

# Abstract property form:
abstract property[<module>::]<name> [extending<base> [, ...]]
[ "{"
[ readonly := {true |false} ; ]
[ <annotation-declarations> ]
...
"}" ]

# Concrete property form used inside type declaration:
[overloaded ] [{required|optional}] [{single | multi}]
[ property] <name> : <type>
[ "{"
(continues on next page)

**8.2. SDL 619**


```
(continued from previous page)
[ extending<base> [, ...] ; ]
[ default:= <expression> ; ]
[ readonly := {true|false} ; ]
[ <annotation-declarations> ]
[ <constraint-declarations> ]
```
```
"}" ]
```
# Computed property form used inside type declaration:
[{required |optional}] [{single |multi}]
property <name> := <expression>;

# Computed property form used inside type declaration (extended):
[overloaded ] [{required|optional}] [{single | multi}]
property <name> [: <type>]
[ "{"
using (<expression>) ;
[ extending<base> [, ...] ; ]
[ <annotation-declarations> ]
[ <constraint-declarations> ]

```
"}" ]
```
# Abstract property form:
abstract property[<module>::]<name>
[ "{"
[extending<base> [, ...] ; ]
[ readonly := {true |false} ; ]
[ <annotation-declarations> ]

```
"}" ]
```
### 8.2.5.3 Description

There are several forms ofpropertydeclaration, as shown in the syntax synopsis above. The first form is the canonical
definition form, the second and third forms are used for defining a _computed property_ , and the last one is a form to
define anabstract property. The abstract form allows declaring the property directly inside a _module_. Concrete
property forms are always used as sub-declarations for an _object type_ or a _link_.

The following options are available:

overloadedIf specified, indicates that the property is inherited and that some feature of it may be altered in the
current object type. It is an error to declare a property as _overloaded_ if it is not inherited.

requiredIf specified, the property is considered _required_ for the parent object type. It is an error for an object to
have a required property resolve to an empty value. Child properties **always** inherit the _required_ attribute, i.e it
is not possible to make a required property non-required by extending it.

optionalThis is the default qualifier assumed when no qualifier is specified, but it can also be specified explicitly.
The property is considered _optional_ for the parent object type, i.e. it is possible for the property to resolve to an
empty value.

multiSpecifies that there may be more than one instance of this property in an object, in other words,Object.
propertymay resolve to a set of a size greater than one.

**620 Chapter 8. Reference**


singleSpecifies that there may be at most _one_ instance of this property in an object, in other words,Object.
propertymay resolve to a set of a size not greater than one.singleis assumed if nethermultinorsingle
qualifier is specified.

extending <base> [, ...]Optional clause specifying the _parents_ of the new property item.

```
Use ofextendingcreates a persistent schema relationship between the new property and its parents. Schema
modifications to the parent(s) propagate to the child.
As of EdgeDB 3.0, theextendedclause is now a sub-declaration of the property and included inside the curly
braces rather than an option as in earlier versions.
```
<type>The type must be a valid _type expression_ denoting a non-abstract scalar or a container type.

The valid SDL sub-declarations are listed below:

default := <expression>Specifies the default value for the property as an EdgeQL expression. The default value
is used in aninsertstatement if an explicit value for this property is not specified.

readonly := {true | false}Iftrue, the property is considered _read-only_. Modifications of this property are
prohibited once an object is created. All of the derived properties **must** preserve the original _read-only_ value.

<annotation-declarations>Set property _annotation_ to a given _value_.

<constraint-declarations>Define a concrete _constraint_ on the property.

```
See also
Schema > Properties
DDL > Properties
Introspection > Object types
```
## 8.2.6 Expression Aliases

This section describes the SDL declarations pertaining to _expression aliases_.

### 8.2.6.1 Example

Declare a “UserAlias” that provides additional information for a “User” via a _computed link_ “friend_of”:

aliasUserAlias := User {
# declare a computed link
friend_of := User.<friends[is User]
};

### 8.2.6.2 Syntax

Define a new alias corresponding to the _more explicit DDL commands_.

alias<alias-name> := <alias-expr> ;

alias<alias-name> "{"
using<alias-expr>;
[ <annotation-declarations> ]
"}" ;

**8.2. SDL 621**


### 8.2.6.3 Description

This declaration defines a new alias with the following options:

<alias-name>The name (optionally module-qualified) of an alias to be created.

<alias-expr>The aliased expression. Can be any valid EdgeQL expression.

The valid SDL sub-declarations are listed below:

<annotation-declarations>Set alias _annotation_ to a given _value_.

```
See also
Schema > Aliases
DDL > Aliases
Cheatsheets > Aliases
```
## 8.2.7 Indexes

This section describes the SDL declarations pertaining to _indexes_.

### 8.2.7.1 Example

Declare an index for a “User” based on the “name” property:

typeUser {
required propertyname -> str;
propertyaddress -> str;

```
multi linkfriends -> User;
```
# define an index for User based on name
index on(.name) {
annotationtitle :='User name index';
}
}

typeUser {
requiredname: str;
address: str;

```
multifriends: User;
```
# define an index for User based on name
index on(.name) {
annotationtitle :='User name index';
}
}

**622 Chapter 8. Reference**


### 8.2.7.2 Syntax

Define a new index corresponding to the _more explicit DDL commands_.

index on( <index-expr> )
[except ( <except-expr> ) ]
[ "{" <annotation-declarations> "}" ] ;

### 8.2.7.3 Description

This declaration defines a new index with the following options:

on ( <index-expr> )The specific expression for which the index is made. Note also that<index-expr>itself
has to be parenthesized.

except ( <exception-expr> )

```
An optional expression defining a condition to create exceptions to the index. If<exception-expr>eval-
uates totrue, the object is omitted from the index. If it evaluates tofalseor{}, it appears in the index.
```
The valid SDL sub-declarations are listed below:

<annotation-declarations>Set index _annotation_ to a given _value_.

```
See also
Schema > Indexes
DDL > Indexes
Introspection > Indexes
```
## 8.2.8 Constraints

This section describes the SDL declarations pertaining to _constraints_.

### 8.2.8.1 Examples

Declare an _abstract_ constraint:

abstract constraint min_value(min:anytype) {
errmessage :=
'Minimum allowed value for {__subject__} is {min}.';

using(__subject__ >= min);
}

Declare a _concrete_ constraint on an integer type:

scalar typeposint64extendingint64 {
constraintmin_value(0);
}

Declare a _concrete_ constraint on an object type:

**8.2. SDL 623**


typeVector {
required propertyx -> float64;
required propertyy -> float64;
constraint expression on(
__subject__.x^2 + __subject__.y^2 < 25
);
}

typeVector {
requiredx: float64;
requiredy: float64;
constraint expression on(
__subject__.x^2 + __subject__.y^2 < 25
);
}

### 8.2.8.2 Syntax

Define a constraint corresponding to the _more explicit DDL commands_.

[{abstract |delegated}] constraint<name> [ ( [<argspec>] [, ...] ) ]
[on ( <subject-expr> ) ]
[except ( <except-expr> ) ]
[extending <base> [, ...] ]
"{"
[using <constr-expression> ; ]
[ errmessage := <error-message> ; ]
[ <annotation-declarations> ]
[ ... ]
"}" ;

# where <argspec> is:

[ <argname>: ] {<argtype> | <argvalue>}

### 8.2.8.3 Description

This declaration defines a new constraint with the following options:

abstractIf specified, the constraint will be _abstract_.

delegatedIf specified, the constraint is defined as _delegated_ , which means that it will not be enforced on the type
it’s declared on, and the enforcement will be delegated to the subtypes of this type. This is particularly useful for
exclusiveconstraints in abstract types. This is only valid for _concrete constraints_.

<name>The name (optionally module-qualified) of the new constraint.

<argspec>An optional list of constraint arguments.

```
For an abstract constraint <argname>optionally specifies the argument name and<argtype>specifies the
argument type.
For a concrete constraint <argname>optionally specifies the argument name and<argvalue>specifies the ar-
gument value. The argument value specification must match the parameter declaration of the abstract constraint.
```
**624 Chapter 8. Reference**


on ( <subject-expr> )An optional expression defining the _subject_ of the constraint. If not specified, the subject is
the value of the schema item on which the concrete constraint is defined. The expression must refer to the original
subject of the constraint as__subject__. Note also that<subject-expr>itself has to be parenthesized.

except ( <exception-expr> )

```
An optional expression defining a condition to create exceptions to the constraint. If<exception-expr>
evaluates totrue, the constraint is ignored for the current subject. If it evaluates tofalseor{}, the
constraint applies normally.
exceptmay only be declared on object constraints, and is otherwise follows the same rules ason, above.
```
extending <base> [, ...]If specified, declares the _parent_ constraints for this abstract constraint.

The valid SDL sub-declarations are listed below:

using <constr_expression>A boolean expression that returnstruefor valid data andfalsefor invalid data.
The expression may refer to the subject of the constraint as__subject__. This declaration is only valid for
_abstract constraints_.

errmessage := <error_message>An optional string literal defining the error message template that is raised when
the constraint is violated. The template is a formatted string that may refer to constraint context variables in curly
braces. The template may refer to the following:

- $argname– the value of the specified constraint argument
- __subject__– the value of thetitleannotation of the scalar type, property or link on which the con-
    straint is defined.
If the content of curly braces does not match any variables, the curly braces are emitted as-is. They can also be
escaped by using double curly braces.

<annotation-declarations>Set constraint _annotation_ to a given _value_.

```
See also
Schema > Constraints
DDL > Constraints
Introspection > Constraints
Standard Library > Constraints
Tutorial > Advanced EdgeQL > Constraints
```
## 8.2.9 Annotations

This section describes the SDL declarations pertaining to _annotations_.

### 8.2.9.1 Examples

Declare a new annotation:

abstract annotation admin_note;

Specify the value of an annotation for a type:

typeStatus {
annotationadmin_note := 'system-critical';
required propertyname -> str {
constraintexclusive
(continues on next page)

**8.2. SDL 625**


(continued from previous page)
}
}

typeStatus {
annotationadmin_note := 'system-critical';
requiredname: str {
constraintexclusive
}
}

### 8.2.9.2 Syntax

Define a new annotation corresponding to the _more explicit DDL commands_.

# Abstract annotation form:
abstract[ inheritable] annotation<name>
[ "{" <annotation-declarations>; [...] "}" ] ;

# Concrete annotation (same as <annotation-declarations>) form:
annotation <name> := <value> ;

### 8.2.9.3 Description

There are two forms of annotation declarations: abstract and concrete. The _abstract annotation_ form is used for declar-
ing new kinds of annotation in a module. The _concrete annotation_ declarations are used as sub-declarations for all
other declarations in order to actually annotate them.

The annotation declaration options are as follows:

abstractIf specified, the annotation will be _abstract_.

inheritableIf specified, the annotation will be _inheritable_. The annotations are non-inheritable by default. That is,
if a schema item has an annotation defined on it, the descendants of that schema item will not automatically inherit
the annotation. Normal inheritance behavior can be turned on by declaring the annotation with theinheritable
qualifier. This is only valid for _abstract annotation_.

<name>The name (optionally module-qualified) of the annotation.

<value>Any string value that the specified annotation is intended to have for the given context.

The only valid SDL sub-declarations are _concrete annotations_ :

<annotation-declarations>Annotations can also have annotations. Set the _annotation_ of the enclosing annota-
tion to a specific value.

```
See also
Schema > Annotations
DDL > Annotations
Cheatsheets > Annotations
Introspection > Object types
```
**626 Chapter 8. Reference**


## 8.2.10 Globals

This section describes the SDL commands pertaining to global variables.

### 8.2.10.1 Examples

Declare a new global variable:

global current_user_id -> uuid;
global current_user := (
select Userfilter.id = globalcurrent_user_id
);

Set the global variable to a specific value using _session-level commands_ :

set global current_user_id :=
<uuid>'00ea8eaa-02f9-11ed-a676-6bd11cc6c557';

Use the computed global variable that is based on the value that was just set:

select globalcurrent_user { name };

_Reset_ the global variable to its default value:

reset globaluser_id;

### 8.2.10.2 Syntax

Define a new global variable corresponding to the _more explicit DDL commands_.

# Global variable declaration:
[{required |optional}] [single]
global <name> -> <type>
[ "{"
[ default:= <expression> ; ]
[ <annotation-declarations> ]
...
"}" ]

# Computed global variable declaration:
[{required |optional}] [{single |multi}]
global <name> := <expression>;

**8.2. SDL 627**


### 8.2.10.3 Description

There two different forms ofglobaldeclaration, as shown in the syntax synopsis above. The first form is for defining
aglobalvariable that can be _set_ in a session. The second form is not directly set, but instead it is _computed_ based on
an expression, potentially deriving its value from other global variables.

The following options are available:

requiredIf specified, the global variable is considered _required_. It is an error for this variable to have an empty
value. If a global variable is declared _required_ , it must also declare a _default_ value.

optionalThis is the default qualifier assumed when no qualifier is specified, but it can also be specified explicitly.
The global variable is considered _optional_ , i.e. it is possible for the variable to have an empty value.

multiSpecifies that the global variable may have a set of values. Only _computed_ global variables can have this
qualifier.

singleSpecifies that the global variable must have at most a _single_ value. It is assumed that a global variable is
singleif nethermultinorsinglequalifier is specified. All non-computed global variables must be _single_.

<name>Specifies the name of the global variable. The name has to be either fully-qualified with the module name it
belongs to or it will be assumed to belong to the module in which it appears.

<type>The type must be a valid _type expression_ denoting a non-abstract scalar or a container type.

<name> := <expression>Defines a _computed_ global variable. The provided expression can be any valid EdgeQL
expression, including one referring to other global variables. The type of a _computed_ global variable is not
limited to scalar and container types, but also includes object types. So it is possible to use that to define a global
object variable based on an another global scalar variable.
For example:

```
# Global scalar variable that can be set in a session:
global current_user_id -> uuid;
# Global computed object based on that:
global current_user := (
selectUser filter.id = globalcurrent_user_id
);
```
The valid SDL sub-declarations are listed below:

default := <expression>Specifies the default value for the global variable as an EdgeQL expression. The default
value is used by the session if the value was not explicitly specified or by the client or was reset with the _reset_
command.

<annotation-declarations>Set global variable _annotation_ to a given _value_.

```
See also
Schema > Globals
DDL > Globals
```
**628 Chapter 8. Reference**


## 8.2.11 Access Policies

This section describes the SDL declarations pertaining to access policies.

### 8.2.11.1 Examples

Declare a schema where users can only see their own profiles:

# Declare some global variables to store "current user"
# information.
global current_user_id -> uuid;
global current_user := (
select Userfilter.id = globalcurrent_user_id
);

typeUser {
required propertyname -> str;
}

typeProfile {
linkowner -> User;

# Only allow reading to the owner, but also
# ensure that a user cannot set the "owner" link
# to anything but themselves.
access policyowner_only
allow all using (.owner =globalcurrent_user)
{ errmessage := 'Profile may only be accessed by the owner'; }
}

# Declare some global variables to store "current user"
# information.
global current_user_id: uuid;
global current_user := (
select Userfilter.id = globalcurrent_user_id
);

typeUser {
requiredname: str;
}

typeProfile {
owner: User;

# Only allow reading to the owner, but also
# ensure that a user cannot set the "owner" link
# to anything but themselves.
access policyowner_only
allow all using (.owner =globalcurrent_user);
}

**8.2. SDL 629**


### 8.2.11.2 Syntax

Define a new access policy corresponding to the _more explicit DDL commands_.

# Access policy used inside a type declaration:
access policy<name>
[ when(<condition>) ]
{ allow| deny} <action> [, <action> ... ]
[ using(<expr>) ]
[ <annotation-declarations> ] ;

# where <action> is one of
all
select
insert
delete
update [{read| write}]

# Access policy used inside a type declaration:
access policy<name>
[ when(<condition>) ]
{ allow| deny} <action> [, <action> ... ]
[ using(<expr>) ]
[ <annotation-declarations> ]
[ "{"
[ errmessage := value ; ]
"}" ] ;

# where <action> is one of
all
select
insert
delete
update [{read| write}]

### 8.2.11.3 Description

Access policies are used to implement object-level security and as such they are defined on object types. In practice
the access policies often work together with _global variables_.

Access policies are an opt-in feature, so once at least one access policy is defined for a given type, all access not
explicitly allowed by that policy becomes forbidden.

Any sub-type _extending_ a base type also inherits all the access policies of the base type.

The access policy declaration options are as follows:

<name>The name of the access policy.

when (<condition>)Specifies which objects this policy applies to. The<condition>has to be aboolexpression.

```
When omitted, it is assumed that this policy applies to all objects of a given type.
```
allowIndicates that qualifying objects should allow access under this policy.

**630 Chapter 8. Reference**


denyIndicates that qualifying objects should _not_ allow access under this policy. This flavor supersedes anyallow
policy and can be used to selectively deny access to a subset of objects that otherwise explicitly allows accessing
them.

allApply the policy to all actions. It is exactly equivalent to listingselect,insert,delete,updateactions
explicitly.

selectApply the policy to all selection queries. Note that any object that cannot be selected, cannot be modified
either. This makesselectthe most basic “visibility” policy.

insertApply the policy to all inserted objects. If a newly inserted object would violate this policy, an error is produced
instead.

deleteApply the policy to all objects about to be deleted. If an object does not allow access under this kind of policy,
it is not going to be considered by anydeletecommand.
Note that any object that cannot be selected, cannot be modified either.

update readApply the policy to all objects selected for an update. If an object does not allow access under this kind
of policy, it is not visible cannot be updated.
Note that any object that cannot be selected, cannot be modified either.

update writeApply the policy to all objects at the end of an update. If an updated object violates this policy, an
error is produced instead.
Note that any object that cannot be selected, cannot be modified either.

updateThis is just a shorthand forupdate readandupdate write.

```
Note that any object that cannot be selected, cannot be modified either.
```
using <expr>Specifies what the policy is with respect to a given eligible (based onwhenclause) object. The<expr>
has to be aboolexpression. The specific meaning of this value also depends on whether this policy flavor is
allowordeny.
When omitted, it is assumed that this policy applies to all eligible objects of a given type.

set errmessage := <value>Set a custom error message of<value>that is displayed when this access policy
prevents a write action.

<annotation-declarations>Set access policy _annotation_ to a given _value_.

```
See also
Schema > Access policies
DDL > Access policies
```
## 8.2.12 Functions

This section describes the SDL declarations pertaining to _functions_.

**8.2. SDL 631**


### 8.2.12.1 Example

Declare a custom function that concatenates the length of a string to the end of the that string:

functionfoo(s: str) -> str
using(
selects ++ <str>len(a)
);

### 8.2.12.2 Syntax

Define a new function corresponding to the _more explicit DDL commands_.

function<name> ([ <argspec> ] [, ... ]) -> <returnspec>
using( <edgeql> );

function<name> ([ <argspec> ] [, ... ]) -> <returnspec>
using<language> <functionbody> ;

function<name> ([ <argspec> ] [, ... ]) -> <returnspec>
"{"
[ <annotation-declarations> ]
[ volatility := {'Immutable' |'Stable'| 'Volatile'} ]
[using ( <expr> ) ; ]
[using <language> <functionbody> ; ]
[ ... ]
"}" ;

# where <argspec> is:

[ <argkind> ] <argname>: [ <typequal> ] <argtype> [ = <default> ]

# <argkind> is:

[ {variadic|named only } ]

# <typequal> is:

[ {set of |optional} ]

# and <returnspec> is:

[ <typequal> ] <rettype>

**632 Chapter 8. Reference**


### 8.2.12.3 Description

This declaration defines a new constraint with the following options:

<name>The name (optionally module-qualified) of the function to create.

<argkind>The kind of an argument:variadicornamed only.

```
If not specified, the argument is called positional.
Thevariadicmodifier indicates that the function takes an arbitrary number of arguments of the specified type.
The passed arguments will be passed as as array of the argument type. Positional arguments cannot follow a
variadicargument.variadicparameters cannot have a default value.
Thenamed onlymodifier indicates that the argument can only be passed using that specific name. Positional
arguments cannot follow anamed onlyargument.
```
<argname>The name of an argument. Ifnamed onlymodifier is used this argument _must_ be passed using this name
only.

<typequal>The type qualifier:set oforoptional.

```
Theset ofqualifier indicates that the function is taking the argument as a whole set , as opposed to being called
on the input product element-by-element.
Theoptionalqualifier indicates that the function will be called if the argument is an empty set. The default
behavior is to return an empty set if the argument is not marked asoptional.
```
<argtype>The data type of the function’s arguments (optionally module-qualified).

<default>An expression to be used as default value if the parameter is not specified. The expression has to be of a
type compatible with the type of the argument.

<rettype>The return data type (optionally module-qualified).

```
Theset ofmodifier indicates that the function will return a non-singleton set.
Theoptionalqualifier indicates that the function may return an empty set.
```
The valid SDL sub-declarations are listed below:

volatility := {'Immutable'| 'Stable' |'Volatile'}Function volatility determines how aggressively
the compiler can optimize its invocations.
If not explicitly specified the function volatility is set toVolatileby default.

- AVolatilefunction can modify the database and can return different results on successive calls with the
    same arguments.
- AStablefunction cannot modify the database and is guaranteed to return the same results given the same
    arguments _within a single statement_.
- AnImmutablefunction cannot modify the database and is guaranteed to return the same results given the
    same arguments _forever_.

using ( <expr> )Specified the body of the function.<expr>is an arbitrary EdgeQL expression.

using <language> <functionbody>A verbose version of theusingclause that allows to specify the language of
the function body.

- <language>is the name of the language that the function is implemented in. Currently can only beedgeql.
- <functionbody>is a string constant defining the function. It is often helpful to use _dollar quoting_ to write
    the function definition string.

<annotation-declarations>Set function _annotation_ to a given _value_.

**8.2. SDL 633**


The function name must be distinct from that of any existing function with the same argument types in the same module.
Functions of different argument types can share a name, in which case the functions are called _overloaded functions_.

```
See also
Schema > Functions
DDL > Functions
Reference > Function calls
Introspection > Functions
Cheatsheets > Functions
Tutorial > Advanced EdgeQL > User-Defined Functions
```
## 8.2.13 Triggers

This section describes the SDL declarations pertaining to _triggers_.

### 8.2.13.1 Example

Declare a trigger that inserts aLogobject for each newUserobject:

typeUser {
required name: str;

trigger log_insert after insert foreachdo (
insert Log {
action := 'insert',
target_name := __new__.name
}
);
}

### 8.2.13.2 Syntax

Define a new trigger corresponding to the _more explicit DDL commands_.

type<type-name> "{"
trigger <name>
after
{insert |update |delete} [, ...]
for{each |all}
do <expr>
"}"

**634 Chapter 8. Reference**


### 8.2.13.3 Description

This declaration defines a new trigger with the following options:

<type-name>The name (optionally module-qualified) of the type to be triggered on.

<name>The name of the trigger.

insert | update | delete [, ...]The query type (or types) to trigger on. Separate multiple values with com-
mas to invoke the same trigger for multiple types of queries.

eachThe expression will be evaluated once per modified object.__new__and__old__in this context within the
expression will refer to a single object.

allThe expression will be evaluted once for the entire query, even if multiple objects were modified.__new__and
__old__in this context within the expression refer to sets of the modified objects.

<expr>The expression to be evaluated when the trigger is invoked.

The trigger name must be distinct from that of any existing trigger on the same type.

```
See also
Schema > Triggers
DDL > Triggers
Introspection > Triggers
```
## 8.2.14 Mutation rewrites

This section describes the SDL declarations pertaining to _mutation rewrites_.

### 8.2.14.1 Example

Declare two mutation rewrites: one that sets acreatedproperty when a new object is inserted and one that sets a
modifiedproperty on each update:

typeUser {
created: datetime {
rewriteinsert using(datetime_of_statement());
}
modified: datetime {
rewriteupdate using(datetime_of_statement());
}
};

### 8.2.14.2 Syntax

Define a new mutation rewrite corresponding to the _more explicit DDL commands_.

rewrite {insert |update} [, ...]
using <expr>

Mutation rewrites must be defined inside a property or link block.

**8.2. SDL 635**


### 8.2.14.3 Description

This declaration defines a new trigger with the following options:

insert | update [, ...]The query type (or types) the rewrite runs on. Separate multiple values with commas
to invoke the same rewrite for multiple types of queries.

<expr>The expression to be evaluated to produce the new value of the property.

```
See also
Schema > Mutation rewrites
DDL > Mutation rewrites
Introspection > Mutation rewrites
```
## 8.2.15 Extensions

This section describes the SDL commands pertaining to _extensions_.

### 8.2.15.1 Syntax

Declare that the current schema enables a particular extension.

using extension <ExtensionName> ";"

### 8.2.15.2 Description

Extension declaration must be outside any _module block_ since extensions affect the entire database and not a specific
module.

### 8.2.15.3 Examples

Enable _GraphQL_ extension for the current schema:

using extension graphql;

Enable _EdgeQL over HTTP_ extension for the current database:

using extension edgeql_http;

## 8.2.16 Future Behavior

This section describes the SDL commands pertaining to _future_.

**636 Chapter 8. Reference**


### 8.2.16.1 Syntax

Declare that the current schema enables a particular future behavior.

usingfuture <FutureBehavior> ";"

### 8.2.16.2 Description

Future behavior declaration must be outside any _module block_ since this behavior affects the entire database and not a
specific module.

### 8.2.16.3 Examples

Enable simpler non-recursive access policy behavior _non-recursive access policy_ for the current schema:

using extension nonrecursive_access_policies;

## 8.3 DDL

### 8.3.1 Modules

This section describes the DDL commands pertaining to _modules_.

#### 8.3.1.1 Create module

```
eql-statement
```
Create a new module.

create module<name> [if not exists ];

There’s a _corresponding SDL declaration_ for a module, although in SDL a module declaration is likely to also include
that module’s content.

You may also create a nested module.

create module<parent-name>::<name> [ if not exists];

##### 8.3.1.1.1 Description

The commandcreate moduledefines a new module for the current database. The name of the new module must
be distinct from any existing module in the current database. Unlike _SDL module declaration_ thecreate module
command does not have sub-commands, as module contents are created separately.

**8.3. DDL 637**


##### 8.3.1.1.2 Parameters

if not existsNormally creating a module that already exists is an error, but with this flag the command will
succeed. It is useful for scripts that add something to a module or if the module is missing the module is created
as well.

##### 8.3.1.1.3 Examples

Create a new module:

create modulepayments;

Create a new nested module:

create modulepayments::currencies;

#### 8.3.1.2 Drop module

```
eql-statement
```
Remove a module.

drop module<name> ;

##### 8.3.1.2.1 Description

The commanddrop moduleremoves an existing module from the current database. All schema items and data con-
tained in the module are removed as well.

##### 8.3.1.2.2 Examples

Remove a module:

drop modulepayments;

### 8.3.2 Object Types

This section describes the DDL commands pertaining to _object types_.

**638 Chapter 8. Reference**


#### 8.3.2.1 Create type

```
eql-statement
eql-haswith
```
_Define_ a new object type.

[with <with-item> [, ...] ]
create [abstract]type<name> [extending <supertype> [, ...] ]
[ "{" <subcommand>; [...] "}" ] ;

# where <subcommand> is one of

```
create annotation <annotation-name> := <value>
create link<link-name> ...
create property <property-name> ...
create constraint <constraint-name> ...
create index on <index-expr>
```
##### 8.3.2.1.1 Description

The commandcreate typedefines a new object type for use in the current database.

If _name_ is qualified with a module name, then the type is created in that module, otherwise it is created in the current
module. The type name must be distinct from that of any existing schema item in the module.

##### 8.3.2.1.2 Parameters

Most sub-commands and options of this command are identical to the _SDL object type declaration_ , with some additional
features listed below:

with <with-item> [, ...]Alias declarations.

```
Thewithclause allows specifying module aliases that can be referenced by the command. See With block for
more information.
```
The following subcommands are allowed in thecreate typeblock:

create annotation <annotation-name> := <value>Set object type<annotation-name>to<value>.

```
Seecreate annotationfor details.
```
create link <link-name> ...Define a new link for this object type. Seecreate linkfor details.

create property <property-name> ...Define a new property for this object type. Seecreate propertyfor
details.

create constraint <constraint-name> ...Define a concrete constraint for this object type. Seecreate
constraintfor details.

create index on <index-expr>Define a new _index_ using _index-expr_ for this object type. Seecreate index
for details.

**8.3. DDL 639**


##### 8.3.2.1.3 Examples

Create an object typeUser:

create typeUser {
create property name -> str;
};

#### 8.3.2.2 Alter type

```
eql-statement
eql-haswith
```
Change the definition of an _object type_.

[with <with-item> [, ...] ]
alter type <name>
[ "{" <subcommand>; [...] "}" ] ;

[with <with-item> [, ...] ]
alter type <name> <subcommand> ;

# where <subcommand> is one of

```
rename to <newname>
extending <parent> [, ...]
create annotation <annotation-name> := <value>
alter annotation<annotation-name> := <value>
drop annotation <annotation-name>
create link<link-name> ...
alter link <link-name> ...
drop link <link-name> ...
create property <property-name> ...
alter property <property-name> ...
drop property <property-name> ...
create constraint <constraint-name> ...
alter constraint<constraint-name> ...
drop constraint <constraint-name> ...
create index on <index-expr>
drop index on <index-expr>
```
##### 8.3.2.2.1 Description

The commandalter typechanges the definition of an object type. _name_ must be a name of an existing object type,
optionally qualified with a module name.

**640 Chapter 8. Reference**


##### 8.3.2.2.2 Parameters

The following subcommands are allowed in thealter typeblock:

with <with-item> [, ...]Alias declarations.

```
Thewithclause allows specifying module aliases that can be referenced by the command. See With block for
more information.
```
<name>The name (optionally module-qualified) of the type being altered.

extending <parent> [, ...]Alter the supertype list. The full syntax of this subcommand is:

```
extending<parent> [, ...]
[first| last| before<exparent> |after <exparent> ]
```
```
This subcommand makes the type a subtype of the specified list of supertypes. The requirements for the parent-
child relationship are the same as when creating an object type.
It is possible to specify the position in the parent list using the following optional keywords:
```
- first– insert parent(s) at the beginning of the parent list,
- last– insert parent(s) at the end of the parent list,
- before <parent>– insert parent(s) before an existing _parent_ ,
- after <parent>– insert parent(s) after an existing _parent_.

alter annotation <annotation-name>;Alter object type annotation <annotation-name>. See alter
annotationfor details.

drop annotation <annotation-name>Remove object type<annotation-name>. Seedrop annotationfor
details.

alter link <link-name> ...Alter the definition of a link for this object type. Seealter linkfor details.

drop link <link-name>Remove a link item from this object type. Seedrop linkfor details.

alter property <property-name> ...Alter the definition of a property item for this object type. Seealter
propertyfor details.

drop property <property-name>Remove a property item from this object type. Seedrop propertyfor details.

alter constraint <constraint-name> ...Alter the definition of a constraint for this object type. Seealter
constraintfor details.

drop constraint <constraint-name>;Remove a constraint from this object type. Seedrop constraintfor
details.

drop index on <index-expr>Remove an _index_ defined as _index-expr_ from this object type. Seedrop indexfor
details.

All the subcommands allowed in thecreate typeblock are also valid subcommands foralter typeblock.

**8.3. DDL 641**


##### 8.3.2.2.3 Examples

Alter theUserobject type to makenamerequired:

alter type User {
alter propertyname {
set required;
}
};

#### 8.3.2.3 Drop type

```
eql-statement
eql-haswith
```
Remove the specified object type from the schema.

drop type<name> ;

##### 8.3.2.3.1 Description

The commanddrop typeremoves the specified object type from the schema. schema. All subordinate schema items
defined on this type, such as links and indexes, are removed as well.

##### 8.3.2.3.2 Examples

Remove theUserobject type:

drop typeUser;

```
See also
Schema > Object types
SDL > Object types
Introspection > Object types
Cheatsheets > Object types
```
### 8.3.3 Scalar Types

This section describes the DDL commands pertaining to _scalar types_.

**642 Chapter 8. Reference**


#### 8.3.3.1 Create scalar type

```
eql-statement
eql-haswith
```
_Define_ a new scalar type.

[with <with-item> [, ...] ]
create [abstract]scalar type<name> [extending<supertype> ]
[ "{" <subcommand>; [...] "}" ] ;

# where <subcommand> is one of

```
create annotation <annotation-name> := <value>
create constraint <constraint-name> ...
```
##### 8.3.3.1.1 Description

The commandcreate scalar typedefines a new scalar type for use in the current database.

If _name_ is qualified with a module name, then the type is created in that module, otherwise it is created in the current
module. The type name must be distinct from that of any existing schema item in the module.

If theabstractkeyword is specified, the created type will be _abstract_.

All non-abstract scalar types must have an underlying core implementation. For user-defined scalar types this means
thatcreate scalar typemust have another non-abstract scalar type as its _supertype_.

The most common use ofcreate scalar typeis to define a scalar subtype with constraints.

Most sub-commands and options of this command are identical to the _SDL scalar type declaration_. The following
subcommands are allowed in thecreate scalar typeblock:

create annotation <annotation-name> := <value>;Set scalar type’s<annotation-name>to<value>.

```
Seecreate annotationfor details.
```
create constraint <constraint-name> ...Define a new constraint for this scalar type. See create
constraintfor details.

##### 8.3.3.1.2 Examples

Create a new non-negative integer type:

create scalar typeposint64extending int64 {
create constraintmin_value(0);
};

Create a new enumerated type:

create scalar typeColor
extendingenum<Black, White, Red>;

**8.3. DDL 643**


#### 8.3.3.2 Alter scalar type

```
eql-statement
eql-haswith
```
Alter the definition of a _scalar type_.

[with <with-item> [, ...] ]
alter scalar type<name>
"{" <subcommand>; [...] "}" ;

# where <subcommand> is one of

```
rename to <newname>
extending ...
create annotation <annotation-name> := <value>
alter annotation<annotation-name> := <value>
drop annotation <annotation-name>
create constraint <constraint-name> ...
alter constraint<constraint-name> ...
drop constraint <constraint-name> ...
```
##### 8.3.3.2.1 Description

The commandalter scalar typechanges the definition of a scalar type. _name_ must be a name of an existing scalar
type, optionally qualified with a module name.

The following subcommands are allowed in thealter scalar typeblock:

rename to <newname>;Change the name of the scalar type to _newname_.

extending ...Alter the supertype list. It works the same way as inalter type.

alter annotation <annotation-name>;Alter scalar type<annotation-name>. Seealter annotationfor
details.

drop annotation <annotation-name>Remove scalar type’s<annotation-name>from<value>. Seedrop
annotationfor details.

alter constraint <constraint-name> ...Alter the definition of a constraint for this scalar type. Seealter
constraintfor details.

drop constraint <constraint-name>Remove a constraint from this scalar type. Seedrop constraintfor
details.

All the subcommands allowed in thecreate scalar typeblock are also valid subcommands foralter scalar
typeblock.

**644 Chapter 8. Reference**


##### 8.3.3.2.2 Examples

Define a new constraint on a scalar type:

alter scalar typeposint64 {
create constraintmax_value(100);
};

Add one more label to an enumerated type:

alter scalar typeColor
extendingenum<Black, White, Red, Green>;

#### 8.3.3.3 Drop scalar type

```
eql-statement
eql-haswith
```
Remove a scalar type.

[with <with-item> [, ...] ]
drop scalar type<name> ;

##### 8.3.3.3.1 Description

The commanddrop scalar typeremoves a scalar type.

##### 8.3.3.3.2 Parameters

**_name_** The name (optionally qualified with a module name) of an existing scalar type.

##### 8.3.3.3.3 Example

Remove a scalar type:

drop scalar typeposint64;

### 8.3.4 Links

This section describes the DDL commands pertaining to _links_.

**8.3. DDL 645**


#### 8.3.4.1 Create link

```
eql-statement
eql-haswith
```
_Define_ a new link.

[with <with-item> [, ...] ]
{create|alter}type <TypeName> "{"
[ ... ]
create [{required|optional}] [{single |multi}]
link<name>
[extending <base> [, ...] ] -> <type>
[ "{" <subcommand>; [...] "}" ] ;
[ ... ]
"}"

# Computed link form:

[with <with-item> [, ...] ]
{create|alter}type <TypeName> "{"
[ ... ]
create [{required|optional}] [{single |multi}]
link<name> := <expression>;
[ ... ]
"}"

# Abstract link form:

[with <with-item> [, ...] ]
create abstract link[<module>::]<name> [extending <base> [, ...]]
[ "{" <subcommand>; [...] "}" ]

# where <subcommand> is one of

```
set default:= <expression>
setreadonly := {true |false}
create annotation <annotation-name> := <value>
create property <property-name> ...
create constraint <constraint-name> ...
on target delete<action>
reset on target delete
create index on <index-expr>
```
**646 Chapter 8. Reference**


##### 8.3.4.1.1 Description

The combinations ofcreate type ... create linkandalter type ... create linkdefine a new concrete
link for a given object type.

There are three forms ofcreate link, as shown in the syntax synopsis above. The first form is the canonical definition
form, the second form is a syntax shorthand for defining a _computed link_ , and the third is a form to define an abstract
link item. The abstract form allows creating the link in the specified<module>. Concrete link forms are always created
in the same module as the containing object type.

##### 8.3.4.1.2 Parameters

Most sub-commands and options of this command are identical to the _SDL link declaration_. The following subcom-
mands are allowed in thecreate linkblock:

set default := <expression>Specifies the default value for the link as an EdgeQL expression. Other than a
slight syntactical difference this is the same as the corresponding SDL declaration.

set readonly := {true | false}Specifies whether the link is considered _read-only_. Other than a slight syntac-
tical difference this is the same as the corresponding SDL declaration.

create annotation <annotation-name> := <value>;Add an annotation <annotation-name> set to
<value>to the type.
Seecreate annotationfor details.

create property <property-name> ...Define a concrete property item for this link. Seecreate property
for details.

create constraint <constraint-name> ...Define a concrete constraint for this link. See create
constraintfor details.

on target delete <action>Valid values for _action_ are:restrict,DELETE SOURCE,allow, anddeferred
restrict. The details of whaton target deleteoptions mean are described in _this section_.

reset on target deleteReset the delete policy to either the inherited value or to the defaultrestrict. The
details of whaton target deleteoptions mean are described in _this section_.

create index on <index-expr>Define a new _index_ using _index-expr_ for this link. Seecreate indexfor details.

##### 8.3.4.1.3 Examples

Define a new linkfriendson theUserobject type:

alter type User {
create multi linkfriends -> User
};

Define a new _computed link_ special_groupon theUserobject type, which contains all the friends from the same
town:

alter type User {
create linkspecial_group := (
select__source__.friends
filter.town = __source__.town
)
};

**8.3. DDL 647**


Define a new abstract linkorderableand a concrete linkintereststhat extends it, inheriting itsweightproperty:

create abstract linkorderable {
create property weight -> std::int64
};

alter type User {
create multi linkinterestsextending orderable -> Interest
};

#### 8.3.4.2 Alter link

```
eql-statement
eql-haswith
```
Change the definition of a _link_.

[with <with-item> [, ...] ]
{create|alter}type <TypeName> "{"
[ ... ]
alter link <name>
[ "{" ] <subcommand>; [...] [ "}" ];
[ ... ]
"}"

[with <with-item> [, ...] ]
alter abstract link [<module>::]<name>
[ "{" ] <subcommand>; [...] [ "}" ];

# where <subcommand> is one of

```
set default:= <expression>
reset default
setreadonly := {true |false}
reset readonly
rename to <newname>
extending ...
set required
set optional
reset optionality
set single
set multi
reset cardinality
set type <typename> [using (<conversion-expr)]
reset type
using (<computed-expr>)
create annotation <annotation-name> := <value>
alter annotation<annotation-name> := <value>
drop annotation <annotation-name>
create property <property-name> ...
alter property <property-name> ...
(continues on next page)
```
**648 Chapter 8. Reference**


```
(continued from previous page)
drop property <property-name> ...
create constraint <constraint-name> ...
alter constraint<constraint-name> ...
drop constraint <constraint-name> ...
on target delete<action>
create index on <index-expr>
drop index on <index-expr>
```
##### 8.3.4.2.1 Description

The combinations of``create type ... alter link``andalter type ... alter linkchange the definition of a con-
crete link for a given object type.

The commandalter abstract linkchanges the definition of an abstract link item. _name_ must be the identity of
an existing abstract link, optionally qualified with a module name.

##### 8.3.4.2.2 Parameters

The following subcommands are allowed in thealter linkblock:

rename to <newname>Change the name of the link item to _newname_. All concrete links inheriting from this links
are also renamed.

extending ...Alter the link parent list. The full syntax of this subcommand is:

```
extending<name> [, ...]
[first| last| before<parent> | after<parent> ]
```
```
This subcommand makes the link a child of the specified list of parent links. The requirements for the parent-child
relationship are the same as when creating a link.
It is possible to specify the position in the parent list using the following optional keywords:
```
- first– insert parent(s) at the beginning of the parent list,
- last– insert parent(s) at the end of the parent list,
- before <parent>– insert parent(s) before an existing _parent_ ,
- after <parent>– insert parent(s) after an existing _parent_.

set requiredMake the link _required_.

set optionalMake the link no longer _required_ (i.e. make it _optional_ ).

reset optionalityReset the optionality of the link to the default value (optional), or, if the link is inherited, to
the value inherited from links in supertypes.

set singleChange the link set’s maximum cardinality to _one_. Only valid for concrete links.

set multiRemove the upper limit on the link set’s cardinality. Only valid for concrete links.

reset cardinalityReset the link set’s maximum cardinality to the default value (single), or to the value inherited
from the link’s supertypes.

set type <typename> [using (<conversion-expr)]Change the type of the link to the specified<typename>.
The optionalusingclause specifies a conversion expression that computes the new link value from the old. The

**8.3. DDL 649**


```
conversion expression must return a singleton set and is evaluated on each element ofmultilinks. Ausing
clause must be provided if there is no implicit or assignment cast from old to new type.
```
reset typeReset the type of the link to be strictly the inherited type. This only has an effect on links that have been
_overloaded_ in order to change their inherited type. It is an error toreset typeon a link that is not inherited.

using (<computed-expr>)Change the expression of a _computed link_. Only valid for concrete links.

alter annotation <annotation-name>;Alter link annotation<annotation-name>. Seealter annotation
for details.

drop annotation <annotation-name>;Remove link item’s annotation <annotation-name>. See drop
annotationfor details.

alter property <property-name> ...Alter the definition of a property item for this link. Seealter
propertyfor details.

drop property <property-name>;Remove a property item from this link. Seedrop propertyfor details.

alter constraint <constraint-name> ...Alter the definition of a constraint for this link. Seealter
constraintfor details.

drop constraint <constraint-name>;Remove a constraint from this link. Seedrop constraintfor details.

drop index on <index-expr>Remove an _index_ defined on _index-expr_ from this link. Seedrop indexfor details.

reset defaultRemove the default value from this link, or reset it to the value inherited from a supertype, if the link
is inherited.

reset readonlySet link writability to the default value (writable), or, if the link is inherited, to the value inherited
from links in supertypes.

All the subcommands allowed in thecreate linkblock are also valid subcommands foralter linkblock.

##### 8.3.4.2.3 Examples

On the object typeUser, set thetitleannotation of itsfriendslink to"Friends":

alter type User {
alter linkfriendscreate annotationtitle := "Friends";
};

Rename the abstract linkorderabletosorted:

alter abstract link orderablerename tosorted;

Redefine the _computed link_ special_groupto be those who have some shared interests:

alter type User {
create linkspecial_group := (
select__source__.friends
# at least one of the friend's interests
# must match the user's
filter.interests IN __source__.interests
)
};

**650 Chapter 8. Reference**


#### 8.3.4.3 Drop link

```
eql-statement
eql-haswith
```
Remove the specified link from the schema.

[with <with-item> [, ...] ]
alter type <TypeName> "{"
[ ... ]
drop link <name>
[ ... ]
"}"

[with <with-item> [, ...] ]
drop abstract link[<module>]::<name>

##### 8.3.4.3.1 Description

The combination ofalter typeanddrop linkremoves the specified link from its containing object type. All links
that inherit from this link are also removed.

The commanddrop abstract linkremoves an existing link item from the database schema. All subordinate schema
items defined on this link, such as link properties and constraints, are removed as well.

##### 8.3.4.3.2 Examples

Remove linkfriendsfrom object typeUser:

alter type Userdrop linkfriends;

Drop abstract linkorderable:

drop abstract linkorderable;

```
See also
Schema > Links
SDL > Links
Introspection > Object types
```
### 8.3.5 Properties

This section describes the DDL commands pertaining to _properties_.

**8.3. DDL 651**


#### 8.3.5.1 Create property

```
eql-statement
eql-haswith
```
_Define_ a new property.

[with <with-item> [, ...] ]
{create|alter} {type|link} <SourceName> "{"
[ ... ]
create [{required|optional}] [{single |multi}]
property<name>
[extending <base> [, ...] ] -> <type>
[ "{" <subcommand>; [...] "}" ] ;
[ ... ]
"}"

# Computed property form:

[with <with-item> [, ...] ]
{create|alter} {type|link} <SourceName> "{"
[ ... ]
create [{required|optional}] [{single |multi}]
property<name> := <expression>;
[ ... ]
"}"

# Abstract property form:

[with <with-item> [, ...] ]
create abstract property[<module>::]<name> [extending <base> [, ...]]
[ "{" <subcommand>; [...] "}" ]

# where <subcommand> is one of

```
set default:= <expression>
setreadonly := {true |false}
create annotation <annotation-name> := <value>
create constraint <constraint-name> ...
```
##### 8.3.5.1.1 Description

The combination{create|alter} {type|link} ... create propertydefines a new concrete property for a
given object type or link.

There are three forms ofcreate property, as shown in the syntax synopsis above. The first form is the canonical
definition form, the second form is a syntax shorthand for defining a _computed property_ , and the third is a form to
define an abstract property item. The abstract form allows creating the property in the specified<module>. Concrete
property forms are always created in the same module as the containing object or property.

**652 Chapter 8. Reference**


##### 8.3.5.1.2 Parameters

Most sub-commands and options of this command are identical to the _SDL property declaration_. The following sub-
commands are allowed in thecreate propertyblock:

set default := <expression>Specifies the default value for the property as an EdgeQL expression. Other than
a slight syntactical difference this is the same as the corresponding SDL declaration.

set readonly := {true | false}Specifies whether the property is considered _read-only_. Other than a slight
syntactical difference this is the same as the corresponding SDL declaration.

create annotation <annotation-name> := <value>Set property<annotation-name>to<value>.

```
Seecreate annotationfor details.
```
create constraintDefine a concrete constraint on the property. Seecreate constraintfor details.

##### 8.3.5.1.3 Examples

Define a new linkaddresson theUserobject type:

alter type User {
create property address -> str
};

Define a new _computed property_ number_of_connectionson theUserobject type counting the number of interests:

alter type User {
create property number_of_connections :=
count(.interests)
};

Define a new abstract linkorderablewithweightproperty:

create abstract linkorderable {
create property weight -> std::int64
};

#### 8.3.5.2 Alter property

```
eql-statement
eql-haswith
```
Change the definition of a _property_.

[with <with-item> [, ...] ]
{create |alter} {type| link} <source> "{"
[ ... ]
alter property <name>
[ "{" ] <subcommand>; [...] [ "}" ];
[ ... ]
"}"

```
(continues on next page)
```
**8.3. DDL 653**


```
(continued from previous page)
```
[with <with-item> [, ...] ]
alter abstract property [<module>::]<name>
[ "{" ] <subcommand>; [...] [ "}" ];

# where <subcommand> is one of

```
set default:= <expression>
reset default
setreadonly := {true |false}
reset readonly
rename to <newname>
extending ...
set required
set optional
reset optionalily
set single
set multi
reset cardinality
set type <typename> [using (<conversion-expr)]
reset type
using (<computed-expr>)
create annotation <annotation-name> := <value>
alter annotation<annotation-name> := <value>
drop annotation <annotation-name>
create constraint <constraint-name> ...
alter constraint<constraint-name> ...
drop constraint <constraint-name> ...
```
##### 8.3.5.2.1 Description

The combination{create|alter} {type|link} ... create propertydefines a new concrete property for a
given object type or link.

The commandalter abstract propertychanges the definition of an abstract property item.

##### 8.3.5.2.2 Parameters

<source>The name of an object type or link on which the property is defined. May be optionally qualified with
module.

<name>The unqualified name of the property to modify.

<module>Optional name of the module to create or alter the abstract property in. If not specified, the current module
is used.

The following subcommands are allowed in thealter linkblock:

rename to <newname>Change the name of the property to<newname>. All concrete properties inheriting from this
property are also renamed.

extending ...Alter the property parent list. The full syntax of this subcommand is:

**654 Chapter 8. Reference**


```
extending<name> [, ...]
[first| last| before<parent> | after<parent> ]
```
```
This subcommand makes the property a child of the specified list of parent property items. The requirements for
the parent-child relationship are the same as when creating a property.
It is possible to specify the position in the parent list using the following optional keywords:
```
- first– insert parent(s) at the beginning of the parent list,
- last– insert parent(s) at the end of the parent list,
- before <parent>– insert parent(s) before an existing _parent_ ,
- after <parent>– insert parent(s) after an existing _parent_.

set requiredMake the property _required_.

set optionalMake the property no longer _required_ (i.e. make it _optional_ ).

reset optionalilyReset the optionality of the property to the default value (optional), or, if the property is
inherited, to the value inherited from properties in supertypes.

set singleChange the maximum cardinality of the property set to _one_. Only valid for concrete properties.

set multiChange the maximum cardinality of the property set to _greater than one_. Only valid for concrete proper-
ties.

reset cardinalityReset the maximum cardinality of the property to the default value (single), or, if the property
is inherited, to the value inherited from properties in supertypes.

set type <typename> [using (<conversion-expr)]Change the type of the property to the specified
<typename>. The optionalusingclause specifies a conversion expression that computes the new property
value from the old. The conversion expression must return a singleton set and is evaluated on each element of
multiproperties. Ausingclause must be provided if there is no implicit or assignment cast from old to new
type.

reset typeReset the type of the property to the type inherited from properties of the same name in supertypes. It is
an error toreset typeon a property that is not inherited.

using (<computed-expr>)Change the expression of a _computed property_. Only valid for concrete properties.

alter annotation <annotation-name>;Alter property annotation <annotation-name>. See alter
annotationfor details.

drop annotation <annotation-name>;Remove property annotation <annotation-name>. See drop
annotationfor details.

alter constraint <constraint-name> ...Alter the definition of a constraint for this property. Seealter
constraintfor details.

drop constraint <constraint-name>;Remove a constraint from this property. Seedrop constraintfor de-
tails.

reset defaultRemove the default value from this property, or reset it to the value inherited from a supertype, if the
property is inherited.

reset readonlySet property writability to the default value (writable), or, if the property is inherited, to the value
inherited from properties in supertypes.

All the subcommands allowed in thecreate propertyblock are also valid subcommands foralter property
block.

**8.3. DDL 655**


##### 8.3.5.2.3 Examples

Set thetitleannotation of propertyaddressof object typeUserto"Home address":

alter type User {
alter propertyaddress
create annotationtitle := "Home address";
};

Add a maximum-length constraint to propertyaddressof object typeUser:

alter type User {
alter propertyaddress {
create constraintmax_len_value(500);
};
};

Rename the propertyweightof linkorderabletosort_by:

alter abstract link orderable {
alter propertyweight rename tosort_by;
};

Redefine the _computed property_ number_of_connectionsto be the number of friends:

alter type User {
alter propertynumber_of_connectionsusing (
count(.friends)
)
};

#### 8.3.5.3 Drop property

```
eql-statement
eql-haswith
```
Remove a _property_ from the schema.

[with <with-item> [, ...] ]
{create|alter}type <TypeName> "{"
[ ... ]
drop link <name>
[ ... ]
"}"

[with <with-item> [, ...] ]
drop abstract property<name> ;

**656 Chapter 8. Reference**


**8.3.5.3.1 Description**

The combinationalter {type|link} drop propertyremoves the specified property from its containing object
type or link. All properties that inherit from this property are also removed.

The commanddrop abstract propertyremoves the specified abstract property item from the schema.

**8.3.5.3.2 Example**

Remove propertyaddressfrom typeUser:

alter type User {
drop propertyaddress;
};

```
See also
Schema > Properties
SDL > Properties
Introspection > Object types
```
#### 8.3.6 Aliases

This section describes the DDL commands pertaining to _expression aliases_.

**8.3.6.1 Create alias**

```
eql-statement
eql-haswith
```
_Define_ a new expression alias in the schema.

[with <with-item> [, ...] ]
create alias<alias-name> := <alias-expr> ;

[with <with-item> [, ...] ]
create alias<alias-name> "{"
using<alias-expr>;
[create annotation <attr-name> := <attr-value>; ... ]
"}" ;

# where <with-item> is:

[ <module-alias> := ]module <module-name>

**8.3. DDL 657**


**8.3.6.1.1 Description**

The commandcreate aliasdefines a new expression alias in the schema. The schema-level expression aliases are
functionally equivalent to expression aliases defined in a statement _with block_ , but are available to all queries using the
schema and can be introspected.

If _name_ is qualified with a module name, then the alias is created in that module, otherwise it is created in the current
module. The alias name must be distinct from that of any existing schema item in the module.

**8.3.6.1.2 Parameters**

Most sub-commands and options of this command are identical to the _SDL alias declaration_ , with some additional
features listed below:

[ <module-alias> := ] module <module-name>An optional list of module alias declarations to be used in the
alias definition.

create annotation <annotation-name> := <value>;An optional list of annotation values for the alias. See
create annotationfor details.

**8.3.6.1.3 Example**

Create a new alias:

create aliasSuperusers := (
select UserfilterUser.groups.name = 'Superusers'
);

**8.3.6.2 Drop alias**

```
eql-statement
eql-haswith
```
Remove an expression alias from the schema.

[with <with-item> [, ...] ]
drop alias <alias-name> ;

**8.3.6.2.1 Description**

The commanddrop aliasremoves an expression alias from the schema.

**658 Chapter 8. Reference**


**8.3.6.2.2 Parameters**

**_alias-name_** The name (optionally qualified with a module name) of an existing expression alias.

**8.3.6.2.3 Example**

Remove an alias:

drop alias SuperUsers;

```
See also
Schema > Aliases
SDL > Aliases
Cheatsheets > Aliases
```
#### 8.3.7 Indexes

This section describes the DDL commands pertaining to _indexes_.

**8.3.7.1 Create index**

```
eql-statement
```
_Define_ an new index for a given object type or link.

create index on ( <index-expr> )
[except ( <except-expr> ) ]
[ "{" <subcommand>; [...] "}" ] ;

# where <subcommand> is one of

```
create annotation <annotation-name> := <value>
```
**8.3.7.1.1 Description**

The commandcreate indexconstructs a new index for a given object type or link using _index-expr_.

**8.3.7.1.2 Parameters**

Most sub-commands and options of this command are identical to the _SDL index declaration_. There’s only one sub-
command that is allowed in thecreate indexblock:

create annotation <annotation-name> := <value>Set object type<annotation-name>to<value>.

```
Seecreate annotationfor details.
```
**8.3. DDL 659**


**8.3.7.1.3 Example**

Create an object typeUserwith an indexednameproperty:

create typeUser {
create property name -> str {
set default:='';
};

create index on (.name);
};

**8.3.7.2 Alter index**

```
eql-statement
```
Alter the definition of an _index_.

alter index on( <index-expr> ) [ except( <except-expr> ) ]
[ "{" <subcommand>; [...] "}" ] ;

# where <subcommand> is one of

```
create annotation <annotation-name> := <value>
alter annotation<annotation-name> := <value>
drop annotation <annotation-name>
```
**8.3.7.2.1 Description**

The commandalter indexis used to change the _annotations_ of an index. The _index-expr_ is used to identify the
index to be altered.

**8.3.7.2.2 Parameters**

on ( <index-expr> )The specific expression for which the index is made. Note also that<index-expr>itself
has to be parenthesized.

The following subcommands are allowed in thealter indexblock:

create annotation <annotation-name> := <value>Set index <annotation-name> to <value>. See
create annotationfor details.

alter annotation <annotation-name>;Alter index<annotation-name>. Seealter annotationfor de-
tails.

drop annotation <annotation-name>;Remove constraint<annotation-name>. Seedrop annotationfor
details.

**660 Chapter 8. Reference**


**8.3.7.2.3 Example**

Add an annotation to the index on thenameproperty of object typeUser:

alter type User {
alter index on(.name) {
create annotationtitle := "User name index";
};
};

**8.3.7.3 Drop index**

```
eql-statement
```
Remove an index from a given schema item.

drop index on( <index-expr> ) [ except( <except-expr> ) ];

**8.3.7.3.1 Description**

The commanddrop indexremoves an index from a schema item.

on ( <index-expr> )The specific expression for which the index was made.

This statement can only be used as a subdefinition in another DDL statement.

**8.3.7.3.2 Example**

Drop thenameindex from theUserobject type:

alter type User {
drop index on(.name);
};

```
See also
Schema > Indexes
SDL > Indexes
Introspection > Indexes
```
#### 8.3.8 Constraints

This section describes the DDL commands pertaining to _constraints_.

**8.3. DDL 661**


**8.3.8.1 Create abstract constraint**

```
eql-statement
eql-haswith
```
_Define_ a new abstract constraint.

[with [ <module-alias> := ]module<module-name> ]
create abstract constraint<name> [ ( [<argspec>] [, ...] ) ]
[ on ( <subject-expr> ) ]
[ extending<base> [, ...] ]
"{" <subcommand>; [...] "}" ;

# where <argspec> is:

```
[ <argname>: ] <argtype>
```
# where <subcommand> is one of

```
using <constr-expression>
seterrmessage := <error-message>
create annotation <annotation-name> := <value>
```
**8.3.8.1.1 Description**

The commandcreate abstract constraintdefines a new abstract constraint.

If _name_ is qualified with a module name, then the constraint is created in that module, otherwise it is created in the
current module. The constraint name must be distinct from that of any existing schema item in the module.

**8.3.8.1.2 Parameters**

Most sub-commands and options of this command are identical to the _SDL constraint declaration_ , with some additional
features listed below:

[ <module-alias> := ] module <module-name>An optional list of module alias declarations to be used in the
migration definition. When _module-alias_ is not specified, _module-name_ becomes the effective current module
and is used to resolve all unqualified names.

set errmessage := <error_message>An optional string literal defining the error message template that is raised
when the constraint is violated. Other than a slight syntactical difference this is the same as the corresponding
SDL declaration.

create annotation <annotation-name> := <value>;Set constraint<annotation-name>to<value>.

```
Seecreate annotationfor details.
```
**662 Chapter 8. Reference**


**8.3.8.1.3 Example**

Create an abstract constraint “uppercase” which checks if the subject is a string in upper case.

create abstract constraintuppercase {
create annotationtitle := "Upper case constraint";
using(str_upper(__subject__) = __subject__);
seterrmessage := "{__subject__} is not in upper case";
};

**8.3.8.2 Alter abstract constraint**

```
eql-statement
eql-haswith
```
Alter the definition of an _abstract constraint_.

[with [ <module-alias> := ]module<module-name> ]
alter abstract constraint<name>
"{" <subcommand>; [...] "}" ;

# where <subcommand> is one of

```
rename to <newname>
using <constr-expression>
seterrmessage := <error-message>
reset errmessage
create annotation <annotation-name> := <value>
alter annotation<annotation-name> := <value>
drop annotation <annotation-name>
```
**8.3.8.2.1 Description**

The commandalter abstract constraintchanges the definition of an abstract constraint item. _name_ must be a
name of an existing abstract constraint, optionally qualified with a module name.

**8.3.8.2.2 Parameters**

[ <module-alias> := ] module <module-name>An optional list of module alias declarations to be used in the
migration definition. When _module-alias_ is not specified, _module-name_ becomes the effective current module
and is used to resolve all unqualified names.

<name>The name (optionally module-qualified) of the constraint to alter.

The following subcommands are allowed in thealter abstract constraintblock:

rename to <newname>Change the name of the constraint to _newname_. All concrete constraints inheriting from this
constraint are also renamed.

alter annotation <annotation-name>;Alter constraint<annotation-name>. Seealter annotationfor
details.

**8.3. DDL 663**


drop annotation <annotation-name>;Remove constraint<annotation-name>. Seedrop annotationfor
details.

reset errmessage;Remove the error message from this abstract constraint. The error message specified in the base
abstract constraint will be used instead.

All the subcommands allowed in acreate abstract constraintblock are also valid subcommands for analter
abstract constraintblock.

**8.3.8.2.3 Example**

Rename the abstract constraint “uppercase” to “upper_case”:

alter abstract constraintuppercaserename to upper_case;

**8.3.8.3 Drop abstract constraint**

```
eql-statement
eql-haswith
```
Remove an _abstract constraint_ from the schema.

[with [ <module-alias> := ]module<module-name> ]
drop abstract constraint<name> ;

**8.3.8.3.1 Description**

The commanddrop abstract constraintremoves an existing abstract constraint item from the database schema.
If any schema items depending on this constraint exist, the operation is refused.

**8.3.8.3.2 Parameters**

[ <module-alias> := ] module <module-name>An optional list of module alias declarations to be used in the
migration definition. When _module-alias_ is not specified, _module-name_ becomes the effective current module
and is used to resolve all unqualified names.

<name>The name (optionally module-qualified) of the constraint to remove.

**8.3.8.3.3 Example**

Drop abstract constraintupper_case:

drop abstract constraintupper_case;

**664 Chapter 8. Reference**


**8.3.8.4 Create constraint**

```
eql-statement
```
Define a concrete constraint on the specified schema item.

[with [ <module-alias> := ]module<module-name> ]
create [delegated] constraint<name>
[ ( [<argspec>] [, ...] ) ]
[ on ( <subject-expr> ) ]
[ except ( <except-expr> ) ]
"{" <subcommand>; [...] "}" ;

# where <argspec> is:

```
[ <argname>: ] <argvalue>
```
# where <subcommand> is one of

```
seterrmessage := <error-message>
create annotation <annotation-name> := <value>
```
**8.3.8.4.1 Description**

The commandcreate constraintdefines a new concrete constraint. It can only be used in the context ofcreate
scalar type,alter scalar type,create property,alter property,create link, oralter link.

_name_ must be a name (optionally module-qualified) of previously defined abstract constraint.

**8.3.8.4.2 Parameters**

Most sub-commands and options of this command are identical to the _SDL constraint declaration_ , with some additional
features listed below:

[ <module-alias> := ] module <module-name>An optional list of module alias declarations to be used in the
migration definition. When _module-alias_ is not specified, _module-name_ becomes the effective current module
and is used to resolve all unqualified names.

set errmessage := <error_message>An optional string literal defining the error message template that is raised
when the constraint is violated. Other than a slight syntactical difference this is the same as the corresponding
SDL declaration.

create annotation <annotation-name> := <value>;An optional list of annotations for the constraint. See
create annotationfor details.

**8.3. DDL 665**


**8.3.8.4.3 Example**

Create a “score” property on the “User” type with a minimum value constraint:

alter type Usercreate propertyscore -> int64 {
create constraintmin_value(0)
};

Create a Vector with a maximum magnitude:

create typeVector {
create required propertyx -> float64;
create required propertyy -> float64;
create constraint expression ON(
__subject__.x^2 + __subject__.y^2 < 25
);
}

**8.3.8.5 Alter constraint**

```
eql-statement
```
Alter the definition of a concrete constraint on the specified schema item.

[with [ <module-alias> := ]module<module-name> [, ...] ]
alter constraint<name>
[ ( [<argspec>] [, ...] ) ]
[ on ( <subject-expr> ) ]
[ except ( <except-expr> ) ]
"{" <subcommand>; [ ... ] "}" ;

# -- or --

[with [ <module-alias> := ]module<module-name> [, ...] ]
alter constraint<name>
[ ( [<argspec>] [, ...] ) ]
[ on ( <subject-expr> ) ]
<subcommand> ;

# where <subcommand> is one of:

```
set delegated
set not delegated
seterrmessage := <error-message>
reset errmessage
create annotation <annotation-name> := <value>
alter annotation<annotation-name>
drop annotation <annotation-name>
```
**666 Chapter 8. Reference**


**8.3.8.5.1 Description**

The commandalter constraintchanges the definition of a concrete constraint. As for mostaltercommands,
both single- and multi-command forms are supported.

**8.3.8.5.2 Parameters**

[ <module-alias> := ] module <module-name>An optional list of module alias declarations to be used in the
migration definition. When _module-alias_ is not specified, _module-name_ becomes the effective current module
and is used to resolve all unqualified names.

<name>The name (optionally module-qualified) of the concrete constraint that is being altered.

<argspec>A list of constraint arguments as specified at the time ofcreate constraint.

on ( <subject-expr> )A expression defining the _subject_ of the constraint as specified at the time ofcreate
constraint.

The following subcommands are allowed in thealter constraintblock:

set delegatedMakes the constraint delegated.

set not delegatedMakes the constraint non-delegated.

rename to <newname>Change the name of the constraint to<newname>.

alter annotation <annotation-name>;Alter constraint<annotation-name>. Seealter annotationfor
details.

drop annotation <annotation-name>;Remove an _annotation_. Seedrop annotationfor details.

reset errmessage;Remove the error message from this constraint. The error message specified in the abstract
constraint will be used instead.

All the subcommands allowed in thecreate constraintblock are also valid subcommands foralter constraint
block.

**8.3.8.5.3 Example**

Change the error message on the minimum value constraint on the property “score” of the “User” type:

alter type Useralter propertyscore
alter constraintmin_value(0)
seterrmessage :='Score cannot be negative';

**8.3.8.6 Drop constraint**

```
eql-statement
eql-haswith
```
Remove a concrete constraint from the specified schema item.

[with [ <module-alias> := ]module<module-name> [, ...] ]
drop constraint <name>
[ ( [<argspec>] [, ...] ) ]
(continues on next page)

**8.3. DDL 667**


```
(continued from previous page)
[ on ( <subject-expr> ) ]
[ except ( <except-expr> ) ] ;
```
**8.3.8.6.1 Description**

The commanddrop constraintremoves the specified constraint from its containing schema item.

**8.3.8.6.2 Parameters**

[ <module-alias> := ] module <module-name>An optional list of module alias declarations to be used in the
migration definition. When _module-alias_ is not specified, _module-name_ becomes the effective current module
and is used to resolve all unqualified names.

<name>The name (optionally module-qualified) of the concrete constraint to remove.

<argspec>A list of constraint arguments as specified at the time ofcreate constraint.

on ( <subject-expr> )A expression defining the _subject_ of the constraint as specified at the time ofcreate
constraint.

**8.3.8.6.3 Example**

Remove constraint “min_value” from the property “score” of the “User” type:

alter type Useralter propertyscore
drop constraint min_value(0);

```
See also
Schema > Constraints
SDL > Constraints
Introspection > Constraints
Standard Library > Constraints
Tutorial > Advanced EdgeQL > Constraints
```
#### 8.3.9 Annotations

This section describes the DDL commands pertaining to _annotations_.

**8.3.9.1 Create abstract annotation**

```
eql-statement
```
_Define_ a new annotation.

[with <with-item> [, ...] ]
create abstract [inheritable]annotation <name>
[ "{"
create annotation<annotation-name> := <value> ;
(continues on next page)

**668 Chapter 8. Reference**


```
(continued from previous page)
[...]
"}" ] ;
```
**8.3.9.1.1 Description**

The commandcreate abstract annotationdefines a new annotation for use in the current database.

If _name_ is qualified with a module name, then the annotation is created in that module, otherwise it is created in the
current module. The annotation name must be distinct from that of any existing schema item in the module.

The annotations are non-inheritable by default. That is, if a schema item has an annotation defined on it, the descendants
of that schema item will not automatically inherit the annotation. Normal inheritance behavior can be turned on by
declaring the annotation with theinheritablequalifier.

Most sub-commands and options of this command are identical to the _SDL annotation declaration_. There’s only one
subcommand that is allowed in thecreate annotationblock:

create annotation <annotation-name> := <value>Annotations can also have annotations. Set the
<annotation-name>of the enclosing annotation to a specific<value>. Seecreate annotationfor details.

**8.3.9.1.2 Example**

Declare an annotationextrainfo.

create abstract annotationextrainfo;

**8.3.9.2 Alter abstract annotation**

```
eql-statement
```
Change the definition of an _annotation_.

alter abstract annotation<name>
[ "{" ] <subcommand>; [...] [ "}" ];

# where <subcommand> is one of

```
rename to <newname>
create annotation <annotation-name> := <value>
alter annotation<annotation-name> := <value>
drop annotation <annotation-name>
```
**8.3. DDL 669**


**8.3.9.2.1 Description**

alter abstract annotationchanges the definition of an abstract annotation.

**8.3.9.2.2 Parameters**

<name>The name (optionally module-qualified) of the annotation to alter.

The following subcommands are allowed in thealter abstract annotationblock:

rename to <newname>Change the name of the annotation to<newname>.

alter annotation <annotation-name>;Annotations can also have annotations. Change<annotation-name>
to a specific<value>. Seealter annotationfor details.

drop annotation <annotation-name>;Annotations can also have annotations. Remove annotation
<annotation-name>. Seedrop annotationfor details.

All the subcommands allowed in thecreate abstract annotationblock are also valid subcommands foralter
annotationblock.

**8.3.9.2.3 Examples**

Rename an annotation:

alter abstract annotationextrainfo
rename toextra_info;

**8.3.9.3 Drop abstract annotation**

```
eql-statement
```
Remove a _schema annotation_.

[with <with-item> [, ...] ]
drop abstract annotation<name> ;

**8.3.9.3.1 Description**

The commanddrop abstract annotationremoves an existing schema annotation from the database schema. Note
that theinheritablequalifier is not necessary in this statement.

**8.3.9.3.2 Example**

Drop the annotationextra_info:

drop abstract annotationextra_info;

**670 Chapter 8. Reference**


**8.3.9.4 Create annotation**

```
eql-statement
```
Define an annotation value for a given schema item.

create annotation<annotation-name> := <value>

**8.3.9.4.1 Description**

The commandcreate annotationdefines an annotation for a schema item.

<annotation-name>refers to the name of a defined annotation, and<value>must be a constant EdgeQL expression
evaluating into a string.

This statement can only be used as a subcommand in another DDL statement.

**8.3.9.4.2 Example**

Create an object typeUserand set itstitleannotation to"User type".

create typeUser {
create annotationtitle := "User type";
};

**8.3.9.5 Alter annotation**

```
eql-statement
```
Alter an annotation value for a given schema item.

alter annotation<annotation-name> := <value>

**8.3.9.5.1 Description**

The commandalter annotationalters an annotation value on a schema item.

<annotation-name>refers to the name of a defined annotation, and<value>must be a constant EdgeQL expression
evaluating into a string.

This statement can only be used as a subcommand in another DDL statement.

**8.3.9.5.2 Example**

Alter an object typeUserand alter the value of its previously settitleannotation to"User type".

alter type User {
alter annotationtitle := "User type";
};

**8.3. DDL 671**


**8.3.9.6 Drop annotation**

```
eql-statement
```
Remove an annotation from a given schema item.

drop annotation <annotation-name> ;

**8.3.9.6.1 Description**

The commanddrop annotationremoves an annotation value from a schema item.

<annotaion_name>refers to the name of a defined annotation. The annotation value does not have to exist on a
schema item.

This statement can only be used as a subcommand in another DDL statement.

**8.3.9.6.2 Example**

Drop thetitleannotation from theUserobject type:

alter type User {
drop annotation title;
};

```
See also
Schema > Annotations
SDL > Annotations
Cheatsheets > Annotations
Introspection > Object types
```
#### 8.3.10 Globals

This section describes the DDL commands pertaining to global variables.

**8.3.10.1 Create global**

```
eql-statement
eql-haswith
```
_Declare_ a new global variable.

[with <with-item> [, ...] ]
create [{required| optional}] [single]
global <name> -> <type>
[ "{" <subcommand>; [...] "}" ] ;

# Computed global variable form:

[with <with-item> [, ...] ]
(continues on next page)

**672 Chapter 8. Reference**


```
(continued from previous page)
```
create [{required| optional}] [{single| multi}]
global <name> := <expression>;

# where <subcommand> is one of

```
set default:= <expression>
create annotation <annotation-name> := <value>
```
**8.3.10.1.1 Description**

There two different forms ofglobaldeclaration, as shown in the syntax synopsis above. The first form is for defining
aglobalvariable that can be _set_ in a session. The second form is not directly set, but instead it is _computed_ based on
an expression, potentially deriving its value from other global variables.

**8.3.10.1.2 Parameters**

Most sub-commands and options of this command are identical to the _SDL global variable declaration_. The following
subcommands are allowed in thecreate globalblock:

set default := <expression>Specifies the default value for the global variable as an EdgeQL expression. The
default value is used by the session if the value was not explicitly specified or by the _reset_ command.

create annotation <annotation-name> := <value>Set global variable<annotation-name>to<value>.

```
Seecreate annotationfor details.
```
**8.3.10.1.3 Examples**

Define a new global propertycurrent_user_id:

create globalcurrent_user_id -> uuid;

Define a new _computed_ global propertycurrent_userbased on the previously definedcurrent_user_id:

create globalcurrent_user := (
select Userfilter.id = globalcurrent_user_id
);

**8.3.10.2 Alter global**

```
eql-statement
eql-haswith
```
Change the definition of a global variable.

[with <with-item> [, ...] ]
alter global<name>
[ "{" <subcommand>; [...] "}" ] ;

```
(continues on next page)
```
**8.3. DDL 673**


```
(continued from previous page)
```
# where <subcommand> is one of

```
set default:= <expression>
reset default
rename to <newname>
set required
set optional
reset optionalily
set single
set multi
reset cardinality
set type <typename>reset to default
using (<computed-expr>)
create annotation <annotation-name> := <value>
alter annotation<annotation-name> := <value>
drop annotation <annotation-name>
```
**8.3.10.2.1 Description**

The commandalter globalchanges the definition of a global variable.

**8.3.10.2.2 Parameters**

<name>The name of the global variable to modify.

The following subcommands are allowed in thealter globalblock:

reset defaultRemove the default value from this global variable.

rename to <newname>Change the name of the global variable to<newname>.

set requiredMake the global variable _required_.

set optionalMake the global variable no longer _required_ (i.e. make it _optional_ ).

reset optionalilyReset the optionality of the global variable to the default value (optional).

set singleChange the maximum cardinality of the global variable to _one_.

set multiChange the maximum cardinality of the global variable set to _greater than one_. Only valid for computed
global variables.

reset cardinalityReset the maximum cardinality of the global variable to the default value (single), or, if the
property is computed, to the value inferred from its expression.

set type <typename> reset to defaultChange the type of the global variable to the specified<typename>.
Thereset to defaultclause is mandatory and it specifies that the variable will be reset to its default value
after this command.

using (<computed-expr>)Change the expression of a computed global variable. Only valid for computed vari-
ables.

alter annotation <annotation-name>;Alter global variable annotation<annotation-name>. Seealter
annotationfor details.

drop annotation <annotation-name>;Remove global variable<annotation-name>. Seedrop annotation
for details.

**674 Chapter 8. Reference**


All the subcommands allowed in thecreate globalblock are also valid subcommands foralter globalblock.

**8.3.10.2.3 Examples**

Set thedescriptionannotation of global variablecurrent_user:

alter globalcurrent_user
create annotationdescription :=
'Current User as specified by the global ID';

Make thecurrent_user_idglobal variablerequired:

alter globalcurrent_user_id {
set required;
# A required global variable MUST have a default value.
set default:= <uuid>'00ea8eaa-02f9-11ed-a676-6bd11cc6c557';
}

**8.3.10.3 Drop global**

```
eql-statement
eql-haswith
```
Remove a global variable from the schema.

[with <with-item> [, ...] ]
drop global<name> ;

**8.3.10.3.1 Description**

The commanddrop globalremoves the specified global variable from the schema.

**8.3.10.3.2 Example**

Remove thecurrent_userglobal variable:

drop globalcurrent_user;

```
See also
Schema > Globals
SDL > Globals
```
**8.3. DDL 675**


#### 8.3.11 Access Policies

This section describes the DDL commands pertaining to access policies.

**8.3.11.1 Create access policy**

```
eql-statement
```
_Declare_ a new object access policy.

[with <with-item> [, ...] ]
{create | alter}type <TypeName> "{"
[ ... ]
create access policy<name>
[when (<condition>) ; ]
{allow |deny} <action> [, <action> ... ; ]
[using (<expr>) ; ]
[create annotation <annotation-name> := <value> ; ]
"}"

# where <action> is one of
all
select
insert
delete
update [{read| write}]

[with with-item [, ...] ]
{create | alter}type TypeName "{"
[ ... ]
create access policyname
[when (condition) ; ]
{allow |deny} action [, action ... ; ]
[using (expr) ; ]
[create annotation annotation-name := value ; ]
[ "{"
[seterrmessage := value ; ]
"}" ; ]
"}"

# where <action> is one of
all
select
insert
delete
update [{read| write}]

**676 Chapter 8. Reference**


**8.3.11.1.1 Description**

The combination{create | alter} type ... create access policydefines a new access policy for a given
object type.

**8.3.11.1.2 Parameters**

Most sub-commands and options of this command are identical to the _SDL access policy declaration_.

<name>The name of the access policy.

when (<condition>)Specifies which objects this policy applies to. The<condition>has to be aboolexpression.

```
When omitted, it is assumed that this policy applies to all objects of a given type.
```
allowIndicates that qualifying objects should allow access under this policy.

denyIndicates that qualifying objects should _not_ allow access under this policy. This flavor supersedes anyallow
policy and can be used to selectively deny access to a subset of objects that otherwise explicitly allows accessing
them.

allApply the policy to all actions. It is exactly equivalent to listingselect,insert,delete,updateactions
explicitly.

selectApply the policy to all selection queries. Note that any object that cannot be selected, cannot be modified
either. This makesselectthe most basic “visibility” policy.

insertApply the policy to all inserted objects. If a newly inserted object would violate this policy, an error is produced
instead.

deleteApply the policy to all objects about to be deleted. If an object does not allow access under this kind of policy,
it is not going to be considered by anydeletecommand.
Note that any object that cannot be selected, cannot be modified either.

update readApply the policy to all objects selected for an update. If an object does not allow access under this kind
of policy, it is not visible cannot be updated.
Note that any object that cannot be selected, cannot be modified either.

update writeApply the policy to all objects at the end of an update. If an updated object violates this policy, an
error is produced instead.
Note that any object that cannot be selected, cannot be modified either.

updateThis is just a shorthand forupdate readandupdate write.

```
Note that any object that cannot be selected, cannot be modified either.
```
using <expr>Specifies what the policy is with respect to a given eligible (based onwhenclause) object. The<expr>
has to be aboolexpression. The specific meaning of this value also depends on whether this policy flavor is
allowordeny.
When omitted, it is assumed that this policy applies to all eligible objects of a given type.

The following subcommands are allowed in thecreate access policyblock:

set errmessage := <value>Set a custom error message of<value>that is displayed when this access policy
prevents a write action.

create annotation <annotation-name> := <value>Set access policy annotation<annotation-name>to
<value>.
Seecreate annotationfor details.

**8.3. DDL 677**


**8.3.11.2 Alter access policy**

```
eql-statement
```
_Declare_ a new object access policy.

[with <with-item> [, ...] ]
alter type <TypeName> "{"
[ ... ]
alter access policy <name> "{"
[when (<condition>) ; ]
[reset when ; ]
{allow |deny} <action> [, <action> ... ; ]
[using (<expr>) ; ]
[reset expression; ]
[create annotation <annotation-name> := <value> ; ]
[alter annotation<annotation-name> := <value> ; ]
[drop annotation <annotation-name>; ]
"}"
"}"

# where <action> is one of
all
select
insert
delete
update [{read| write}]

[with <with-item> [, ...] ]
alter type <TypeName> "{"
[ ... ]
alter access policy <name> "{"
[when (<condition>) ; ]
[reset when ; ]
{allow |deny} <action> [, <action> ... ; ]
[using (<expr>) ; ]
[seterrmessage := value ; ]
[reset expression; ]
[create annotation <annotation-name> := <value> ; ]
[alter annotation<annotation-name> := <value> ; ]
[drop annotation <annotation-name>; ]
"}"
"}"

# where <action> is one of
all
select
insert
delete
update [{read| write}]

**678 Chapter 8. Reference**


**8.3.11.2.1 Description**

The combination{create | alter} type ... create access policydefines a new access policy for a given
object type.

**8.3.11.2.2 Parameters**

The parameters describing the action policy are identical to the parameters used bycreate action policy. There
are a handful of additional subcommands that are allowed in thecreate access policyblock:

reset whenClear thewhen (<condition>)so that the policy applies to all objects of a given type. This is equiv-
alent towhen (true).

reset expressionClear theusing (<condition>)so that the policy always passes. This is equivalent tousing
(true).

alter annotation <annotation-name>;Alter access policy annotation<annotation-name>. Seealter
annotationfor details.

drop annotation <annotation-name>;Remove access policy annotation<annotation-name>. Seedrop
annotationfor details.

All the subcommands allowed in thecreate access policyblock are also valid subcommands foralter access
policyblock.

**8.3.11.3 Drop access policy**

```
eql-statement
```
Remove an access policy from an object type.

[with <with-item> [, ...] ]
alter type <TypeName> "{"
[ ... ]
drop access policy <name> ;
"}"

**8.3.11.3.1 Description**

The combinationalter type ... drop access policyremoves the specified access policy from a given object
type.

```
See also
Schema > Access policies
SDL > Access policies
```
**8.3. DDL 679**


#### 8.3.12 Functions

This section describes the DDL commands pertaining to _functions_.

**8.3.12.1 Create function**

```
eql-statement
eql-haswith
```
_Define_ a new function.

[with <with-item> [, ...] ]
create function <name> ([ <argspec> ] [, ... ]) -> <returnspec>
using( <expr> );

[with <with-item> [, ...] ]
create function <name> ([ <argspec> ] [, ... ]) -> <returnspec>
using<language> <functionbody> ;

[with <with-item> [, ...] ]
create function <name> ([ <argspec> ] [, ... ]) -> <returnspec>
"{" <subcommand> [, ...] "}" ;

# where <argspec> is:

```
[ <argkind> ] <argname>: [ <typequal> ] <argtype> [ = <default> ]
```
# <argkind> is:

```
[ {variadic| named only} ]
```
# <typequal> is:

```
[ {set of | optional} ]
```
# and <returnspec> is:

```
[ <typequal> ] <rettype>
```
# and <subcommand> is one of

```
setvolatility := {'Immutable' |'Stable'| 'Volatile'} ;
create annotation <annotation-name> := <value> ;
using ( <expr> ) ;
using <language> <functionbody> ;
```
**680 Chapter 8. Reference**


**8.3.12.1.1 Description**

The commandcreate functiondefines a new function. If _name_ is qualified with a module name, then the function
is created in that module, otherwise it is created in the current module.

The function name must be distinct from that of any existing function with the same argument types in the same module.
Functions of different argument types can share a name, in which case the functions are called _overloaded functions_.

**8.3.12.1.2 Parameters**

Most sub-commands and options of this command are identical to the _SDL function declaration_ , with some additional
features listed below:

set volatility := {'Immutable'| 'Stable' |'Volatile'} Function volatility determines how aggres-
sively the compiler can optimize its invocations. Other than a slight syntactical difference this is the same as the
corresponding SDL declaration.

create annotation <annotation-name> := <value>Set the function’s<annotation-name>to<value>.

```
Seecreate annotationfor details.
```
**8.3.12.1.3 Examples**

Define a function returning the sum of its arguments:

create function mysum(a: int64, b: int64) -> int64
using(
select a + b
);

The same, but using a variadic argument and an explicit language:

create function mysum(variadicargv: int64) -> int64
usingedgeql $$
select sum(array_unpack(argv))
$$;

Define a function using the block syntax:

create function mysum(a: int64, b: int64) -> int64 {
using(
selecta + b
);
create annotationtitle := "My sum function.";
};

**8.3. DDL 681**


**8.3.12.2 Alter function**

```
eql-statement
eql-haswith
```
Change the definition of a function.

[with <with-item> [, ...] ]
alter function<name> ([ <argspec> ] [, ... ]) "{"
<subcommand> [, ...]
"}"

# where <argspec> is:

[ <argkind> ] <argname>: [ <typequal> ] <argtype> [ = <default> ]

# and <subcommand> is one of

```
setvolatility := {'Immutable' |'Stable'| 'Volatile'} ;
reset volatility ;
rename to <newname> ;
create annotation <annotation-name> := <value> ;
alter annotation<annotation-name> := <value> ;
drop annotation <annotation-name> ;
using ( <expr> ) ;
using <language> <functionbody> ;
```
**8.3.12.2.1 Description**

The commandalter functionchanges the definition of a function. The command allows to change annotations, the
volatility level, and other attributes.

**8.3.12.2.2 Subcommands**

The following subcommands are allowed in thealter functionblock in addition to the commands common to the
create function:

reset volatilityRemove explicitly specified volatility in favor of the volatility inferred from the function body.

rename to <newname>Change the name of the function to _newname_.

alter annotation <annotation-name>;Alter function<annotation-name>. Seealter annotationfor de-
tails.

drop annotation <annotation-name>;Remove function<annotation-name>. Seedrop annotationfor
details.

reset errmessage;Remove the error message from this abstract constraint. The error message specified in the base
abstract constraint will be used instead.

**682 Chapter 8. Reference**


**8.3.12.2.3 Example**

create function mysum(a: int64, b: int64) -> int64 {
using(
selecta + b
);
create annotationtitle := "My sum function.";
};

alter functionmysum(a: int64, b: int64) {
setvolatility :='Immutable';
DROP ANNOTATION title;
};

alter functionmysum(a: int64, b: int64) {
using(
select(a + b) * 100
)
};

**8.3.12.3 Drop function**

```
eql-statement
eql-haswith
```
Remove a function.

[with <with-item> [, ...] ]
drop function<name> ([ <argspec> ] [, ... ]);

# where <argspec> is:

[ <argkind> ] <argname>: [ <typequal> ] <argtype> [ = <default> ]

**8.3.12.3.1 Description**

The commanddrop functionremoves the definition of an existing function. The argument types to the function
must be specified, since there can be different functions with the same name.

**8.3.12.3.2 Parameters**

<name>The name (optionally module-qualified) of an existing function.

<argname>The name of an argument used in the function definition.

<argmode>The mode of an argument:set oforoptionalorvariadic.

<argtype>The data type(s) of the function’s arguments (optionally module-qualified), if any.

**8.3. DDL 683**


**8.3.12.3.3 Example**

Remove themysumfunction:

drop functionmysum(a: int64, b: int64);

```
See also
Schema > Functions
SDL > Functions
Reference > Function calls
Introspection > Functions
Cheatsheets > Functions
Tutorial > Advanced EdgeQL > User-Defined Functions
```
#### 8.3.13 Triggers

This section describes the DDL commands pertaining to _triggers_.

**8.3.13.1 Create trigger**

```
eql-statement
```
_Define_ a new trigger.

{create |alter} type<type-name> "{"
create trigger <name>
after
{insert |update |delete} [, ...]
for{each |all}
do <expr>
"}"

**8.3.13.1.1 Description**

The commandcreate triggernested undercreate typeoralter typedefines a new trigger for a given object
type.

The trigger name must be distinct from that of any existing trigger on the same type.

**8.3.13.1.2 Parameters**

The options of this command are identical to the _SDL trigger declaration_.

**684 Chapter 8. Reference**


**8.3.13.1.3 Example**

Declare a trigger that inserts aLogobject for each newUserobject:

alter type User {
create trigger log_insertafter insert foreach do(
insert Log {
action := 'insert',
target_name := __new__.name
}
);
};

**8.3.13.2 Drop trigger**

```
eql-statement
```
Remove a trigger.

alter type <type-name> "{"
drop trigger <name>;
"}"

**8.3.13.2.1 Description**

The commanddrop triggerinside analter typeblock removes the definition of an existing trigger on the speci-
fied type.

**8.3.13.2.2 Parameters**

<type-name>The name (optionally module-qualified) of the type being triggered on.

<name>The name of the trigger.

**8.3.13.2.3 Example**

Remove thelog_inserttrigger on theUsertype:

alter type User {
drop trigger log_insert;
};

```
See also
Schema > Triggers
SDL > Triggers
Introspection > Triggers
```
**8.3. DDL 685**


#### 8.3.14 Mutation Rewrites

This section describes the DDL commands pertaining to _mutation rewrites_.

**8.3.14.1 Create rewrite**

```
eql-statement
```
_Define_ a new mutation rewrite.

When creating a new property or link:

{create |alter} type<type-name> "{"
create { property|link} <prop-or-link-name> -> <type> "{"
create rewrite {insert| update} [, ...]
using <expr>
"}" ;
"}" ;

When altering an existing property or link:

{create |alter} type<type-name> "{"
alter {property| link} <prop-or-link-name> "{"
create rewrite {insert| update} [, ...]
using <expr>
"}" ;
"}" ;

**8.3.14.1.1 Description**

The commandcreate rewritenested undercreate typeoralter typeand then undercreate property/
linkoralter property/linkdefines a new mutation rewrite for the given property or link on the given object.

**8.3.14.1.2 Parameters**

<type-name>The name (optionally module-qualified) of the type containing the rewrite.

<prop-or-link-name>The name (optionally module-qualified) of the property or link being rewritten.

insert | update [, ...]The query type (or types) that are rewritten. Separate multiple values with commas to
invoke the same rewrite for multiple types of queries.

**8.3.14.1.3 Examples**

Declare two mutation rewrites on new properties: one that sets acreatedproperty when a new object is inserted and
one that sets amodifiedproperty on each update:

alter type User {
create property created -> datetime {
create rewriteinsert using(datetime_of_statement());
};
(continues on next page)

**686 Chapter 8. Reference**


(continued from previous page)
create property modified -> datetime {
create rewriteupdate using(datetime_of_statement());
};
};

**8.3.14.2 Drop rewrite**

```
eql-statement
```
Remove a mutation rewrite.

alter type <type-name> "{"
alter property <prop-or-link-name> "{"
droprewrite {insert |update} ;
"}" ;
"}" ;

**8.3.14.2.1 Description**

The commanddrop rewriteinside analter typeblock and further inside analter propertyblock removes
the definition of an existing mutation rewrite on the specified property or link of the specified type.

**8.3.14.2.2 Parameters**

<type-name>The name (optionally module-qualified) of the type containing the rewrite.

<prop-or-link-name>The name (optionally module-qualified) of the property or link being rewritten.

insert | update [, ...]The query type (or types) that are rewritten. Separate multiple values with commas to
invoke the same rewrite for multiple types of queries.

**8.3.14.2.3 Example**

Remove theinsertrewrite of thecreatedproperty on theUsertype:

alter type User {
alter property created {
droprewriteinsert;
};
};

```
See also
Schema > Mutation rewrites
SDL > Mutation rewrites
Introspection > Mutation rewrites
```
**8.3. DDL 687**


#### 8.3.15 Extensions

This section describes the DDL commands pertaining to _extensions_.

**8.3.15.1 Create extension**

```
eql-statement
```
Enable a particular extension for the current schema.

create extension<ExtensionName> ";"

There’s a _corresponding SDL declaration_ for enabling an extension, which is the recommended way of doing this.

**8.3.15.1.1 Description**

The commandcreate extensionenables the specified extension for the current database.

**8.3.15.1.2 Examples**

Enable _GraphQL_ extension for the current schema:

create extensiongraphql;

Enable _EdgeQL over HTTP_ extension for the current database:

create extensionedgeql_http;

**8.3.15.2 drop extension**

```
eql-statement
```
Disable an extension.

drop extension<ExtensionName> ";"

**8.3.15.2.1 Description**

The commanddrop extensiondisables a currently active extension for the current database.

**8.3.15.2.2 Examples**

Disable _GraphQL_ extension for the current schema:

drop extensiongraphql;

Disable _EdgeQL over HTTP_ extension for the current database:

drop extensionedgeql_http;

**688 Chapter 8. Reference**


#### 8.3.16 Future Behavior

This section describes the DDL commands pertaining to _future_.

**8.3.16.1 Create future**

```
eql-statement
```
Enable a particular future behavior for the current schema.

create future <FutureBehavior> ";"

There’s a _corresponding SDL declaration_ for enabling a future behavior, which is the recommended way of doing this.

**8.3.16.1.1 Description**

The commandcreate futureenables the specified future behavior for the current database.

**8.3.16.1.2 Examples**

Enable simpler non-recursive access policy behavior _non-recursive access policy_ for the current schema:

create future nonrecursive_access_policies;

**8.3.16.2 drop future**

```
eql-statement
```
Stop importing future behavior prior to the EdgeDB version in which it appears.

dropfuture <FutureBehavior> ";"

**8.3.16.2.1 Description**

The commanddrop futuredisables a currently active future behavior for the current database. However, this is only
possible for versions of EdgeDB when the behavior in question is not officially introduced. Once a particular behavior
is introduced as the standard behavior in an EdgeDB release, it cannot be disabled. Running this command will simply
denote that no special action is needed to enable it in this case.

**8.3.16.2.2 Examples**

Disable simpler non-recursive access policy behavior _non-recursive access policy_ for the current schema. This will
make access policy restrictions apply to the expressions defining other access policies:

dropfuture nonrecursive_access_policies;

Once EdgeDB 3.0 is released there is no more need for enabling non-recursive access policy behavior anymore. So the
above command will simply indicate that the databse no longer does anything non-standard.

**8.3. DDL 689**


#### 8.3.17 Migrations

This section describes the DDL commands pertaining to migrations.

**Note:** Like all DDL commands,start migrationand other migration commands are considered low-level. Users
are encouraged to use the built-in _migration tools_ instead.

**8.3.17.1 Start migration**

```
eql-statement
```
Start a migration block.

start migration to"{"
<sdl-declaration> ;
[ ... ]
"}" ;

**8.3.17.1.1 Parameters**

<sdl-declaration>Complete schema defined with the declarative _EdgeDB schema definition language_.

**8.3.17.1.2 Description**

The commandstart migrationdefines a migration of the schema to a new state. The target schema state is described
using _SDL_ and describes the entire schema. This is important to remember when creating a migration to add a few
more things to an existing schema as all the existing schema objects and the new ones must be included in thestart
migrationcommand. Objects that aren’t included in the command will be removed from the new schema (which may
result in data loss).

This command also starts a transaction block if not inside a transaction already.

While inside a migration block, all issued EdgeQL statements are not executed immediately and are instead recorded
to be part of the migration script. Aside from normal EdgeQL commands the following special migration commands
are available:

- describe current migration– return a list of statements currently recorded as part of the migration;
- populate migration– auto-populate the migration with system-generated DDL statements to achieve the
    target schema state;
- abort migration– abort the migration block and discard the migration;
- commit migration– commit the migration by executing the migration script statements and recording the
    migration into the system migration log.

**690 Chapter 8. Reference**


**8.3.17.1.3 Examples**

Create a new migration to a target schema specified by the EdgeDB Schema syntax:

start migration to{
module default{
typeUser {
propertyusername -> str;
};
};
};

**8.3.17.2 create migration**

```
eql-statement
```
Create a new migration using an explicit EdgeQL script.

create migration"{"
<edgeql-statement> ;
[ ... ]
"}" ;

**8.3.17.2.1 Parameters**

<edgeql-statement>Any valid EdgeQL statement, except database, role, configure, migration, or
transactionstatements.

**8.3.17.2.2 Description**

The commandcreate migrationexecutes all the nested EdgeQL commands and records the migration into the
system migration log.

**8.3.17.2.3 Examples**

Create a new migration to a target schema specified by the EdgeDB Schema syntax:

create migration{
create typedefault::User {
create property username -> str;
}
};

**8.3. DDL 691**


**8.3.17.3 Abort migration**

```
eql-statement
```
Abort the current migration block and discard the migration.

abort migration ;

**8.3.17.3.1 Description**

The commandabort migrationis used to abort a migration block started bystart migration. Issuingabort
migrationoutside of a migration block is an error.

**8.3.17.3.2 Examples**

Start a migration block and then abort it:

start migration to{
module default{
typeUser;
};
};

abort migration;

**8.3.17.4 Populate migration**

```
eql-statement
```
Populate the current migration with system-generated statements.

populate migration;

**8.3.17.4.1 Description**

The commandpopulate migrationis used within a migration block started bystart migrationto automatically
fill the migration with system-generated statements to achieve the desired target schema state. If the system is unable
to automatically find a satisfactory sequence of statements to perform the migration, an error is returned. Issuing
populate migrationoutside of a migration block is also an error.

```
Warning: The statements generated bypopulate migrationmay drop schema objects, which may result in
data loss. Make sure to inspect the generated migration usingdescribe current migrationbefore running
commit migration!
```
**692 Chapter 8. Reference**


**8.3.17.4.2 Examples**

Start a migration block and populate it with auto-generated statements.

start migration to{
module default{
typeUser;
};
};

populate migration;

**8.3.17.5 Describe current migration**

```
eql-statement
```
Describe the migration in the current migration block.

describe current migration[ as{ddl|json} ];

**8.3.17.5.1 Description**

The commanddescribe current migrationgenerates a description of the migration in the current migration block
in the specified output format:

as ddlShow a sequence of statements currently recorded as part of the migration using valid _DDL_ syntax. The output
will indicate if the current migration is fully defined, i.e. the recorded statements bring the schema to the state
specified bystart migration.

as jsonProvide a machine-readable description of the migration using the following JSON format:

```
{
// Name of the parent migration
"parent": "<parent-migraiton-name>",
```
```
// Whether the confirmed DDL makes the migration complete,
// i.e. there are no more statements to issue.
"complete": {true|false},
```
```
// List of confirmed migration statements
"confirmed": [
"<stmt text>",
...
],
```
```
// The variants of the next statement
// suggested by the system to advance
// the migration script.
"proposed": {
"statements": [{
"text": "<stmt text template>"
}],
(continues on next page)
```
**8.3. DDL 693**


```
(continued from previous page)
"required-user-input": [
{
"placeholder": "<placeholder variable>",
"prompt": "<statement prompt>",
},
...
],
"confidence": (0..1), // confidence coefficient
"prompt": "<operation prompt>",
"prompt_id": "<prompt id>",
// Whether the operationisconsidered to be non-destructive.
"data_safe": {true|false}
}
}
```
```
Where:
<stmt text>Regular statement text.
<stmt text template>Statement text template with interpolation points using the\(name)syntax.
<placeholder variable>The name of an interpolation variable in the statement text template for which the
user prompt is given.
<statement prompt>The text of a user prompt for an interpolation variable.
<operation prompt>Prompt for the proposed migration step.
<prompt id>An opaque string identifier for a particular operation prompt. The client should not repeat
prompts with the same prompt id.
```
**8.3.17.6 Commit migration**

```
eql-statement
```
Commit the current migration to the database.

commit migration;

**8.3.17.6.1 Description**

The commandcommit migrationexecutes all the commands defined by the current migration and records the mi-
gration as the most recent migration in the database.

Issuingcommit migrationoutside of a migration block initiated bystart migrationis an error.

**694 Chapter 8. Reference**


**8.3.17.6.2 Example**

Create and execute the current migration:

commit migration;

**8.3.17.7 Reset schema to initial**

```
eql-statement
```
Reset the database schema to its initial state.

reset schema to inital ;

```
Warning: This command will drop all entities and, as a consequence, all data. You won’t want to use this statement
on a production instance unless you want to lose all that instance’s data.
```
**8.3.17.8 Migration Rewrites**

Migration rewrites allow you to change the migration history as long as your final schema matches the current database
schema.

**8.3.17.8.1 Start migration rewrite**

Start a migration rewrite.

start migration rewrite ;

Once the migration rewrite is started, you can run any arbitrary DDL until you are ready to _commit_ your new migration
history. The most useful DDL in this context will be _create migration_ statements, which will allow you to create a
sequence of migrations that will become your new migration history.

**8.3.17.8.2 Declare savepoint**

Establish a new savepoint within the current migration rewrite.

declare savepoint<savepoint-name> ;

**Parameters**

<savepoint-name>The name which will be used to identify the new savepoint if you need to later release it or roll
back to it.

**8.3. DDL 695**


**8.3.17.8.3 Release savepoint**

Destroys a savepoint previously defined in the current migration rewrite.

release savepoint<savepoint-name> ;

**Parameters**

<savepoint-name>The name of the savepoint to be released.

**8.3.17.8.4 Rollback to savepoint**

Rollback to the named savepoint.

rollback to savepoint<savepoint-name> ;

All changes made after the savepoint are discarded. The savepoint remains valid and can be rolled back to again later,
if needed.

**Parameters**

<savepoint-name>The name of the savepoint to roll back to.

**8.3.17.8.5 Rollback**

Rollback the entire migration rewrite.

rollback;

All updates made within the transaction are discarded.

**8.3.17.8.6 Commit migration rewrite**

Commit a migration rewrite.

commit migrationrewrite ;

```
edb-alt-title Data Definition Language
```
EdgeQL includes a set of _data definition language_ (DDL) commands that manipulate the database’s schema. DDL
is the low-level equivalent to _EdgeDB schema definition language_. You can execute DDL commands against your
database, just like any other EdgeQL query.

edgedb>create typePerson {
....... create required propertyname -> str;
....... };
OK:CREATE TYPE
edgedb>create typeMovie {
....... create required propertytitle -> str;
(continues on next page)

**696 Chapter 8. Reference**


```
(continued from previous page)
```
....... create required linkdirector -> Person;
....... };
OK:CREATE TYPE

In DDL, the _order_ of commands is important. In the example above, you couldn’t createMoviebeforePerson, because
Moviecontains a link toPerson.

Under the hood, all migrations are represented as DDL scripts: a sequence of imperative commands representing the
migration. When you _create a migration_ with the CLI, EdgeDB produces a DDL script.

#### 8.3.18 Comparison to SDL

SDL is sort of like a 3D printer: you design the final shape and it puts it together for you. DDL is like building a house
with traditional methods: to add a window, you first need a frame, to have a frame you need a wall, and so on.

DDL lets you make quick changes to your schema without creating migrations. But it can be dangerous too; someDDL
commands can destroy user data permanantly. In practice, we recommend most users stick with SDL until they get
comfortable, then start experimenting with DDL.

### 8.4 Connection parameters

- _Instance parameters_
- _Priority levels_
- _Granular parameters_

The CLI and client libraries (collectively referred to as “clients” below) must connect to an EdgeDB instance to run
queries or commands. There are several connection parameters, each of which can be specified in several ways.

#### 8.4.1 Specifying an instance

There are several ways to uniquely identify an EdgeDB instance.

```
Parameter CLI flag Environment variable
Instance name --instance/-I <name> EDGEDB_INSTANCE
DSN --dsn <dsn> EDGEDB_DSN
Host and port
--host/-H <host>
--port/-P <port>
```
```
EDGEDB_HOSTandEDGEDB_PORT
```
```
Credentials file --credentials-file <path> EDGEDB_CREDENTIALS_FILE
Project linking N/A N/A
```
Let’s dig into each of these a bit more.

**Instance name** All local instances (instances created on your local machine using the CLI) are associated with a
name. This name is that’s needed to connect; under the hood, the CLI stores the instance credentials (username,
password, etc) on your file system in the EdgeDB _config directory_. The CLI and client libraries look up these
credentials to connect.
You can also assign names to remote instances using _edgedb instance link_. The CLI will save the credentials
locally, so you can connect to a remote instance using just its name, just like a local instance.

**8.4. Connection parameters 697**


**DSN** DSNs (data source names, also referred to as “connection strings”) are a convenient and flexible way to specify
connection information with a simple string. It takes the following form:

```
edgedb://USERNAME:PASSWORD@HOSTNAME:PORT/DATABASE
```
```
# example
edgedb://alice:pa$$w0rd@example.com:1234/my_db
```
```
All components of the DSN are optional; technicallyedgedb://is a valid DSN. The unspecified values will
fall back to their defaults:
```
```
Host: "localhost"
Port: 5656
User: "edgedb"
Password: null
Database name: "edgedb"
```
```
DSNs also accept query parameters to support advanced use cases. Read the DSN Specification reference for
details.
```
**Host and port** In general, we recommend using a fully-qualified DSN when connecting to the database. For conve-
nience, it’s possible to individually specify a host and/or a port.
When not otherwise specified, the host defaults to"localhost"and the port defaults to 5656.

**Credentials file** e.g./path/to/credentials.json.

```
If you wish, you can store your credentials as a JSON file. Checking this file into version control could present
a security risk and is not recommended.
```
```
{
"host": "localhost",
"port": 10702,
"user": "testuser",
"password": "testpassword",
"database": "edgedb",
"tls_cert_data": "-----BEGIN CERTIFICATE-----\nabcdef..."
}
```
```
Relative paths are resolved relative to the current working directory.
```
**Project-linked instances** When you runedgedb project initin a given directory, EdgeDB creates an instance
and “links” it to that directory. There’s nothing magical about this link; it’s just a bit of metadata that gets stored
in the EdgeDB config directory. When you use the client libraries or run a CLI command inside a project-linked
directory, the library/CLI can detect this, look up the linked instance’s credentials, and connect automatically.
For more information on how this works, check out the release post foredgedb project.

**698 Chapter 8. Reference**


#### 8.4.2 Priority levels

The section above describes the various ways of specifying an EdgeDB instance. There are also several ways to pro-
vide this configuration information to the client. From highest to lowest priority, you can pass them explicitly as
parameters/flags (useful for debugging), use environment variables (recommended for production), or rely onedgedb
project(recommended for development).

1. **Explicit connection parameters**. For security reasons, hard-coding connection information or credentials in
    your codebase is not recommended, though it may be useful for debugging or testing purposes. As such, explicitly
    provided parameters are given the highest priority.
    In the context of the client libraries, this means passing an option explicitly into theconnectcall. Here’s how
    this looks using the JavaScript library:

```
import *as edgedbfrom "edgedb";
```
```
constpool = awaitedgedb.connect({
instance: "my_instance"
});
```
```
In the context of the CLI, this means using the appropriate command-line flags:
```
```
$ edgedb --instance my_instance
EdgeDB 2.x
Type \help for help, \quit to quit.
edgedb>
```
2. **Environment variables**.
    This is the recommended mechanism for providing connection information to your EdgeDB client, especially
    in production or when running EdgeDB inside a container. All clients read the following variables from the
    environment:
       - EDGEDB_DSN
       - EDGEDB_INSTANCE
       - EDGEDB_CREDENTIALS_FILE
       - EDGEDB_HOST/EDGEDB_PORT
    When one of these environment variables is defined, there’s no need to pass any additional information to the
    client. The CLI and client libraries will be able to connect without any additional information. You can execute
    CLI commands without any additional flags, like so:

```
$ edgedb # no flags needed
EdgeDB 2.x
Type \help for help, \quit to quit.
edgedb>
```
```
Using the JavaScript client library:
```
```
import *as edgedbfrom "edgedb";
```
```
constpool = edgedb.connect();
pool.query(`select 2 + 2;`).then(result => {
// do stuff
})
```
**8.4. Connection parameters 699**


```
Warning: Ambiguity is not permitted. For instance, specifying bothEDGEDB_INSTANCEandEDGEDB_DSN
will result in an error. You can useEDGEDB_HOSTandEDGEDB_PORTsimultaneously.
```
3. **Project-linked credentials**
    If you are usingedgedb project(which we recommend!) and haven’t otherwise specified any connection
    parameters, the CLI and client libraries will connect to the instance that’s been linked to your project.
    This makes it easy to get up and running with EdgeDB. Once you’ve runedgedb project init, the CLI and
    client libraries will be able to connect to your database without any explicit flags or parameters, as long as you’re
    inside the project directory.

If no connection information can be detected using the above mechanisms, the connection fails.

```
Warning: Within a given priority level, you cannot specify multiple instances “instance selection parameters”
simultaneously. For instance, specifying bothEDGEDB_INSTANCEandEDGEDB_DSNenvironment variables will
result in an error.
```
#### 8.4.3 Granular parameters

The _instance selection_ section describes several mechanisms for providing a complete set of connection information
in a single package. Occasionally—perhaps in development or for testing—it may be useful to override a particular
_component_ of this configuration.

The following “granular” parameters will override any value set by the instance-level configuration object.

```
Environment variable CLI flag
EDGEDB_DATABASE --database/-d <name>
EDGEDB_USER --user/-u <user>
EDGEDB_PASSWORD --password <pass>
EDGEDB_TLS_CA_FILE --tls-ca-file <path>
EDGEDB_CLIENT_TLS_SECURITY --tls-security
EDGEDB_CLIENT_SECURITY N/A
```
**EDGEDB_DATABASE** Each EdgeDB _instance_ can contain multiple _databases_. When in instance is created, a default
database namededgedbis created. Unless otherwise specified, all incoming connections connect to theedgedb
database.

**EDGEDB_USER/EDGEDB_PASSWORD** These are the credentials of the database user account to connect to the
EdgeDB instance.

**EDGEDB_TLS_CA_FILE** TLS is required to connect to any EdgeDB instance. To do so, the client needs a reference
to the root certificate of your instance’s certificate chain. Typically this will be handled for you when you create
a local instance orlinka remote one.
If you’re using a globally trusted CA like Let’s Encrypt, the root certificate will almost certainly exist already
in your system’s global certificate pool. In this case, you won’t need to specify this path; it will be discovered
automatically by the client.
If you’re self-issuing certificates, you must download the root certificate and provide a path to its location on the
filesystem. Otherwise TLS will fail to connect.

**EDGEDB_CLIENT_TLS_SECURITY** Sets the TLS security mode. Determines whether certificate and hostname
verification is enabled. Possible values:

**700 Chapter 8. Reference**


- "strict"( **default** ) — certificates and hostnames will be verified
- "no_host_verification"— verify certificates but not hostnames
- "insecure"— client libraries will trust self-signed TLS certificates. useful for self-signed or custom
    certificates.
This setting defaults to "strict"unless a custom certificate is supplied, in which case it is set to
"no_host_verification".

**EDGEDB_CLIENT_SECURITY** Provides some simple “security presets”.

```
Currently there is only one valid value: insecure_dev_mode. Setting
EDGEDB_CLIENT_SECURITY=insecure_dev_mode disables all TLS security measures. Currently it is
equivalent to settingEDGEDB_CLIENT_TLS_SECURITY=insecurebut it may encompass additional configura-
tion settings later. This is most commonly used when developing locally with Docker.
```
**8.4.3.1 Override behavior**

When specified, the connection parameters (user, password, and database) will _override_ the corresponding element of
a DSN, credentials file, etc. For instance, consider the following environment variables:

EDGEDB_DSN=edgedb://olduser:oldpass@hostname.com:5656
EDGEDB_USER=newuser
EDGEDB_PASSWORD=newpass

In this scenario,newuserwill overrideolduserandnewpasswill overrideoldpass. The client library will try to
connect using this modified DSN:edgedb://newuser:newpass@hostname.com:5656.

**8.4.3.2 Overriding across priority levels**

This override behavior only happens _same or lower priority level_. For instance:

- EDGEDB_PASSWORD **will** override the password specified inEDGEDB_DSN
- EDGEDB_PASSWORD **will be ignored** if a DSN is passed explicitly using the--dsnflag. Explicit parameters
    take precedence over environment variables. To override the password of an explicit DSN, you need to pass it
    explicitly as well:

```
$ edgedb --dsn edgedb://username:oldpass@hostname.com --password qwerty
# connects to edgedb://username:qwerty@hostname.com
```
- EDGEDB_PASSWORD **will** override the stored password associated with a project-linked instance. (This is unlikely
    to be desirable.)

### 8.5 Environment Variables

The behavior of EdgeDB can be configured with environment variables. The variables documented on this page are
supported when using theedgedb-servertool and the official _Docker image_.

**8.5. Environment Variables 701**


#### 8.5.1 Variants

Some environment variables (noted below) support*_FILEand*_ENVvariants.

- The*_FILEvariant expects its value to be a file name. The file’s contents will be read and used as the value.
- The*_ENVvariant expects its value to be the name of another environment variable. The value of the other
    environment variable is then used as the final value. This is convenient in deployment scenarios where relevant
    values are auto populated into fixed environment variables.

#### 8.5.2 Supported variables

**8.5.2.1 EDGEDB_SERVER_BOOTSTRAP_COMMAND**

Useful to fine-tune initial user and database creation, and other initial setup.

Maps directly to theedgedb-serverflag--default-auth-method. The*_FILEand*_ENVvariants are also sup-
ported.

**8.5.2.2 EDGEDB_SERVER_DEFAULT_AUTH_METHOD**

Optionally specifies the authentication method used by the server instance. Supported values areSCRAM(the default)
andTrust. When set toTrust, the database will allow complete unauthenticated access for all who have access to the
database port.

This is often useful when setting an admin password on an instance that lacks one.

Use at your own risk and only for development and testing.

The*_FILEand*_ENVvariants are also supported.

**8.5.2.3 EDGEDB_SERVER_TLS_CERT_MODE**

Specifies what to do when the TLS certificate and key are either not specified or are missing. When
set torequire_file, the TLS certificate and key must be specified in theEDGEDB_SERVER_TLS_CERT and
EDGEDB_SERVER_TLS_KEYvariables and both must exist. When set togenerate_self_signeda new self-signed
certificate and private key will be generated and placed in the path specified byEDGEDB_SERVER_TLS_CERTand
EDGEDB_SERVER_TLS_KEY, if those are set, otherwise the generated certificate and key are stored asedbtlscert.
pemandedbprivkey.peminEDGEDB_SERVER_DATADIR, or, ifEDGEDB_SERVER_DATADIRis not set then they will
be placed in/etc/ssl/edgedb.

The default isgenerate_self_signedwhenEDGEDB_SERVER_SECURITY=insecure_dev_mode. Otherwise the
default isrequire_file.

Maps directly to theedgedb-serverflag--tls-cert-mode. The*_FILEand*_ENVvariants are also supported.

**702 Chapter 8. Reference**


**8.5.2.4 EDGEDB_SERVER_TLS_CERT_FILE/EDGEDB_SERVER_TLS_KEY_FILE**

The TLS certificate and private key files, exclusive withEDGEDB_SERVER_TLS_CERT_MODE=generate_self_signed.

Maps directly to theedgedb-serverflags--tls-cert-fileand--tls-key-file.

**8.5.2.5 EDGEDB_SERVER_SECURITY**

When set toinsecure_dev_mode, sets EDGEDB_SERVER_DEFAULT_AUTH_METHODtoTrust (see above), and
EDGEDB_SERVER_TLS_CERT_MODEtogenerate_self_signed(unless an explicit TLS certificate is specified). Fi-
nally, if this option is set, the server will accept plaintext HTTP connections.

Use at your own risk and only for development and testing.

Maps directly to theedgedb-serverflag--security.

**8.5.2.6 EDGEDB_SERVER_PORT**

Specifies the network port on which EdgeDB will listen. The default is 5656.

Maps directly to theedgedb-serverflag--port. The*_FILEand*_ENVvariants are also supported.

**8.5.2.7 EDGEDB_SERVER_BIND_ADDRESS**

Specifies the network interface on which EdgeDB will listen.

Maps directly to theedgedb-serverflag--bind-address. The*_FILEand*_ENVvariants are also supported.

**8.5.2.8 EDGEDB_SERVER_DATADIR**

Specifies a path where the database files are located. Defaults to/var/lib/edgedb/data. Cannot be specified at the
same time withEDGEDB_SERVER_BACKEND_DSN.

Maps directly to theedgedb-serverflag--data-dir.

**8.5.2.9 EDGEDB_SERVER_BACKEND_DSN**

Specifies a PostgreSQL connection string in the URI format. If set, the PostgreSQL cluster specified by the URI is
used instead of the builtin PostgreSQL server. Cannot be specified at the same time withEDGEDB_SERVER_DATADIR.

Maps directly to theedgedb-serverflag--backend-dsn. The*_FILEand*_ENVvariants are also supported.

**8.5.2.10 EDGEDB_SERVER_RUNSTATE_DIR**

Specifies a path where EdgeDB will place its Unix socket and other transient files.

Maps directly to theedgedb-serverflag--runstate-dir.

**8.5. Environment Variables 703**


**8.5.2.11 EDGEDB_SERVER_ADMIN_UI**

Set toenabledto enable the web-based admininstrative UI for the instance.

Maps directly to theedgedb-serverflag--admin-ui.

### 8.6 Create a project

Projects are the most convenient way to develop applications with EdgeDB. This is the recommended approach.

To get started, navigate to the root directory of your codebase in a shell and runedgedb project init. You’ll see
something like this:

$ edgedb project init
No `edgedb.toml` found in this repo or above.
Do you want to initialize a new project? [Y/n]
> Y
Checking EdgeDB versions...
Specify the version of EdgeDB to use with this project [1-rc3]:
> # left blank for default
Specify the name of EdgeDB instance to use with this project:
> my_instance
Initializing EdgeDB instance...
Bootstrap complete. Server is up and running now.
Project initialialized.

Let’s unpack that.

1. First, it asks you to specify an EdgeDB version, defaulting to the most recent version you have installed. You can
    also specify a version you _don’t_ have installed, in which case it will be installed.
2. Then it asks you how you’d like to run EdgeDB: locally, in a Docker image, or in the cloud (coming soon!).
3. Then it asks for an instance name. If no instance currently exists with this name, it will be created (using the
    method you specified in #2).
4. Then it **links** the current directory to that instance. A “link” is represented as some metadata stored in EdgeDB’s
    _config directory_ —feel free to peek inside to see how it’s stored.
5. Then it creates anedgedb.tomlfile, which marks this directory as an EdgeDB project.
6. Finally, it creates adbschemadirectory and adbschema/default.esdlschema file (if they don’t already
    exist).

#### 8.6.1 FAQ

**8.6.1.1 How does this help me?**

Once you’ve initialized a project, your project directory is _linked_ to a particular instance. That means, you can run CLI
commands without connection flags. For instance,edgedb -I my_instance migratebecomes simplyedgedb
migrate. The CLI detects the existence of theedgedb.tomlfile, reads the current directory, and checks if it’s associ-
ated with an existing project. If it is, it looks up the credentials of the linked instance (they’re stored in a _standardized
location_ ), uses that information to connect to the instance, and applies the command.

Similarly, all _client libraries_ will use the same mechanism to auto-connect inside project directories, no hard-coded
credentials required.

**704 Chapter 8. Reference**


```
import edgedb from "edgedb";
```
- const pool = edgedb.createPool("my_instance");
+ const pool = edgedb.createPool();

**8.6.1.2 What do you mean** **_link_****?**

The “link” is just metaphor that makes projects easier to think about; in practice, it’s just a bit of metadata we store
in the EdgeDB _config directory_. When the CLI or client libraries try to connect to an instance, they read the currect
directory and cross-reference it against the list of initialized projects. If there’s a match, it reads the credentials of the
project’s associated instance and auto-connects.

**8.6.1.3 How does this work in production?**

It doesn’t. Projects are intended as a convenient development tool that make it easier to develop EdgeDB-backed appli-
cations locally. In production, you should provide instance credentials to your client library of choice using environment
variables. See _Connection parameters_ page for more information.

**8.6.1.4 What’s the** edgedb.toml **file?**

The contents of this file aren’t terribly important; this most important thing is simply that the file exists, since it’s how
the CLI knows that a directory is an instance-linked EdgeDB project.

But since we’re talking about it,edgedb.tomlcurrently supports just one configuration setting:server-version,
This lets you specify the EdgeDB version expected by this project. The value in the creatededgedb.tomlis determined
by the EdgeDB version you selected during the setup process.

**Note:** If you’re not familiar with the TOML file format, it’s a very cool, minimal language for config files designed to
be simpler than JSON or YAML—check out a short cheatsheet here.

**8.6.1.5 How do I use** edgedb project **for existing codebases?**

If you already have an project on your computer that uses EdgeDB, follow these steps to convert it into an EdgeDB
project:

1. Navigate into the project directory (the one containing youdbschemadirectory).
2. Runedgedb project init.
3. When asked for an instance name, enter the name of the existing local instance you use for development.

This will createedgedb.tomland link your project directory to the instance. And you’re done! Try running some
commands without connection flags. Feels good, right?

**8.6. Create a project 705**


**8.6.1.6 How does this make projects more portable?**

Let’s say you just cloned a full-stack application that uses EdgeDB. The project directory already contains anedgedb.
tomlfile. What do you do?

Just runedgedb project initinside the directory! This is the beauty ofedgedb project. You don’t need to
worry about creating an instance with a particular name, running on a particular port, creating users and passwords,
specifying environment variables, or any of the other things that make setting up local databases hard. Runningedgedb
project initwill install the necessary version of EdgeDB (if you don’t already have it installed), create an instance,
apply all unapplied migrations. Then you can start up the application and it should work out of the box.

**8.6.1.7 How do I unlink a project?**

If you want to remove the link between your project and its linked instance, runedgedb project unlinkanywhere
inside the project. This doesn’t affect the instance, it continues running as before. After unlinking, can runedgedb
project initinside project again to create or select a new instance.

$ edgedb project init
No `edgedb.toml` found in`~/path/to/my_project`or above.
Do you want to initialize a new project? [Y/n]
> Y
Specify the name of EdgeDB instance to use with this project
[default: my_project]:
> my_project
Checking EdgeDB versions...
Specify the version of EdgeDB to use with this project [default: 2.x]:
> 2.x

**8.6.1.8 How do I use** edgedb project **with a non-local instance?**

Sometimes you may want to work on an EdgeDB instance that is just not in your local development environment, like
you may have a second workstation, or you want to test against a staging database shared by the team.

This is totally a valid case and EdgeDB fully supports it!

Before runningedgedb project init, you just need to create a local link to the remote EdgeDB instance first:

$ edgedb instance link
Specify the host of the server [default: localhost]:
> 192.168.4.2
Specify the port of the server [default: 5656]:
> 10818
Specify the database user [default: edgedb]:
> edgedb
Specify the database name [default: edgedb]:
> edgedb
Unknown server certificate: SHA1:c38a7a90429b033dfaf7a81e08112a9d58d97286. Trust? [y/N]
> y
Password for'edgedb':
Specify a new instance name for the remote server [default: 192_168_4_2_10818]:
> staging_db
Successfully linked to remote instance. To connect run:
edgedb -I staging_db

**706 Chapter 8. Reference**


Then you could run the normaledgedb project initand usestaging_dbas the instance name.

**Note:** When using an existing instance, make sure that the project source tree is in sync with the current migration
revision of the instance. If the current revision in the database doesn’t exist underdbschema/migrations/, it’ll raise
an error trying to migrate or create new migrations. In this case, you should update your local source tree to the revision
that matches the current revision of the database.

### 8.7 DSN specification

DSNs (data source names) are a convenient and flexible way to specify connection information with a simple string. It
takes the following form:

edgedb://USERNAME:PASSWORD@HOSTNAME:PORT/DATABASE

For instance, here is a typical DSN:edgedb://alice:pa$$w0rd@example.com:1234/my_db.

All components of the DSN are optional; in fact,edgedb://is a valid DSN. Any unspecified values will fall back to
their defaults:

Host: "localhost"
Port: 5656
User: "edgedb"
Password: null
Database name: "edgedb"

#### 8.7.1 Query parameters

DSNs also support query parameters (?host=myhost.com) to support advanced use cases. The value for a given
parameter can be specified in three ways: directly (e.g.?host=example.com), by specifying an environment vari-
able containing the value (?host_env=HOST_VAR), or by specifying a file containing the value (?host_file=./
hostname.txt).

**Note:** For a breakdown of these configuration options, see _Reference > Connection Parameters_.

```
Plain param File param Environment param
host host_file host_env
port port_file port_env
database database_file database_env
user user_file user_env
password password_file password_env
tls_ca_file tls_ca_file_file tls_ca_file_env
tls_security tls_security_file tls_security_env
```
**Plain params** These “plain” parameters can be used to provide values for options that can’t otherwise be reflected in
the DSN, like TLS settings (described in more detail below).
You can’t specify the same setting both in the body of the DSN and in a query parameter. For instance, the DSN
below is invalid, as the port is ambiguous.

**8.7. DSN specification 707**


```
edgedb://hostname.com:1234?port=5678
```
**File params** If you prefer to store sensitive credentials in local files, you can use file params to specify a path to a local
UTF-8 encoded file. This file should contain a single line containing the relevant value.

```
edgedb://hostname.com:1234?user_file=./username.txt
```
```
# ./username.txt
my_username
```
```
Relative params are resolved relative to the current working directory at the time of connection.
```
**Environment params** Environment params lets you specify a _pointer_ to another environment variable. At runtime,
the specified environment variable will be read. If it isn’t set, an error will be thrown.

```
MY_PASSWORD=p@$$w0rd
EDGEDB_DSN=edgedb://hostname.com:1234?password_env=MY_PASSWORD
```
### 8.8 Dump file format

This description uses the same _conventions_ as the protocol description.

#### 8.8.1 General Structure

Dump file is structure as follows:

1. Dump file format marker\xFF\xD8\x00\x00\xD8EDGEDB\x00DUMP\x00(17 bytes)
2. Format version number\x00\x00\x00\x00\x00\x00\x00\x01(8 bytes)
3. Header block
4. Any number of data blocks

#### 8.8.2 General Dump Block

Both header and data blocks are formatted as follows:

struct DumpHeader{
int8 mtype;

```
// SHA1 hash sum of block data
byte sha1sum[20];
```
```
// Length of message contents in bytes,
// including self.
int32 message_length;
```
// Block data. Should be treated in opaque way by a client.
byte data[message_length];
}

Upon receiving a protocol dump data message, the dump client should:

**708 Chapter 8. Reference**


- **Replace packet type:**
    **-** @(0x40)→H(0x48)
    **-** =(0x3d)→D(0x44)
- Prepend SHA1 checksum to the block
- Append the entire dump protocol message disregarding the first byte (the message type).

#### 8.8.3 Header Block

Format:

struct DumpHeader{
// Message type ('H')
int8 mtype = 0x48;

```
// SHA1 hash sum of block data
byte sha1sum[20];
```
```
// Length of message contents in bytes,
// including self.
int32 message_length;
```
```
// A set of message headers.
Headers headers;
```
```
// Protocol version of the dump
int16 major_ver;
int16 minor_ver;
```
```
// Schema data
string schema_ddl;
```
```
// Type identifiers
int32 num_types;
TypeInfo types[num_types];
```
// Object descriptors
int32 num_descriptors;
ObjectDesc descriptors[num_descriptors]
};

struct TypeInfo {
string type_name;
string type_class;
byte type_id[16];
}

struct ObjectDesc{
byte object_id[16];
bytes description;

```
(continues on next page)
```
**8.8. Dump file format 709**


(continued from previous page)
int16 num_dependencies;
byte dependency_id[num_dependencies][16];
}

Known headers:

- 101 BLOCK_TYPE– block type, always “I”
- 102 SERVER_TIME– server time when dump is started as a floating point unix timestamp stringified
- 103 SERVER_VERSION– full version of server as string
- 105 SERVER_CATALOG_VERSION– the catalog version of the server, as a 64-bit integer. The catalog version is
    an identifier that is incremented whenever a change is made to the database layout or standard library.

#### 8.8.4 Data Block

Format:

struct DumpBlock{
// Message type ('=')
int8 mtype = 0x3d;

```
// Length of message contents in bytes,
// including self.
int32 message_length;
```
// A set of message headers.
Headers headers;
}

Known headers:

- 101 BLOCK_TYPE– block type, always “D”
- 110 BLOCK_ID– block identifier (16 bytes of UUID)
- 111 BLOCK_NUM– integer block index stringified
- 112 BLOCK_DATA– the actual block data

### 8.9 Backend high-availability

High availability is a sophisticated and systematic challenge, especially for databases. To address the problem, EdgeDB
server now supports selected highly-available backend Postgres clusters, namely in 2 categories:

- API-based HA
- Adaptive HA without API

When the backend HA feature is enabled in EdgeDB, EdgeDB server will try its best to detect and react to backend
failovers, whether a proper API is available or not.

During backend failover, no frontend connections will be closed; instead, all incoming queries will fail with a retryable
error until failover has completed successfully. If the query originates from a client that supports retrying transactions,
these queries may be retried by the client until the backend connection is restored and the query can be properly resolved.

**710 Chapter 8. Reference**


#### 8.9.1 API-based HA

EdgeDB server accepts different types of backends by looking into the protocol of the--backend-dsncommand-line
parameter. EdgeDB supports the following DSN protocols currently:

- stolon+consul+http://
- stolon+consul+https://

When using these protocols, EdgeDB builds the actual DSN of the cluster’s leader node by calling the corresponding
API using credentials in the--backend-dsnand subscribes to that API for failover events. Once failover is detected,
EdgeDB drops all backend connections and routes all new backend connections to the new leader node.

Stolon is an open-source cloud native PostgreSQL manager for PostgreSQL high availability. Currently, EdgeDB
supports using a Stolon cluster as the backend in a Consul-based setup, where EdgeDB acts as a Stolon proxy. This
way, you only need to manage Stolon sentinels and keepers, plus a Consul deployment. To use a Stolon cluster, run
EdgeDB server with a DSN, like so:

$ edgedb-server \
--backend-dsn stolon+consul+http://localhost:8500/my-cluster

EdgeDB will connect to the Consul HTTP service atlocalhost:8500, and subscribe to the updates of the cluster
namedmy-cluster.

Using a regularpostgres://DSN disables API-based HA.

#### 8.9.2 Adaptive HA

EdgeDB also supports DNS-based generic HA backends. This may be a cloud database with multi-AZ failover or some
custom HA Postgres cluster that keeps a DNS name always resolved to the leader node. Adaptive HA can be enabled
with a switch in addition to a regular backend DSN:

$ edgedb-server \
--backend-dsn postgres://xxx.rds.amazonaws.com \
--enable-backend-adaptive-ha

Once enabled, EdgeDB server will keep track of unusual backend events like unexpected disconnects or Postgres shut-
down notifications. When a threshold is reached, EdgeDB considers the backend to be in the “failover” state. It then
drops all current backend connections and try to re-establish new connections with the same backend DSN. Because
EdgeDB doesn’t cache resolved DNS values, the new connections will be established with the new leader node.

Under the hood of adaptive HA, EdgeDB maintains a state machine to avoid endless switch-overs in an unstable network.
State changes only happen when certain conditions are met.

**Set of possible states:**

- Healthy- all is good
- Unhealthy- a staging state before failover
- Failover- backend failover is in process

**Rules of state switches:**

Unhealthy->Healthy

- Successfully connected to a non-hot-standby backend.

Unhealthy->Failover

**8.9. Backend high-availability 711**


- More than 60% (configurable with environment variableEDGEDB_SERVER_BACKEND_ADAPTIVE_HA_DISCONNECT_PERCENT)
    of existing pgcons are “unexpectedly disconnected” (number of existing pgcons is captured at the moment we
    change toUnhealthystate, and maintained on “expected disconnects” too).
- (and) InUnhealthystate for more than 30 seconds (EDGEDB_SERVER_BACKEND_ADAPTIVE_HA_UNHEALTHY_MIN_TIME).
- (and) sys_pgcon is down.
- (or) Postgres shutdown/hot-standby notification received.

Healthy->Unhealthy

- Any unexpected disconnect.

Healthy->Failover

- Postgres shutdown/hot-standby notification received.

Failover->Healthy

- Successfully connected to a non-hot-standby backend.
- (and) sys_pgcon is healthy.

(“pgcon” is a code name for backend connections, and “sys_pgcon” is a special backend connection which EdgeDB
uses to talk to the “EdgeDB system database”.)

### 8.10 Server configuration

EdgeDB exposes a number of configuration parameters that affect its behavior. In this section we review the ways to
change the server configuration, as well as detail each available configuration parameter.

#### 8.10.1 Configuring the server

**8.10.1.1 EdgeQL**

Theconfigurecommand can be used to set the configuration parameters using EdgeQL. For example:

edgedb>configure instance setlisten_addresses := {'127.0.0.1','::1'};
CONFIGURE: OK

**8.10.1.2 CLI**

The _edgedb configure_ command allows modifying the system configuration from a terminal:

$ edgedb configure set listen_addresses 127.0.0.1 ::1

**712 Chapter 8. Reference**


#### 8.10.2 Available settings

Below is an overview of available settings. a full reference of settings is available at _Standard Library > Config_.

**8.10.2.1 Connection settings**

listen_addresses -> multi strThe TCP/IP address(es) on which the server is to listen for connections from
client applications.

listen_port -> int16The TCP port the server listens on; defaults to 5656.

**8.10.2.2 Resource usage**

effective_io_concurrency -> int64The number of concurrent disk I/O operations that can be executed simul-
taneously.

query_work_mem -> cfg::memoryThe amount of memory used by internal query operations such as sorting.

shared_buffers -> cfg::memoryThe amount of memory used for shared memory buffers.

**8.10.2.3 Query planning**

default_statistics_target -> int64The default data statistics target for the planner.

effective_cache_size -> cfg::memoryAn estimate of the effective size of the disk cache available to a single
query.

**8.10.2.4 Query behavior**

allow_bare_ddl -> cfg::AllowBareDDLAllows for running bare DDL outside a migration. Possible values are
cfg::AllowBareDDL.AlwaysAllowandcfg::AllowBareDDL.NeverAllow.
When you create an instance, this is set tocfg::AllowBareDDL.AlwaysAllowuntil you run a migration. At
that point it is set tocfg::AllowBareDDL.NeverAllowbecause it’s generally a bad idea to mix migrations
with bare DDL.

apply_access_policies -> boolDetermines whether access policies should be applied when running queries.
Setting this tofalseeffectively puts you into super-user mode, ignoring any access policies that might otherwise
limit you on the instance.

```
Note: This setting can also be conveniently accessed via the “Config” dropdown menu at the top of the EdgeDB
UI (accessible by running the CLI commandedgedb uifrom within a project). The setting will apply only to
your UI session, so you won’t have to remember to re-enable it when you’re done.
```
**8.10. Server configuration 713**


**8.10.2.5 Client connections**

session_idle_timeout -> std::durationHow long client connections can stay inactive before being closed by
the server. Defaults to 60 seconds; set to<duration>' 0 'to disable the mechanism.

session_idle_transaction_timeout -> std::durationHow long client connections can stay inactive while
in a transaction. Defaults to 10 seconds; set to<duration>' 0 'to disable the mechanism.

query_execution_timeout -> std::durationHow long an individual query can run before being aborted. A
value of<duration>' 0 'disables the mechanism; it is disabled by default.

### 8.11 HTTP API

Using HTTP, you may check the health of your EdgeDB instance, check metrics on your instance, and make queries.

Your instance’s URL takes the form of [http://<hostname>:<port>/.](http://<hostname>:<port>/.) For queries, you will appenddb/
<database-name>/edgeql.

**Note:** Here’s how to determine your local EdgeDB instance’s HTTP server URL:

- Thehostnamewill belocalhost
- Find theportby runningedgedb instance list. This will print a table of all EdgeDB instances on your
    machine, including their associated port number.
- In most cases,database_namewill beedgedb. An EdgeDB _instance_ can contain multiple databases. On
    initialization, a default database callededgedbis created; all queries are executed against this database unless
    otherwise specified.

To determine the URL of a remote instance you have linked with the CLI, you can get both the hostname and port of
the instance from the “Port” column of theedgedb instance listtable (formatted as<hostname>:<port>). The
same guidance on local database names applies here.

#### 8.11.1 Health Checks

EdgeDB exposes endpoints to check for aliveness and readiness of your database instance.

**8.11.1.1 Aliveness**

Check if your instance is alive.

[http://<hostname>:<port>/server/status/alive](http://<hostname>:<port>/server/status/alive)

If your instance is alive, it will respond with a 200 status code and"OK"as the payload. Otherwise, it will respond
with a50xor a network error.

**714 Chapter 8. Reference**


**8.11.1.2 Readiness**

Check if your instance is ready to receive queries.

[http://<hostname>:<port>/server/status/ready](http://<hostname>:<port>/server/status/ready)

If your instance is ready, it will respond with a 200 status code and"OK"as the payload. Otherwise, it will respond
with a50xor a network error.

#### 8.11.2 Observability

Retrieve instance metrics.

[http://<hostname>:<port>/metrics](http://<hostname>:<port>/metrics)

All EdgeDB instances expose a Prometheus-compatible endpoint available via GET request. The following metrics are
made available.

**8.11.2.1 Processes**

compiler_process_spawns_total **Counter.** Total number of compiler processes spawned.

compiler_processes_current **Gauge.** Current number of active compiler processes.

**8.11.2.2 Backend connections and performance**

backend_connections_total **Counter.** Total number of backend connections established.

backend_connections_current **Gauge.** Current number of active backend connections.

backend_connection_establishment_errors_total **Counter.** Number of times the server could not establish
a backend connection.

backend_connection_establishment_latency **Histogram.** Time it takes to establish a backend connection, in
seconds.

backend_query_duration **Histogram.** Time it takes to run a query on a backend connection, in seconds.

**8.11.2.3 Client connections**

client_connections_total **Counter.** Total number of clients.

client_connections_current **Gauge.** Current number of active clients.

client_connections_idle_total **Counter.** Total number of forcefully closed idle client connections.

**8.11. HTTP API 715**


**8.11.2.4 Query compilation**

edgeql_query_compilations_total **Counter.** Number of compiled/cached queries or scripts.

edgeql_query_compilation_duration **Histogram.** Time it takes to compile an EdgeQL query or script, in sec-
onds.

**8.11.2.5 Errors**

background_errors_total **Counter.** Number of unhandled errors in background server routines.

#### 8.11.3 Querying

Before querying over HTTP, you must first enable the HTTP extension in your schema. Add this to your schema, outside
anymodule:

using extension edgeql_http;

Then create a new migration and apply it using _edgedb migration create_ and _edgedb migrate_ , respectively.

Your instance is now able to receive EdgeQL queries over HTTP.

**Note:** Enabling the HTTP extension is only required for querying over HTTP. It is _not_ required for health checks or
observability.

**8.11.3.1 Making a query request**

Make a query to your EdgeDB database using this URL:

[http://<hostname>:<port>/db/<database-name>/edgeql](http://<hostname>:<port>/db/<database-name>/edgeql)

You may make queries via either the POST or GET HTTP method. Query requests can take the following fields:

- query- contains the EdgeQL query string
- variables- contains a JSON object where the keys are the parameter names from the query and the values are
    the arguments to be used in this execution of the query.

When using the GET method, supplyqueryandvariablesas query parameters. For a POST request, use the
application/jsoncontent type and submit a JSON payload withqueryandvariablesas top-level keys in that
payload as in this example:

Here’s an example query you might want to run to insert a new person in your database, as executed from the EdgeDB
REPL:

db>insert Person { name := <str>$name };
Parameter <str>$name: Pat
{default::Person {id: e9009b00-8d4e-11ed-a556-c7b5bdd6cf7a}}

The query inserts aPersonobject. The object’snamevalue is parameterized in the query as$name.

This GET request would run the same query (assuming the instance is local and the database is namededgedb):

**716 Chapter 8. Reference**


GET [http://localhost:<port>/db/edgedb/edgeql?query=insert%20Person%20%7B%20name%20%3A%3D](http://localhost:<port>/db/edgedb/edgeql?query=insert%20Person%20%7B%20name%20%3A%3D)
˓→%20%3Cstr%3E$name%20%7D%3B&variables=%7B%22name%22%3A%20%22Pat%22%7D

As you can see with even this simple query, URL encoding can quickly become onerous with queries over GET.

Here’s the JSON payload of a POST request to execute the query:

{
"query": "insert Person { name := <str>$name };",
"variables": { "name": "Pat" }
}

**8.11.3.2 Response**

The response format is the same for both methods. The body of the response is JSON of the following form:

{
"data": [ ... ],
"error": {
"message": "Error message",
"type": "ErrorType",
"code": 123456
}
}

Thedataresponse field will contain the response set serialized as a JSON array.

Note that theerrorfield will only be present if an error actually occurred. Theerrorwill further contain themessage
field with the error message string, thetypefield with the name of the type of error and thecodefield with an integer
_error code_.

**Note:** Caution is advised when readingdecimalorbigintvalues using the HTTP protocol because the results are
provided in JSON format. The JSON specification does not have a limit on significant digits, so adecimalor abigint
number can be losslessly represented in JSON. However, JSON decoders in many languages will read all such numbers
as some kind of of 32- or 64-bit number type, which may result in errors or precision loss. If such loss is unacceptable,
then consider casting the value intostrand decoding it on the client side into a more appropriate type.

### 8.12 SQL support

#### 8.12.1 Connecting

EdgeDB supports running read-only SQL queries via the Postgres protocol to enable connecting EdgeDB to existing
BI and analytics solutions. Any Postgres-compatible client can connect to your EdgeDB database by using the same
port that is used for the EdgeDB protocol and the same database name, username, and password you already use for
your database.

Here’s how you might connect to a local instance on port 10701 (determined by runningedgedb instance list)
with a databaseedgedbusing thepsqlCLI:

$ psql -h localhost -p 10701 -U edgedb -d edgedb

**8.12. SQL support 717**


You’ll then be prompted for a password. If you don’t have it, you can runedgedb instance credentials
--insecure-dsnand grab it out of the DSN the command returns. (It’s the string between the second colon and
the “at” symbol:edgedb://edgedb:PASSWORD_IS_HERE@<host>:<port>/<database>)

This works well to test SQL support, but if you are going to be using it on an ongoing basis, you may want to create
a new role and use it to authenticate your SQL clients. Set a password when you create your role. Then, use the role
name as your user name when you connect via your SQL client.

create superuser rolesql {
setpassword :='your-password'
};

$ psql -h localhost -p 10701 -U sql -d edgedb

In this example, when prompted for the password, you would enteryour-password.

```
Warning: EdgeDB server requires TLS by default, and this is also true for our SQL support. Make sure to
require SSL encryption in your SQL tool or client when using EdgeDB’s SQL support. Alternatively, you can
disable the TLS requirement by setting theEDGEDB_SERVER_BINARY_ENDPOINT_SECURITYenvironment variable
tooptional.
```
#### 8.12.2 Querying

Object types in your EdgeDB schema are exposed as regular SQL tables containing all the data you store in your
EdgeDB database.

If you have a database with the following schema:

module default{
typePerson {
name: str;
};

typeMovieextending common::Content {
release_year: int32;
director: Person;
star: Person {
role: str;
};
multiactors: Person {
role: str;
};
multilabels: str;
};
}
module common {
typeContent {
title: str;
};
}

you can access your data after connecting using the following SQL queries:

**718 Chapter 8. Reference**


SELECT id, nameFROM"Person";
SELECT id, title, release_year, director_id, star_idFROM"Movie";

Because the linkstarhas link properties, it has its own table.sourceis theidof theMovie.targetis theidof the
Person.

SELECT source, target,role FROM "Movie.star";

Links are in separate tables.

SELECT source, target,role FROM "Movie.actors";

Multi properties are in separate tables.sourceis theidof the Movie.targetis the value of the property.

SELECT source, targetFROM"Movie.labels";

When types are extended, parent object types’ tables will by default contain all objects of both the type and any types
extended by it. The query below will return allcommon::Contentobjects as well as allMovieobjects.

SELECT id, titleFROMcommon."Content";

To omit objects of extended types, useONLY. This query will returncommon::Contentobjects but notMovieobjects.

SELECT id, titleFROM ONLYcommon."Content";

The SQL connector supports read-only statements and will throw errors if the client attemptsINSERT,UPDATE,DELETE,
or any DDL command. It supports all SQL expressions supported by Postgres.

SELECT id,'Title is:' || tittle
FROM"Movie" m
JOIN"Person" d ONm.director_id = d.id
WHERE EXISTS(
SELECT 1
FROM"Movie.actors" act
WHEREact.source = m.id
);

EdgeDB accomplishes this by emulating theinformation_schemaandpg_catalogviews to mimic the catalogs
provided by Postgres 13.

**Note:** Learn more about the Postgres information schema from the Postgres information schema documentation.

```
Warning: Some tables may be truncated and may not contain all objects you would expect a true Postgres instance
to contain. This may be a source of problems when using tools that introspect the database and rely on internal
Postgres features.
```
**8.12. SQL support 719**


#### 8.12.3 Tested SQL tools

- pg_dump
- Metabase
- Cluvio
- Tableau
- DataGrip
- Airbyte^1
- Fivetran^1
- Hevo^1
- Stitch^1
- dbt^2

### 8.13 Binary protocol

EdgeDB uses a message-based binary protocol for communication between clients and servers. The protocol is sup-
ported over TCP/IP.

(^1) At the moment, EdgeDB does not support “Log replication” (i.e., using the Postgres replication mechanism). Supported replication methods
include XMIN Replication, incremental updates using “a user-defined monotonically increasing id,” and full table updates.
(^2) dbt models are built and stored in the database as either tables or views. Because the EdgeDB SQL connector does not allow writing or even
creating schemas, view, or tables, any attempt to materialize dbt models will result in errors. If you want to build the models, we suggest first
transferring your data to a true Postgres instance via pg_dump or Airbyte. Tests and previews can still be run directy against the EdgeDB instance.
**720 Chapter 8. Reference**


#### 8.13.1 Messages

```
Server Messages
AuthenticationOK Authentication is successful.
AuthenticationSASL SASL authentication is required.
AuthenticationSASLContinue SASL authentication challenge.
AuthenticationSASLFinal SASL authentication final message.
CommandComplete Successful completion of a command.
CommandDataDescription Description of command data input and output.
StateDataDescription Description of state data.
Data Command result data element.
Dump Header Initial message of the database backup protocol
Dump Block Single chunk of database backup data
ErrorResponse Server error.
LogMessage Server log message.
ParameterStatus Server parameter value.
ReadyForCommand Server is ready for a command.
RestoreReady Successful response to the Restore message
ServerHandshake Initial server connection handshake.
ServerKeyData Opaque token identifying the server connection.
Client Messages
AuthenticationSASLInitialResponse SASL authentication initial response.
AuthenticationSASLResponse SASL authentication response.
ClientHandshake Initial client connection handshake.
Dump Initiate database backup
Parse Parse EdgeQL command(s).
Execute Parse and/or execute a query.
Restore Initiate database restore
RestoreBlock Next block of database dump
RestoreEof End of database dump
Sync Provide an explicit synchronization point.
Terminate Terminate the connection.
```
**8.13.1.1 ErrorResponse**

Sent by: server.

Format:

struct ErrorResponse{
// Message type ('E').
uint8 mtype = 0x45;

```
// Length of message contents in bytes,
// including self.
uint32 message_length;
```
```
// Message severity.
uint8<ErrorSeverity> severity;
```
```
// Message code.
(continues on next page)
```
**8.13. Binary protocol 721**


```
(continued from previous page)
uint32 error_code;
```
```
// Error message.
string message;
```
// Error attributes.
uint16 num_attributes;
KeyValue attributes[num_attributes];
};

enumErrorSeverity {
ERROR = 0x78;
FATAL = 0xc8;
PANIC = 0xff;
};

See the _list of error codes_ for all possible error codes.

Known headers:

- 0x0001HINT:str– error hint.
- 0x0002DETAILS:str– error details.
- 0x0101SERVER_TRACEBACK:str– error traceback from server (is only sent in dev mode).
- 0xFFF1POSITION_START– byte offset of the start of the error span.
- 0xFFF2POSITION_END– byte offset of the end of the error span.
- 0xFFF3LINE_START– one-based line number of the start of the error span.
- 0xFFF4COLUMN_START– one-based column number of the start of the error span.
- 0xFFF5UTF16_COLUMN_START– zero-based column number in UTF-16 encoding of the start of the error span.
- 0xFFF6LINE_END– one-based line number of the start of the error span.
- 0xFFF7COLUMN_END– one-based column number of the start of the error span.
- 0xFFF8UTF16_COLUMN_END– zero-based column number in UTF-16 encoding of the end of the error span.
- 0xFFF9CHARACTER_START– zero-based offset of the error span in terms of Unicode code points.
- 0xFFFACHARACTER_END– zero-based offset of the end of the error span.

Notes:

1. Error span is the range of characters (or equivalent bytes) of the original query that compiler points to as the
    source of the error.
2. COLUMN_*is defined in terms of width of characters defined by Unicode Standard Annex #11, in other words,
    the column number in the text if rendered with monospace font, e.g. in a terminal.
3. UTF16_COLUMN_*is defined as number of UTF-16 code units (i.e. two byte-pairs) that precede target character
    on the same line.
4. *_ENDpoints to a next character after the last character of the error span.

**722 Chapter 8. Reference**


**8.13.1.2 LogMessage**

Sent by: server.

Format:

struct LogMessage{
// Message type ('L').
uint8 mtype = 0x4c;

```
// Length of message contents in bytes,
// including self.
uint32 message_length;
```
```
// Message severity.
uint8<MessageSeverity> severity;
```
```
// Message code.
uint32 code;
```
```
// Message text.
string text;
```
// Message annotations.
uint16 num_annotations;
Annotation annotations[num_annotations];
};

enumMessageSeverity {
DEBUG = 0x14;
INFO = 0x28;
NOTICE = 0x3c;
WARNING = 0x50;
};

See the _list of error codes_ for all possible log message codes.

**8.13.1.3 ReadyForCommand**

Sent by: server.

Format:

struct ReadyForCommand{
// Message type ('Z').
uint8 mtype = 0x5a;

```
// Length of message contents in bytes,
// including self.
uint32 message_length;
```
```
// A set of annotations.
uint16 num_annotations;
Annotation annotations[num_annotations];
(continues on next page)
```
**8.13. Binary protocol 723**


```
(continued from previous page)
```
// Transaction state.
uint8<TransactionState> transaction_state;
};

enumTransactionState {
NOT_IN_TRANSACTION = 0x49;
IN_TRANSACTION = 0x54;
IN_FAILED_TRANSACTION = 0x45;
};

**8.13.1.4 RestoreReady**

Sent by: server.

Initial _Restore_ message accepted, ready to receive data. See _Restore Database Flow_.

Format:

struct RestoreReady {
// Message type ('+').
uint8 mtype = 0x2b;

```
// Length of message contents in bytes,
// including self.
uint32 message_length;
```
```
// A set of annotations.
uint16 num_annotations;
Annotation annotations[num_annotations];
```
// Number of parallel jobs for restore,
// currently always "1"
uint16 jobs;
};

**8.13.1.5 CommandComplete**

Sent by: server.

Format:

struct CommandComplete{
// Message type ('C').
uint8 mtype = 0x43;

```
// Length of message contents in bytes,
// including self.
uint32 message_length;
```
```
// A set of annotations.
(continues on next page)
```
**724 Chapter 8. Reference**


```
(continued from previous page)
uint16 num_annotations;
Annotation annotations[num_annotations];
```
```
// A bit mask of allowed capabilities.
uint64<Capability> capabilities;
```
```
// Command status.
string status;
```
```
// State data descriptor ID.
uuid state_typedesc_id;
```
// Encoded state data.
bytes state_data;
};

**8.13.1.6 Dump**

Sent by: client.

Initiates a database backup. See _Dump Database Flow_.

Format:

struct Dump{
// Message type ('>').
uint8 mtype = 0x3e;

```
// Length of message contents in bytes,
// including self.
uint32 message_length;
```
// A set of annotations.
uint16 num_annotations;
Annotation annotations[num_annotations];
};

**8.13.1.7 CommandDataDescription**

Sent by: server.

Format:

struct CommandDataDescription{
// Message type ('T').
uint8 mtype = 0x54;

```
// Length of message contents in bytes,
// including self.
uint32 message_length;
```
```
(continues on next page)
```
**8.13. Binary protocol 725**


```
(continued from previous page)
// A set of annotations.
uint16 num_annotations;
Annotation annotations[num_annotations];
```
```
// A bit mask of allowed capabilities.
uint64<Capability> capabilities;
```
```
// Actual result cardinality.
uint8<Cardinality> result_cardinality;
```
```
// Argument data descriptor ID.
uuid input_typedesc_id;
```
```
// Argument data descriptor.
bytes input_typedesc;
```
```
// Output data descriptor ID.
uuid output_typedesc_id;
```
// Output data descriptor.
bytes output_typedesc;
};

enumCardinality {
NO_RESULT = 0x6e;
AT_MOST_ONE = 0x6f;
ONE = 0x41;
MANY = 0x6d;
AT_LEAST_ONE = 0x4d;
};

The format of the _input_typedesc_ and _output_typedesc_ fields is described in the _Type descriptors_ section.

**8.13.1.8 StateDataDescription**

Sent by: server.

Format:

struct StateDataDescription{
// Message type ('s').
uint8 mtype = 0x73;

```
// Length of message contents in bytes,
// including self.
uint32 message_length;
```
```
// Updated state data descriptor ID.
uuid typedesc_id;
```
```
// State data descriptor.
(continues on next page)
```
**726 Chapter 8. Reference**


(continued from previous page)
bytes typedesc;
};

The format of the _typedesc_ fields is described in the _Type descriptors_ section.

**8.13.1.9 Sync**

Sent by: client.

Format:

struct Sync{
// Message type ('S').
uint8 mtype = 0x53;

// Length of message contents in bytes,
// including self.
uint32 message_length;
};

**8.13.1.10 Restore**

Sent by: client.

Initiate restore to the current database. See _Restore Database Flow_.

Format:

struct Restore{
// Message type ('<').
uint8 mtype = 0x3c;

```
// Length of message contents in bytes,
// including self.
uint32 message_length;
```
```
// A set of key-value pairs.
uint16 num_attributes;
KeyValue attributes[num_attributes];
```
```
// Number of parallel jobs for restore
// (only "1" is supported)
uint16 jobs;
```
// Original DumpHeader packet data
// excluding mtype and message_length
bytes header_data;
};

**8.13. Binary protocol 727**


**8.13.1.11 RestoreBlock**

Sent by: client.

Send dump file data block. See _Restore Database Flow_.

Format:

struct RestoreBlock {
// Message type ('=').
uint8 mtype = 0x3d;

```
// Length of message contents in bytes,
// including self.
uint32 message_length;
```
// Original DumpBlock packet data excluding
// mtype and message_length
bytes block_data;
};

**8.13.1.12 RestoreEof**

Sent by: client.

Notify server that dump is fully uploaded. See _Restore Database Flow_.

Format:

struct RestoreEof{
// Message type ('.').
uint8 mtype = 0x2e;

// Length of message contents in bytes,
// including self.
uint32 message_length;
};

**8.13.1.13 Execute**

Sent by: client.

Format:

struct Execute{
// Message type ('O').
uint8 mtype = 0x4f;

```
// Length of message contents in bytes,
// including self.
uint32 message_length;
```
```
// A set of annotations.
uint16 num_annotations;
(continues on next page)
```
**728 Chapter 8. Reference**


```
(continued from previous page)
Annotation annotations[num_annotations];
```
```
// A bit mask of allowed capabilities.
uint64<Capability> allowed_capabilities;
```
```
// A bit mask of query options.
uint64<CompilationFlag> compilation_flags;
```
```
// Implicit LIMIT clause on returned sets.
uint64 implicit_limit;
```
```
// Data output format.
uint8<OutputFormat> output_format;
```
```
// Expected result cardinality.
uint8<Cardinality> expected_cardinality;
```
```
// Command text.
string command_text;
```
```
// State data descriptor ID.
uuid state_typedesc_id;
```
```
// Encoded state data.
bytes state_data;
```
```
// Argument data descriptor ID.
uuid input_typedesc_id;
```
```
// Output data descriptor ID.
uuid output_typedesc_id;
```
// Encoded argument data.
bytes arguments;
};

enumOutputFormat {
BINARY = 0x62;
JSON = 0x6a;
JSON_ELEMENTS = 0x4a;
NONE = 0x6e;
};

Use:

- BINARYto return data encoded in binary.
- JSONto return data as single row and single field that contains the resultset as a single JSON array”.
- JSON_ELEMENTSto return a single JSON string per top-level set element. This can be used to iterate over a large
    result set efficiently.
- NONEto prevent the server from returning data, even if the EdgeQL command does.

The data in _arguments_ must be encoded as a _tuple value_ described by a type descriptor identified by _input_typedesc_id_.

**8.13. Binary protocol 729**


enumCardinality {
NO_RESULT = 0x6e;
AT_MOST_ONE = 0x6f;
ONE = 0x41;
MANY = 0x6d;
AT_LEAST_ONE = 0x4d;
};

**8.13.1.14 Parse**

Sent by: client.

struct Parse{
// Message type ('P').
uint8 mtype = 0x50;

```
// Length of message contents in bytes,
// including self.
uint32 message_length;
```
```
// A set of annotations.
uint16 num_annotations;
Annotation annotations[num_annotations];
```
```
// A bit mask of allowed capabilities.
uint64<Capability> allowed_capabilities;
```
```
// A bit mask of query options.
uint64<CompilationFlag> compilation_flags;
```
```
// Implicit LIMIT clause on returned sets.
uint64 implicit_limit;
```
```
// Data output format.
uint8<OutputFormat> output_format;
```
```
// Expected result cardinality.
uint8<Cardinality> expected_cardinality;
```
```
// Command text.
string command_text;
```
```
// State data descriptor ID.
uuid state_typedesc_id;
```
// Encoded state data.
bytes state_data;
};

enumCapability {
MODIFICATIONS = 0x1;
(continues on next page)

**730 Chapter 8. Reference**


(continued from previous page)
SESSION_CONFIG = 0x2;
TRANSACTION = 0x4;
DDL = 0x8;
PERSISTENT_CONFIG = 0x10;
ALL = 0xffffffffffffffff;
};

See RFC1004 for more information on capability flags.

enumCompilationFlag {
INJECT_OUTPUT_TYPE_IDS = 0x1;
INJECT_OUTPUT_TYPE_NAMES = 0x2;
INJECT_OUTPUT_OBJECT_IDS = 0x4;
};

Use:

- 0x0000_0000_0000_0001(INJECT_OUTPUT_TYPE_IDS) – if set, all returned objects have a__tid__property
    set to their type ID (equivalent to having an implicit__tid__ := .__type__.idcomputed property.)
- 0x0000_0000_0000_0002(INJECT_OUTPUT_TYPE_NAMES) – if set all returned objects have a__tname__
    property set to their type name (equivalent to having an implicit__tname__ := .__type__.namecomputed
    property.) Note that specifying this flag might slow down queries.
- 0x0000_0000_0000_0004(INJECT_OUTPUT_OBJECT_IDS) – if set all returned objects have anidproperty
    set to their identifier, even if not specified explicitly in the output shape.

enumOutputFormat {
BINARY = 0x62;
JSON = 0x6a;
JSON_ELEMENTS = 0x4a;
NONE = 0x6e;
};

Use:

- BINARYto return data encoded in binary.
- JSONto return data as single row and single field that contains the resultset as a single JSON array”.
- JSON_ELEMENTSto return a single JSON string per top-level set element. This can be used to iterate over a large
    result set efficiently.
- NONEto prevent the server from returning data, even if the EdgeQL statement does.

enumCardinality {
NO_RESULT = 0x6e;
AT_MOST_ONE = 0x6f;
ONE = 0x41;
MANY = 0x6d;
AT_LEAST_ONE = 0x4d;
};

**8.13. Binary protocol 731**


**8.13.1.15 Data**

Sent by: server.

Format:

struct Data{
// Message type ('D').
uint8 mtype = 0x44;

```
// Length of message contents in bytes,
// including self.
uint32 message_length;
```
// Encoded output data array. The array is
// currently always of size 1.
uint16 num_data;
DataElement data[num_data];
};

struct DataElement{
// Encoded output data.
uint32 num_data;
uint8 data[num_data];
};

The exact encoding ofDataElement.datais defined by the query output _type descriptor_.

Wire formats for the standard scalar types and collections are documented in _Data wire formats_.

**8.13.1.16 Dump Header**

Sent by: server.

Initial message of database backup protocol. See _Dump Database Flow_.

Format:

struct DumpHeader{
// Message type ('@').
uint8 mtype = 0x40;

```
// Length of message contents in bytes,
// including self.
uint32 message_length;
```
```
// A set of key-value pairs.
uint16 num_attributes;
KeyValue attributes[num_attributes];
```
```
// Major version of EdgeDB.
uint16 major_ver;
```
```
// Minor version of EdgeDB.
(continues on next page)
```
**732 Chapter 8. Reference**


```
(continued from previous page)
uint16 minor_ver;
```
```
// Schema.
string schema_ddl;
```
```
// Type identifiers.
uint32 num_types;
DumpTypeInfo types[num_types];
```
// Object descriptors.
uint32 num_descriptors;
DumpObjectDesc descriptors[num_descriptors];
};

struct DumpTypeInfo {
string type_name;

```
string type_class;
```
uuid type_id;
};

struct DumpObjectDesc{
uuid object_id;

```
bytes description;
```
uint16 num_dependencies;
uuid dependencies[num_dependencies];
};

Known headers:

- 101 BLOCK_TYPE– block type, always “I”
- 102 SERVER_TIME– server time when dump is started as a floating point unix timestamp stringified
- 103 SERVER_VERSION– full version of server as string
- 105 SERVER_CATALOG_VERSION– the catalog version of the server, as a 64-bit integer. The catalog version is
    an identifier that is incremented whenever a change is made to the database layout or standard library.

**8.13.1.17 Dump Block**

Sent by: server.

The actual protocol data in the backup protocol. See _Dump Database Flow_.

Format:

struct DumpBlock{
// Message type ('=').
uint8 mtype = 0x3d;

```
(continues on next page)
```
**8.13. Binary protocol 733**


```
(continued from previous page)
// Length of message contents in bytes,
// including self.
uint32 message_length;
```
// A set of key-value pairs.
uint16 num_attributes;
KeyValue attributes[num_attributes];
};

Known headers:

- 101 BLOCK_TYPE– block type, always “D”
- 110 BLOCK_ID– block identifier (16 bytes of UUID)
- 111 BLOCK_NUM– integer block index stringified
- 112 BLOCK_DATA– the actual block data

**8.13.1.18 ServerKeyData**

Sent by: server.

Format:

struct ServerKeyData{
// Message type ('K').
uint8 mtype = 0x4b;

```
// Length of message contents in bytes,
// including self.
uint32 message_length;
```
// Key data.
uint8 data[32];
};

**8.13.1.19 ParameterStatus**

Sent by: server.

Format:

struct ParameterStatus{
// Message type ('S').
uint8 mtype = 0x53;

```
// Length of message contents in bytes,
// including self.
uint32 message_length;
```
```
// Parameter name.
bytes name;
(continues on next page)
```
**734 Chapter 8. Reference**


```
(continued from previous page)
```
// Parameter value.
bytes value;
};

Known statuses:

- suggested_pool_concurrency– suggested default size for clients connection pools. Serialized as UTF-8
    encoded string.
- system_config– a set of instance-level configuration settings exposed to clients on connection. Serialized as:

```
struct ParameterStatus_SystemConfig{
// Type descriptor prefixed with type
// descriptor uuid.
uint32 num_typedesc;
uint8 typedesc[num_typedesc];
```
```
// Configuration settings data.
DataElement data[1];
};
```
```
WhereDataElementis defined in the same way as for the Data message:
```
```
struct DataElement{
// Encoded output data.
uint32 num_data;
uint8 data[num_data];
};
```
**8.13.1.20 ClientHandshake**

Sent by: client.

Format:

struct ClientHandshake{
// Message type ('V').
uint8 mtype = 0x56;

```
// Length of message contents in bytes,
// including self.
uint32 message_length;
```
```
// Requested protocol major version.
uint16 major_ver;
```
```
// Requested protocol minor version.
uint16 minor_ver;
```
```
// Connection parameters.
uint16 num_params;
ConnectionParam params[num_params];
(continues on next page)
```
**8.13. Binary protocol 735**


```
(continued from previous page)
```
// Requested protocol extensions.
uint16 num_extensions;
ProtocolExtension extensions[num_extensions];
};

struct ConnectionParam {
string name;

string value;
};

struct ProtocolExtension{
// Extension name.
string name;

// A set of extension annotaions.
uint16 num_annotations;
Annotation annotations[num_annotations];
};

TheClientHandshakemessage is the first message sent by the client upon connecting to the server. It is the first
phase of protocol negotiation, where the client sends the requested protocol version and extensions. Currently, the
only definedmajor_veris 1 , andminor_veris 0. No protocol extensions are currently defined. The server always
responds with the _ServerHandshake_.

**8.13.1.21 ServerHandshake**

Sent by: server.

Format:

struct ServerHandshake{
// Message type ('v').
uint8 mtype = 0x76;

```
// Length of message contents in bytes,
// including self.
uint32 message_length;
```
```
// maximum supported or client-requested
// protocol major version, whichever is
// greater.
uint16 major_ver;
```
```
// maximum supported or client-requested
// protocol minor version, whichever is
// greater.
uint16 minor_ver;
```
```
// Supported protocol extensions.
(continues on next page)
```
**736 Chapter 8. Reference**


(continued from previous page)
uint16 num_extensions;
ProtocolExtension extensions[num_extensions];
};

struct ProtocolExtension{
// Extension name.
string name;

// A set of extension annotaions.
uint16 num_annotations;
Annotation annotations[num_annotations];
};

TheServerHandshakemessage is a direct response to the _ClientHandshake_ message and is sent by the server in the
case where the server does not support the protocol version or protocol extensions requested by the client. It contains
the maximum protocol version supported by the server, considering the version requested by the client. It also contains
the intersection of the client-requested and server-supported protocol extensions. Any requested extensions not listed
in theServer Handshakemessage are considered unsupported.

**8.13.1.22 AuthenticationOK**

Sent by: server.

Format:

struct AuthenticationOK {
// Message type ('R').
uint8 mtype = 0x52;

```
// Length of message contents in bytes,
// including self.
uint32 message_length;
```
// Specifies that this message contains a
// successful authentication indicator.
uint32 auth_status;
};

TheAuthenticationOKmessage is sent by the server once it considers the authentication to be successful.

**8.13.1.23 AuthenticationSASL**

Sent by: server.

Format:

struct AuthenticationRequiredSASLMessage{
// Message type ('R').
uint8 mtype = 0x52;

```
// Length of message contents in bytes,
// including self.
(continues on next page)
```
**8.13. Binary protocol 737**


```
(continued from previous page)
uint32 message_length;
```
```
// Specifies that this message contains a
// SASL authentication request.
uint32 auth_status = 0xa;
```
// A list of supported SASL authentication
// methods.
uint32 num_methods;
string methods[num_methods];
};

TheAuthenticationSASLmessage is sent by the server if it determines that a SASL-based authentication method is
required in order to connect using the connection parameters specified in the _ClientHandshake_. The message contains
a list of _authentication methods_ supported by the server in the order preferred by the server.

**Note:** At the moment, the only SASL authentication method supported by EdgeDB isSCRAM-SHA-256(RFC 7677).

The client must select an appropriate authentication method from the list returned by the server and send an _Authenti-
cationSASLInitialResponse_. One or more server-challenge and client-response message follow. Each server-challenge
is sent in an _AuthenticationSASLContinue_ , followed by a response from the client in an _AuthenticationSASLResponse_
message. The particulars of the messages are mechanism specific. Finally, when the authentication exchange is com-
pleted successfully, the server sends an _AuthenticationSASLFinal_ , followed immediately by an _AuthenticationOK_.

**8.13.1.24 AuthenticationSASLContinue**

Sent by: server.

Format:

struct AuthenticationSASLContinue{
// Message type ('R').
uint8 mtype = 0x52;

```
// Length of message contents in bytes,
// including self.
uint32 message_length;
```
```
// Specifies that this message contains a
// SASL challenge.
uint32 auth_status = 0xb;
```
// Mechanism-specific SASL data.
bytes sasl_data;
};

**738 Chapter 8. Reference**


**8.13.1.25 AuthenticationSASLFinal**

Sent by: server.

Format:

struct AuthenticationSASLFinal{
// Message type ('R').
uint8 mtype = 0x52;

```
// Length of message contents in bytes,
// including self.
uint32 message_length;
```
```
// Specifies that SASL authentication has
// completed.
uint32 auth_status = 0xc;
```
bytes sasl_data;
};

**8.13.1.26 AuthenticationSASLInitialResponse**

Sent by: client.

Format:

struct AuthenticationSASLInitialResponse{
// Message type ('p').
uint8 mtype = 0x70;

```
// Length of message contents in bytes,
// including self.
uint32 message_length;
```
```
// Name of the SASL authentication
// mechanism that the client selected.
string method;
```
// Mechanism-specific "Initial Response"
// data.
bytes sasl_data;
};

**8.13. Binary protocol 739**


**8.13.1.27 AuthenticationSASLResponse**

Sent by: client.

Format:

struct AuthenticationSASLResponse{
// Message type ('r').
uint8 mtype = 0x72;

```
// Length of message contents in bytes,
// including self.
uint32 message_length;
```
// Mechanism-specific response data.
bytes sasl_data;
};

**8.13.1.28 Terminate**

Sent by: client.

Format:

struct Terminate{
// Message type ('X').
uint8 mtype = 0x58;

// Length of message contents in bytes,
// including self.
uint32 message_length;
};

#### 8.13.2 Errors

**8.13.2.1 Errors inheritance**

Each error in EdgeDB consists of a code, a name, and optionally tags. Errors in EdgeDB can inherit from other
errors. This is denoted by matching code prefixes. For example,TransactionConflictError(0x_05_03_01_00)
is the parent error forTransactionSerializationError(0x_05_03_01_01) andTransactionDeadlockError
(0x_05_03_01_02). The matching prefix here is0x_05_03_01.

When the EdgeDB client expects a more general error and EdgeDB returns a more specific error that inherits from the
general error, the check in the client must take this into account. This can be expressed by thebinary andoperation
or&opeator in most programming languages:

(expected_error_code & server_error_code) == expected_error_code

Note that although it is not explicitly stated in theedb/api/errors.txtfile, each inherited error must contain all
tags of the parent error. Given that,TransactionSerializationErrorandTransactionDeadlockError, for
example, must contain theSHOULD_RETRYtag that is defined forTransactionConflictError.

**740 Chapter 8. Reference**


**8.13.2.2 Error codes**

Error codes and names as specified inedb/api/errors.txt:

#### 8.13.3 Type descriptors

This section describes how type information for query input and results is encoded. Specifically, this is needed to
decode the server response to the _CommandDataDescription_ message.

The type descriptor is essentially a list of type information _blocks_ :

- each _block_ encodes one type;
- _blocks_ can reference other _blocks_.

While parsing the _blocks_ , a database driver can assemble an _encoder_ or a _decoder_ of the EdgeDB binary data.

An _encoder_ is used to encode objects, native to the driver’s runtime, to binary data that EdegDB can decode and work
with.

A _decoder_ is used to decode data from EdgeDB native format to data types native to the driver.

There is one special type with _type id_ of zero:00000000-0000-0000-0000-000000000000. The describe result of
this type contains zero _blocks_. It’s used when a statement returns no meaningful results, e.g. theCREATE DATABASE
examplestatement. It is also used to represent the input descriptor when a query does not receive any arguments, or
the state descriptor for an empty/default state.

**8.13.3.1 Set Descriptor**

struct SetDescriptor{
// Indicates that this is a Set value descriptor.
uint8 type = 0;

```
// Descriptor ID.
uuid id;
```
// Set element type descriptor index.
uint16 type_pos;
};

Set values are encoded on the wire as _single-dimensional arrays_.

**8.13.3.2 Object Shape Descriptor**

struct ObjectShapeDescriptor {
// Indicates that this is an
// Object Shape descriptor.
uint8 type = 1;

```
// Descriptor ID.
uuid id;
```
```
// Number of elements in shape.
uint16 element_count;
(continues on next page)
```
**8.13. Binary protocol 741**


```
(continued from previous page)
```
ShapeElement elements[element_count];
};

struct ShapeElement {
// Field flags:
// 1 << 0: the field is implicit
// 1 << 1: the field is a link property
// 1 << 2: the field is a link
uint32 flags;

```
uint8<Cardinality> cardinality;
```
```
// Field name.
string name;
```
// Field type descriptor index.
uint16 type_pos;
};

enumCardinality {
NO_RESULT = 0x6e;
AT_MOST_ONE = 0x6f;
ONE = 0x41;
MANY = 0x6d;
AT_LEAST_ONE = 0x4d;
};

Objects are encoded on the wire as _tuples_.

**8.13.3.3 Base Scalar Type Descriptor**

struct BaseScalarTypeDescriptor{
// Indicates that this is an
// Base Scalar Type descriptor.
uint8 type = 2;

// Descriptor ID.
uuid id;
};

The descriptor IDs for base scalar types are constant. The following table lists all EdgeDB base types descriptor IDs:

**742 Chapter 8. Reference**


```
ID Type
00000000-0000-0000-0000-000000000100 std::uuid
00000000-0000-0000-0000-000000000101 std::str
00000000-0000-0000-0000-000000000102 std::bytes
00000000-0000-0000-0000-000000000103 std::int16
00000000-0000-0000-0000-000000000104 std::int32
00000000-0000-0000-0000-000000000105 std::int64
00000000-0000-0000-0000-000000000106 std::float32
00000000-0000-0000-0000-000000000107 std::float64
00000000-0000-0000-0000-000000000108 std::decimal
00000000-0000-0000-0000-000000000109 std::bool
00000000-0000-0000-0000-00000000010A std::datetime
00000000-0000-0000-0000-00000000010E std::duration
00000000-0000-0000-0000-00000000010F std::json
00000000-0000-0000-0000-00000000010B cal::local_datetime
00000000-0000-0000-0000-00000000010C cal::local_date
00000000-0000-0000-0000-00000000010D cal::local_time
00000000-0000-0000-0000-000000000110 std::bigint
00000000-0000-0000-0000-000000000111 cal::relative_duration
00000000-0000-0000-0000-000000000112 cal::date_duration
00000000-0000-0000-0000-000000000130 cfg::memory
```
**8.13.3.4 Scalar Type Descriptor**

struct ScalarTypeDescriptor{
// Indicates that this is a
// Scalar Type descriptor.
uint8 type = 3;

```
// Descriptor ID.
uuid id;
```
// Parent type descriptor index.
uint16 base_type_pos;
};

**8.13.3.5 Tuple Type Descriptor**

struct TupleTypeDescriptor{
// Indicates that this is a
// Tuple Type descriptor.
uint8 type = 4;

```
// Descriptor ID.
uuid id;
```
```
// The number of elements in tuple.
uint16 element_count;
```
```
(continues on next page)
```
**8.13. Binary protocol 743**


(continued from previous page)
// Indexes of element type descriptors.
uint16 element_types[element_count];
};

An empty tuple type descriptor has an ID of00000000-0000-0000-0000-0000000000FF.

**8.13.3.6 Named Tuple Type Descriptor**

struct NamedTupleTypeDescriptor{
// Indicates that this is a
// Named Tuple Type descriptor.
uint8 type = 5;

```
// Descriptor ID.
uuid id;
```
```
// The number of elements in tuple.
uint16 element_count;
```
// Indexes of element type descriptors.
TupleElement elements[element_count];
};

struct TupleElement {
// Field name.
string name;

// Field type descriptor index.
int16 type_pos;
};

**8.13.3.7 Array Type Descriptor**

struct ArrayTypeDescriptor{
// Indicates that this is an
// Array Type descriptor.
uint8 type = 6;

```
// Descriptor ID.
uuid id;
```
```
// Element type descriptor index.
uint16 type_pos;
```
```
// The number of array dimensions, at least 1.
uint16 dimension_count;
```
```
// Sizes of array dimensions, -1 indicates
// unbound dimension.
(continues on next page)
```
**744 Chapter 8. Reference**


(continued from previous page)
uint32 dimensions[dimension_count];
};

**8.13.3.8 Enumeration Type Descriptor**

struct EnumerationTypeDescriptor {
// Indicates that this is an
// Enumeration Type descriptor.
uint8 type = 7;

```
// Descriptor ID.
uuid id;
```
```
// The number of enumeration members.
uint16 member_count;
```
// Names of enumeration members.
string members[member_count];
};

**8.13.3.9 Input Shape Descriptor**

struct InputShapeDescriptor{
// Indicates that this is an
// Object Shape descriptor.
uint8 type = 8;

```
// Descriptor ID.
uuid id;
```
```
// Number of elements in shape.
uint16 element_count;
```
ShapeElement elements[element_count];
};

Input objects are encoded on the wire as _sparse objects_.

**8.13.3.10 Range Type Descriptor**

struct RangeTypeDescriptor{
// Indicates that this is a
// Range Type descriptor.
uint8 type = 9;

```
// Descriptor ID.
uuid id;
```
```
(continues on next page)
```
**8.13. Binary protocol 745**


(continued from previous page)
// Range type descriptor index.
uint16 type_pos;
};

Ranges are encoded on the wire as _ranges_.

**8.13.3.11 Scalar Type Name Annotation**

Part of the type descriptor when the _Execute_ client message has theINLINE_TYPENAMESheader set. Every non-builtin
base scalar type and all enum types would have their full schema name provided via this annotation.

struct TypeAnnotationDescriptor{
uint8 type = 0xff;

```
// ID of the scalar type.
uuid id;
```
// Type name.
string type_name;
};

**8.13.3.12 Type Annotation Descriptor**

Drivers must ignore unknown type annotations.

struct TypeAnnotationDescriptor{
// Indicates that this is an
// Type Annotation descriptor.
uint8 type = 0x80..0xfe;

```
// ID of the descriptor the
// annotation is for.
uuid id;
```
// Annotation text.
string annotation;
};

#### 8.13.4 Data wire formats

This section describes the data wire format of standard EdgeDB types.

**746 Chapter 8. Reference**


**8.13.4.1 Sets and array<>**

The set and array values are represented as the following structure:

struct SetOrArrayValue{
// Number of dimensions, currently must
// always be 0 or 1. 0 indicates an empty set or array.
int32 ndims;

```
// Reserved.
int32 reserved0;
```
```
// Reserved.
int32 reserved1;
```
```
// Dimension data.
Dimension dimensions[ndims];
```
// Element data, the number of elements
// in this array is the sum of dimension sizes:
// sum((d.upper - d.lower + 1) for d in dimensions)
Element elements[];
};

struct Dimension{
// Upper dimension bound, inclusive,
// number of elements in the dimension
// relative to the lower bound.
int32 upper;

// Lower dimension bound, always 1.
int32 lower;
};

struct Element{
// Encoded element data length in bytes.
int32 length;

// Element data.
uint8 data[length];
};

Note: zero-length arrays (and sets) are represented as a 12-byte value wheredimsequal to zero regardless of the shape
in type descriptor.

Sets of arrays are a special case. Every array within a set is wrapped in an Envelope. The full structure follows:

struct SetOfArrayValue{
// Number of dimensions, currently must
// always be 0 or 1. 0 indicates an empty set.
int32 ndims;

```
// Reserved.
int32 reserved0;
(continues on next page)
```
**8.13. Binary protocol 747**


```
(continued from previous page)
```
```
// Reserved.
int32 reserved1;
```
```
// Dimension data. Same layout as above.
Dimension dimensions[ndims];
```
// Envelope data, the number of elements
// in this array is the sum of dimension sizes:
// sum((d.upper - d.lower + 1) for d in dimensions)
Envelope elements[];
};

struct Envelope {
// Encoded envelope element length in bytes.
int32 length;

```
// Number of elements, currently must
// always be 1.
int32 nelems;
```
```
// Reserved.
int32 reserved
```
// Element data. Same layout as above.
Element element[nelems];
};

**8.13.4.2 tuple<>, namedtuple<>, and object<>**

The values are represented as the following structure:

struct TupleOrNamedTupleOrObjectValue{
// Number of elements
int32 nelems;

// Element data.
Element elements[nelems];
};

struct Element{
// Reserved.
int32 reserved;

```
// Encoded element data length in bytes.
int32 length;
```
// Element data.
uint8 data[length];
};

Note that for objects,Element.lengthcan be set to-1, which means an empty set.

**748 Chapter 8. Reference**


**8.13.4.3 Sparse Objects**

The values are represented as the following structure:

struct SparseObjectValue{
// Number of elements
int32 nelems;

// Element data.
Element elements[nelems];
};

struct Element{
// Index of the element in the input shape.
int32 index;

```
// Encoded element data length in bytes.
int32 length;
```
// Element data.
uint8 data[length];
};

**8.13.4.4 Ranges**

The ranges are represented as the following structure:

struct Range{
// A bit mask of range definition.
uint8<RangeFlag> flags;

```
// Lower boundary data.
Boundary lower;
```
// Upper boundary data.
Boundary upper;
};

struct Boundary {
// Encoded boundary data length in bytes.
int32 length;

// Boundary data.
uint8 data[length];
};

enumRangeFlag {
// Empty range.
EMPTY = 0x0001;

```
// Included lower boundary.
LB_INC = 0x0002;
(continues on next page)
```
**8.13. Binary protocol 749**


```
(continued from previous page)
```
```
// Included upper boundary.
UB_INC = 0x0004;
```
```
// Inifinity (excluded) lower boundary.
LB_INF = 0x0008;
```
// Infinity (excluded) upper boundary.
UB_INF = 0x0010;
};

**8.13.4.5 std::uuid**

Thestd::uuidvalues are represented as a sequence of 16 unsigned byte values.

For example, the UUID valueb9545c35-1fe7-485f-a6ea-f8ead251abd3is represented as:

0xb9 0x54 0x5c 0x35 0x1f 0xe7 0x48 0x5f
0xa6 0xea 0xf8 0xea 0xd2 0x51 0xab 0xd3

**8.13.4.6 std::str**

Thestd::strvalues are represented as a UTF-8 encoded byte string. For example, thestrvalue'Hello! 'is
encoded as:

0x48 0x65 0x6c 0x6c 0x6f 0x21 0x20 0xf0 0x9f 0x99 0x82

**8.13.4.7 std::bytes**

Thestd::bytesvalues are represented as-is.

**8.13.4.8 std::int16**

Thestd::int16values are represented as two bytes, most significant byte first.

For example, theint16value 6556 is represented as:

0x19 0x9c

**8.13.4.9 std::int32**

Thestd::int32values are represented as four bytes, most significant byte first.

For example, theint32value 655665 is represented as:

0x00 0x0a 0x01 0x31

**750 Chapter 8. Reference**


**8.13.4.10 std::int64**

Thestd::int64values are represented as eight bytes, most significant byte first.

For example, theint64value 123456789987654321 is represented as:

0x01 0xb6 0x9b 0x4b 0xe0 0x52 0xfa 0xb1

**8.13.4.11 std::float32**

Thestd::float32values are represented as a IEEE 754-2008 binary 32-bit value, most significant byte first.

For example, thefloat32value-15.625is represented as:

0xc1 0x7a 0x00 0x00

**8.13.4.12 std::float64**

Thestd::float32values are represented as a IEEE 754-2008 binary 64-bit value, most significant byte first.

For example, thefloat64value-15.625is represented as:

0xc0 0x2f 0x40 0x00 0x00 0x00 0x00 0x00

**8.13.4.13 std::decimal**

Thestd::decimalvalues are represented as the following structure:

struct Decimal{
// Number of digits in digits[], can be 0.
uint16 ndigits;

```
// Weight of first digit.
int16 weight;
```
```
// Sign of the value
uint16<DecimalSign> sign;
```
```
// Value display scale.
uint16 dscale;
```
// base-10000 digits.
uint16 digits[ndigits];
};

enumDecimalSign {
// Positive value.
POS = 0x0000;

// Negative value.
NEG = 0x4000;
};

**8.13. Binary protocol 751**


The decimal values are represented as a sequence of base-10000 _digits_. The first digit is assumed to be multiplied by
_weight_ * 10000, i.e. there might be up to weight + 1 digits before the decimal point. Trailing zeros can be absent. It is
possible to have negative weight.

_dscale_ , or display scale, is the nominal precision expressed as number of base-10 digits after the decimal point. It is
always non-negative. dscale may be more than the number of physically present fractional digits, implying significant
trailing zeroes. The actual number of digits physically present in the _digits_ array contains trailing zeros to the next
4-byte increment (meaning that integer and fractional part are always distinc base-10000 digits).

For example, the decimal value-15000.6250000is represented as:

// ndigits
0x00 0x04

// weight
0x00 0x01

// sign
0x40 0x00

// dscale
0x00 0x07

// digits
0x00 0x01 0x13 0x88 0x18 0x6a 0x00 0x00

**8.13.4.14 std::bool**

Thestd::boolvalues are represented as an int8 with only two valid values:0x01fortrueand0x00forfalse.

**8.13.4.15 std::datetime**

Thestd::datetimevalues are represented as a 64-bit integer, most sigificant byte first. The value is the number of
_microseconds_ between the encoded datetime and January 1st 2000, 00:00 UTC. A Unix timestamp can be converted
into an EdgeDBdatetimevalue using this formula:

edb_datetime = (unix_ts + 946684800) * 1000000

For example, thedatetimevalue'2019-05-06T12:00+00:00'is encoded as:

0x00 0x02 0x2b 0x35 0x9b 0xc4 0x10 0x00

See _client libraries_ section for more info about how to handle different precision when encoding data.

**752 Chapter 8. Reference**


**8.13.4.16 cal::local_datetime**

Thecal::local_datetimevalues are represented as a 64-bit integer, most sigificant byte first. The value is the
number of _microseconds_ between the encoded datetime and January 1st 2000, 00:00.

For example, thelocal_datetimevalue'2019-05-06T12:00'is encoded as:

0x00 0x02 0x2b 0x35 0x9b 0xc4 0x10 0x00

See _client libraries_ section for more info about how to handle different precision when encoding data.

**8.13.4.17 cal::local_date**

Thecal::local_datevalues are represented as a 32-bit integer, most sigificant byte first. The value is the number
of _days_ between the encoded date and January 1st 2000.

For example, thelocal_datevalue'2019-05-06'is encoded as:

0x00 0x00 0x1b 0x99

**8.13.4.18 cal::local_time**

Thecal::local_timevalues are represented as a 64-bit integer, most sigificant byte first. The value is the number
of _microseconds_ since midnight.

For example, thelocal_timevalue'12:10'is encoded as:

0x00 0x00 0x00 0x0a 0x32 0xae 0xf6 0x00

See _client libraries_ section for more info about how to handle different precision when encoding data.

**8.13.4.19 std::duration**

Thestd::durationvalues are represented as the following structure:

struct Duration {
int64 microseconds;

```
// deprecated, is always 0
int32 days;
```
// deprecated, is always 0
int32 months;
};

For example, thedurationvalue'48 hours 45 minutes 7.6 seconds'is encoded as:

// microseconds
0x00 0x00 0x00 0x28 0xdd 0x11 0x72 0x80

// days
0x00 0x00 0x00 0x00

```
(continues on next page)
```
**8.13. Binary protocol 753**


```
(continued from previous page)
```
// months
0x00 0x00 0x00 0x00

See _client libraries_ section for more info about how to handle different precision when encoding data.

**8.13.4.20 cal::relative_duration**

Thecal::relative_durationvalues are represented as the following structure:

struct Duration {
int64 microseconds;
int32 days;
int32 months;
};

For example, thecal::relative_durationvalue'2 years 7 months 16 days 48 hours 45 minutes 7.6
seconds'is encoded as:

// microseconds
0x00 0x00 0x00 0x28 0xdd 0x11 0x72 0x80

// days
0x00 0x00 0x00 0x10

// months
0x00 0x00 0x00 0x1f

See _client libraries_ section for more info about how to handle different precision when encoding data.

**8.13.4.21 cal::date_duration**

Thecal::date_durationvalues are represented as the following structure:

struct DateDuration {
int64 reserved;
int32 days;
int32 months;
};

For example, thecal::date_durationvalue'1 years 2 days'is encoded as:

// reserved
0x00 0x00 0x00 0x00 0x00 0x00 0x00 0x00

// days
0x00 0x00 0x00 0x02

// months
0x00 0x00 0x00 0x0c

**754 Chapter 8. Reference**


**8.13.4.22 std::json**

Thestd::jsonvalues are represented as the following structure:

struct JSON{
uint8 format;
uint8 jsondata[];
};

_format_ is currently always 1 , and _jsondata_ is a UTF-8 encoded JSON string.

**8.13.4.23 std::bigint**

Thestd::bigintvalues are represented as the following structure:

struct BigInt{
// Number of digits in digits[], can be 0.
uint16 ndigits;

```
// Weight of first digit.
int16 weight;
```
```
// Sign of the value
uint16<DecimalSign> sign;
```
```
// Reserved value, must be zero
uint16 reserved;
```
// base-10000 digits.
uint16 digits[ndigits];
};

enumBigIntSign {
// Positive value.
POS = 0x0000;

// Negative value.
NEG = 0x4000;
};

The decimal values are represented as a sequence of base-10000 _digits_. The first digit is assumed to be multiplied by
_weight_ * 10000, i.e. there might be up to weight + 1 digits. Trailing zeros can be absent.

For example, the bigint value-15000is represented as:

// ndigits
0x00 0x02

// weight
0x00 0x01

// sign
0x40 0x00

```
(continues on next page)
```
**8.13. Binary protocol 755**


```
(continued from previous page)
```
// reserved
0x00 0x00

// digits
0x00 0x01 0x13 0x88

**8.13.4.24 cfg::memory**

Thecfg::memoryvalues are represented as a number of _bytes_ encoded as a 64-bit integer, most sigificant byte first.

For example, thecfg::memoryvalue123MiBis represented as:

0x00 0x00 0x00 0x00 0x07 0xb0 0x00 0x00

#### 8.13.5 Conventions and data Types

The message format descriptions in this section use a C-like struct definitions to describe their layout. The structs are
_packed_ , i.e. there are never any alignment gaps.

The following data types are used in the descriptions:

**756 Chapter 8. Reference**


```
int8 8-bit integer
int16 16-bit integer, most significant byte first
int32 32-bit integer, most significant byte first
int64 64-bit integer, most significant byte first
uint8 8-bit unsigned integer
uint16 16-bit unsigned integer, most significant byte first
uint32 32-bit unsigned integer, most significant byte first
uint64 64-bit unsigned integer, most significant byte first
int8<T>oruint8<T> an 8-bit signed or unsigned integer enumeration, where
T denotes the name of the enumeration
string a UTF-8 encoded text string prefixed with its byte length
asuint32
bytes a byte string prefixed with its length asuint32
KeyValue
struct KeyValue {
// Key code (specific to the type of the
// Message).
uint16 code;
```
```
// Value data.
bytes value;
};
```
```
Annotation
struct Annotation{
// Name of the annotation
string name;
```
```
// Value of the annotation (in JSON
// format).
string value;
};
```
```
uuid an array of 16 bytes with no length prefix, equivalent to
byte[16]
```
#### 8.13.6 Message Format

All messages in the EdgeDB wire protocol have the following format:

struct {
uint8 message_type;
int32 payload_length;
uint8 payload[payload_length - 4];
};

The server and the client _MUST_ not fragment messages. I.e the complete message must be sent before starting a new
message. It’s advised that whole message should be buffered before initiating a network call (but this requirement is
neither observable nor enforceable at the other side). It’s also common to buffer the whole message on the receiver side
before starting to process it.

**8.13. Binary protocol 757**


#### 8.13.7 Errors

At any point the server may send an _ErrorResponse_ indicating an error condition. This is implied in the message flow
documentation, and only successful paths are explicitly documented. The handling of theErrorResponsemessage
depends on the connection phase, as well as the severity of the error.

If the server is not able to recover from an error, the connection is closed immediately after anErrorResponsemessage
is sent.

#### 8.13.8 Logs

Similarly toErrorResponsethe server may send a _LogMessage_ message. The client should handle the message and
continue as before.

#### 8.13.9 Message Flow

There are two main phases in the lifetime of an EdgeDB connection: the connection phase, and the command phase.
The connection phase is responsible for negotiating the protocol and connection parameters, including authentication.
The command phase is the regular operation phase where the server is processing queries sent by the client.

**8.13.9.1 Connection Phase**

To begin a session, a client opens a connection to the server, and sends the _ClientHandshake_. The server responds in
one of three ways:

1. One of the authentication messages (see _below_ );
2. _ServerHandshake_ followed by one of the authentication messages;
3. _ErrorResponse_ which indicates an invalid client handshake message.

_ServerHandshake_ is only sent if the requested connection parameters cannot be fully satisfied; the server responds to
offer the protocol parameters it is willing to support. Client may proceed by noting lower protocol version and/or absent
extensions. Client _MUST_ close the connection if protocol version is unsupported. Server _MUST_ send subset of the
extensions received in _ClientHandshake_ (i.e. it never adds extra ones).

While it’s not required by the protocol specification itself, EdgeDB server currently requires setting the following
params in _ClientHandshake_ :

- user– username for authentication
- database– database to connect to

**8.13.9.2 Authentication**

The server then initiates the authentication cycle by sending an authentication request message, to which the client must
respond with an appropriate authentication response message.

The following messages are sent by the server in the authentication cycle:

**_AuthenticationOK_** Authentication is successful.

**_AuthenticationSASL_** The client must now initiate a SASL negotiation, using one of the SASL mechanisms listed in the
message. The client will send an _AuthenticationSASLInitialResponse_ with the name of the selected mechanism,
and the first part of the SASL data stream in response to this. If further messages are needed, the server will
respond with _AuthenticationSASLContinue_.

**758 Chapter 8. Reference**


**_AuthenticationSASLContinue_** This message contains challenge data from the previous step of SASL negotiation ( _Au-
thenticationSASL_ , or a previous _AuthenticationSASLContinue_ ). The client must respond with an _Authentication-
SASLResponse_ message.

**_AuthenticationSASLFinal_** SASL authentication has completed with additional mechanism-specific data for the client.
The server will next send _AuthenticationOK_ to indicate successful authentication, or an _ErrorResponse_ to indicate
failure. This message is sent only if the SASL mechanism specifies additional data to be sent from server to client
at completion.

If the frontend does not support the authentication method requested by the server, then it should immediately close
the connection.

Once the server has confirmed successful authentication with _AuthenticationOK_ , it then sends one or more of the
following messages:

**_ServerKeyData_** This message provides per-connection secret-key data that the client must save if it wants to be able to
issue certain requests later. The client should not respond to this message.

**_ParameterStatus_** This message informs the frontend about the setting of certain server parameters. The client can
ignore this message, or record the settings for its future use. The client should not respond to this message.

The connection phase ends when the server sends the first _ReadyForCommand_ message, indicating the start of a com-
mand cycle.

**8.13.9.3 Command Phase**

In the command phase, the server expects the client to send one of the following messages:

**_Parse_** Instructs the server to parse the provided command or commands for execution. The server responds with a
_CommandDataDescription_ containing the _type descriptor_ data necessary to perform data I/O for this command.

**_Execute_** Execute the provided command or commands. This message expects the client to declare a correct _type
descriptor_ identifier for command arguments. If the declared input type descriptor does not match the expected
value, a _CommandDataDescription_ message is returned followed by aParameterTypeMismatchErrorin an
ErrorResponsemessage.
If the declared output type descriptor does not match, the server will send a _CommandDataDescription_ prior to
sending any _Data_ messages.

The client could attach state data in both messages. When doing so, the client must also set a correct _type descriptor_
identifier for the state data. If the declared state type descriptor does not match the expected value, a _StateDataDescrip-
tion_ message is returned followed by aStateMismatchErrorin anErrorResponsemessage. However, the special
type id of zero00000000-0000-0000-0000-000000000000for empty/default state is always a match.

Each of the messages could contain one or more EdgeQL commands separated by a semicolon (;). If more than one
EdgeQL command is found in a single message, the server will treat the commands as an EdgeQL script. EdgeQL
scripts are always atomic, they will be executed in an implicit transaction block if no explicit transaction is currently
active. Therefore, EdgeQL scripts have limitations on the kinds of EdgeQL commands they can contain:

- Transaction control commands are not allowed, likestart transaction,commit,declare savepoint, or
    rollback to savepoint.
- Non-transactional commands, likecreate databaseorconfigure instanceare not allowed.

In the command phase, the server can be in one of the three main states:

- _idle_ : server is waiting for a command;
- _busy_ : server is executing a command;
- _error_ : server encountered an error and is discarding incoming messages.

**8.13. Binary protocol 759**


Whenever a server switches to the _idle_ state, it sends a _ReadyForCommand_ message.

Whenever a server encounters an error, it sends an _ErrorResponse_ message and switches into the _error_ state.

To switch a server from the _error_ state into the _idle_ state, a _Sync_ message must be sent by the client.

**8.13.9.4 Dump Database Flow**

Backup flow goes as following:

1. Client sends _Dump_ message
2. Server sends _Dump Header_ message
3. Server sends one or more _Dump Block_ messages
4. Server sends _CommandComplete_ message

Usually client should send _Sync_ afterDumpmessage to finish implicit transaction.

**8.13.9.5 Restore Database Flow**

Restore procedure fills up the database the client is connected to with the schema and data from the dump file.

Flow is the following:

1. Client sends _Restore_ message with the dump header block
2. Server sends _RestoreReady_ message as a confirmation that it has accepted the header, restored schema and ready
    to receive data blocks
3. Clients sends one or more _RestoreBlock_ messages
4. Client sends _RestoreEof_ message
5. Server sends _CommandComplete_ message

Note: _ErrorResponse_ may be sent from the server at any time. In case of error, _Sync_ must be sent and all subsequent
messages ignored until _ReadyForCommand_ is received.

Restore protocol doesn’t require a _Sync_ message except for error cases.

#### 8.13.10 Termination

The normal termination procedure is that the client sends a _Terminate_ message and immediately closes the connection.
On receipt of this message, the server cleans up the connection resources and closes the connection.

In some cases the server might disconnect without a client request to do so. In such cases the server will attempt to
send an _ErrorResponse_ or a _LogMessage_ message to indicate the reason for the disconnection.

**760 Chapter 8. Reference**


### 8.14 Client Libraries

EdgeDB client libraries are a bit higher level than usual database bindings. In particular, they contain:

- Structured data retrieval
- Connection pooling
- Retrying of failed transactions and queries

Additionally, client libraries might provide:

- Code generation for type-safe database access
- Query builder

This is a **work-in-progress** reference for writing client libraries for EdgeDB.

External Links:

- _Official Client Libraries_
- _Binary protocol_
- RFC 1004 - Robust Client API

Contents:

#### 8.14.1 Date/Time Handling

EdgeDB has 6 types related to date and time handling:

- datetime( _binary format_ )
- duration( _binary format_ )
- cal::local_datetime( _binary format_ )
- cal::local_date( _binary format_ )
- cal::relative_duration( _binary format_ )
- cal::date_duration( _binary format_ )

Usually we try to map those types to the respective language-native types, with the following caveats:

- The type in standard library
- It has enough range (EdgeDB has timestamps from year 1 to 9999)
- And it has good enough precision (at least microseconds)

If any of the above criteria is not met, we usually provide a custom type in the client library itself that can be converted
to a type from the language’s standard library or from a popular third-party library. Exception: The JavaScriptDate
type (which is actually a timestamp) has millisecond precision. We decided it would be better to use that type by default
even though it doesn’t have sufficient precision.

**8.14. Client Libraries 761**


**8.14.1.1 Precision**

datetime,duration,cal::local_datetimeandcal::relative_durationall have precision of **1 millisecond**.

This means that if language-native type have a bigger precision such as nanosecond, client library has to round that
timestamp when encoding it for EdgeDB.

We use **rouding to the nearest even** for that operation. Here are some examples of timetamps with high precision, and
how they are stored in the database:

2022-02-24T05:43:03.123456789Z→2022-02-24T05:43:03.123457Z

2022-02-24T05:43:03.000002345Z→2022-02-24T05:43:03.000002Z
2022-02-24T05:43:03.000002500Z→2022-02-24T05:43:03.000002Z
2022-02-24T05:43:03.000002501Z→2022-02-24T05:43:03.000003Z
2022-02-24T05:43:03.000002499Z→2022-02-24T05:43:03.000002Z

2022-02-24T05:43:03.000001234Z→2022-02-24T05:43:03.000001Z
2022-02-24T05:43:03.000001500Z→2022-02-24T05:43:03.000002Z
2022-02-24T05:43:03.000001501Z→2022-02-24T05:43:03.000002Z
2022-02-24T05:43:03.000001499Z→2022-02-24T05:43:03.000001Z

**Note:** A quick refresher on rounding types: If we perform multiple operations of summing while rounding half-up
or rounding half-down, the error margin of the resulting value tends to increase. If we round half-to-even instead, the
expected value of summing tends to be more accurate.

Note as described in _datetime protocol documentation_ the value is encoded as a _signed_ microseconds delta since a fixed
time. Some care must be taken when rounding negative microsecond values. See tests for Rust implementation for a
good set of test cases.

Rounding to the nearest even applies to all operations that client libraries perform, in particular:

1. Encoding timestamps _and_ time deltas (see the _list of types_ ) to the binary format if precision of the native type is
    higher than microseconds.
2. Decoding timestamps _and_ time deltas from the binary format is precision of native type is lower than microsec-
    onds (applies for JavaScript for example)
3. Converting from EdgeDB specific type (if there is one) to native type and back (depending on the difference in
    precision)
4. Parsing a string to an EdgeDB specific type (this operation is optional to implement, but if it is implemented, it
    must obey the rules)

### 8.15 Administration

Administrative commands for managing EdgeDB:

- _configure_
    Configure server behavior.
- _database_
    Create or remove a database.

**762 Chapter 8. Reference**


- _role_
    Create, remove or alter a role.

#### 8.15.1 Configure

```
eql-statement
```
configure– change a server configuration parameter

configure{session| current database|instance}
set<parameter> := <value> ;
configure instance insert<parameter-class> <insert-shape> ;
configure{session| current database|instance} reset<parameter> ;
configure{current database| instance}
reset<parameter-class> [ filter <filter-expr> ] ;

**8.15.1.1 Description**

This command allows altering the server configuration.

The effects ofconfigure sessionlast until the end of the current session. Some configuration parameters cannot
be modified byconfigure sessionand can only be set byconfigure instance.

configure current databaseis used to configure an individual EdgeDB database within a server instance with
the changes persisted across server restarts.

configure instanceis used to configure the entire EdgeDB instance with the changes persisted across server
restarts. This variant acts directly on the file system and cannot be rolled back, so it cannot be used in a transaction
block.

Theconfigure instance insertvariant is used for composite configuration parameters, such asAuth.

**8.15.1.2 Parameters**

<parameter>The name of a primitive configuration parameter. Available configuration parameters are described in
the _Config_ section.

<parameter-class>The name of a composite configuration value class. Available configuration classes are de-
scribed in the _Config_ section.

<filter-expr>An expression that returns a value of typestd::bool. Only configuration objects matching this
condition will be affected.

**8.15.1.3 Examples**

Set thelisten_addressesparameter:

configure instance setlisten_addresses := {'127.0.0.1','::1'};

Set thequery_work_memparameter for the duration of the session:

configure session setquery_work_mem := <cfg::memory>'4MiB';

Set the same parameter, but for the current database:

**8.15. Administration 763**


configure current database setquery_work_mem := <cfg::memory>'4MiB';

Add a Trust authentication method for “my_user”:

configure instance insertAuth {
priority := 1,
method := (insert Trust),
user :='my_user'
};

Remove all Trust authentication methods:

configure instance resetAuthfilter Auth.methodis Trust;

#### 8.15.2 Database

```
edb-alt-title Databases
```
This section describes the administrative commands pertaining to _databases_.

**8.15.2.1 Create database**

```
eql-statement
```
Create a new database.

create database <name> ;

**8.15.2.1.1 Description**

The commandcreate databasecreates a new EdgeDB database.

The new database will be created with all standard schemas prepopulated.

**8.15.2.1.2 Examples**

Create a new database:

create database appdb;

**8.15.2.2 Drop database**

```
eql-statement
```
Remove a database.

drop database<name> ;

**764 Chapter 8. Reference**


**8.15.2.2.1 Description**

The commanddrop databaseremoves an existing database. It cannot be executed while there are existing connec-
tions to the target database.

```
Warning: Executingdrop databaseremoves data permanently and cannot be undone.
```
**8.15.2.2.2 Examples**

Remove a database:

drop databaseappdb;

#### 8.15.3 Role

```
edb-alt-title Roles
```
This section describes the administrative commands pertaining to _roles_.

**8.15.3.1 Create role**

```
eql-statement
```
Create a role.

create superuser role<name> [extending<base> [, ...] ]
"{" <subcommand>; [...] "}" ;

# where <subcommand> is one of

```
setpassword := <password>
```
**8.15.3.1.1 Description**

The commandcreate roledefines a new database role.

superuserIf specified, the created role will have the _superuser_ status, and will be exempt from all permission checks.
Currently, thesuperuserqualifier is mandatory, i.e. it is not possible to create non-superuser roles for now.

<name>The name of the role to create.

extending <base> [, ...]If specified, declares the parent roles for this role. The role inherits all the privileges
of the parents.

The following subcommands are allowed in thecreate roleblock:

set password := <password>Set the password for the role.

**8.15. Administration 765**


**8.15.3.1.2 Examples**

Create a new role:

create rolealice {
setpassword :='wonderland';
};

**8.15.3.2 Alter role**

```
eql-statement
```
Alter an existing role.

alter role <name> "{" <subcommand>; [...] "}" ;

# where <subcommand> is one of

```
rename to <newname>
setpassword := <password>
extending ...
```
**8.15.3.2.1 Description**

The commandalter rolechanges the settings of an existing role.

<name>The name of the role to alter.

The following subcommands are allowed in thealter roleblock:

rename to <newname>Change the name of the role to _newname_.

extending ...Alter the role parent list. The full syntax of this subcommand is:

```
extending<name> [, ...]
[first| last| before<parent> | after<parent> ]
```
```
This subcommand makes the role a child of the specified list of parent roles. The role inherits all the privileges
of the parents.
It is possible to specify the position in the parent list using the following optional keywords:
```
- first– insert parent(s) at the beginning of the parent list,
- last– insert parent(s) at the end of the parent list,
- before <parent>– insert parent(s) before an existing _parent_ ,
- after <parent>– insert parent(s) after an existing _parent_.

**766 Chapter 8. Reference**


**8.15.3.2.2 Examples**

Alter a role:

alter role alice {
setpassword :='new password';
};

**8.15.3.3 Drop role**

```
eql-statement
```
Remove a role.

drop role<name> ;

**8.15.3.3.1 Description**

The commanddrop roleremoves an existing role.

**8.15.3.3.2 Examples**

Remove a role:

drop rolealice;

This section contains comprehensive reference documentation on the internals of EdgeDB, the binary protocol, the
formal syntax of EdgeQL, and more.

**8.15. Administration 767**


**768 Chapter 8. Reference**


```
CHAPTER
```
### NINE

### CHANGELOG

Changes introduced in all of the releases of EdgeDB so far:

### 9.1 v1.0

```
edb-alt-title EdgeDB v1 (Nova)
```
EdgeDB 1.0 was released on February 10, 2022. Read the announcement blog post here.

We would like to thank our community for reporting issues and contributing fixes. You are awesome!

#### 9.1.1 1.4

- Avoid unnecessary updates to parent views and triggers (#3771)
- Drop broken special case for nested insertFOR(#3797)
- FixIN array_unpackfor bigints (#3820)
- Put more parens around index expressions in generated DDL (#3822)
- Fix a weird computable/alias interaction (#3828)
- Support linkprops on backlinks (#3841)
- Fix generation of dummy_pathid in nonconflict ctes (#3848)

```
769
```

- Always correctly handle variadic arguments when producing AST from migrations (#3855)

#### 9.1.2 1.3

- Fix a multiplicity computation bug for tuples (#3632`)
- Fix a multiplicity issue with doubly nested loops (#3636)
- Fix a bug involving computable shadowing (#3652)
- Make replace_prefix change PointerRefs to make types line up (#3642)
- Search the source_rvar for materialized refs (#3657)
- Fix min/max when no source aspect is present (#3664)
- Don’t create UnionTypeShell for views of unions (#3670)
- Fix a collection of json casting bugs (#3676)
- ha/stolon: Don’t attempt to parse unsuccessful Consul responses (#3698)
- ha/stolon: Add exponential backoff on unsuccessful Consul KV responses (#3699)
- Make sure the sets in conflict clauses are have correct scope (#3686)
- Produce an error instead of malformed SQL oninsert foo { name }(#3687)
- Don’t treat everything with a binding as STABLE (#3689)
- Check that index expressions are immutable (#3690)
- Fix fetching computed propery of UNION of same type (#3691)
- Fix references to__subject__in object constraints (#3695)
- Fix unions of DML overlays on reverse inline pointers (#3694)
- Fix some inheritance issues with renames and expr refs (#3696)
- Fix a card inference bug when dealing with computables (#3628)
- Fix a collection of nested shape path reference issues (#3700)
- Produce a proper error ondescribeof nonexisting function, module (#3701)
- Pin the version of edgedb-cli that we use (#3705)
- Fix[NOT] IN array_unpack(foo)when foo is empty (#3752)
- InjectSYNCbetween state restore &START TRANSACTIONin [execute] flow. (#3749`)
- Fail if local Postgres cluster fails to start

#### 9.1.3 1.2

- Add on-demand compiler pool scaling (#3550).
    Use--compiler-pool-mode=on_demandto switch to the new mode, which will a spawn new compiler worker
    process every 3 seconds if the compiling requests keep queueing up. The upper limit on the number of these
    spawned processes is the number of CPUs. After 60 seconds without compiling requests, the compiler pool will
    scale down to--compiler-pool-sizewith a default of 1 under on-demand mode.
- Fix an issue with default module and module aliases inside transactions (#3604).
- Addreset on target deleteto _DDL_ in order to fix some migration bugs concerning links (#3611).

**770 Chapter 9. Changelog**


- Enforce newly createdexclusiveconstraints across existing data (#3613).
- Fix an issue with a self-referencingupdate(#3605).
- Fix an issue with a constraint bug inupdate(#3603).
- Fix a constraint bug inupdate(#3603).
- Fix an SDL issue with computed links referencing each other (#3499).
- Fix self-referencing nested mutations in GraphQL (#3470).
- Fix GraphQL fragments for types (#3514).
- Addinoperator to GraphQL (#3443).
- Fix cardinality inference in some special cases (#3590).
- Fix inheritance from enum types (#3578).
- Fix cardinality inference bug and extend cardinality restrictions to longer paths (#3566).
    Specifically, correctly infer that filtering on a long path where each hop isexclusiveproduces at most one
    result.
    For example:select Foo filter .bar.baz = 'key'should have cardinality of at most one if bothbar
    andbazhaveexclusiveconstraints.
- Fix issues involving scalar set identity (#3525).
- Fix exclusive constraints on tuple properties (#3559).

#### 9.1.4 1.1

- Fix a migration issue with handlingdefaulton inherited _links_ or _properties_ (#3544).
- Fix a migration issue with an inherited _property_ (#3542).
- Fix a migration issue with dropping a type (#3521).
- Fix a migration issue with changing a _link_ fromsingletomulti(#3392).
- Provide a more detailed message for _constraints_ errors (#3522).
- Produce an error on an invalid regex (#3412).
- Produce a proper error when an expression is invalid in a certain special contexts, such asdefault(#3494).
- Format the database name correctly inDuplicateDatabaseDefinitionError(#3228)
- Fix an error when working with a compositeexclusiveconstraint (#3502).
- Correctly infer cardinality of a property on a multi link in the context of the _constraint_ on that link (#3536).
- Disable changing the concrete base of a _scalar type_ (#3529).
- Avoid generating pointless self joins (#2567).
- Fix IPv6 address parsing (#3454).
- If a type has object instances, it cannot be madeabstract(#3399).
- Fix an issue that sometimes causedwithblock variables to be unusable (#3385).

**9.1. v1.0 771**


#### 9.1.5 Pre-releases

EdgeDB 1.0 had a series of pre-preleases. Read the full history here:

Alpha 2, alpha 3, alpha 4, alpha 5, alpha 6, alpha 7, beta 1, beta 2, beta 3, RC 1, RC 2, RC 3, RC 4, RC 5.

### 9.2 v2.0

```
edb-alt-title EdgeDB v2 (Sagittarius)
```
EdgeDB 2.0 was released on July 28th, 2022. Read the announcement blog post here.

We would like to thank our community for reporting issues and contributing fixes. You are awesome!

To play with the new features, install the CLI and initialize a new project. For an interesting schema with test data,
check out the MCU Sandbox repo.

$ edgedb project init

#### 9.2.1 Upgrading

**Local instances**

To upgrade a local project, run the following command inside the project directory.

$ edgedb project upgrade --to-latest

Alternatively, specify an instance name if you aren’t using a project.

$ edgedb project upgrade --to-latest -I my_instance

**Hosted instances**

To upgrade a remote (hosted) instance, we recommend the following dump-and-restore process.

1. Spin up an empty 2.0 instance by following one of our _deployment guides_. These guides have been updated to 2.0.
Keep the DSN of the newly created instance handy.

**772 Chapter 9. Changelog**


2. Take your application offline, then dump your v1.x database with the CLI

```
$ edgedb dump --dsn <old dsn> --all my_database.dump/
```
```
This will dump the schema and contents of your current database to a file on your local disk calledmy_database.
dump. The file name isn’t important.
```
3. Restore the empty v2.x instance from the dump

```
$ edgedb restore --all my_database.dump/ --dsn <new dsn>
```
```
Once the restore is complete, update your application to connect to the new instance.
```
This process will involve some downtime, specifically during steps 2 and 3. We are working on an in-place upgrade
workflow that will reduce the amount of downtime involved and avoid the need to spin up a new instance. We’ll publish
that soon; join the Discord for updates. Though for most applications the dump-and-restore workflow will be simpler
and less error-prone.

**9.2.1.1 Client libraries**

We’ve released new versions of our JavaScript and Python client libraries that support all 2.0 features and implement the
updated protocol. These versions are backwards compatible with v1.x instances, so we encourage all users to upgrade.

```
TypeScript/JS edgedb@0.21.0
Python edgedb@0.24.0
Golang edgedb@0.12.0
Rust edgedb-tokio@0.3.0
.NET (community-maintained) EdgeDB.Net.Driver@0.3.0
Elixir (community-maintained) edgedb@0.4.0
```
#### 9.2.2 New features

**9.2.2.1 Integrated admin UI**

All v2 instances ship with a built-in rich admin GUI. Access it by runningedgedb uiinside any _EdgeDB project_ , or
specify a local instance name withedgedb ui -I my_inst. The command opens the instance’s admin UI using the
default system browser.

The current iteration of the GUI has

- a data browser and editor
- a REPL for writing and executing EdgeQL queries
- a schema introspection tool with text-based and graphical visualizations of the instance’s current schema

**9.2. v2.0 773**


**9.2.2.2 Analytical queries with** GROUP

The new _GROUP_ expression can be used to partition and aggregate data. The output ofGROUPare _free objects_ repre-
senting each group, including the grouping, the grouping _key_ , and the set of elements.

db>groupMovie { title } by .release_year;
{
{
key: {release_year: 2017},
grouping: {'release_year'},
elements: {
default::Movie {title: 'Guardians of the Galaxy Vol. 2'},
default::Movie {title: 'Spider-Man: Homecoming'},
default::Movie {title: 'Thor: Ragnarok'},
},
},
{
key: {release_year: 2013},
grouping: {'release_year'},
elements: {
default::Movie {title: 'Iron Man 3'},
default::Movie {title: 'Thor: The Dark World'},
},
},
...
}

Browse the _docs_ for more details and examples, or refer to the original RFC 1009.

**774 Chapter 9. Changelog**


**9.2.2.3 Global variables**

Your schema can now contain _global variables_. These are contextual variables that are provided by the client and can
be referenced in your queries and schema.

global current_user -> uuid;

select Userfilter.id = globalcurrent_user;

Client libraries have been updated to provide method for attaching global variables to aClientinstance; these values
are sent along with all queries originating from thatClient.

```
Listing 1: typescript
```
import {createClient}from'edgedb';

constclient = createClient().withGlobals({
current_user: '2141a5b4-5634-4ccc-b835-437863534c51',
});

awaitclient.query(`select global current_user;`);

```
Listing 2: python
```
from edgedb import create_client

client = create_client().with_globals({
'current_user': '580cc652-8ab8-4a20-8db9-4c79a4b1fd81'
})

result = client.query("""
select global current_user;
""")

```
Listing 3: go
```
packagemain

import (
"context"
"fmt"
"log"

"github.com/edgedb/edgedb-go"
)

funcmain() {
ctx := context.Background()
client, err := edgedb.CreateClient(ctx, edgedb.Options{})
if err != nil{
log.Fatal(err)
}
defer client.Close()
(continues on next page)

**9.2. v2.0 775**


```
(continued from previous page)
```
```
id, err := edgedb.ParseUUID("2141a5b4-5634-4ccc-b835-437863534c51")
if err != nil{
log.Fatal(err)
}
```
```
varresult edgedb.UUID
err = client.
WithGlobals(map[string]interface{}{"current_user": id}).
QuerySingle(ctx, "SELECT global current_user;", &result)
if err != nil{
log.Fatal(err)
}
```
fmt.Println(result)
}

Globals are primarily intended as an enabling mechanism for object-level security.

**9.2.2.4 Object-level security**

Object types can now be augmented with object-level access policies. When combined with global variables, access
policies can be used to push authorization logic into the database.

global current_user -> uuid;

typeUser {
required property email -> str {constraint exclusive; };
}

typeBlogPost {
required property title -> str;
link author -> User;
access policy own_postsallow all using (
.author.id ?=global current_user
)
}

Refer to _the docs_ or RFC 1011 for full details.

**9.2.2.5 Range types**

EdgeDB now supports _range types_ representing intervals of values.

db>select range(1, 10);
{range(1, 10, inc_lower :=true, inc_upper := false)}
db>select range_unpack(range(1, 10))
{1, 2, 3, 4, 5, 6, 7, 8, 9}

**776 Chapter 9. Changelog**


**9.2.2.6 The** cal::date_duration **type**

This release also introduces a new datatypecal::date_durationto represent a span of _months/days_. It is nearly
equivalent to the existingcal::relative_durationbut cannot represent sub-day durations.

This type is primarily intended to simplifycal::local_datelogic.

db> select <cal::local_date>'2022-06-25'+
... <cal::date_duration>'5 days';
{<cal::local_date>'2022-06-30'}
db> select <cal::local_date>'2022-06-30'-
... <cal::local_date>'2022-06-25';
{<cal::date_duration>'P5D'}

**9.2.2.7 Source deletion policies**

Add deletion cascade functionality withon source delete.

typeBlogPost {
property title -> str;
}

typePerson {
multi link posts -> BlogPost {
on source delete delete target;
}
}

Under this policy, deleting aUserwill unconditionally delete itspostsas well.

To avoid deleting aPostthat is linked to by other schema entities, appendif orphan.

```
type Person {
multi link posts -> BlogPost {
```
- on source delete delete target;
+ on source delete delete target if orphan;
    }
}

#### 9.2.3 Additional changes

**9.2.3.1 EdgeQL**

- Support additional operations on local date and time types, including duration_get(),
    cal::duration_normalize_hours(), andcal::duration_normalize_days(). Per RFC 1013.
- Support user-provided values for theidproperty when inserting objects (#3895). This can be useful when
    migrating data from an existing database.

```
insert User {
id := <uuid>"5abf67cc-9f9f-4bbc-b009-d117d463a12e",
email := "jayz@example.com"
}
```
**9.2. v2.0 777**


- Support partial constraints and indexes (#3949, _docs_ ).
- Add the newjson_set()function (#4118).

**9.2.3.2 Server**

- Support socket activation to reduce memory footprint on developer machines (#3899).
- Introduce edgedb+http, a which tunnels the binary protocol over HTTP using JWT for authentication (#3979).
- Support using JWT to authenticate to local instances (#3991).

**9.2.3.3 Bug fixes**

- Generate uniqueidfields for each free shape object, and don’t use an actual in-database object to represent it,
    and make multiplicity inference understand free shapes better (#3631, #3633, #3634).
- Fail if local Postgres cluster fails to start.
- Addcfg::memoryto base types descriptor IDs table (#3882).
- Fix a cross-type exclusive constraint bug that could allow exclusive constraints to be violated in some complex
    type hierarchies (#3887).
- Fix issue where server might attempt to acquire one more connection than it is configured to permit (#3901).
- Fix use ofassert_existson properties that are being directly output (#3911).
- Fix a scope leakage that could cause a link referenced inside a computable to improperly correlate with something
    outside the computable (#3912).
- Fix a number of issues with the floordiv (//) and modulus (%) operators where we could return incorrect values
    or produce spurious errors, especially on very large values (#3909).
- Allow adding annotations toabstract annotationdefinitions (#3929).
- Exposebodyandlanguagefields onschema::Function(#3944).
- Make indexes extend fromschema::InheritingObject(#3942).
- Fix some mis-compilations of nested shapes inside calls to functions likeassert_single(#3927).
- FixSET TYPEon properties with default values (#3954).
- Fixdescribe/populate/describesequence (#3959).
- Upgrade many casts and functions from “Stable” to “Immutable” (#3975).
- Fix link properties in type filtered shape links (#3987).
- Allow DML statements in free shapes (#4002).
- Allow customizing assertion messages inassert_existsand friends (#4019).

**778 Chapter 9. Changelog**


**9.2.3.4 Protocol overhaul**

- A new version of the protocol—version 1.0—has been introduced. It eliminates all server state associated with
    connections that do not use transactions.
- Support passing parameters to and returning values from multi-statement scripts.

#### 9.2.4 2.1

- Fix global defaults with nontrivial computation (#4182)
- Fix migration that removes policy using clause (#4183)
- Support ELSE-less UNLESS CONFLICT on explicit id INSERT (#4185)
- Don’t create constraints on derived views when adding a pointer to a type (#4187)
- Fix a bunch of missing source contexts in declarative (#4188)
- Fix an ISE when a computed link is directly a property reference (#4193)
- Fix an ISE when using an empty shape in some contexts (#4194)
- Fix a number of error messages involving collection types in schemas (#4195)
- Avoid doing semi-joins after a sequence of single links (#4196)
- Make range() properly strict in its non-optional arguments (#4207)
- Allow multiple FDs per socket in activation (#4189)
- Add SCRAM authentication over HTTP (#4197)
- Always arm auto-shutdown timer when it’s greater than zero (#4214)
- Fix json -> array<json> cast of ‘[]’ (#4217)

#### 9.2.5 2.2

- Support UNLESS CONFLICT ON for pointers with DML in them (#4357)
- Fix cardinality in CommandDataDescription (#4347)
- Prevent access rule hidden ids from leaking when accessed directly (#4339)
- Better messages for required links hidden by policies (#4338)
- Fix access policies on DELETE of a UNION type (#4337)
- Strip out all views from DML subjects when computing what tables to use (#4336, #4333)
- Fix interaction between access policies and omitted fields in insert (#4332, #4219)
- Fix a tracer issue with reverse links and IS (#4331)
- Don’t include union types in link triggers (#4329, #4320)
    If you encounter this issue, after upgrading to a version with this patch, it can be fixed by doing a dump/restore
    or by adding a new link to the affected type.
- Require ON for constraints on objects (#4324, #4268)
- Fix interaction between DETACHED and aliases/globals (#4321, #4258)
- Disable access policy rewrite when compiling constraints (#4248, #4245)

**9.2. v2.0 779**


- Expose--admin-uias an environment variable and document it (#4255)
- PreventHttpProtocol.closefrom crashing on closed client connection (#4238)
- Fix permitted JSON null in nested array cast (#4221)
- Fixrange_unpackboundary bug.
    Therange_unpackfunction was incorrectly excluding values close to boundary, especially when the boundary
    was not itself inclusive. (#4282)
- UI: Allow selection of read-only properties in data editor (edgedb/edgedb-ui/#65)
- UI: Hide subtype columns in data editor by default; add a toggle to show them. (edgedb/edgedb-ui/#43)
- UI: Add “create example database” to the database selection screen. (edgedb/edgedb-ui/#61)
- UI: Fix navigation from being reset on switching the UI panes. (edgedb/edgedb-ui/#61)
- UI: Fix rendering of range types. (edgedb/edgedb-ui/#61)
- UI: Fix the data editor UI to render types that have some properties or links masked by an access policy.
    (edgedb/edgedb-ui/#61)
- UI: Implement login page for remote instances. (edgedb/edgedb-ui/#40)

#### 9.2.6 2.3

- Clarify error message when UI is not enabled (#4256)
- Fix an issue with inherited computeds (#4371)
- Fix bug in diamond pattern constraint inheritance (#4379)
- When finding common parent for arrays, never use expr alias arrays (#4080)
- Properly quote numeric names when in codegen (#4344)
- Fix computed global scoping behavior (#4388)
- Fix DDL performance issues on databases with lots of data (#4401)
- Fix potentially missed constraints on DML (#4410)
- Fix slicing with an empty set (#4404)
- Fix slicing array of tuples (#4391)
- Don’t apply access policies when compiling indexes (#4420)
- Fix slicing of tuple arrays with null inputs (#4421)
- Propagate database creation and deletion events to adjacent servers (#4415)

**780 Chapter 9. Changelog**


#### 9.2.7 2.4

- Fix database initialization on hosted environments like Heroku. (#4432)
- Prevent spurious errors when using backlinks on types that have properties with the same name but different
    types (#4443)
- Fix some spurious errors when removing a link from the schema. (#4451)
- For query_single, only check that the _last_ query in a script is single. (#4453)
- Catch when POPULATE MIGRATION generates incorrect DDL. This should prevent bugs where the schema
    can get into wedged states. (#4484)
- workflows: Publish multiarch Docker images (#4486)
- Make unused param insertion in the sql compiler more reliable (#4497)
- Properly propagate creation and deletion of extensions
- Fix potential exclusive constraint violations when doing an UPDATE on a union (#4507)
- Don’t lose type from inheritance views when rebasing (#4509)
- Make object type descriptor ids be derived from type name (#4503)
- Check for invalid arrays arguments at the protocol level (#4511)
- Fix SET REQUIRED on newly created properties with alias subtypes (#4513)
- Make newly created link properties get added to the relevant alias types (#4512)
- Fix handling of link properties namedid(#4514)
- Disallow queries using conflict machinery on a link property. This prevents certain potential exclusive constraint
    violations that were not handled correctly. (#4515)
- Fix performing multiple deletions at once in the UI (#4523)
- Fix casting empty sets to built in enum types (#4532)
- Produce better error messages when usingenumincorrectly (#4527)
- Make'\b'produce the correct value in string and bytes literals (#4535)

#### 9.2.8 2.5

- Properly infer cardinality of empty array as ONE (#4533)
- Fix several issues that manifest when using GROUP BY (#4549, #4439)
- Fix migration scripts when combined with access policies (#4553)
- Fix failure when aALTER ... EXTENDINGdoesn’t change the set of ancestors (#4554)
- FixUNLESS CONFLICT ONfor a not-inserted property (#4556)
- Fix access policies that use shapes internally (#4555)
- Allow overloading__type__with a computed in shapes (#4557)

**9.2. v2.0 781**


#### 9.2.9 2.6

**9.2.9.1 Nonrecursive access policies and future behaviors**

Starting with EdgeDB 3.0, access policy restrictions will **not** be applied while evaluating other access policy expres-
sions (#4574).

It is possible (and recommended) to enable this _future_ behavior in EdgeDB 2.6 by adding the following to the schema:
using future nonrecursive_access_policies;

For more details, see _the docs_.

To enable opting in to this behavior, 2.6 adds a general mechanism to opt into _future_ behavior changes (#4574, #4606).

**9.2.9.2 Other changes**

- Fix passing zero dimensional array as arguments. This was a regression introduced in 2.4, and affected passing
    empty arrays from the the Rust bindings. (#4511)
- Require that constraint expressions be immutable (#4593)
- Only permit valid UUID-generation functions to be made the default value forid(#4616)
- UI: New mechanism for copying data in REPL and in Data Editor. Hover over a data line and click the context
    “COPY” button.
- UI: “Disable Access Policies” and “Persist Query” options in REPL remember their state between page refreshes.
- UI: Basic autocomplete now works forINSERT,UPDATE, andDELETEqueries.

#### 9.2.10 2.7

- Improve error messages when compiling pointer default (#4624)
- Fix using WITH-bound DML from an UPDATE in an ELSE clause (#4641)
- Allow WITH MODULE in ddl in CREATE MIGRATION (#4668)
- Fix some broken casts from object types to JSON (#4663)
- Fix putting a statement as the body of an access policy (#4667)
- Loosen the rules on when we produce a “would change the interpretation” error. It is not only produced when a
    link is being used, not a property. (#4643)

**782 Chapter 9. Changelog**


- Fix certain errors involving default values in access policies (#4679)
- Avoid ISE when pickling DynamicRangeVar (#4681)
- Fixmax_ex_valueconstraint. (#4671)
- Fix SET GLOBAL capabilities to no longer break in the CLI. (#4688)
- Fix links to schema::ObjectType breaking DROP TYPE. If you have a link in your schema to
    schema::ObjectTypeor one of its ancestors and you encounter internal server errors when trying to drop a type,
    it should be possible to repair your database by creating and then deleting a new link toschema::ObjectType.
    (#4670)
- Don’t insert unnecessaryassert_existscalls on required links inside access policies bodies in some cases.
    (#4695)

#### 9.2.11 2.8

- Fix DML access policies that use shapes internally (#4589)
- Give a proper error message creating a migration with a USING that has DML (#4707)
- Don’t incorrectly evaluate DML access policies when elements are also DML. This fixes some cases in which
    policies would pass incorrectly. (#4745)
- Fix direct use of__subject__from insert access policies (#4752)
- Produce an error message on casts to and literal references of enum types from indexes and constraints. Currently
    we generate an internal server error. A real fix unfortunately must wait for 3.0 for technical reasons. (#4754)
- Only apply filter cardinality inference to unique sets (#4763)
- Fix changing a link to non-computed and single at the same time (#4764)
- Fix error message for function calls on derived types (#4757)
- Fix deleting certain complex aliases (#4777)
- Fix link properties on inherited backlinks (#4788)
- Fix using array/string/bytes/json subscripting inside of indexes and constraints. (#4760)
- Fix apparent startup hangs due to a lock fd leaking into postgres (#4797)
- Fix some migrations with tricky constraint/computed interactions (#4794)

#### 9.2.12 2.9

- Fix broken DROPs of pointers in some multiple-inheritance situations (#4809)
- Properly execute function calls in UPDATE once per object (#4810)
- Fix accessing tuple elements on link properties (#4811)
- Fixassert_exists()not firing on some tuple values (#4812)
- Fix GROUP on the result of enumerate (#4813)
- Support more env vars in args.py, standardize docs (#4387)
- Fix computed properties that just copy id (#4807)
- Fix backlinks on derived union types (#4818)
- Fix references to the enclosing type in schema-defined computeds (#4826)

**9.2. v2.0 783**


- UI: Fix regression introduced in 2.8 when editing empty string fields in data explorer
- UI: Improvements to handling of union link targets in schema and data explorer views
- UI: Fix loading indicators on tabs

#### 9.2.13 2.10

- Fix mismatch in session state after aROLLBACK
- Fix ISE when doing set default on an abstract pointer (#4843)
- Fix accesses to__type__from insert access policies (#4865)
- Properly forbid aggregation in index expressions (#4869)
- Fixgroupingfield when grouping by one key or nothing (#4906)
- Fix two issues with mutation in free objects (#4902)
- Only allow type names as the subject of an insert. (Previously dotted paths were allowed, with nonsensical
    behavior.) (#4922)
- Fix array arguments in HTTP interface (#4956)
- Support multi properties inUNLESS CONFLICT ON(#4955)
- Fix polymorphic type tests on result of update (#4954)
- Optimize trivialWITH-boundGROUPuses (#4978)
- Fix a category of confusing scoping related bugs in access policies (#4994)
- Get rid of the “unused alias definition” error. (#4819)
- Support mutation inUSINGexpressions when changing a link torequiredor tosingleduring a migration
    (#4873)
- Fix custom function calls on the HTTP interface (#4998)
- Avoid infinite recursion in some do-nothing intersection cases (#5007)
- Don’t mangle cast error messages when the cast value contains a type name (#5008)
- Allow JWT token auth in binary protocol (#4830)
- Use prepared statement cache in EdgeQL script execution (#4931)
- Fix non-transactional commands likeDROP DATABASEwhen using Postgres 14.7 (#5026)
- Update packaged Postgres to 14.7
- Fixset singleon required properties (#5031)
- Fix a ISE when using assert_exists and linkprops using query builder (#4961)

**784 Chapter 9. Changelog**


#### 9.2.14 2.11

- Fix adding a link property with a default value to an existing link (a regression in 2.10) (#5061)

#### 9.2.15 2.12

- Fix GROUP regression with some query-builder queries (a regression in 2.10) (#5073)

#### 9.2.16 2.13

- Implement a MIGRATION REWRITE system. This provides a mechanism for safely rewriting the migration
    history of a database while ensuring that the new history produces the same result as the old history. CLI tooling
    to take advantage of this feature is coming soon. (#4585)
- Fix DigitalOcean support: allow its custom error in bootstrap (#5139)
- Add a hint to the error message about link targets. (#5131)
- Infer cardinality ofrequired multipointers as AT_LEAST_ONE (#5180)
- Fix dump/restore of migrations with messages on them (#5171)
- Fix interaction of link properties andassert_existsand similar (#5182)
- Makeassert_singleand similar not lose track of values updated in anUPDATEin their argument. (#5088)
- Add a test for assert_exists+assert_single+UPDATE (#5242)
- Add support for new JWT layout (#5197)
- Fix uses of volatile expressions in update write access policies (#5256)
- Allow globals to be used in defaults (#5268)
- Fix errmessage interpolation to not produce an internal server error on braces in a message. Allow{{and}}to
    be used to escape braces. (#5295)

#### 9.2.17 2.14

**9.2.17.1 Schema repair on upgades**

Previously, certain bug fixes and changes (such as the fix to cardinality inferenced ofrequired multipointers re-
leased in 2.13 (#5180)), could cause schemas to enter an inconsistent state from which many migrations were not
possible.

The cause of this problem is that an incorrectly inferred value (such as the cardinality of a computed property) may
have been computed and stored in a previous version. When a newer version is used, there will be a mismatch between
the correctly inferred value on the new version, and the incorrectly stored value in the database’s schema.

The most straightforward way to fix such problems was to perform a dump and then a restore.

To fix this, we have introduced a schema repair mechanism that will run when upgrading a database to 2.14. This repair
mechanism will fix any incorrectly inferred fields that are stored in the schema.

One particular hazard in this, however, is that the repair is not easily reversible if you need to downgrade to an earlier
version. **We recommend performing a dump before upgrading to 2.14.**

These changes were made in (#5337); more discussion of the issue can be found in (#5321).

**9.2. v2.0 785**


**9.2.17.2 Other changes**

- Correctly display constraint errors onid(#5344)
- Fix adding certain computed links to a type with an alias (#5329)

#### 9.2.18 2.15

- In multi-server instances, properly reload schema after a restore (#5463)
- Fix several bugs synchronizing configuration state
- Fix dropping a pointer’s constraint and making it computed at the same time (#5411)
- Don’t claim that making a pointer computed is data-safe (#5412)
- Prohibit NUL character in query source (#5414)
- Fix migration that delete an link alias computed in a parent and child (#5428)
- Fix GraphQL updates for multi links. (#4260)
- Fix altering enum that is used in a tuple (#5445)
- Fix changing cardinality of properties on types used in unions (#5457)
- Enable GraphQL support for type unions.
- Fix making pointer non-computed and giving it an abstract base at the same time (#5458)
- Make json casts of object arrays not include extra fields (#5484)
- Make coalesce infer a union type (#5472)

### 9.3 v3.0 (dev)

```
edb-alt-title EdgeDB v3 (dev)
```
```
Warning: The latest stable EdgeDB release is 2.x. EdgeDB 3.0 stable will be released soon.
```
**786 Chapter 9. Changelog**


EdgeDB 3.0 is currently in pre-release. We would like to thank our community for reporting issues and contributing
fixes. You are awesome!

To play with the new features, install the CLI using our installation guide and initialize a new project.

$ edgedb project init --server-version=3.0-rc.1

**Note:** Good news, everyone! Upgrades across pre-release versions of 3.0 and then from pre-release 3.0 to the final
3.0 release will _not_ require a dump and restore. You can try out 3.0 with the assurance that your initial upgrade to any
3.0 pre-release version will be the last dump and restore that is required of you.

#### 9.3.1 Upgrading

**Local instances**

To upgrade a local project, first ensure that your CLI is up to date withedgedb cli upgrade. Then run an upgrade
check to make sure your schema will migrate cleanly to 3.0.

$ edgedb migration upgrade-check

**Note:** EdgeDB 3.0 fixes a bug that will cause it to care about the ordering of your ancestors in multiple inheritence.
This used to work before 3.0:

typeA;
typeB extendingA;
typeC extendingA, B;

but as of 3.0, the order of ancestors must be changed to match the order of the bases:

typeA;
typeB extendingA;
typeC extendingB, A;

This is a key instance where schemas may be incompatible with 3.0.

If the upgrade-check finds any problems, fix them in your schema and squash your migrations.

$ edgedb migration create --squash

Then run the following command inside the project directory.

$ edgedb project upgrade --to-testing

Alternatively, specify an instance name if you aren’t using a project.

$ edgedb instance upgrade --to-testing -I my_instance

**Hosted instances**

To upgrade a remote (hosted) instance, we recommend the following dump-and-restore process.

1. Spin up an empty 3.0 instance. You can use one of our _deployment guides_ , but you will need to modify some of
    the commands to use our testing channel and the beta release.

**9.3. v3.0 (dev) 787**


```
Under Debian/Ubuntu, when adding the EdgeDB package repository, use this command instead:
```
```
$ echo deb [signed-by=/usr/local/share/keyrings/edgedb-keyring.gpg] \
https://packages.edgedb.com/apt \
$(grep "VERSION_CODENAME=" /etc/os-release | cut -d= -f2) testing \
| sudo tee /etc/apt/sources.list.d/edgedb.list
```
```
Use this command for installation under Debian/Ubuntu:
```
```
$ sudo apt-get update && sudo apt-get install edgedb-3-rc1
```
```
Under CentOS/RHEL, use this installation command:
```
```
$ sudo yum install edgedb-3-rc1
```
```
In any requiredsystemctlcommands, replaceedgedb-server-2withedgedb-server-3.
Under any Docker setups, supply the3.0-rc.1tag.
```
2. Take your application offline, then dump your v2.x database with the CLI

```
$ edgedb dump --dsn <old dsn> --all --format dir my_database.dump/
```
```
This will dump the schema and contents of your current database to a directory on your local disk called
my_database.dump. The directory name isn’t important.
```
3. Restore the empty v3.x instance from the dump

```
$ edgedb restore --all my_database.dump/ --dsn <new dsn>
```
```
Once the restore is complete, update your application to connect to the new instance.
This process will involve some downtime, specifically during steps 2 and 3.
```
**Pre-1.0 Instances**

If you’re still running pre-1.0 EdgeDB instances (e.g., 1.0-beta3) and want to upgrade to 3.0, we recommend you
upgrade to version 2.x first, followed by another upgrade to 3.0, both using the same dump-and-restore process.

**9.3.1.1 Client libraries**

Many of the client libraries have gained code generation capabilities since our 2.0 release. Look for new releases of all
of our client libraries soon which will support all 3.0 features.

#### 9.3.2 New features

**9.3.2.1 Simplified SDL syntax**

As part of our commitment to delivering the best developer experience in databases, we’ve made our schema definition
language (or SDL) easier to use. You’re no longer required to use thepropertyorlinkkeywords for non-computed
properties and links. Also, we’ve replaced arrows with colons for a cleaner look that’s easier to type.

**Note:** If you prefer the arrow syntax of pre-3.0, feel free to keep using it. That syntax is still fully supported.

**788 Chapter 9. Changelog**


This change paves the way for a future syntax for declaring ad-hoc types in queries and functions. (Read more about it
in the free types RFC.)

That means that this type definition:

typeUser {
required property email -> str;
multi link friends -> User;
}

could be replaced with this equivalent one in EdgeDB 3+:

typeUser {
required email: str;
multi friends: User;
}

Selecting “v3” from the version dropdown in the sidebar will update SDL code in versioned sections of the documen-
tation to the new syntax.

**9.3.2.2 Query performance analysis**

Among other improvements, the UI now includes a visual query analyzer to help you tweak performance on your
EdgeQL queries. Just drop theanalyzekeyword in front of your query in the UI’s “Query Editor” tab to see the query
analyzer in action.

Query analysis is available in the CLI REPL by prepending your query withanalyzeor using the\analyzebackslash
command, and in the CLI directly using theedgedb analyze <query>command.

**9.3. v3.0 (dev) 789**


**9.3.2.3 UI improvements**

The EdgeDB UI got a lot of love in this release. In addition to the visual query planning shown above, you’ll see a
number of improvements.

**9.3.2.3.1 New UI for setting globals and configuration**

We’ve made it easier to set your globals and change configuration.

**9.3.2.3.2 New UI REPL**

The UI’s redesigned REPL makes it easy to drill into values and copy parts of your query results to the clipboard.

**790 Chapter 9. Changelog**


**9.3.2.3.3 Query editor and visual builder**

The query editor has a great new on-demand UI for setting parameters.

It also comes with a visual query builder which makes it easy to write queries, even when you’re just learning EdgeQL.

**9.3. v3.0 (dev) 791**


**9.3.2.4** edgedb watch **and a new development workflow**

The newedgedb watchCLI command starts a long-running process that watches for changes in schema files in your
project’sdbschemadirectory and applies those changes to your database in real time. This command opens up an
entirely new workflow for prototyping schema that will result in less migration clutter in your repositories.

**9.3.2.4.1 1. Start the** watch **command**

$ edgedb watch
Initialized. Monitoring "/projects/my-edgedb-project".

**9.3.2.4.2 2. Write an initial schema**

Just start writing your schema in yourdefault.esdlfile in your project’sdbschemadirectory. Once you save your
initial schema, assuming it is valid, thewatchcommand will pick it up and apply it to your database.

**9.3.2.4.3 3. Edit your schema files**

As your application evolves, directly edit your schema files to reflect your desired data model. When you save your
changes,watchwill immediately begin applying your new schema to the database.

Once you have the schema the way you want it, you’re ready to lock it in by generating a migration.

**9.3.2.4.4 4. Generate a migration**

To generate a migration that reflects all your changes, runedgedb migration create.

$ edgedb migration create

This “locks in” the changes you prototyped using thewatchcommand. Now, these are ready to commit and push to
your remote to share with your team.

**792 Chapter 9. Changelog**


**9.3.2.5 Triggers**

Our new triggers feature is one of the most anticipated 3.0 features! Triggers allow you to define an expression to
be executed whenever a given query type is run on an object type. The original query will _trigger_ your pre-defined
expression to run in a transaction along with the original query. These can be defined in your schema.

typePerson {
required name: str;

trigger log_insert after insert foreachdo (
insert Log {
action := 'insert',
target_name := __new__.name
}
);
}

The trigger above inserts aLogobject any time aPersonobject is inserted.

You can read more about our triggers implementation in the triggers RFC.

**9.3.2.6 Mutation rewrites**

The mutation rewrites feature is the sibling, or at least the first cousin, of triggers. Both are automatically invoked when
a write operation occurs on the type they’re on, but triggers are not able to make changes to the object that invoked
them. Mutation rewrites are built to do just that!

typePost {
required title: str;
required body: str;
modified: datetime {
rewriteinsert, update using(datetime_of_statement())
}
}

This shows one reason mutation rewrites is one of our most wanted features: modified timestamps! When
a user inserts or updates a Post, the rewrite will set the value of themodifiedproperty to that value of
datetime_of_statement(). There are tons of other uses too. Give them a try!

Learn about our mutation rewrites implementation in the mutation rewrites RFC.

**9.3.2.7 Splats**

This is one of the most fun features in 3.0, both to say _and_ to use! With splats, you can easily select all properties in
your queries without typing all of them out.

Before splats, you would have needed this query to selectMovieobjects along with all their properties:

select Movie {id, release_year, title, region, director, studio};

Now, you can simplify down to this query instead using a splat:

select Movie {*};

If you wanted to select the movie and its characters before splats, you would have needed this:

**9.3. v3.0 (dev) 793**


select Movie {
id,
release_year,
title,
region,
director: {id, name, birth_year},
actors: {id, name, birth_year},
characters: { id, name }
};

Now, you can get it done with just a double-splat to select all the object’s properties and the properties of any linked
objects nested a single layer within it.

db>select Movie {**};

It’s a super-handy way to quickly explore your data.

Read more about splats in our splats RFC.

**9.3.2.8 SQL support**

EdgeDB supports running read-only SQL queries via the Postgres protocol to enable connecting EdgeDB to existing
BI and analytics solutions. Any Postgres-compatible client can connect to your EdgeDB database by using the same
port that is used for the EdgeDB protocol and the same database name, username, and password you already use for
your database.

$ psql -h localhost -p 10701 -U edgedb -d edgedb

Our SQL support has been tested against a number of SQL tools:

- pg_dump
- Metabase
- Cluvio
- Tableau
- DataGrip
- Airbyte
- Fivetran
- Hevo
- Stitch
- dbt

**794 Chapter 9. Changelog**


**9.3.2.9 Nested modules**

You can now put a module inside another module to let you organize your schema in any way that makes sense to you.

module momma_module {
module baby_module {
# <schema-declarations>
}
}

In EdgeQL, you can reference entities inside nested modules like this:momma_module::baby_module::<entity-name>

Aside from giving you additional flexibility, it will also allow us to expand our list of standard modules in a backwards-
compatible way.

**9.3.2.10** intersect **and** except **operators**

Slice and dice your sets in new ways with theintersectandexceptoperators. Useintersectto find common
members between sets.

db>select {1, 2, 3, 4, 5} intersect {3, 4, 5, 6, 7};
{3, 5, 4}

Useexceptto find members of the first set that are not in the second.

db>select {1, 2, 3, 4, 5}except {3, 4, 5, 6, 7};
{1, 2}

These work with sets of anything, including sets of objects.

db>withbig_cities := (selectCityfilter .population > 1000000),
... s_cities := (select Cityfilter .namelike'S%')
...select (big_cities intersect s_cities) {name};
{default::City {name:'San Antonio'}, default::City {name: 'San Diego'}}
db>withbig_cities := (selectCityfilter .population > 1000000),
... s_cities := (select Cityfilter .namelike'S%')
...select (big_citiesexcept s_cities) {name};
{
default::City {name:'New York'},
default::City {name:'Los Angeles'},
default::City {name:'Chicago'},
default::City {name:'Houston'},
default::City {name:'Phoenix'},
default::City {name:'Philadelphia'},
default::City {name:'Dallas'}
}

**9.3. v3.0 (dev) 795**


**9.3.2.11** assert **function**

The newassertfunction lets you do handy things like create powerful constraints when paired with triggers:

typePerson {
required name: str;
multi friends: User;
multi enemies: User;

trigger prohibit_frenemies after insert, update foreach do(
assert(
not exists (__new__.friends intersect __new__.enemies),
message := "Invalid frenemies",
)
)
}

db>insert Person {name :='Quincey Morris'};
{default::Person {id: e4a55480-d2de-11ed-93bd-9f4224fc73af}}
db>insert Person {name :='Dracula'};
{default::Person {id: e7f2cff0-d2de-11ed-93bd-279780478afb}}
db>update User
...filter .name ='Quincey Morris'
...set{
... enemies := (select Personfilter .name ='Dracula')
... };
{default::Person {id: e4a55480-d2de-11ed-93bd-9f4224fc73af}}
db>update User
...filter .name ='Quincey Morris'
...set{
... friends := (select Personfilter .name ='Dracula')
... };
edgedb error: EdgeDBError: Invalid frenemies

You can use it in other contexts too — any time you want to throw an error when things don’t go as planned.

#### 9.3.3 Additional changes

**9.3.3.1 EdgeQL**

- Support custom user-defined error messages for access policies (#4529)

```
typeUser {
required property email -> str {constraint exclusive; };
required property is_admin -> bool {default:=false };
access policy admin_only
allow all
using(global current_user.is_admin ??false) {
errmessage := 'Only admins may query Users'
};
}
```
**796 Chapter 9. Changelog**


- Support casting a UUID to a type (#4469). This is a handy way to select an object, assuming the type you cast
    into has an object with the UUID being cast.

```
db>select<Hero><uuid>'01d9cc22-b776-11ed-8bef-73f84c7e91e7';
{default::Hero {id: 01d9cc22-b776-11ed-8bef-73f84c7e91e7}}
```
- Add thejson_object_pack()function to construct JSON from an array of key/value tuples. (#4474)

```
db>selectjson_object_pack({("hello", <json>"world")});
{Json("{\"hello\": \"world\"}")}
```
- Support tuples as query arguments (#4489)

```
select <tuple<str, bool>>$var;
select <optional tuple<str, bool>>$var;
select <tuple<name: str, flag: bool>>$var;
select <optional tuple<name: str, flag: bool>>$var;
select <array<tuple<int64, str>>>$var;
select <optional array<tuple<int64, str>>>$var;
```
- Add the syntax for abstract indexes (#4691)
    Exposes some Postgres indexes that you can use in your schemas. These are exposed through thepgmodule.
       **-** pg::hash- Index based on a 32-bit hash derived from the indexed value
       **-** pg::btree- B-tree index can be used to retrieve data in sorted order
       **-** pg::gin- GIN is an “inverted index” appropriate for data values that contain multiple elements, such as
          arrays and JSON
       **-** pg::gist- GIST index can be used to optimize searches involving ranges
       **-** pg::spgist- SP-GIST index can be used to optimize searches involving ranges and strings
       **-** pg::brin- BRIN (Block Range INdex) index works with summaries about the values stored in consecutive
          physical block ranges in the database
    Learn more about the index types we expose in the Postgres documentation.
    You can use them like this:

```
typeUser {
required property name -> str;
index pg::spgiston (.name);
};
```
- Implement migration rewrites (#4585)
- Implement schema reset (#4714)
- Support link properties on computed backlinks (#5227)

**9.3. v3.0 (dev) 797**


**9.3.3.2 CLI**

- Add theedgedb migration upgrade-checkcommand
    Checks your schema against the new EdgeDB version. You can add --to-version <version>,
    --to-testing,--to-nightly, or--to-channel <channel>to check against a specific version.
- Add the--squashoption to theedgedb migration createcommand
    This squashes all your migrations into a single migration.
- Change the backslash command\d object <name>to\d <name>
- Add theedgedb migration editcommand ( _docs_ ; released in 2.1)
- Add the--getoption to theedgedb infocommand (released in 2.1)
    Adding the--getoption followed by a name of one of the info values —config-dir,cache-dir,data-dir,
    orservice-dir— returns only the requested path. This makes scripting with theedgedb infocommand
    more convenient.

**9.3.3.3 Bug fixes**

- Fix crash on cycle between defaults in insert (#5355)
- Improvements to top-level server error reporting (#5349)
- Forbid ranges of user-defined scalars (#5345)
- Forbid DML in non-scalar function args (#5310)
- Don’t let “owned” affect how we calculate backlinks (#5306)
- Require inheritance order to be consistent with the specified base order (#5276)
- Support using non-strict functions in simple expressions (#5271)
- Don’t duplicate the computation of single links with link properties (#5264)
- Properly rebase computed links when changing their definition (#5222)
- Fix 3-way unions of certain types with policies (#5205)
- Fix simultaneous deletion of objects related by multi links (#5201)
- Respectenforce_access_policies := falseinside functions (#5199)
- Fix inferred link/property kind when extending abstract link (#5196)
- Forbidon target delete deferred restricton required links. (#5189)
- Make uuidgen properly set versions in uuid4/uuid5 (#5188)
- Disallow variadic arguments with optional types in user code. (#5110)
- Support casting between scalars with a common concrete base (#5108)
- Fix GROUP regression with some query-builder queries (#5071)
- Fix a ISE when usingassert_existsand linkprops using query builder (#5036)
- Fix bug that dropping non-existing db leaves with unaccessible state (#5032)
- Fix non-transactional errors in Postgres 14.7 (#5028)
- Properly cast to containers of enums when loading from the schema (#4988)
- Implement manual error override configuration (#4974)

**798 Chapter 9. Changelog**


- Fix protocol state confusion after rollback (#4970), (#4953)

**9.3.3.4 Deprecations**

The support of version pre-1.0 binary protocol is deprecated in EdgeDB 3.0, and will be completely dropped in EdgeDB
4.0. If you’re still using a deprecated version of the binary protocol or any client libraries that _only_ support the pre-1.0
binary protocol as listed below, please consider upgrading to a newer version.

- edgedb-js / edgedb-deno v0.20 or lower
- edgedb-python v0.23 or lower
- edgedb-go v0.10 or lower
- edgedb-tokio (Rust) v0.2 or lower
- EdgeDB.NET v0.2 or lower
- edgedb-elixir v0.3 or lower

#### 9.3.4 New release schedule

Unfortunately, the 3.0 release will not include full-text search. We have many requirements for this new API (see the
FTS RFC for details), and, while we’ve made significant progress, we have unfortunately run out of time to be 100%
sure that it is ready for prime time.

We don’t want this delay to hold back the release of EdgeDB 3.0, which includes many other exciting features that are
ready for you to start using right now. That’s why we’ve decided to delay only the FTS feature rather than delaying the
entire 3.0 release.

That said we’re working hard to get FTS ready as soon as possible. After the release of 3.0, we’ll be moving to a much
more frequent release cycle so that features like FTS can be in your hands as soon as they’re ready.

Going forward, expect EdgeDB releases every four months. These releases will naturally incorporate fewer features
than our past releases, but we think the more predictable cadence will be worth it. Every third release starting with 3.0
will be a long-term support (LTS) release. These releases will continue to receive support for a year and a half after
their initial release.

#### 9.3.5 3.0 RC 1

**9.3.5.1 Changes to new 3.0 features**

- Fix indirect references to properties in triggers (#5450)
- Fix rewrites of aliases types (#5461)
- Do nicer translation of relation names inANALYZE(#5467)
- Fix schema ordering bug whenINSERTappears in triggers (#5489)
- Produce correct error source locations in the SQL interface (#5462)
- Fix deleting a pointer with rewrites in a migration (#5503)

**9.3. v3.0 (dev) 799**


**9.3.5.2 Other changes and fixes**

- Support disabling dynamic configuration of system config (#5425)
- In multi-server instances, properly reload schema after a restore (#5463)
- Fix several bugs synchronizing configuration state
- Fix dropping a pointer’s constraint and making it computed at the same time (#5411)
- Don’t claim that making a pointer computed is data-safe (#5412)
- Prohibit NUL character in query source (#5414)
- Fix migration that delete an link alias computed in a parent and child (#5428)
- Fix GraphQL updates for multi links. (#4260)
- Fix altering enum that is used in a tuple (#5445)
- Fix changing cardinality of properties on types used in unions (#5457)
- Enable GraphQL support for type unions.
- Fix making pointer non-computed and giving it an abstract base at the same time (#5458)
- Make json casts of object arrays not include extra fields (#5484)
- Make coalesce infer a union type (#5472)
- Fix graphql queries made against a freshly started server (#5456)
- Fix version for project init (#5460)
- Produce a proper error for too many constraint args (#5454)
- Prevent using leading dot notation in inserts (#5142)
- Fix operations on single link with only computable link properties (#5499)
- Don’t ISE on free shape in insert (#5438)
- Work around postgres server crashes on Digital Ocean during edgedb setup (#5505)
- Always set cardinality of derived __tname__ and __tid__ pointers (#5508)
- Make failovers more resilient (#5511)

### 9.4 Deprecation Policy

- We continue to support one previous version of EdgeDB with critical bug fixes.
- Client bindings will support the current and the previous major version.
- CLI supports all versions from version 1.

**800 Chapter 9. Changelog**
